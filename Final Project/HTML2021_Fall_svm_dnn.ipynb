{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTML2021_Fall.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPq4TTonXy1PfuXmw82qzN9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Offliners/HTML_2021Fall/blob/main/Final%20Project/HTML2021_Fall_svm_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Directory**\n",
        "\n",
        "```\n",
        "data_dir\n",
        "    ├── data\n",
        "    │   ├── Test_IDs.csv\n",
        "    │   ├── ...\n",
        "    │   ├── status.csv\n",
        "    ├── statistics\n",
        "    │   ├── Churn Category_stat.png\n",
        "    │   ├── ...\n",
        "    │   ├── miss rate_stat.png\n",
        "```"
      ],
      "metadata": {
        "id": "PD40tT3p379e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Display information of GPU**"
      ],
      "metadata": {
        "id": "ldW8_oif3EEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf0PLuNJf95W",
        "outputId": "19a38ce7-029c-4d0d-979d-34446a5d3c50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 12 12:19:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download Dataset**"
      ],
      "metadata": {
        "id": "JxUhMWWmJPHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"./data\"\n",
        "!mkdir \"./statistics\"\n",
        "!gdown --id 1X5yz7QLAu4nttnCea4ALf6alae6Clv_o --output \"./data/dataset.zip\"\n",
        "!unzip -q \"./data/dataset.zip\" -d \"./data\"\n",
        "!rm \"./data/dataset.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjX-fvNeKG3p",
        "outputId": "1a068344-3f45-4277-95e6-af1a9f8e0af1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1X5yz7QLAu4nttnCea4ALf6alae6Clv_o\n",
            "To: /content/data/dataset.zip\n",
            "\r  0% 0.00/660k [00:00<?, ?B/s]\r100% 660k/660k [00:00<00:00, 41.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Some Packages**"
      ],
      "metadata": {
        "id": "hosMVZZWI_6B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "-lrHo2qeI-p9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set a Random Seed**"
      ],
      "metadata": {
        "id": "HH36XbKB0P3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for reproducibility\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  \n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "sM7IyXfL0ekd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CSV Files Combination**"
      ],
      "metadata": {
        "id": "Q69ecrSlJpyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = './data/Train_IDs.csv'  # path to training data\n",
        "test_path = './data/Test_IDs.csv'    # path to testing data\n",
        "\n",
        "files = glob('./data/*.csv')\n",
        "data_csv = []\n",
        "data_csv.append(train_path)\n",
        "for csv in files:\n",
        "    if ('IDs' not in csv) and ('sample' not in csv) and ('population' not in csv) and ('result' not in csv):\n",
        "        data_csv.append(csv)\n",
        "  \n",
        "print(data_csv)\n",
        "df_list = [pd.read_csv(file) for file in data_csv]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PubV0z-fNFWK",
        "outputId": "bc57f64c-63aa-430e-cab7-f57da1e0cf00"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./data/Train_IDs.csv', './data/services.csv', './data/status.csv', './data/satisfaction.csv', './data/demographics.csv', './data/location.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_total = df_list[0]\n",
        "for df in df_list[1:]:\n",
        "    result_total = pd.merge(result_total, df, how='outer', on='Customer ID')\n",
        "\n",
        "result_total.to_csv('./data/result_total.csv') # Save combined all result to result_total.csv"
      ],
      "metadata": {
        "id": "gsRnzcD243J2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 7043 total customer data\n",
        "print(result_total)"
      ],
      "metadata": {
        "id": "HmdXTPLLuLnc",
        "outputId": "765dcb75-c544-4103-a02f-8a3ab1b86fec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Count_x  ...   Latitude   Longitude\n",
            "0     0650-BWOZN      1.0  ...        NaN         NaN\n",
            "1     0562-FGDCR      1.0  ...  34.903052 -118.411251\n",
            "2     6688-UZPWD      1.0  ...  33.721917 -118.043237\n",
            "3     2905-KFQUV      1.0  ...        NaN -122.000887\n",
            "4     9720-JJJOR      1.0  ...  39.672813 -120.456699\n",
            "...          ...      ...  ...        ...         ...\n",
            "7038  6485-QXWWE      NaN  ...        NaN -118.149953\n",
            "7039  9408-SSNVZ      NaN  ...  33.818477 -118.038307\n",
            "7040  3426-NIYYL      NaN  ...        NaN         NaN\n",
            "7041  8231-BSWXX      NaN  ...  34.097863 -116.594561\n",
            "7042  4482-EWFMI      NaN  ...        NaN -120.132870\n",
            "\n",
            "[7043 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train_IDs has 5634 customer data\n",
        "result_train = df_list[0]\n",
        "for df in df_list[1:]:\n",
        "    result_train = pd.merge(result_train, df, how='left', on='Customer ID')\n",
        "\n",
        "print(result_train)"
      ],
      "metadata": {
        "id": "XC9OTia4vQyw",
        "outputId": "f67c2b28-a804-4b82-c5a8-93b033c4d21f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Count_x  ...   Latitude   Longitude\n",
            "0     0650-BWOZN      1.0  ...        NaN         NaN\n",
            "1     0562-FGDCR      1.0  ...  34.903052 -118.411251\n",
            "2     6688-UZPWD      1.0  ...  33.721917 -118.043237\n",
            "3     2905-KFQUV      1.0  ...        NaN -122.000887\n",
            "4     9720-JJJOR      1.0  ...  39.672813 -120.456699\n",
            "...          ...      ...  ...        ...         ...\n",
            "5629  1178-PZGAB      1.0  ...        NaN         NaN\n",
            "5630  4806-KEXQR      1.0  ...  37.140104 -119.657092\n",
            "5631  8809-RIHDD      1.0  ...        NaN         NaN\n",
            "5632  6663-JOCQO      1.0  ...        NaN         NaN\n",
            "5633  7010-ZMVBF      1.0  ...  36.623632 -119.741322\n",
            "\n",
            "[5634 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test_Ids has 1409 customer data\n",
        "df_test = pd.read_csv(test_path)\n",
        "result_test = df_test\n",
        "for df in df_list[1:]:\n",
        "    result_test = pd.merge(result_test, df, how='left', on='Customer ID')\n",
        "\n",
        "print(result_test)"
      ],
      "metadata": {
        "id": "fE-wQXgit9JQ",
        "outputId": "28a06f57-52e5-4a89-975a-3d40525444ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Count_x  ...   Latitude   Longitude\n",
            "0     9938-EKRGF      1.0  ...  33.141265 -116.967221\n",
            "1     7379-POKDZ      1.0  ...  34.231318 -117.662032\n",
            "2     0654-HMSHN      1.0  ...  32.802959 -117.027095\n",
            "3     2045-BMBTJ      1.0  ...        NaN         NaN\n",
            "4     0701-TJSEF      1.0  ...  33.581045 -117.147190\n",
            "...          ...      ...  ...        ...         ...\n",
            "1404  4587-VVTOX      1.0  ...  37.871416         NaN\n",
            "1405  7716-YTYHG      NaN  ...  40.448632         NaN\n",
            "1406  7649-PHJVR      NaN  ...        NaN         NaN\n",
            "1407  7855-DIWPO      1.0  ...  33.688546         NaN\n",
            "1408  8197-BFWVU      1.0  ...  33.956445 -118.358634\n",
            "\n",
            "[1409 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_total.dropna()) # Find customer with full data infomation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wbcLdCPLMBV",
        "outputId": "87150606-fe15-42aa-966c-fab293ba33f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Count_x  ...   Latitude   Longitude\n",
            "666   0454-OKRCT      1.0  ...  38.425280 -119.475741\n",
            "678   1735-XMJVH      1.0  ...  38.809175 -121.171375\n",
            "1799  1245-HARPS      1.0  ...  40.587919 -122.464732\n",
            "2805  8445-DNBAE      1.0  ...  41.212695 -122.392067\n",
            "2883  8708-XPXHZ      1.0  ...  40.342928 -124.063329\n",
            "3062  9522-ZSINC      1.0  ...  34.128284 -118.047732\n",
            "4297  0836-SEYLU      1.0  ...  36.414611 -121.638600\n",
            "5146  7274-RTAPZ      1.0  ...  36.657462 -119.595293\n",
            "\n",
            "[8 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_cols = result_total.columns\n",
        "print(result_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h42U-NQJkntr",
        "outputId": "1caf16e3-b8a4-4693-8740-7365b5fa6533"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Customer ID', 'Count_x', 'Quarter', 'Referred a Friend',\n",
            "       'Number of Referrals', 'Tenure in Months', 'Offer', 'Phone Service',\n",
            "       'Avg Monthly Long Distance Charges', 'Multiple Lines',\n",
            "       'Internet Service', 'Internet Type', 'Avg Monthly GB Download',\n",
            "       'Online Security', 'Online Backup', 'Device Protection Plan',\n",
            "       'Premium Tech Support', 'Streaming TV', 'Streaming Movies',\n",
            "       'Streaming Music', 'Unlimited Data', 'Contract', 'Paperless Billing',\n",
            "       'Payment Method', 'Monthly Charge', 'Total Charges', 'Total Refunds',\n",
            "       'Total Extra Data Charges', 'Total Long Distance Charges',\n",
            "       'Total Revenue', 'Churn Category', 'Satisfaction Score', 'Count_y',\n",
            "       'Gender', 'Age', 'Under 30', 'Senior Citizen', 'Married', 'Dependents',\n",
            "       'Number of Dependents', 'Count', 'Country', 'State', 'City', 'Zip Code',\n",
            "       'Lat Long', 'Latitude', 'Longitude'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing = result_train.isnull().sum().reset_index().rename(columns={0:'missNum'})\n",
        "missing['missRate'] = missing['missNum'] / result_train.shape[0]\n",
        "miss_analy = missing[missing.missRate > 0].sort_values(by='missRate', ascending=False)\n",
        "\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "plt.bar(np.arange(miss_analy.shape[0]), list(miss_analy.missRate.values), align='center')\n",
        "\n",
        "plt.title('Histogram of missing value of variables of training dataset')\n",
        "plt.xlabel('variables names')\n",
        "plt.ylabel('missing rate')\n",
        "plt.xticks(np.arange(miss_analy.shape[0]), list(miss_analy['index']))\n",
        "plt.xticks(rotation=90)\n",
        "for x, y in enumerate(list(miss_analy.missRate.values)):\n",
        "    plt.text(x, y + 0.12, '{:.2%}'.format(y), ha='center', rotation=90)    \n",
        "\n",
        "plt.ylim([0, 1.2])  \n",
        "plt.savefig(f'./statistics/miss rate_train_stat.png')  \n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "HDjocf2IYbFs",
        "outputId": "93b653d5-71d0-434e-8ff5-12c56edf2a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing = result_test.isnull().sum().reset_index().rename(columns={0:'missNum'})\n",
        "missing['missRate'] = missing['missNum'] / result_test.shape[0]\n",
        "miss_analy = missing[missing.missRate > 0].sort_values(by='missRate', ascending=False)\n",
        "\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "plt.bar(np.arange(miss_analy.shape[0]), list(miss_analy.missRate.values), align='center')\n",
        "\n",
        "plt.title('Histogram of missing value of variables of test dataset')\n",
        "plt.xlabel('variables names')\n",
        "plt.ylabel('missing rate')\n",
        "plt.xticks(np.arange(miss_analy.shape[0]), list(miss_analy['index']))\n",
        "plt.xticks(rotation=90)\n",
        "for x, y in enumerate(list(miss_analy.missRate.values)):\n",
        "    plt.text(x, y + 0.12, '{:.2%}'.format(y), ha='center', rotation=90)    \n",
        "\n",
        "plt.ylim([0, 1.4])  \n",
        "plt.savefig(f'./statistics/miss rate_test_stat.png')  \n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "BVN8BclJkD1J",
        "outputId": "4e6a78ec-aff2-43c8-d5e7-03f95e879d8b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Statistics and Data Preprocessing**"
      ],
      "metadata": {
        "id": "eYyJOoclqCFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_train_copy = result_train.copy(deep=True)\n",
        "result_test_copy = result_test.copy(deep=True)\n",
        "def label_statistics(label):\n",
        "    freq = result_train.groupby(label).size() \n",
        "\n",
        "    names = [name for name, _ in freq.items()]\n",
        "    counts = [count for _, count in freq.items()]\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    x = np.arange(len(names))\n",
        "    plt.bar(x, counts)\n",
        "    plt.xticks(x, names, rotation=15)\n",
        "    plt.title(f'Statistics of {label}')\n",
        "    plt.savefig(f'./statistics/Statistics of {label}.png')\n",
        "    print(f'Statistics of {label}.png saved')\n",
        "    plt.close()\n",
        "\n",
        "    # Replace NaN with random choice label with the original distribution\n",
        "    probability = [p / np.sum(counts) for p in counts]\n",
        "    result_train_copy[label] = result_train_copy[label].apply(lambda x: np.random.choice(names, p=probability) if pd.isnull(x) else x)\n",
        "    result_test_copy[label] = result_test_copy[label].apply(lambda x: np.random.choice(names, p=probability) if pd.isnull(x) else x)"
      ],
      "metadata": {
        "id": "ho-LNzp4g_Eb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "need_statistics_col = ['Churn Category', 'Satisfaction Score', \n",
        "       'Gender', 'Under 30', 'Senior Citizen', 'Married', 'Dependents',\n",
        "       'Number of Dependents', 'Country', 'State', 'City', 'Quarter',\n",
        "       'Referred a Friend', 'Number of Referrals', 'Offer',\n",
        "       'Phone Service', 'Multiple Lines', 'Internet Service', 'Internet Type',\n",
        "       'Online Security', 'Online Backup', 'Device Protection Plan',\n",
        "       'Premium Tech Support', 'Streaming TV', 'Streaming Movies',\n",
        "       'Streaming Music', 'Unlimited Data', 'Contract', 'Paperless Billing',\n",
        "       'Payment Method']\n",
        "\n",
        "# Replace NaN with the most frequent label\n",
        "for need_col in need_statistics_col:\n",
        "    label_statistics(need_col)\n",
        "\n",
        "    # Encode target labels with value\n",
        "    le = LabelEncoder()\n",
        "    result_train_copy[need_col] = le.fit_transform(result_train_copy[need_col])\n",
        "    result_test_copy[need_col] = le.fit_transform(result_test_copy[need_col])\n",
        "\n",
        "    if need_col == 'Churn Category':\n",
        "        encoder_map = dict(zip(le.classes_, le.transform(le.classes_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl4omt-mIGDW",
        "outputId": "72c64789-e2b3-4443-d112-7dab543f31e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics of Churn Category.png saved\n",
            "Statistics of Satisfaction Score.png saved\n",
            "Statistics of Gender.png saved\n",
            "Statistics of Under 30.png saved\n",
            "Statistics of Senior Citizen.png saved\n",
            "Statistics of Married.png saved\n",
            "Statistics of Dependents.png saved\n",
            "Statistics of Number of Dependents.png saved\n",
            "Statistics of Country.png saved\n",
            "Statistics of State.png saved\n",
            "Statistics of City.png saved\n",
            "Statistics of Quarter.png saved\n",
            "Statistics of Referred a Friend.png saved\n",
            "Statistics of Number of Referrals.png saved\n",
            "Statistics of Offer.png saved\n",
            "Statistics of Phone Service.png saved\n",
            "Statistics of Multiple Lines.png saved\n",
            "Statistics of Internet Service.png saved\n",
            "Statistics of Internet Type.png saved\n",
            "Statistics of Online Security.png saved\n",
            "Statistics of Online Backup.png saved\n",
            "Statistics of Device Protection Plan.png saved\n",
            "Statistics of Premium Tech Support.png saved\n",
            "Statistics of Streaming TV.png saved\n",
            "Statistics of Streaming Movies.png saved\n",
            "Statistics of Streaming Music.png saved\n",
            "Statistics of Unlimited Data.png saved\n",
            "Statistics of Contract.png saved\n",
            "Statistics of Paperless Billing.png saved\n",
            "Statistics of Payment Method.png saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "need_avg_col = [item for item in result_cols if item not in need_statistics_col]\n",
        "\n",
        "# Replace NaN with median value or 0\n",
        "for avg_col in need_avg_col[1:]:\n",
        "    if avg_col == 'Zip Code' or avg_col == 'Lat Long':\n",
        "        continue\n",
        "    elif 'Count' in avg_col:\n",
        "        result_train_copy[avg_col] = result_train_copy[avg_col].fillna(0)\n",
        "        result_test_copy[avg_col] = result_test_copy[avg_col].fillna(0)\n",
        "    else:\n",
        "        result_train_copy[avg_col] = result_train_copy[avg_col].fillna(result_train_copy[avg_col].median()) \n",
        "        result_test_copy[avg_col] = result_test_copy[avg_col].fillna(result_train_copy[avg_col].median())"
      ],
      "metadata": {
        "id": "hjvCj4CgJPoJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the correlation of columns\n",
        "cor_matrix = result_train_copy.corr().abs()\n",
        "print(cor_matrix['Churn Category'])"
      ],
      "metadata": {
        "id": "WdnuvMdMS7_L",
        "outputId": "c55a63f9-c8ed-4e49-dd2c-aef3ad867985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count_x                              0.001317\n",
            "Quarter                                   NaN\n",
            "Referred a Friend                    0.039161\n",
            "Number of Referrals                  0.081623\n",
            "Tenure in Months                     0.124967\n",
            "Offer                                0.064084\n",
            "Phone Service                        0.007903\n",
            "Avg Monthly Long Distance Charges    0.012097\n",
            "Multiple Lines                       0.025724\n",
            "Internet Service                     0.093695\n",
            "Internet Type                        0.041499\n",
            "Avg Monthly GB Download              0.040774\n",
            "Online Security                      0.057228\n",
            "Online Backup                        0.013486\n",
            "Device Protection Plan               0.003886\n",
            "Premium Tech Support                 0.065226\n",
            "Streaming TV                         0.011442\n",
            "Streaming Movies                     0.038226\n",
            "Streaming Music                      0.020193\n",
            "Unlimited Data                       0.069493\n",
            "Contract                             0.137617\n",
            "Paperless Billing                    0.078954\n",
            "Payment Method                       0.035229\n",
            "Monthly Charge                       0.092739\n",
            "Total Charges                        0.058857\n",
            "Total Refunds                        0.014575\n",
            "Total Extra Data Charges             0.015636\n",
            "Total Long Distance Charges          0.092469\n",
            "Total Revenue                        0.080331\n",
            "Churn Category                       1.000000\n",
            "Satisfaction Score                   0.254697\n",
            "Count_y                              0.040754\n",
            "Gender                               0.001889\n",
            "Age                                  0.046805\n",
            "Under 30                             0.024823\n",
            "Senior Citizen                       0.059089\n",
            "Married                              0.018871\n",
            "Dependents                           0.074275\n",
            "Number of Dependents                 0.053742\n",
            "Count                                0.024353\n",
            "Country                                   NaN\n",
            "State                                     NaN\n",
            "City                                 0.001694\n",
            "Zip Code                             0.016380\n",
            "Latitude                             0.050255\n",
            "Longitude                            0.029237\n",
            "Name: Churn Category, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dropColumns(label):\n",
        "    global result_train_copy, result_test_copy\n",
        "    result_train_copy = result_train_copy.drop(label, axis=1)\n",
        "    result_test_copy = result_test_copy.drop(label, axis=1)"
      ],
      "metadata": {
        "id": "K5quNy8vHQzb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Throw away the data columns I think is useless\n",
        "useless = ['Count_x', 'Count_y', 'Country', 'State', 'City', 'Zip Code', 'Lat Long', 'Latitude', 'Longitude', 'Count', 'Quarter']\n",
        "\n",
        "for item in useless:\n",
        "    dropColumns(item)"
      ],
      "metadata": {
        "id": "Cis3gTDOG9Im"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_train_copy.to_csv('./data/result_after_preprocessing.csv') # Save after preprocessing result to result_after_preprocessing.csv\n",
        "\n",
        "print(result_train_copy)\n",
        "print(result_test_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DsDpzq_Lgp3",
        "outputId": "acf9c604-656c-4b72-892e-b1e13b6f0207"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Referred a Friend  ...  Dependents  Number of Dependents\n",
            "0     0650-BWOZN                  0  ...           0                     0\n",
            "1     0562-FGDCR                  0  ...           0                     0\n",
            "2     6688-UZPWD                  1  ...           1                     0\n",
            "3     2905-KFQUV                  0  ...           0                     0\n",
            "4     9720-JJJOR                  1  ...           0                     0\n",
            "...          ...                ...  ...         ...                   ...\n",
            "5629  1178-PZGAB                  0  ...           0                     0\n",
            "5630  4806-KEXQR                  0  ...           0                     0\n",
            "5631  8809-RIHDD                  0  ...           1                     2\n",
            "5632  6663-JOCQO                  0  ...           1                     3\n",
            "5633  7010-ZMVBF                  1  ...           0                     0\n",
            "\n",
            "[5634 rows x 37 columns]\n",
            "     Customer ID  Referred a Friend  ...  Dependents  Number of Dependents\n",
            "0     9938-EKRGF                  1  ...           0                     0\n",
            "1     7379-POKDZ                  0  ...           0                     0\n",
            "2     0654-HMSHN                  1  ...           0                     0\n",
            "3     2045-BMBTJ                  1  ...           1                     3\n",
            "4     0701-TJSEF                  1  ...           0                     0\n",
            "...          ...                ...  ...         ...                   ...\n",
            "1404  4587-VVTOX                  0  ...           0                     0\n",
            "1405  7716-YTYHG                  1  ...           0                     0\n",
            "1406  7649-PHJVR                  0  ...           0                     0\n",
            "1407  7855-DIWPO                  1  ...           0                     3\n",
            "1408  8197-BFWVU                  0  ...           0                     0\n",
            "\n",
            "[1409 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train**"
      ],
      "metadata": {
        "id": "bPTqADO2Ox2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = result_train_copy['Churn Category'].values\n",
        "X_train = result_train_copy.drop('Customer ID', axis=1)\n",
        "X_train = X_train.drop('Churn Category', axis=1)"
      ],
      "metadata": {
        "id": "RiyIrSnaNq6F"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"normal data distribution: {Counter(y_train)}\")\n",
        "\n",
        "smo = ADASYN(random_state=seed)\n",
        "X_train, y_train = smo.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"SMOTE data distribution: {Counter(y_train)}\")"
      ],
      "metadata": {
        "id": "LmlxI28WQUG2",
        "outputId": "fbd727b2-64fc-48c1-e8d9-973b427332f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal data distribution: Counter({3: 4133, 1: 662, 0: 271, 2: 222, 4: 175, 5: 171})\n",
            "SMOTE data distribution: Counter({5: 4185, 2: 4172, 3: 4133, 4: 4132, 1: 4120, 0: 4054})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "ss = StandardScaler().fit(X_train)\n",
        "X_train_std = ss.transform(X_train)\n",
        "mms = MinMaxScaler(feature_range=(0, 1)).fit(X_train_std)\n",
        "X_train_std = mms.transform(X_train_std)"
      ],
      "metadata": {
        "id": "euCLdtvkO-nO"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM**"
      ],
      "metadata": {
        "id": "3HpyuY-RQEz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf', gamma=0.7, C=10, decision_function_shape='ovr')\n",
        "\n",
        "# SVM with class weight\n",
        "# svm = SVC(kernel='rbf', gamma=0.7, class_weight={0:10, 1:10, 2:10, 3:1, 4:10, 5:10})\n",
        "\n",
        "start_time = time.time()\n",
        "model = svm.fit(X_train_std, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f'Training use {round(end_time - start_time, 3)}s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXuL_lKqW_mD",
        "outputId": "c56b1fbc-3ff4-47b1-fe46-632cac144a7e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training use 45.686s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_predict = svm.predict(X_train_std)\n",
        "Ein = np.mean(np.array(y_train_predict) != y_train)\n",
        "F1in = metrics.f1_score(y_train, y_train_predict, average='macro')  \n",
        "print(f'Ein = {round(Ein, 5)}')\n",
        "print(f'F1_in = {round(F1in, 5)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WivcNevbY1lB",
        "outputId": "87d5d58a-38f9-49dc-9ecf-646760239913"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ein = 0.01391\n",
            "F1_in = 0.98606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model, X_train_std, y_train)\n",
        "print(encoder_map)"
      ],
      "metadata": {
        "id": "yWM9fKw1MLr1",
        "outputId": "68388ae2-beec-4151-838e-a41838cbb3f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Attitude': 0, 'Competitor': 1, 'Dissatisfaction': 2, 'No Churn': 3, 'Other': 4, 'Price': 5}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_train_predict))"
      ],
      "metadata": {
        "id": "LMiWePsbSW4Y",
        "outputId": "ae90c528-f560-46e2-9855-97d3fe2123ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      4054\n",
            "           1       0.99      0.96      0.98      4120\n",
            "           2       0.98      0.99      0.98      4172\n",
            "           3       1.00      1.00      1.00      4133\n",
            "           4       0.99      0.99      0.99      4132\n",
            "           5       0.98      0.99      0.99      4185\n",
            "\n",
            "    accuracy                           0.99     24796\n",
            "   macro avg       0.99      0.99      0.99     24796\n",
            "weighted avg       0.99      0.99      0.99     24796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM Test**"
      ],
      "metadata": {
        "id": "ViqMiLyMavbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = result_test_copy.drop('Customer ID', axis=1)\n",
        "X_test = X_test.drop('Churn Category', axis=1)\n",
        "ss = StandardScaler().fit(X_test)\n",
        "X_test_std = ss.transform(X_test)\n",
        "mms = MinMaxScaler(feature_range=(0, 1)).fit(X_test_std)\n",
        "X_test_std = mms.transform(X_test_std)\n",
        "y_test = svm.predict(X_test_std)"
      ],
      "metadata": {
        "id": "dxd93_hUauU5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model, X_test_std, y_test)\n",
        "print(encoder_map)"
      ],
      "metadata": {
        "id": "098w16TfMkqn",
        "outputId": "60f3528b-e1d8-414e-cf80-2d9191538509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Attitude': 0, 'Competitor': 1, 'Dissatisfaction': 2, 'No Churn': 3, 'Other': 4, 'Price': 5}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit_result = './svm_result.csv'\n",
        "\n",
        "new_encoder_map = {'No Churn':0, 'Competitor': 1, 'Dissatisfaction':2, 'Attitude': 3, 'Price':4, 'Other':5}\n",
        "\n",
        "with open(submit_result, 'w') as f:\n",
        "    f.write('Customer ID,Churn Category\\n')\n",
        "    for i in range(len(df_test.values)):\n",
        "        id = str(df_test.values[i]).replace('[\\'', '')\n",
        "        id = id.replace('\\']', '')\n",
        "        pred = new_encoder_map.get(list(encoder_map.keys())[list(encoder_map.values()).index(y_test[i])])\n",
        "        f.write(f'{id},{pred}\\n')"
      ],
      "metadata": {
        "id": "6N35sOjrcpNd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(submit_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0tLUThI7nWnj",
        "outputId": "89f41415-3d93-46e6-c3a7-9ff72e510de1"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ee5fe1ff-1ea5-49dd-b601-f0aaa100fea0\", \"result.csv\", 18344)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Neural Network**"
      ],
      "metadata": {
        "id": "ZFjmDSVGQPwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IBMDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(np.int)\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "G5F9W_RkSub3"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(35, 512)\n",
        "        self.layer2 = nn.Linear(512, 256)\n",
        "        self.layer3 = nn.Linear(256, 128)\n",
        "        self.out = nn.Linear(128, 6) \n",
        "        self.act_fn = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "classifier = Classifier()\n",
        "summary(classifier, X_train.shape, device=\"cpu\")"
      ],
      "metadata": {
        "id": "K_ofbzUUQdOX",
        "outputId": "6e48db69-7337-4f0f-c746-4a0a17b023d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1           [-1, 24796, 512]          18,432\n",
            "           Sigmoid-2           [-1, 24796, 512]               0\n",
            "            Linear-3           [-1, 24796, 256]         131,328\n",
            "           Sigmoid-4           [-1, 24796, 256]               0\n",
            "            Linear-5           [-1, 24796, 128]          32,896\n",
            "           Sigmoid-6           [-1, 24796, 128]               0\n",
            "            Linear-7             [-1, 24796, 6]             774\n",
            "================================================================\n",
            "Total params: 183,430\n",
            "Trainable params: 183,430\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.31\n",
            "Forward/backward pass size (MB): 340.14\n",
            "Params size (MB): 0.70\n",
            "Estimated Total Size (MB): 344.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_RATIO = 0.2\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "percent = int(X_train.shape[0] * (1 - VAL_RATIO))\n",
        "X_train = X_train.values\n",
        "train_x, train_y, val_x, val_y = X_train[:percent], y_train[:percent], X_train[percent:], y_train[percent:]\n",
        "print('Size of training set: {}'.format(train_x.shape))\n",
        "print('Size of validation set: {}'.format(val_x.shape))"
      ],
      "metadata": {
        "id": "3lDEMsTdTVd3",
        "outputId": "d3331f9e-cc9b-44c0-a0c5-fea95f1f2ebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: (19836, 35)\n",
            "Size of validation set: (4960, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = IBMDataset(train_x, train_y)\n",
        "val_set = IBMDataset(val_x, val_y)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) # only shuffle the training data\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "RaPDAgDzTcrs"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get device \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# training parameters\n",
        "num_epoch = 3000             # number of training epoch\n",
        "learning_rate = 0.0001       # learning rate\n",
        "\n",
        "# the path where checkpoint saved\n",
        "model_path = './best_model.ckpt'\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "CMbU0r5fRwai",
        "outputId": "8929d23a-b2f3-417b-f14b-6708e8dc9798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(inputs) \n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        batch_loss.backward() \n",
        "        optimizer.step() \n",
        "\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                batch_loss = criterion(outputs, labels) \n",
        "                _, val_pred = torch.max(outputs, 1) \n",
        "            \n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            # if the model improves, save a checkpoint at this epoch\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
        "    else:\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "\n",
        "# if not validating, save the last epoch\n",
        "if len(val_set) == 0:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('saving model at last epoch')\n",
        "\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "zYGRiadPSNDo",
        "outputId": "2ddb952b-8c3f-45cc-8e44-7399926967c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/3000] Train Acc: 0.224239 Loss: 1.658367 | Val Acc: 0.000000 loss: 3.794760\n",
            "[002/3000] Train Acc: 0.246421 Loss: 1.630245 | Val Acc: 0.000000 loss: 3.987758\n",
            "[003/3000] Train Acc: 0.268754 Loss: 1.610965 | Val Acc: 0.000000 loss: 4.000502\n",
            "[004/3000] Train Acc: 0.292347 Loss: 1.592151 | Val Acc: 0.000000 loss: 3.992181\n",
            "[005/3000] Train Acc: 0.306715 Loss: 1.573729 | Val Acc: 0.000000 loss: 4.087987\n",
            "[006/3000] Train Acc: 0.323654 Loss: 1.554366 | Val Acc: 0.000000 loss: 4.067157\n",
            "[007/3000] Train Acc: 0.338677 Loss: 1.534961 | Val Acc: 0.000000 loss: 4.116709\n",
            "[008/3000] Train Acc: 0.353045 Loss: 1.510781 | Val Acc: 0.001411 loss: 4.123823\n",
            "saving model with acc 0.001\n",
            "[009/3000] Train Acc: 0.375176 Loss: 1.487714 | Val Acc: 0.010484 loss: 4.106392\n",
            "saving model with acc 0.010\n",
            "[010/3000] Train Acc: 0.385763 Loss: 1.462513 | Val Acc: 0.014315 loss: 4.172632\n",
            "saving model with acc 0.014\n",
            "[011/3000] Train Acc: 0.398165 Loss: 1.436156 | Val Acc: 0.019355 loss: 4.092817\n",
            "saving model with acc 0.019\n",
            "[012/3000] Train Acc: 0.411373 Loss: 1.410038 | Val Acc: 0.019556 loss: 4.129485\n",
            "saving model with acc 0.020\n",
            "[013/3000] Train Acc: 0.425136 Loss: 1.381823 | Val Acc: 0.019556 loss: 4.173814\n",
            "[014/3000] Train Acc: 0.437487 Loss: 1.359526 | Val Acc: 0.017944 loss: 4.176112\n",
            "[015/3000] Train Acc: 0.445201 Loss: 1.335199 | Val Acc: 0.014315 loss: 4.327611\n",
            "[016/3000] Train Acc: 0.452964 Loss: 1.318460 | Val Acc: 0.014516 loss: 4.300149\n",
            "[017/3000] Train Acc: 0.458207 Loss: 1.301326 | Val Acc: 0.025806 loss: 4.324242\n",
            "saving model with acc 0.026\n",
            "[018/3000] Train Acc: 0.470004 Loss: 1.281689 | Val Acc: 0.023185 loss: 4.263811\n",
            "[019/3000] Train Acc: 0.474642 Loss: 1.266710 | Val Acc: 0.028226 loss: 4.294382\n",
            "saving model with acc 0.028\n",
            "[020/3000] Train Acc: 0.479986 Loss: 1.253522 | Val Acc: 0.021774 loss: 4.436376\n",
            "[021/3000] Train Acc: 0.489363 Loss: 1.239663 | Val Acc: 0.032258 loss: 4.357440\n",
            "saving model with acc 0.032\n",
            "[022/3000] Train Acc: 0.496320 Loss: 1.228139 | Val Acc: 0.028024 loss: 4.435035\n",
            "[023/3000] Train Acc: 0.498286 Loss: 1.219193 | Val Acc: 0.028427 loss: 4.428621\n",
            "[024/3000] Train Acc: 0.508167 Loss: 1.203811 | Val Acc: 0.025403 loss: 4.539419\n",
            "[025/3000] Train Acc: 0.509629 Loss: 1.194579 | Val Acc: 0.039919 loss: 4.474014\n",
            "saving model with acc 0.040\n",
            "[026/3000] Train Acc: 0.511898 Loss: 1.188589 | Val Acc: 0.043145 loss: 4.673070\n",
            "saving model with acc 0.043\n",
            "[027/3000] Train Acc: 0.520014 Loss: 1.177877 | Val Acc: 0.036089 loss: 4.442872\n",
            "[028/3000] Train Acc: 0.521980 Loss: 1.169680 | Val Acc: 0.038710 loss: 4.615266\n",
            "[029/3000] Train Acc: 0.530097 Loss: 1.156584 | Val Acc: 0.049395 loss: 4.433350\n",
            "saving model with acc 0.049\n",
            "[030/3000] Train Acc: 0.529845 Loss: 1.154767 | Val Acc: 0.046976 loss: 4.671549\n",
            "[031/3000] Train Acc: 0.537810 Loss: 1.139935 | Val Acc: 0.036290 loss: 4.502205\n",
            "[032/3000] Train Acc: 0.540129 Loss: 1.134999 | Val Acc: 0.059476 loss: 4.681730\n",
            "saving model with acc 0.059\n",
            "[033/3000] Train Acc: 0.543406 Loss: 1.126927 | Val Acc: 0.043548 loss: 4.610441\n",
            "[034/3000] Train Acc: 0.545322 Loss: 1.118551 | Val Acc: 0.046169 loss: 4.572716\n",
            "[035/3000] Train Acc: 0.554043 Loss: 1.104556 | Val Acc: 0.060484 loss: 4.668243\n",
            "saving model with acc 0.060\n",
            "[036/3000] Train Acc: 0.556513 Loss: 1.099037 | Val Acc: 0.052016 loss: 4.706633\n",
            "[037/3000] Train Acc: 0.557774 Loss: 1.092126 | Val Acc: 0.049597 loss: 4.594575\n",
            "[038/3000] Train Acc: 0.563773 Loss: 1.082643 | Val Acc: 0.055040 loss: 4.661078\n",
            "[039/3000] Train Acc: 0.568008 Loss: 1.077851 | Val Acc: 0.059274 loss: 4.637608\n",
            "[040/3000] Train Acc: 0.567856 Loss: 1.074298 | Val Acc: 0.044355 loss: 4.357179\n",
            "[041/3000] Train Acc: 0.572847 Loss: 1.064839 | Val Acc: 0.052823 loss: 4.704501\n",
            "[042/3000] Train Acc: 0.576931 Loss: 1.057120 | Val Acc: 0.055645 loss: 4.642229\n",
            "[043/3000] Train Acc: 0.583585 Loss: 1.047699 | Val Acc: 0.064919 loss: 4.541469\n",
            "saving model with acc 0.065\n",
            "[044/3000] Train Acc: 0.585299 Loss: 1.039924 | Val Acc: 0.062500 loss: 4.472668\n",
            "[045/3000] Train Acc: 0.594928 Loss: 1.030428 | Val Acc: 0.058871 loss: 4.835678\n",
            "[046/3000] Train Acc: 0.598659 Loss: 1.023457 | Val Acc: 0.054637 loss: 4.742002\n",
            "[047/3000] Train Acc: 0.601936 Loss: 1.016363 | Val Acc: 0.050000 loss: 4.817844\n",
            "[048/3000] Train Acc: 0.604457 Loss: 1.009209 | Val Acc: 0.065121 loss: 4.612483\n",
            "saving model with acc 0.065\n",
            "[049/3000] Train Acc: 0.602642 Loss: 1.008265 | Val Acc: 0.063710 loss: 4.705506\n",
            "[050/3000] Train Acc: 0.612422 Loss: 0.993311 | Val Acc: 0.061895 loss: 4.936877\n",
            "[051/3000] Train Acc: 0.620337 Loss: 0.987264 | Val Acc: 0.077823 loss: 4.871741\n",
            "saving model with acc 0.078\n",
            "[052/3000] Train Acc: 0.618119 Loss: 0.982832 | Val Acc: 0.078629 loss: 4.745982\n",
            "saving model with acc 0.079\n",
            "[053/3000] Train Acc: 0.623664 Loss: 0.975015 | Val Acc: 0.075806 loss: 4.916661\n",
            "[054/3000] Train Acc: 0.626689 Loss: 0.969677 | Val Acc: 0.057661 loss: 4.864745\n",
            "[055/3000] Train Acc: 0.635914 Loss: 0.958260 | Val Acc: 0.062500 loss: 4.579336\n",
            "[056/3000] Train Acc: 0.637528 Loss: 0.957929 | Val Acc: 0.077218 loss: 4.729469\n",
            "[057/3000] Train Acc: 0.635057 Loss: 0.950917 | Val Acc: 0.072379 loss: 4.787517\n",
            "[058/3000] Train Acc: 0.642670 Loss: 0.944033 | Val Acc: 0.060081 loss: 4.721506\n",
            "[059/3000] Train Acc: 0.645695 Loss: 0.936263 | Val Acc: 0.061895 loss: 4.711989\n",
            "[060/3000] Train Acc: 0.647510 Loss: 0.931033 | Val Acc: 0.083266 loss: 4.862064\n",
            "saving model with acc 0.083\n",
            "[061/3000] Train Acc: 0.649224 Loss: 0.926877 | Val Acc: 0.080444 loss: 4.572736\n",
            "[062/3000] Train Acc: 0.651543 Loss: 0.924107 | Val Acc: 0.057863 loss: 4.721423\n",
            "[063/3000] Train Acc: 0.650887 Loss: 0.916885 | Val Acc: 0.099798 loss: 4.748078\n",
            "saving model with acc 0.100\n",
            "[064/3000] Train Acc: 0.655878 Loss: 0.910798 | Val Acc: 0.072984 loss: 4.604794\n",
            "[065/3000] Train Acc: 0.656029 Loss: 0.910671 | Val Acc: 0.087702 loss: 4.850201\n",
            "[066/3000] Train Acc: 0.664751 Loss: 0.893350 | Val Acc: 0.080444 loss: 4.730739\n",
            "[067/3000] Train Acc: 0.667272 Loss: 0.893201 | Val Acc: 0.096371 loss: 4.545087\n",
            "[068/3000] Train Acc: 0.664902 Loss: 0.888907 | Val Acc: 0.066331 loss: 4.647535\n",
            "[069/3000] Train Acc: 0.664398 Loss: 0.887973 | Val Acc: 0.103226 loss: 5.053550\n",
            "saving model with acc 0.103\n",
            "[070/3000] Train Acc: 0.669843 Loss: 0.882692 | Val Acc: 0.094355 loss: 4.816228\n",
            "[071/3000] Train Acc: 0.679270 Loss: 0.871794 | Val Acc: 0.072379 loss: 4.764701\n",
            "[072/3000] Train Acc: 0.673120 Loss: 0.873215 | Val Acc: 0.104234 loss: 4.747189\n",
            "saving model with acc 0.104\n",
            "[073/3000] Train Acc: 0.675590 Loss: 0.867670 | Val Acc: 0.093145 loss: 4.771295\n",
            "[074/3000] Train Acc: 0.675993 Loss: 0.865219 | Val Acc: 0.096976 loss: 4.503335\n",
            "[075/3000] Train Acc: 0.680883 Loss: 0.853701 | Val Acc: 0.071976 loss: 5.033697\n",
            "[076/3000] Train Acc: 0.679572 Loss: 0.858804 | Val Acc: 0.074194 loss: 4.604174\n",
            "[077/3000] Train Acc: 0.685673 Loss: 0.845933 | Val Acc: 0.083669 loss: 4.773414\n",
            "[078/3000] Train Acc: 0.686429 Loss: 0.845627 | Val Acc: 0.086290 loss: 4.847038\n",
            "[079/3000] Train Acc: 0.683303 Loss: 0.845051 | Val Acc: 0.072581 loss: 4.931229\n",
            "[080/3000] Train Acc: 0.687689 Loss: 0.838098 | Val Acc: 0.095565 loss: 4.913281\n",
            "[081/3000] Train Acc: 0.691016 Loss: 0.833488 | Val Acc: 0.094355 loss: 5.182367\n",
            "[082/3000] Train Acc: 0.694293 Loss: 0.829591 | Val Acc: 0.073992 loss: 5.055733\n",
            "[083/3000] Train Acc: 0.692377 Loss: 0.824270 | Val Acc: 0.102621 loss: 4.794635\n",
            "[084/3000] Train Acc: 0.697066 Loss: 0.821727 | Val Acc: 0.082661 loss: 4.890618\n",
            "[085/3000] Train Acc: 0.694848 Loss: 0.823903 | Val Acc: 0.070766 loss: 4.567207\n",
            "[086/3000] Train Acc: 0.698326 Loss: 0.813603 | Val Acc: 0.104032 loss: 4.837294\n",
            "[087/3000] Train Acc: 0.702410 Loss: 0.809394 | Val Acc: 0.079839 loss: 4.605015\n",
            "[088/3000] Train Acc: 0.703116 Loss: 0.805505 | Val Acc: 0.106653 loss: 4.770992\n",
            "saving model with acc 0.107\n",
            "[089/3000] Train Acc: 0.704275 Loss: 0.801098 | Val Acc: 0.095766 loss: 4.799092\n",
            "[090/3000] Train Acc: 0.702813 Loss: 0.802732 | Val Acc: 0.097782 loss: 4.958018\n",
            "[091/3000] Train Acc: 0.702763 Loss: 0.799232 | Val Acc: 0.076613 loss: 5.030855\n",
            "[092/3000] Train Acc: 0.706040 Loss: 0.797933 | Val Acc: 0.097782 loss: 4.730027\n",
            "[093/3000] Train Acc: 0.705182 Loss: 0.792911 | Val Acc: 0.080847 loss: 4.620506\n",
            "[094/3000] Train Acc: 0.707955 Loss: 0.788814 | Val Acc: 0.103427 loss: 4.791385\n",
            "[095/3000] Train Acc: 0.711686 Loss: 0.783207 | Val Acc: 0.070968 loss: 4.787422\n",
            "[096/3000] Train Acc: 0.709921 Loss: 0.783958 | Val Acc: 0.097379 loss: 4.682400\n",
            "[097/3000] Train Acc: 0.709921 Loss: 0.783396 | Val Acc: 0.099597 loss: 4.900946\n",
            "[098/3000] Train Acc: 0.712946 Loss: 0.773245 | Val Acc: 0.108669 loss: 5.027553\n",
            "saving model with acc 0.109\n",
            "[099/3000] Train Acc: 0.716122 Loss: 0.772671 | Val Acc: 0.076411 loss: 4.936006\n",
            "[100/3000] Train Acc: 0.719349 Loss: 0.768294 | Val Acc: 0.085887 loss: 4.856533\n",
            "[101/3000] Train Acc: 0.719954 Loss: 0.762234 | Val Acc: 0.096976 loss: 4.724576\n",
            "[102/3000] Train Acc: 0.718945 Loss: 0.768295 | Val Acc: 0.097379 loss: 4.973574\n",
            "[103/3000] Train Acc: 0.719802 Loss: 0.766492 | Val Acc: 0.097177 loss: 4.750149\n",
            "[104/3000] Train Acc: 0.715416 Loss: 0.767550 | Val Acc: 0.115726 loss: 4.865042\n",
            "saving model with acc 0.116\n",
            "[105/3000] Train Acc: 0.722878 Loss: 0.758730 | Val Acc: 0.085484 loss: 4.936651\n",
            "[106/3000] Train Acc: 0.723079 Loss: 0.754256 | Val Acc: 0.088105 loss: 4.697875\n",
            "[107/3000] Train Acc: 0.727667 Loss: 0.749115 | Val Acc: 0.108266 loss: 5.205001\n",
            "[108/3000] Train Acc: 0.723785 Loss: 0.754779 | Val Acc: 0.098992 loss: 4.809455\n",
            "[109/3000] Train Acc: 0.729583 Loss: 0.747526 | Val Acc: 0.108871 loss: 4.920710\n",
            "[110/3000] Train Acc: 0.727364 Loss: 0.748301 | Val Acc: 0.112500 loss: 4.765438\n",
            "[111/3000] Train Acc: 0.724894 Loss: 0.746614 | Val Acc: 0.100403 loss: 4.810142\n",
            "[112/3000] Train Acc: 0.726659 Loss: 0.745265 | Val Acc: 0.098185 loss: 5.029351\n",
            "[113/3000] Train Acc: 0.731095 Loss: 0.736361 | Val Acc: 0.104839 loss: 4.874542\n",
            "[114/3000] Train Acc: 0.732557 Loss: 0.731242 | Val Acc: 0.082460 loss: 4.825151\n",
            "[115/3000] Train Acc: 0.726709 Loss: 0.740367 | Val Acc: 0.102016 loss: 4.936624\n",
            "[116/3000] Train Acc: 0.731397 Loss: 0.727941 | Val Acc: 0.085081 loss: 4.934399\n",
            "[117/3000] Train Acc: 0.731196 Loss: 0.730912 | Val Acc: 0.110685 loss: 4.774558\n",
            "[118/3000] Train Acc: 0.735178 Loss: 0.721793 | Val Acc: 0.090121 loss: 5.056615\n",
            "[119/3000] Train Acc: 0.734725 Loss: 0.724917 | Val Acc: 0.100403 loss: 4.834606\n",
            "[120/3000] Train Acc: 0.733969 Loss: 0.728179 | Val Acc: 0.122984 loss: 4.846784\n",
            "saving model with acc 0.123\n",
            "[121/3000] Train Acc: 0.737094 Loss: 0.717977 | Val Acc: 0.107661 loss: 4.606247\n",
            "[122/3000] Train Acc: 0.737145 Loss: 0.719299 | Val Acc: 0.100403 loss: 4.915502\n",
            "[123/3000] Train Acc: 0.737044 Loss: 0.716717 | Val Acc: 0.106653 loss: 4.748386\n",
            "[124/3000] Train Acc: 0.741379 Loss: 0.709591 | Val Acc: 0.098387 loss: 4.747091\n",
            "[125/3000] Train Acc: 0.739161 Loss: 0.711078 | Val Acc: 0.117137 loss: 4.659297\n",
            "[126/3000] Train Acc: 0.740522 Loss: 0.711246 | Val Acc: 0.086290 loss: 5.225258\n",
            "[127/3000] Train Acc: 0.742035 Loss: 0.707496 | Val Acc: 0.100202 loss: 4.801473\n",
            "[128/3000] Train Acc: 0.748437 Loss: 0.699794 | Val Acc: 0.104839 loss: 4.671834\n",
            "[129/3000] Train Acc: 0.740270 Loss: 0.703543 | Val Acc: 0.075202 loss: 5.025093\n",
            "[130/3000] Train Acc: 0.744102 Loss: 0.703963 | Val Acc: 0.092339 loss: 4.685491\n",
            "[131/3000] Train Acc: 0.746622 Loss: 0.694571 | Val Acc: 0.117137 loss: 4.704155\n",
            "[132/3000] Train Acc: 0.746320 Loss: 0.695800 | Val Acc: 0.099597 loss: 4.603224\n",
            "[133/3000] Train Acc: 0.747983 Loss: 0.693306 | Val Acc: 0.111492 loss: 4.973765\n",
            "[134/3000] Train Acc: 0.747429 Loss: 0.699086 | Val Acc: 0.090726 loss: 5.049074\n",
            "[135/3000] Train Acc: 0.745160 Loss: 0.697157 | Val Acc: 0.097177 loss: 4.762500\n",
            "[136/3000] Train Acc: 0.747883 Loss: 0.689851 | Val Acc: 0.097984 loss: 4.654121\n",
            "[137/3000] Train Acc: 0.749143 Loss: 0.689711 | Val Acc: 0.090524 loss: 4.842152\n",
            "[138/3000] Train Acc: 0.748034 Loss: 0.686767 | Val Acc: 0.090726 loss: 4.882328\n",
            "[139/3000] Train Acc: 0.752773 Loss: 0.680415 | Val Acc: 0.113911 loss: 4.958945\n",
            "[140/3000] Train Acc: 0.749748 Loss: 0.682218 | Val Acc: 0.091734 loss: 4.787386\n",
            "[141/3000] Train Acc: 0.754638 Loss: 0.676203 | Val Acc: 0.110081 loss: 4.696970\n",
            "[142/3000] Train Acc: 0.753781 Loss: 0.676802 | Val Acc: 0.103831 loss: 4.873354\n",
            "[143/3000] Train Acc: 0.756907 Loss: 0.669559 | Val Acc: 0.102621 loss: 4.868048\n",
            "[144/3000] Train Acc: 0.752874 Loss: 0.676814 | Val Acc: 0.082056 loss: 5.001494\n",
            "[145/3000] Train Acc: 0.754789 Loss: 0.673484 | Val Acc: 0.119960 loss: 4.594509\n",
            "[146/3000] Train Acc: 0.760536 Loss: 0.664689 | Val Acc: 0.091532 loss: 4.911217\n",
            "[147/3000] Train Acc: 0.759478 Loss: 0.666208 | Val Acc: 0.092540 loss: 4.971359\n",
            "[148/3000] Train Acc: 0.761393 Loss: 0.664226 | Val Acc: 0.101210 loss: 4.920747\n",
            "[149/3000] Train Acc: 0.762250 Loss: 0.660373 | Val Acc: 0.099597 loss: 4.656004\n",
            "[150/3000] Train Acc: 0.761393 Loss: 0.661356 | Val Acc: 0.108871 loss: 4.717342\n",
            "[151/3000] Train Acc: 0.759125 Loss: 0.660024 | Val Acc: 0.070363 loss: 4.615204\n",
            "[152/3000] Train Acc: 0.762553 Loss: 0.655906 | Val Acc: 0.097984 loss: 4.694390\n",
            "[153/3000] Train Acc: 0.762250 Loss: 0.653892 | Val Acc: 0.096976 loss: 4.528192\n",
            "[154/3000] Train Acc: 0.763007 Loss: 0.656040 | Val Acc: 0.098387 loss: 4.995517\n",
            "[155/3000] Train Acc: 0.765477 Loss: 0.649913 | Val Acc: 0.114516 loss: 4.896449\n",
            "[156/3000] Train Acc: 0.763107 Loss: 0.652138 | Val Acc: 0.105645 loss: 4.864803\n",
            "[157/3000] Train Acc: 0.767342 Loss: 0.644957 | Val Acc: 0.099395 loss: 4.873424\n",
            "[158/3000] Train Acc: 0.767493 Loss: 0.645079 | Val Acc: 0.110887 loss: 5.077460\n",
            "[159/3000] Train Acc: 0.764519 Loss: 0.651663 | Val Acc: 0.119556 loss: 4.691301\n",
            "[160/3000] Train Acc: 0.767544 Loss: 0.640451 | Val Acc: 0.117137 loss: 4.964978\n",
            "[161/3000] Train Acc: 0.770065 Loss: 0.637376 | Val Acc: 0.113105 loss: 4.546373\n",
            "[162/3000] Train Acc: 0.770115 Loss: 0.639685 | Val Acc: 0.107056 loss: 4.680543\n",
            "[163/3000] Train Acc: 0.766284 Loss: 0.639941 | Val Acc: 0.086290 loss: 4.751448\n",
            "[164/3000] Train Acc: 0.767241 Loss: 0.641214 | Val Acc: 0.109073 loss: 4.646228\n",
            "[165/3000] Train Acc: 0.769560 Loss: 0.632156 | Val Acc: 0.103427 loss: 4.938776\n",
            "[166/3000] Train Acc: 0.770720 Loss: 0.632952 | Val Acc: 0.133669 loss: 4.964403\n",
            "saving model with acc 0.134\n",
            "[167/3000] Train Acc: 0.772384 Loss: 0.632228 | Val Acc: 0.106048 loss: 4.986217\n",
            "[168/3000] Train Acc: 0.769258 Loss: 0.632649 | Val Acc: 0.108871 loss: 4.971495\n",
            "[169/3000] Train Acc: 0.768149 Loss: 0.634598 | Val Acc: 0.122177 loss: 4.940538\n",
            "[170/3000] Train Acc: 0.772736 Loss: 0.630462 | Val Acc: 0.112702 loss: 4.719206\n",
            "[171/3000] Train Acc: 0.770770 Loss: 0.629680 | Val Acc: 0.109476 loss: 4.902224\n",
            "[172/3000] Train Acc: 0.772636 Loss: 0.626260 | Val Acc: 0.093347 loss: 4.980902\n",
            "[173/3000] Train Acc: 0.773896 Loss: 0.625079 | Val Acc: 0.083468 loss: 4.685156\n",
            "[174/3000] Train Acc: 0.771224 Loss: 0.626274 | Val Acc: 0.097379 loss: 4.916734\n",
            "[175/3000] Train Acc: 0.776114 Loss: 0.621862 | Val Acc: 0.113306 loss: 4.636293\n",
            "[176/3000] Train Acc: 0.771829 Loss: 0.622924 | Val Acc: 0.125403 loss: 4.615076\n",
            "[177/3000] Train Acc: 0.776013 Loss: 0.620629 | Val Acc: 0.123992 loss: 4.813622\n",
            "[178/3000] Train Acc: 0.775509 Loss: 0.613062 | Val Acc: 0.120766 loss: 4.630826\n",
            "[179/3000] Train Acc: 0.776921 Loss: 0.613769 | Val Acc: 0.129032 loss: 4.840282\n",
            "[180/3000] Train Acc: 0.775408 Loss: 0.621849 | Val Acc: 0.098790 loss: 4.904155\n",
            "[181/3000] Train Acc: 0.778635 Loss: 0.612227 | Val Acc: 0.106653 loss: 4.934911\n",
            "[182/3000] Train Acc: 0.779693 Loss: 0.609103 | Val Acc: 0.110081 loss: 4.625954\n",
            "[183/3000] Train Acc: 0.786953 Loss: 0.600322 | Val Acc: 0.107863 loss: 4.897899\n",
            "[184/3000] Train Acc: 0.783122 Loss: 0.604438 | Val Acc: 0.095565 loss: 4.922971\n",
            "[185/3000] Train Acc: 0.782013 Loss: 0.602924 | Val Acc: 0.110282 loss: 4.930399\n",
            "[186/3000] Train Acc: 0.784735 Loss: 0.602368 | Val Acc: 0.119153 loss: 4.694233\n",
            "[187/3000] Train Acc: 0.780853 Loss: 0.606743 | Val Acc: 0.092944 loss: 5.042836\n",
            "[188/3000] Train Acc: 0.782113 Loss: 0.603844 | Val Acc: 0.119758 loss: 4.914053\n",
            "[189/3000] Train Acc: 0.781559 Loss: 0.607474 | Val Acc: 0.100000 loss: 4.412172\n",
            "[190/3000] Train Acc: 0.782063 Loss: 0.597170 | Val Acc: 0.115927 loss: 4.809694\n",
            "[191/3000] Train Acc: 0.781710 Loss: 0.600086 | Val Acc: 0.119153 loss: 4.788940\n",
            "[192/3000] Train Acc: 0.784382 Loss: 0.598635 | Val Acc: 0.114718 loss: 4.508695\n",
            "[193/3000] Train Acc: 0.783273 Loss: 0.593748 | Val Acc: 0.113508 loss: 5.057837\n",
            "[194/3000] Train Acc: 0.782517 Loss: 0.600641 | Val Acc: 0.119355 loss: 4.749934\n",
            "[195/3000] Train Acc: 0.783172 Loss: 0.596326 | Val Acc: 0.116734 loss: 4.818030\n",
            "[196/3000] Train Acc: 0.781609 Loss: 0.601020 | Val Acc: 0.098589 loss: 4.984635\n",
            "[197/3000] Train Acc: 0.786903 Loss: 0.593224 | Val Acc: 0.105444 loss: 4.778915\n",
            "[198/3000] Train Acc: 0.788768 Loss: 0.583091 | Val Acc: 0.121371 loss: 4.791688\n",
            "[199/3000] Train Acc: 0.788566 Loss: 0.583941 | Val Acc: 0.103226 loss: 4.748241\n",
            "[200/3000] Train Acc: 0.781962 Loss: 0.597664 | Val Acc: 0.110484 loss: 4.559023\n",
            "[201/3000] Train Acc: 0.786298 Loss: 0.595572 | Val Acc: 0.104435 loss: 4.759633\n",
            "[202/3000] Train Acc: 0.781811 Loss: 0.596832 | Val Acc: 0.100403 loss: 5.142868\n",
            "[203/3000] Train Acc: 0.789575 Loss: 0.588913 | Val Acc: 0.098589 loss: 5.048653\n",
            "[204/3000] Train Acc: 0.791238 Loss: 0.583743 | Val Acc: 0.119355 loss: 4.764608\n",
            "[205/3000] Train Acc: 0.789020 Loss: 0.582505 | Val Acc: 0.107460 loss: 4.906124\n",
            "[206/3000] Train Acc: 0.794061 Loss: 0.575601 | Val Acc: 0.112500 loss: 4.844604\n",
            "[207/3000] Train Acc: 0.796128 Loss: 0.573851 | Val Acc: 0.084476 loss: 4.869709\n",
            "[208/3000] Train Acc: 0.788768 Loss: 0.585509 | Val Acc: 0.083871 loss: 4.725760\n",
            "[209/3000] Train Acc: 0.791289 Loss: 0.580307 | Val Acc: 0.111492 loss: 4.531158\n",
            "[210/3000] Train Acc: 0.790583 Loss: 0.574310 | Val Acc: 0.126210 loss: 4.531833\n",
            "[211/3000] Train Acc: 0.792398 Loss: 0.574074 | Val Acc: 0.121774 loss: 4.937463\n",
            "[212/3000] Train Acc: 0.787911 Loss: 0.578873 | Val Acc: 0.109274 loss: 4.775305\n",
            "[213/3000] Train Acc: 0.794868 Loss: 0.571041 | Val Acc: 0.110887 loss: 4.495323\n",
            "[214/3000] Train Acc: 0.793960 Loss: 0.572919 | Val Acc: 0.091129 loss: 4.992527\n",
            "[215/3000] Train Acc: 0.792146 Loss: 0.574993 | Val Acc: 0.117339 loss: 4.645758\n",
            "[216/3000] Train Acc: 0.792196 Loss: 0.578138 | Val Acc: 0.124597 loss: 4.876201\n",
            "[217/3000] Train Acc: 0.793406 Loss: 0.568390 | Val Acc: 0.119355 loss: 4.735337\n",
            "[218/3000] Train Acc: 0.794918 Loss: 0.567634 | Val Acc: 0.106452 loss: 4.632090\n",
            "[219/3000] Train Acc: 0.792650 Loss: 0.579327 | Val Acc: 0.118952 loss: 4.602732\n",
            "[220/3000] Train Acc: 0.794011 Loss: 0.570314 | Val Acc: 0.114516 loss: 4.745731\n",
            "[221/3000] Train Acc: 0.799254 Loss: 0.560948 | Val Acc: 0.111290 loss: 4.756084\n",
            "[222/3000] Train Acc: 0.800060 Loss: 0.558962 | Val Acc: 0.124194 loss: 4.852578\n",
            "[223/3000] Train Acc: 0.799203 Loss: 0.559334 | Val Acc: 0.109274 loss: 4.685752\n",
            "[224/3000] Train Acc: 0.797288 Loss: 0.561284 | Val Acc: 0.101613 loss: 4.645221\n",
            "[225/3000] Train Acc: 0.796582 Loss: 0.564274 | Val Acc: 0.103427 loss: 4.561223\n",
            "[226/3000] Train Acc: 0.798346 Loss: 0.562066 | Val Acc: 0.103427 loss: 4.781481\n",
            "[227/3000] Train Acc: 0.802228 Loss: 0.548827 | Val Acc: 0.093347 loss: 4.813025\n",
            "[228/3000] Train Acc: 0.797137 Loss: 0.559407 | Val Acc: 0.117137 loss: 4.587193\n",
            "[229/3000] Train Acc: 0.801069 Loss: 0.552644 | Val Acc: 0.106855 loss: 4.722486\n",
            "[230/3000] Train Acc: 0.798548 Loss: 0.560315 | Val Acc: 0.112903 loss: 4.891853\n",
            "[231/3000] Train Acc: 0.801119 Loss: 0.556655 | Val Acc: 0.125806 loss: 4.873482\n",
            "[232/3000] Train Acc: 0.799808 Loss: 0.559839 | Val Acc: 0.105242 loss: 4.709328\n",
            "[233/3000] Train Acc: 0.799355 Loss: 0.555434 | Val Acc: 0.110685 loss: 4.703768\n",
            "[234/3000] Train Acc: 0.796834 Loss: 0.559948 | Val Acc: 0.107863 loss: 4.718473\n",
            "[235/3000] Train Acc: 0.801724 Loss: 0.548097 | Val Acc: 0.108266 loss: 4.714813\n",
            "[236/3000] Train Acc: 0.805707 Loss: 0.545632 | Val Acc: 0.121169 loss: 4.720899\n",
            "[237/3000] Train Acc: 0.799859 Loss: 0.551853 | Val Acc: 0.117742 loss: 4.507772\n",
            "[238/3000] Train Acc: 0.800817 Loss: 0.549432 | Val Acc: 0.109073 loss: 4.594220\n",
            "[239/3000] Train Acc: 0.800514 Loss: 0.547061 | Val Acc: 0.129435 loss: 4.667087\n",
            "[240/3000] Train Acc: 0.804598 Loss: 0.542294 | Val Acc: 0.122581 loss: 4.544908\n",
            "[241/3000] Train Acc: 0.804598 Loss: 0.543884 | Val Acc: 0.117540 loss: 4.658755\n",
            "[242/3000] Train Acc: 0.803388 Loss: 0.544098 | Val Acc: 0.123992 loss: 4.512547\n",
            "[243/3000] Train Acc: 0.799859 Loss: 0.546378 | Val Acc: 0.101008 loss: 4.523892\n",
            "[244/3000] Train Acc: 0.807270 Loss: 0.533276 | Val Acc: 0.109073 loss: 4.842378\n",
            "[245/3000] Train Acc: 0.808227 Loss: 0.533915 | Val Acc: 0.093548 loss: 4.608763\n",
            "[246/3000] Train Acc: 0.808732 Loss: 0.535623 | Val Acc: 0.101815 loss: 4.813581\n",
            "[247/3000] Train Acc: 0.806614 Loss: 0.541194 | Val Acc: 0.100202 loss: 4.623424\n",
            "[248/3000] Train Acc: 0.802027 Loss: 0.546042 | Val Acc: 0.105444 loss: 4.715206\n",
            "[249/3000] Train Acc: 0.806816 Loss: 0.537878 | Val Acc: 0.119960 loss: 4.860897\n",
            "[250/3000] Train Acc: 0.808379 Loss: 0.534059 | Val Acc: 0.097581 loss: 4.704500\n",
            "[251/3000] Train Acc: 0.805354 Loss: 0.539438 | Val Acc: 0.105847 loss: 4.577252\n",
            "[252/3000] Train Acc: 0.807320 Loss: 0.538136 | Val Acc: 0.116734 loss: 4.576854\n",
            "[253/3000] Train Acc: 0.808026 Loss: 0.535735 | Val Acc: 0.074597 loss: 4.681441\n",
            "[254/3000] Train Acc: 0.810496 Loss: 0.532382 | Val Acc: 0.116734 loss: 4.673057\n",
            "[255/3000] Train Acc: 0.808732 Loss: 0.532585 | Val Acc: 0.117944 loss: 4.372374\n",
            "[256/3000] Train Acc: 0.809236 Loss: 0.530430 | Val Acc: 0.123185 loss: 4.786058\n",
            "[257/3000] Train Acc: 0.809992 Loss: 0.531334 | Val Acc: 0.113710 loss: 4.527269\n",
            "[258/3000] Train Acc: 0.810546 Loss: 0.529837 | Val Acc: 0.105444 loss: 4.816476\n",
            "[259/3000] Train Acc: 0.805959 Loss: 0.537044 | Val Acc: 0.120363 loss: 4.607809\n",
            "[260/3000] Train Acc: 0.809437 Loss: 0.531940 | Val Acc: 0.126008 loss: 4.682452\n",
            "[261/3000] Train Acc: 0.810042 Loss: 0.527711 | Val Acc: 0.127823 loss: 4.876457\n",
            "[262/3000] Train Acc: 0.806564 Loss: 0.531103 | Val Acc: 0.102823 loss: 4.369945\n",
            "[263/3000] Train Acc: 0.814680 Loss: 0.518468 | Val Acc: 0.116935 loss: 4.677052\n",
            "[264/3000] Train Acc: 0.813370 Loss: 0.524764 | Val Acc: 0.131250 loss: 4.790790\n",
            "[265/3000] Train Acc: 0.814630 Loss: 0.514218 | Val Acc: 0.115121 loss: 4.726563\n",
            "[266/3000] Train Acc: 0.811857 Loss: 0.521502 | Val Acc: 0.107056 loss: 4.844458\n",
            "[267/3000] Train Acc: 0.809992 Loss: 0.527063 | Val Acc: 0.108468 loss: 4.549830\n",
            "[268/3000] Train Acc: 0.807320 Loss: 0.528138 | Val Acc: 0.102419 loss: 4.635330\n",
            "[269/3000] Train Acc: 0.815033 Loss: 0.517531 | Val Acc: 0.109073 loss: 4.496268\n",
            "[270/3000] Train Acc: 0.812462 Loss: 0.519334 | Val Acc: 0.110081 loss: 4.566392\n",
            "[271/3000] Train Acc: 0.815033 Loss: 0.517847 | Val Acc: 0.113710 loss: 4.693459\n",
            "[272/3000] Train Acc: 0.812966 Loss: 0.518908 | Val Acc: 0.110484 loss: 4.676163\n",
            "[273/3000] Train Acc: 0.809891 Loss: 0.523270 | Val Acc: 0.117742 loss: 4.681065\n",
            "[274/3000] Train Acc: 0.815840 Loss: 0.516751 | Val Acc: 0.131452 loss: 4.515349\n",
            "[275/3000] Train Acc: 0.814025 Loss: 0.514408 | Val Acc: 0.110081 loss: 4.592444\n",
            "[276/3000] Train Acc: 0.815487 Loss: 0.513328 | Val Acc: 0.100403 loss: 4.565310\n",
            "[277/3000] Train Acc: 0.815487 Loss: 0.516187 | Val Acc: 0.118952 loss: 4.517975\n",
            "[278/3000] Train Acc: 0.814126 Loss: 0.513516 | Val Acc: 0.100000 loss: 4.589205\n",
            "[279/3000] Train Acc: 0.819369 Loss: 0.511932 | Val Acc: 0.106250 loss: 4.571334\n",
            "[280/3000] Train Acc: 0.816596 Loss: 0.511892 | Val Acc: 0.102016 loss: 4.644616\n",
            "[281/3000] Train Acc: 0.815437 Loss: 0.515754 | Val Acc: 0.112298 loss: 4.813418\n",
            "[282/3000] Train Acc: 0.817251 Loss: 0.514271 | Val Acc: 0.106653 loss: 4.441379\n",
            "[283/3000] Train Acc: 0.814630 Loss: 0.514075 | Val Acc: 0.089516 loss: 4.570673\n",
            "[284/3000] Train Acc: 0.817655 Loss: 0.508486 | Val Acc: 0.123185 loss: 4.645230\n",
            "[285/3000] Train Acc: 0.820780 Loss: 0.505054 | Val Acc: 0.094153 loss: 4.547576\n",
            "[286/3000] Train Acc: 0.816546 Loss: 0.509294 | Val Acc: 0.119355 loss: 4.967160\n",
            "[287/3000] Train Acc: 0.818008 Loss: 0.506836 | Val Acc: 0.116734 loss: 4.841336\n",
            "[288/3000] Train Acc: 0.819470 Loss: 0.508805 | Val Acc: 0.117742 loss: 4.715212\n",
            "[289/3000] Train Acc: 0.818713 Loss: 0.504948 | Val Acc: 0.115726 loss: 4.562164\n",
            "[290/3000] Train Acc: 0.822646 Loss: 0.500794 | Val Acc: 0.095968 loss: 4.781150\n",
            "[291/3000] Train Acc: 0.818814 Loss: 0.505493 | Val Acc: 0.123185 loss: 4.687712\n",
            "[292/3000] Train Acc: 0.822041 Loss: 0.505486 | Val Acc: 0.115524 loss: 4.615721\n",
            "[293/3000] Train Acc: 0.822091 Loss: 0.501968 | Val Acc: 0.106250 loss: 4.625667\n",
            "[294/3000] Train Acc: 0.822696 Loss: 0.494542 | Val Acc: 0.101411 loss: 4.605416\n",
            "[295/3000] Train Acc: 0.821032 Loss: 0.500559 | Val Acc: 0.133669 loss: 4.681426\n",
            "[296/3000] Train Acc: 0.821133 Loss: 0.499556 | Val Acc: 0.128629 loss: 4.813101\n",
            "[297/3000] Train Acc: 0.824461 Loss: 0.491932 | Val Acc: 0.129032 loss: 4.503599\n",
            "[298/3000] Train Acc: 0.820276 Loss: 0.499273 | Val Acc: 0.093952 loss: 4.870147\n",
            "[299/3000] Train Acc: 0.825973 Loss: 0.488387 | Val Acc: 0.119758 loss: 4.611227\n",
            "[300/3000] Train Acc: 0.820226 Loss: 0.501116 | Val Acc: 0.113306 loss: 4.641034\n",
            "[301/3000] Train Acc: 0.823553 Loss: 0.489603 | Val Acc: 0.115927 loss: 4.584035\n",
            "[302/3000] Train Acc: 0.816344 Loss: 0.503040 | Val Acc: 0.115726 loss: 4.679061\n",
            "[303/3000] Train Acc: 0.822545 Loss: 0.492842 | Val Acc: 0.116734 loss: 4.634958\n",
            "[304/3000] Train Acc: 0.825217 Loss: 0.488681 | Val Acc: 0.119556 loss: 4.883945\n",
            "[305/3000] Train Acc: 0.824662 Loss: 0.492286 | Val Acc: 0.099395 loss: 4.561777\n",
            "[306/3000] Train Acc: 0.829502 Loss: 0.484639 | Val Acc: 0.122782 loss: 4.419531\n",
            "[307/3000] Train Acc: 0.824007 Loss: 0.489729 | Val Acc: 0.108669 loss: 4.713984\n",
            "[308/3000] Train Acc: 0.821688 Loss: 0.494601 | Val Acc: 0.130242 loss: 4.372252\n",
            "[309/3000] Train Acc: 0.825318 Loss: 0.488018 | Val Acc: 0.113911 loss: 4.595008\n",
            "[310/3000] Train Acc: 0.826275 Loss: 0.487719 | Val Acc: 0.123387 loss: 4.553068\n",
            "[311/3000] Train Acc: 0.828191 Loss: 0.485366 | Val Acc: 0.122177 loss: 4.497185\n",
            "[312/3000] Train Acc: 0.828242 Loss: 0.483414 | Val Acc: 0.112500 loss: 4.678462\n",
            "[313/3000] Train Acc: 0.827334 Loss: 0.490030 | Val Acc: 0.128427 loss: 4.448697\n",
            "[314/3000] Train Acc: 0.822444 Loss: 0.493970 | Val Acc: 0.103427 loss: 4.530546\n",
            "[315/3000] Train Acc: 0.828695 Loss: 0.481776 | Val Acc: 0.129032 loss: 4.687376\n",
            "[316/3000] Train Acc: 0.827485 Loss: 0.479095 | Val Acc: 0.127621 loss: 4.701491\n",
            "[317/3000] Train Acc: 0.831720 Loss: 0.477692 | Val Acc: 0.138911 loss: 4.786784\n",
            "saving model with acc 0.139\n",
            "[318/3000] Train Acc: 0.830661 Loss: 0.477374 | Val Acc: 0.125806 loss: 4.581654\n",
            "[319/3000] Train Acc: 0.824864 Loss: 0.486022 | Val Acc: 0.106653 loss: 4.574261\n",
            "[320/3000] Train Acc: 0.828998 Loss: 0.480776 | Val Acc: 0.105242 loss: 4.568197\n",
            "[321/3000] Train Acc: 0.827889 Loss: 0.480148 | Val Acc: 0.121169 loss: 4.424788\n",
            "[322/3000] Train Acc: 0.827183 Loss: 0.478754 | Val Acc: 0.108669 loss: 4.717812\n",
            "[323/3000] Train Acc: 0.832073 Loss: 0.475632 | Val Acc: 0.115323 loss: 4.645616\n",
            "[324/3000] Train Acc: 0.827637 Loss: 0.483481 | Val Acc: 0.121169 loss: 4.439164\n",
            "[325/3000] Train Acc: 0.828947 Loss: 0.475268 | Val Acc: 0.125000 loss: 4.356180\n",
            "[326/3000] Train Acc: 0.834493 Loss: 0.470844 | Val Acc: 0.111694 loss: 4.529444\n",
            "[327/3000] Train Acc: 0.833233 Loss: 0.473527 | Val Acc: 0.131855 loss: 4.701536\n",
            "[328/3000] Train Acc: 0.828847 Loss: 0.476150 | Val Acc: 0.132863 loss: 4.739947\n",
            "[329/3000] Train Acc: 0.834241 Loss: 0.470194 | Val Acc: 0.116935 loss: 4.663264\n",
            "[330/3000] Train Acc: 0.831317 Loss: 0.470783 | Val Acc: 0.122177 loss: 4.427327\n",
            "[331/3000] Train Acc: 0.831468 Loss: 0.471946 | Val Acc: 0.126008 loss: 4.353730\n",
            "[332/3000] Train Acc: 0.828544 Loss: 0.475486 | Val Acc: 0.108266 loss: 4.601727\n",
            "[333/3000] Train Acc: 0.833535 Loss: 0.468984 | Val Acc: 0.128831 loss: 4.774111\n",
            "[334/3000] Train Acc: 0.830964 Loss: 0.474781 | Val Acc: 0.104234 loss: 4.628337\n",
            "[335/3000] Train Acc: 0.829250 Loss: 0.472024 | Val Acc: 0.140121 loss: 4.636343\n",
            "saving model with acc 0.140\n",
            "[336/3000] Train Acc: 0.834997 Loss: 0.468261 | Val Acc: 0.109879 loss: 4.700701\n",
            "[337/3000] Train Acc: 0.837770 Loss: 0.465967 | Val Acc: 0.120161 loss: 4.403493\n",
            "[338/3000] Train Acc: 0.831972 Loss: 0.468218 | Val Acc: 0.127016 loss: 4.428723\n",
            "[339/3000] Train Acc: 0.832728 Loss: 0.466826 | Val Acc: 0.118750 loss: 4.482872\n",
            "[340/3000] Train Acc: 0.833989 Loss: 0.462436 | Val Acc: 0.126613 loss: 4.561831\n",
            "[341/3000] Train Acc: 0.831518 Loss: 0.467495 | Val Acc: 0.127823 loss: 4.553342\n",
            "[342/3000] Train Acc: 0.834241 Loss: 0.463254 | Val Acc: 0.123387 loss: 4.494051\n",
            "[343/3000] Train Acc: 0.833031 Loss: 0.468828 | Val Acc: 0.124395 loss: 4.586990\n",
            "[344/3000] Train Acc: 0.833938 Loss: 0.466687 | Val Acc: 0.115726 loss: 4.651299\n",
            "[345/3000] Train Acc: 0.839433 Loss: 0.458648 | Val Acc: 0.115323 loss: 4.659844\n",
            "[346/3000] Train Acc: 0.839534 Loss: 0.455596 | Val Acc: 0.104032 loss: 4.361291\n",
            "[347/3000] Train Acc: 0.835703 Loss: 0.463426 | Val Acc: 0.127016 loss: 4.586201\n",
            "[348/3000] Train Acc: 0.836560 Loss: 0.463337 | Val Acc: 0.137500 loss: 4.535864\n",
            "[349/3000] Train Acc: 0.837921 Loss: 0.455546 | Val Acc: 0.140726 loss: 4.447943\n",
            "saving model with acc 0.141\n",
            "[350/3000] Train Acc: 0.837417 Loss: 0.459726 | Val Acc: 0.116734 loss: 4.412467\n",
            "[351/3000] Train Acc: 0.836409 Loss: 0.459102 | Val Acc: 0.134274 loss: 4.522475\n",
            "[352/3000] Train Acc: 0.836056 Loss: 0.457351 | Val Acc: 0.120968 loss: 4.558579\n",
            "[353/3000] Train Acc: 0.839685 Loss: 0.454815 | Val Acc: 0.115927 loss: 4.514840\n",
            "[354/3000] Train Acc: 0.836056 Loss: 0.455321 | Val Acc: 0.110484 loss: 4.459160\n",
            "[355/3000] Train Acc: 0.838677 Loss: 0.456398 | Val Acc: 0.120968 loss: 4.560453\n",
            "[356/3000] Train Acc: 0.839333 Loss: 0.455411 | Val Acc: 0.135484 loss: 4.387322\n",
            "[357/3000] Train Acc: 0.839181 Loss: 0.454083 | Val Acc: 0.103629 loss: 4.594130\n",
            "[358/3000] Train Acc: 0.833989 Loss: 0.465419 | Val Acc: 0.131855 loss: 4.846520\n",
            "[359/3000] Train Acc: 0.838375 Loss: 0.460182 | Val Acc: 0.125000 loss: 4.677165\n",
            "[360/3000] Train Acc: 0.838475 Loss: 0.450170 | Val Acc: 0.085887 loss: 4.585088\n",
            "[361/3000] Train Acc: 0.838274 Loss: 0.455854 | Val Acc: 0.126411 loss: 4.587590\n",
            "[362/3000] Train Acc: 0.843769 Loss: 0.446449 | Val Acc: 0.123790 loss: 4.700654\n",
            "[363/3000] Train Acc: 0.841601 Loss: 0.447081 | Val Acc: 0.119355 loss: 4.552179\n",
            "[364/3000] Train Acc: 0.836761 Loss: 0.459929 | Val Acc: 0.125202 loss: 4.279591\n",
            "[365/3000] Train Acc: 0.836409 Loss: 0.454131 | Val Acc: 0.131250 loss: 4.555064\n",
            "[366/3000] Train Acc: 0.841450 Loss: 0.446333 | Val Acc: 0.128226 loss: 4.698939\n",
            "[367/3000] Train Acc: 0.841097 Loss: 0.447054 | Val Acc: 0.099597 loss: 4.523836\n",
            "[368/3000] Train Acc: 0.843315 Loss: 0.441314 | Val Acc: 0.116935 loss: 4.540852\n",
            "[369/3000] Train Acc: 0.837518 Loss: 0.452610 | Val Acc: 0.110282 loss: 4.496027\n",
            "[370/3000] Train Acc: 0.842357 Loss: 0.445148 | Val Acc: 0.137702 loss: 4.363117\n",
            "[371/3000] Train Acc: 0.843668 Loss: 0.446119 | Val Acc: 0.142540 loss: 4.615387\n",
            "saving model with acc 0.143\n",
            "[372/3000] Train Acc: 0.844676 Loss: 0.439826 | Val Acc: 0.143750 loss: 4.494806\n",
            "saving model with acc 0.144\n",
            "[373/3000] Train Acc: 0.843063 Loss: 0.442573 | Val Acc: 0.123589 loss: 4.771730\n",
            "[374/3000] Train Acc: 0.840492 Loss: 0.449095 | Val Acc: 0.138911 loss: 4.533765\n",
            "[375/3000] Train Acc: 0.843466 Loss: 0.441514 | Val Acc: 0.151815 loss: 4.539107\n",
            "saving model with acc 0.152\n",
            "[376/3000] Train Acc: 0.841954 Loss: 0.444726 | Val Acc: 0.113911 loss: 4.556479\n",
            "[377/3000] Train Acc: 0.840290 Loss: 0.449138 | Val Acc: 0.136290 loss: 4.681534\n",
            "[378/3000] Train Acc: 0.843114 Loss: 0.443344 | Val Acc: 0.149194 loss: 4.586832\n",
            "[379/3000] Train Acc: 0.844979 Loss: 0.435689 | Val Acc: 0.147379 loss: 4.485271\n",
            "[380/3000] Train Acc: 0.845584 Loss: 0.433986 | Val Acc: 0.156653 loss: 4.566540\n",
            "saving model with acc 0.157\n",
            "[381/3000] Train Acc: 0.842710 Loss: 0.443882 | Val Acc: 0.121976 loss: 4.271506\n",
            "[382/3000] Train Acc: 0.844979 Loss: 0.438503 | Val Acc: 0.138508 loss: 4.619512\n",
            "[383/3000] Train Acc: 0.842962 Loss: 0.444342 | Val Acc: 0.124597 loss: 4.523161\n",
            "[384/3000] Train Acc: 0.843668 Loss: 0.440428 | Val Acc: 0.148185 loss: 4.327263\n",
            "[385/3000] Train Acc: 0.841954 Loss: 0.439163 | Val Acc: 0.118145 loss: 4.562840\n",
            "[386/3000] Train Acc: 0.847147 Loss: 0.438232 | Val Acc: 0.140524 loss: 4.673607\n",
            "[387/3000] Train Acc: 0.846491 Loss: 0.435514 | Val Acc: 0.135484 loss: 4.439286\n",
            "[388/3000] Train Acc: 0.846038 Loss: 0.434449 | Val Acc: 0.145363 loss: 4.535617\n",
            "[389/3000] Train Acc: 0.846844 Loss: 0.435478 | Val Acc: 0.138306 loss: 4.462793\n",
            "[390/3000] Train Acc: 0.844374 Loss: 0.439470 | Val Acc: 0.112903 loss: 4.543957\n",
            "[391/3000] Train Acc: 0.844576 Loss: 0.437165 | Val Acc: 0.132258 loss: 4.618947\n",
            "[392/3000] Train Acc: 0.844727 Loss: 0.432170 | Val Acc: 0.126008 loss: 4.625813\n",
            "[393/3000] Train Acc: 0.844374 Loss: 0.434514 | Val Acc: 0.141129 loss: 4.495492\n",
            "[394/3000] Train Acc: 0.845634 Loss: 0.436126 | Val Acc: 0.133669 loss: 4.573243\n",
            "[395/3000] Train Acc: 0.848709 Loss: 0.430685 | Val Acc: 0.126815 loss: 4.400242\n",
            "[396/3000] Train Acc: 0.842307 Loss: 0.438060 | Val Acc: 0.146371 loss: 4.461673\n",
            "[397/3000] Train Acc: 0.848961 Loss: 0.424027 | Val Acc: 0.142540 loss: 4.510368\n",
            "[398/3000] Train Acc: 0.845735 Loss: 0.432498 | Val Acc: 0.117944 loss: 4.460768\n",
            "[399/3000] Train Acc: 0.843668 Loss: 0.433996 | Val Acc: 0.124194 loss: 4.561262\n",
            "[400/3000] Train Acc: 0.851533 Loss: 0.426511 | Val Acc: 0.118952 loss: 4.485799\n",
            "[401/3000] Train Acc: 0.844122 Loss: 0.435282 | Val Acc: 0.120363 loss: 4.511283\n",
            "[402/3000] Train Acc: 0.848457 Loss: 0.427174 | Val Acc: 0.152016 loss: 4.429521\n",
            "[403/3000] Train Acc: 0.848457 Loss: 0.426733 | Val Acc: 0.136895 loss: 4.862743\n",
            "[404/3000] Train Acc: 0.845886 Loss: 0.435243 | Val Acc: 0.125202 loss: 4.436317\n",
            "[405/3000] Train Acc: 0.848256 Loss: 0.428814 | Val Acc: 0.143952 loss: 4.777977\n",
            "[406/3000] Train Acc: 0.848760 Loss: 0.425678 | Val Acc: 0.139919 loss: 4.431461\n",
            "[407/3000] Train Acc: 0.848911 Loss: 0.427347 | Val Acc: 0.140323 loss: 4.226686\n",
            "[408/3000] Train Acc: 0.851633 Loss: 0.424116 | Val Acc: 0.129435 loss: 4.450848\n",
            "[409/3000] Train Acc: 0.849869 Loss: 0.424319 | Val Acc: 0.130444 loss: 4.364607\n",
            "[410/3000] Train Acc: 0.848558 Loss: 0.428739 | Val Acc: 0.137500 loss: 4.576801\n",
            "[411/3000] Train Acc: 0.850928 Loss: 0.419795 | Val Acc: 0.114718 loss: 4.491055\n",
            "[412/3000] Train Acc: 0.847852 Loss: 0.424267 | Val Acc: 0.119960 loss: 4.423171\n",
            "[413/3000] Train Acc: 0.849466 Loss: 0.425647 | Val Acc: 0.144355 loss: 4.721737\n",
            "[414/3000] Train Acc: 0.848558 Loss: 0.428474 | Val Acc: 0.138710 loss: 4.551711\n",
            "[415/3000] Train Acc: 0.851885 Loss: 0.415214 | Val Acc: 0.131250 loss: 4.574439\n",
            "[416/3000] Train Acc: 0.851936 Loss: 0.415090 | Val Acc: 0.118750 loss: 4.335496\n",
            "[417/3000] Train Acc: 0.847852 Loss: 0.427857 | Val Acc: 0.141129 loss: 4.506137\n",
            "[418/3000] Train Acc: 0.851482 Loss: 0.421930 | Val Acc: 0.156048 loss: 4.347846\n",
            "[419/3000] Train Acc: 0.854507 Loss: 0.419342 | Val Acc: 0.135887 loss: 4.668494\n",
            "[420/3000] Train Acc: 0.848256 Loss: 0.422867 | Val Acc: 0.137298 loss: 4.422663\n",
            "[421/3000] Train Acc: 0.854053 Loss: 0.413036 | Val Acc: 0.146976 loss: 4.583522\n",
            "[422/3000] Train Acc: 0.851533 Loss: 0.422019 | Val Acc: 0.147984 loss: 4.700320\n",
            "[423/3000] Train Acc: 0.854608 Loss: 0.412561 | Val Acc: 0.141734 loss: 4.420185\n",
            "[424/3000] Train Acc: 0.851432 Loss: 0.415259 | Val Acc: 0.135887 loss: 4.467109\n",
            "[425/3000] Train Acc: 0.854557 Loss: 0.417309 | Val Acc: 0.149194 loss: 4.635316\n",
            "[426/3000] Train Acc: 0.852591 Loss: 0.420417 | Val Acc: 0.152016 loss: 4.486274\n",
            "[427/3000] Train Acc: 0.854658 Loss: 0.411177 | Val Acc: 0.131048 loss: 4.447467\n",
            "[428/3000] Train Acc: 0.853448 Loss: 0.413971 | Val Acc: 0.141532 loss: 4.410232\n",
            "[429/3000] Train Acc: 0.850978 Loss: 0.423016 | Val Acc: 0.131250 loss: 4.597453\n",
            "[430/3000] Train Acc: 0.853952 Loss: 0.417656 | Val Acc: 0.145161 loss: 4.500119\n",
            "[431/3000] Train Acc: 0.854910 Loss: 0.410937 | Val Acc: 0.145565 loss: 4.398056\n",
            "[432/3000] Train Acc: 0.853650 Loss: 0.409877 | Val Acc: 0.138306 loss: 4.529317\n",
            "[433/3000] Train Acc: 0.854305 Loss: 0.413780 | Val Acc: 0.137097 loss: 4.347371\n",
            "[434/3000] Train Acc: 0.853549 Loss: 0.412803 | Val Acc: 0.157460 loss: 4.636180\n",
            "saving model with acc 0.157\n",
            "[435/3000] Train Acc: 0.857179 Loss: 0.409296 | Val Acc: 0.147581 loss: 4.316570\n",
            "[436/3000] Train Acc: 0.853952 Loss: 0.415670 | Val Acc: 0.148992 loss: 4.683920\n",
            "[437/3000] Train Acc: 0.850676 Loss: 0.421608 | Val Acc: 0.151815 loss: 4.456436\n",
            "[438/3000] Train Acc: 0.854154 Loss: 0.417316 | Val Acc: 0.148185 loss: 4.845089\n",
            "[439/3000] Train Acc: 0.854356 Loss: 0.413102 | Val Acc: 0.145968 loss: 4.387058\n",
            "[440/3000] Train Acc: 0.853549 Loss: 0.414334 | Val Acc: 0.155040 loss: 4.434409\n",
            "[441/3000] Train Acc: 0.852944 Loss: 0.414195 | Val Acc: 0.141734 loss: 4.779569\n",
            "[442/3000] Train Acc: 0.854507 Loss: 0.415910 | Val Acc: 0.138508 loss: 4.986877\n",
            "[443/3000] Train Acc: 0.855465 Loss: 0.409441 | Val Acc: 0.143347 loss: 4.329156\n",
            "[444/3000] Train Acc: 0.854053 Loss: 0.408255 | Val Acc: 0.142944 loss: 4.301174\n",
            "[445/3000] Train Acc: 0.854104 Loss: 0.406931 | Val Acc: 0.145766 loss: 4.451059\n",
            "[446/3000] Train Acc: 0.857028 Loss: 0.405630 | Val Acc: 0.165323 loss: 4.480814\n",
            "saving model with acc 0.165\n",
            "[447/3000] Train Acc: 0.850726 Loss: 0.417034 | Val Acc: 0.163911 loss: 4.468943\n",
            "[448/3000] Train Acc: 0.850726 Loss: 0.415893 | Val Acc: 0.142742 loss: 4.726166\n",
            "[449/3000] Train Acc: 0.855364 Loss: 0.404941 | Val Acc: 0.160685 loss: 4.684442\n",
            "[450/3000] Train Acc: 0.851936 Loss: 0.412832 | Val Acc: 0.131653 loss: 4.650211\n",
            "[451/3000] Train Acc: 0.854961 Loss: 0.411991 | Val Acc: 0.131855 loss: 4.534974\n",
            "[452/3000] Train Acc: 0.852944 Loss: 0.411899 | Val Acc: 0.159677 loss: 4.397813\n",
            "[453/3000] Train Acc: 0.856019 Loss: 0.407411 | Val Acc: 0.143750 loss: 4.481885\n",
            "[454/3000] Train Acc: 0.857834 Loss: 0.405298 | Val Acc: 0.119758 loss: 4.645014\n",
            "[455/3000] Train Acc: 0.858843 Loss: 0.399170 | Val Acc: 0.144355 loss: 4.500545\n",
            "[456/3000] Train Acc: 0.856372 Loss: 0.407602 | Val Acc: 0.137500 loss: 4.302710\n",
            "[457/3000] Train Acc: 0.858691 Loss: 0.400359 | Val Acc: 0.159476 loss: 4.609622\n",
            "[458/3000] Train Acc: 0.859044 Loss: 0.398927 | Val Acc: 0.152621 loss: 4.447348\n",
            "[459/3000] Train Acc: 0.855666 Loss: 0.404320 | Val Acc: 0.143347 loss: 4.436262\n",
            "[460/3000] Train Acc: 0.859145 Loss: 0.402284 | Val Acc: 0.147379 loss: 4.521705\n",
            "[461/3000] Train Acc: 0.858742 Loss: 0.399038 | Val Acc: 0.133871 loss: 4.434496\n",
            "[462/3000] Train Acc: 0.859599 Loss: 0.399196 | Val Acc: 0.137500 loss: 4.536083\n",
            "[463/3000] Train Acc: 0.856070 Loss: 0.403382 | Val Acc: 0.135887 loss: 4.494889\n",
            "[464/3000] Train Acc: 0.858691 Loss: 0.400104 | Val Acc: 0.145565 loss: 4.418431\n",
            "[465/3000] Train Acc: 0.858338 Loss: 0.400390 | Val Acc: 0.148185 loss: 4.695290\n",
            "[466/3000] Train Acc: 0.861363 Loss: 0.397068 | Val Acc: 0.157661 loss: 4.395430\n",
            "[467/3000] Train Acc: 0.860456 Loss: 0.392563 | Val Acc: 0.145161 loss: 4.313880\n",
            "[468/3000] Train Acc: 0.857078 Loss: 0.407037 | Val Acc: 0.134476 loss: 4.303323\n",
            "[469/3000] Train Acc: 0.860204 Loss: 0.397212 | Val Acc: 0.158468 loss: 4.841023\n",
            "[470/3000] Train Acc: 0.863380 Loss: 0.392003 | Val Acc: 0.143145 loss: 4.539400\n",
            "[471/3000] Train Acc: 0.861061 Loss: 0.396631 | Val Acc: 0.152823 loss: 4.579884\n",
            "[472/3000] Train Acc: 0.856120 Loss: 0.404597 | Val Acc: 0.144556 loss: 4.612598\n",
            "[473/3000] Train Acc: 0.860355 Loss: 0.403674 | Val Acc: 0.128226 loss: 4.493348\n",
            "[474/3000] Train Acc: 0.858036 Loss: 0.396838 | Val Acc: 0.134274 loss: 4.415079\n",
            "[475/3000] Train Acc: 0.859447 Loss: 0.396420 | Val Acc: 0.140323 loss: 4.674510\n",
            "[476/3000] Train Acc: 0.859750 Loss: 0.397705 | Val Acc: 0.136895 loss: 4.769995\n",
            "[477/3000] Train Acc: 0.865900 Loss: 0.387719 | Val Acc: 0.159073 loss: 4.601918\n",
            "[478/3000] Train Acc: 0.860657 Loss: 0.396071 | Val Acc: 0.148387 loss: 4.731216\n",
            "[479/3000] Train Acc: 0.858893 Loss: 0.399238 | Val Acc: 0.154435 loss: 4.373393\n",
            "[480/3000] Train Acc: 0.857784 Loss: 0.408061 | Val Acc: 0.148387 loss: 4.497550\n",
            "[481/3000] Train Acc: 0.857431 Loss: 0.399745 | Val Acc: 0.134274 loss: 4.624870\n",
            "[482/3000] Train Acc: 0.860052 Loss: 0.396167 | Val Acc: 0.133065 loss: 4.650788\n",
            "[483/3000] Train Acc: 0.863077 Loss: 0.392213 | Val Acc: 0.150806 loss: 4.505554\n",
            "[484/3000] Train Acc: 0.860304 Loss: 0.393614 | Val Acc: 0.156855 loss: 4.588858\n",
            "[485/3000] Train Acc: 0.860708 Loss: 0.389957 | Val Acc: 0.157460 loss: 4.665077\n",
            "[486/3000] Train Acc: 0.864086 Loss: 0.389123 | Val Acc: 0.132056 loss: 4.552080\n",
            "[487/3000] Train Acc: 0.861666 Loss: 0.395480 | Val Acc: 0.131653 loss: 4.557664\n",
            "[488/3000] Train Acc: 0.861766 Loss: 0.389482 | Val Acc: 0.141935 loss: 4.563731\n",
            "[489/3000] Train Acc: 0.862422 Loss: 0.386819 | Val Acc: 0.147177 loss: 4.669185\n",
            "[490/3000] Train Acc: 0.863430 Loss: 0.390289 | Val Acc: 0.148185 loss: 4.550926\n",
            "[491/3000] Train Acc: 0.861666 Loss: 0.386416 | Val Acc: 0.148185 loss: 4.853366\n",
            "[492/3000] Train Acc: 0.861968 Loss: 0.389120 | Val Acc: 0.146976 loss: 4.346574\n",
            "[493/3000] Train Acc: 0.859952 Loss: 0.396227 | Val Acc: 0.160685 loss: 4.365345\n",
            "[494/3000] Train Acc: 0.861666 Loss: 0.388045 | Val Acc: 0.163508 loss: 4.496328\n",
            "[495/3000] Train Acc: 0.862775 Loss: 0.392473 | Val Acc: 0.153831 loss: 4.688414\n",
            "[496/3000] Train Acc: 0.865144 Loss: 0.385151 | Val Acc: 0.149798 loss: 4.526047\n",
            "[497/3000] Train Acc: 0.864489 Loss: 0.387205 | Val Acc: 0.159476 loss: 4.434260\n",
            "[498/3000] Train Acc: 0.862220 Loss: 0.391126 | Val Acc: 0.142742 loss: 4.528991\n",
            "[499/3000] Train Acc: 0.865800 Loss: 0.380242 | Val Acc: 0.148589 loss: 4.313055\n",
            "[500/3000] Train Acc: 0.863178 Loss: 0.386467 | Val Acc: 0.156653 loss: 4.603418\n",
            "[501/3000] Train Acc: 0.861968 Loss: 0.393387 | Val Acc: 0.156452 loss: 4.415354\n",
            "[502/3000] Train Acc: 0.868270 Loss: 0.378174 | Val Acc: 0.144960 loss: 4.538186\n",
            "[503/3000] Train Acc: 0.862069 Loss: 0.392653 | Val Acc: 0.159879 loss: 4.623706\n",
            "[504/3000] Train Acc: 0.862775 Loss: 0.387468 | Val Acc: 0.157863 loss: 4.542073\n",
            "[505/3000] Train Acc: 0.865850 Loss: 0.379891 | Val Acc: 0.154637 loss: 4.681847\n",
            "[506/3000] Train Acc: 0.863934 Loss: 0.386181 | Val Acc: 0.141129 loss: 4.709200\n",
            "[507/3000] Train Acc: 0.863531 Loss: 0.385051 | Val Acc: 0.119556 loss: 4.537500\n",
            "[508/3000] Train Acc: 0.864539 Loss: 0.381798 | Val Acc: 0.157056 loss: 4.473683\n",
            "[509/3000] Train Acc: 0.864640 Loss: 0.382356 | Val Acc: 0.144556 loss: 4.505655\n",
            "[510/3000] Train Acc: 0.867211 Loss: 0.379367 | Val Acc: 0.160282 loss: 4.487283\n",
            "[511/3000] Train Acc: 0.868572 Loss: 0.375380 | Val Acc: 0.149194 loss: 4.527954\n",
            "[512/3000] Train Acc: 0.868976 Loss: 0.376817 | Val Acc: 0.161694 loss: 4.429025\n",
            "[513/3000] Train Acc: 0.868522 Loss: 0.375108 | Val Acc: 0.153427 loss: 4.369564\n",
            "[514/3000] Train Acc: 0.865144 Loss: 0.378538 | Val Acc: 0.146976 loss: 4.443495\n",
            "[515/3000] Train Acc: 0.863884 Loss: 0.387836 | Val Acc: 0.154234 loss: 4.512890\n",
            "[516/3000] Train Acc: 0.865497 Loss: 0.376477 | Val Acc: 0.156653 loss: 4.738666\n",
            "[517/3000] Train Acc: 0.857582 Loss: 0.395421 | Val Acc: 0.154435 loss: 4.410649\n",
            "[518/3000] Train Acc: 0.867867 Loss: 0.376689 | Val Acc: 0.157258 loss: 4.625139\n",
            "[519/3000] Train Acc: 0.865195 Loss: 0.380996 | Val Acc: 0.164919 loss: 4.752044\n",
            "[520/3000] Train Acc: 0.864237 Loss: 0.382217 | Val Acc: 0.158669 loss: 4.582290\n",
            "[521/3000] Train Acc: 0.863380 Loss: 0.382170 | Val Acc: 0.151008 loss: 4.636435\n",
            "[522/3000] Train Acc: 0.871093 Loss: 0.372579 | Val Acc: 0.131855 loss: 4.552119\n",
            "[523/3000] Train Acc: 0.870538 Loss: 0.368330 | Val Acc: 0.159476 loss: 4.756610\n",
            "[524/3000] Train Acc: 0.870690 Loss: 0.373235 | Val Acc: 0.164315 loss: 4.180465\n",
            "[525/3000] Train Acc: 0.864237 Loss: 0.378104 | Val Acc: 0.166331 loss: 4.632753\n",
            "saving model with acc 0.166\n",
            "[526/3000] Train Acc: 0.867362 Loss: 0.376792 | Val Acc: 0.167540 loss: 4.220330\n",
            "saving model with acc 0.168\n",
            "[527/3000] Train Acc: 0.866606 Loss: 0.377589 | Val Acc: 0.150403 loss: 4.602271\n",
            "[528/3000] Train Acc: 0.869177 Loss: 0.371724 | Val Acc: 0.154032 loss: 4.575877\n",
            "[529/3000] Train Acc: 0.867060 Loss: 0.374485 | Val Acc: 0.147379 loss: 4.440384\n",
            "[530/3000] Train Acc: 0.865850 Loss: 0.378146 | Val Acc: 0.157661 loss: 4.605624\n",
            "[531/3000] Train Acc: 0.869581 Loss: 0.370484 | Val Acc: 0.140524 loss: 4.590971\n",
            "[532/3000] Train Acc: 0.867161 Loss: 0.372484 | Val Acc: 0.165524 loss: 4.622354\n",
            "[533/3000] Train Acc: 0.870286 Loss: 0.367247 | Val Acc: 0.145161 loss: 4.610700\n",
            "[534/3000] Train Acc: 0.868824 Loss: 0.370872 | Val Acc: 0.162097 loss: 4.796649\n",
            "[535/3000] Train Acc: 0.865648 Loss: 0.374204 | Val Acc: 0.166129 loss: 4.452712\n",
            "[536/3000] Train Acc: 0.869379 Loss: 0.369638 | Val Acc: 0.148185 loss: 4.518928\n",
            "[537/3000] Train Acc: 0.871799 Loss: 0.363829 | Val Acc: 0.147581 loss: 4.588383\n",
            "[538/3000] Train Acc: 0.867211 Loss: 0.371263 | Val Acc: 0.158468 loss: 4.344437\n",
            "[539/3000] Train Acc: 0.872152 Loss: 0.364606 | Val Acc: 0.158266 loss: 4.343377\n",
            "[540/3000] Train Acc: 0.871648 Loss: 0.363504 | Val Acc: 0.163508 loss: 4.653547\n",
            "[541/3000] Train Acc: 0.868018 Loss: 0.371299 | Val Acc: 0.153024 loss: 4.836886\n",
            "[542/3000] Train Acc: 0.870841 Loss: 0.372882 | Val Acc: 0.152218 loss: 4.579197\n",
            "[543/3000] Train Acc: 0.873664 Loss: 0.359985 | Val Acc: 0.138508 loss: 4.718862\n",
            "[544/3000] Train Acc: 0.867867 Loss: 0.372177 | Val Acc: 0.161694 loss: 4.426217\n",
            "[545/3000] Train Acc: 0.871597 Loss: 0.371404 | Val Acc: 0.165726 loss: 4.451362\n",
            "[546/3000] Train Acc: 0.867665 Loss: 0.368098 | Val Acc: 0.133065 loss: 4.704755\n",
            "[547/3000] Train Acc: 0.870286 Loss: 0.369826 | Val Acc: 0.144153 loss: 4.738388\n",
            "[548/3000] Train Acc: 0.869076 Loss: 0.368112 | Val Acc: 0.163105 loss: 4.297061\n",
            "[549/3000] Train Acc: 0.870286 Loss: 0.369626 | Val Acc: 0.158266 loss: 4.356356\n",
            "[550/3000] Train Acc: 0.873664 Loss: 0.359532 | Val Acc: 0.153024 loss: 4.665196\n",
            "[551/3000] Train Acc: 0.874017 Loss: 0.360457 | Val Acc: 0.153629 loss: 4.773638\n",
            "[552/3000] Train Acc: 0.874672 Loss: 0.359897 | Val Acc: 0.165726 loss: 4.622357\n",
            "[553/3000] Train Acc: 0.870034 Loss: 0.366296 | Val Acc: 0.157460 loss: 4.770366\n",
            "[554/3000] Train Acc: 0.869278 Loss: 0.366461 | Val Acc: 0.161895 loss: 4.724338\n",
            "[555/3000] Train Acc: 0.872252 Loss: 0.361124 | Val Acc: 0.167944 loss: 4.441514\n",
            "saving model with acc 0.168\n",
            "[556/3000] Train Acc: 0.871648 Loss: 0.364030 | Val Acc: 0.149597 loss: 4.393379\n",
            "[557/3000] Train Acc: 0.870841 Loss: 0.363320 | Val Acc: 0.156250 loss: 4.576917\n",
            "[558/3000] Train Acc: 0.871648 Loss: 0.362395 | Val Acc: 0.153427 loss: 4.862935\n",
            "[559/3000] Train Acc: 0.873160 Loss: 0.361927 | Val Acc: 0.157258 loss: 4.686585\n",
            "[560/3000] Train Acc: 0.872000 Loss: 0.361851 | Val Acc: 0.160887 loss: 4.822339\n",
            "[561/3000] Train Acc: 0.872505 Loss: 0.365056 | Val Acc: 0.175806 loss: 4.581914\n",
            "saving model with acc 0.176\n",
            "[562/3000] Train Acc: 0.872807 Loss: 0.359764 | Val Acc: 0.166532 loss: 4.613448\n",
            "[563/3000] Train Acc: 0.874319 Loss: 0.357519 | Val Acc: 0.155040 loss: 4.760462\n",
            "[564/3000] Train Acc: 0.869328 Loss: 0.370673 | Val Acc: 0.167540 loss: 4.665188\n",
            "[565/3000] Train Acc: 0.875580 Loss: 0.356714 | Val Acc: 0.165121 loss: 4.949992\n",
            "[566/3000] Train Acc: 0.870891 Loss: 0.361090 | Val Acc: 0.165726 loss: 4.383176\n",
            "[567/3000] Train Acc: 0.868925 Loss: 0.368680 | Val Acc: 0.152016 loss: 4.655217\n",
            "[568/3000] Train Acc: 0.872404 Loss: 0.359581 | Val Acc: 0.152621 loss: 4.604587\n",
            "[569/3000] Train Acc: 0.874420 Loss: 0.358009 | Val Acc: 0.161089 loss: 4.611672\n",
            "[570/3000] Train Acc: 0.867766 Loss: 0.364248 | Val Acc: 0.150000 loss: 4.796338\n",
            "[571/3000] Train Acc: 0.874975 Loss: 0.353788 | Val Acc: 0.139718 loss: 4.530086\n",
            "[572/3000] Train Acc: 0.879260 Loss: 0.346459 | Val Acc: 0.152016 loss: 4.599120\n",
            "[573/3000] Train Acc: 0.875580 Loss: 0.353727 | Val Acc: 0.159274 loss: 4.699332\n",
            "[574/3000] Train Acc: 0.867967 Loss: 0.364685 | Val Acc: 0.157056 loss: 4.567520\n",
            "[575/3000] Train Acc: 0.875933 Loss: 0.355369 | Val Acc: 0.150605 loss: 4.967424\n",
            "[576/3000] Train Acc: 0.876134 Loss: 0.351043 | Val Acc: 0.161290 loss: 4.597490\n",
            "[577/3000] Train Acc: 0.873261 Loss: 0.357632 | Val Acc: 0.154839 loss: 5.021443\n",
            "[578/3000] Train Acc: 0.877243 Loss: 0.351782 | Val Acc: 0.139919 loss: 4.822047\n",
            "[579/3000] Train Acc: 0.875529 Loss: 0.354840 | Val Acc: 0.171573 loss: 4.473611\n",
            "[580/3000] Train Acc: 0.874168 Loss: 0.356654 | Val Acc: 0.156048 loss: 4.864120\n",
            "[581/3000] Train Acc: 0.877596 Loss: 0.351350 | Val Acc: 0.156452 loss: 4.539081\n",
            "[582/3000] Train Acc: 0.877546 Loss: 0.351321 | Val Acc: 0.157661 loss: 4.592787\n",
            "[583/3000] Train Acc: 0.875277 Loss: 0.357410 | Val Acc: 0.167742 loss: 4.542892\n",
            "[584/3000] Train Acc: 0.876638 Loss: 0.351106 | Val Acc: 0.167137 loss: 4.556323\n",
            "[585/3000] Train Acc: 0.875479 Loss: 0.350792 | Val Acc: 0.171169 loss: 4.570691\n",
            "[586/3000] Train Acc: 0.876941 Loss: 0.351510 | Val Acc: 0.157460 loss: 4.648759\n",
            "[587/3000] Train Acc: 0.876891 Loss: 0.352312 | Val Acc: 0.146774 loss: 4.817430\n",
            "[588/3000] Train Acc: 0.872908 Loss: 0.352204 | Val Acc: 0.162702 loss: 4.442870\n",
            "[589/3000] Train Acc: 0.873362 Loss: 0.357306 | Val Acc: 0.156452 loss: 4.477163\n",
            "[590/3000] Train Acc: 0.869480 Loss: 0.360692 | Val Acc: 0.177218 loss: 4.583337\n",
            "saving model with acc 0.177\n",
            "[591/3000] Train Acc: 0.876739 Loss: 0.349025 | Val Acc: 0.147379 loss: 4.775137\n",
            "[592/3000] Train Acc: 0.879159 Loss: 0.342928 | Val Acc: 0.161089 loss: 4.347212\n",
            "[593/3000] Train Acc: 0.874521 Loss: 0.353218 | Val Acc: 0.167339 loss: 4.556812\n",
            "[594/3000] Train Acc: 0.879512 Loss: 0.345043 | Val Acc: 0.144960 loss: 4.708278\n",
            "[595/3000] Train Acc: 0.871950 Loss: 0.357449 | Val Acc: 0.157258 loss: 4.774332\n",
            "[596/3000] Train Acc: 0.876840 Loss: 0.346753 | Val Acc: 0.166734 loss: 4.425704\n",
            "[597/3000] Train Acc: 0.877092 Loss: 0.350543 | Val Acc: 0.170565 loss: 4.709500\n",
            "[598/3000] Train Acc: 0.880571 Loss: 0.342114 | Val Acc: 0.164919 loss: 4.252576\n",
            "[599/3000] Train Acc: 0.877445 Loss: 0.345123 | Val Acc: 0.150605 loss: 4.940598\n",
            "[600/3000] Train Acc: 0.872807 Loss: 0.361227 | Val Acc: 0.165121 loss: 4.728078\n",
            "[601/3000] Train Acc: 0.874975 Loss: 0.352623 | Val Acc: 0.162903 loss: 4.697401\n",
            "[602/3000] Train Acc: 0.880067 Loss: 0.340892 | Val Acc: 0.174798 loss: 4.472922\n",
            "[603/3000] Train Acc: 0.875832 Loss: 0.347533 | Val Acc: 0.165927 loss: 4.637839\n",
            "[604/3000] Train Acc: 0.878907 Loss: 0.340869 | Val Acc: 0.154234 loss: 4.471104\n",
            "[605/3000] Train Acc: 0.875076 Loss: 0.347923 | Val Acc: 0.144556 loss: 4.731006\n",
            "[606/3000] Train Acc: 0.876638 Loss: 0.348481 | Val Acc: 0.164315 loss: 4.876489\n",
            "[607/3000] Train Acc: 0.874521 Loss: 0.346797 | Val Acc: 0.167137 loss: 4.662798\n",
            "[608/3000] Train Acc: 0.880974 Loss: 0.342973 | Val Acc: 0.141129 loss: 4.959365\n",
            "[609/3000] Train Acc: 0.878857 Loss: 0.341195 | Val Acc: 0.161290 loss: 4.624745\n",
            "[610/3000] Train Acc: 0.878756 Loss: 0.342733 | Val Acc: 0.145968 loss: 4.731719\n",
            "[611/3000] Train Acc: 0.878756 Loss: 0.341192 | Val Acc: 0.169960 loss: 4.566026\n",
            "[612/3000] Train Acc: 0.881226 Loss: 0.338052 | Val Acc: 0.150806 loss: 4.779288\n",
            "[613/3000] Train Acc: 0.879462 Loss: 0.343394 | Val Acc: 0.156250 loss: 4.771126\n",
            "[614/3000] Train Acc: 0.878907 Loss: 0.347433 | Val Acc: 0.165726 loss: 4.513596\n",
            "[615/3000] Train Acc: 0.877445 Loss: 0.350834 | Val Acc: 0.152016 loss: 4.551297\n",
            "[616/3000] Train Acc: 0.877143 Loss: 0.344540 | Val Acc: 0.159476 loss: 4.859981\n",
            "[617/3000] Train Acc: 0.875479 Loss: 0.344784 | Val Acc: 0.162702 loss: 4.612718\n",
            "[618/3000] Train Acc: 0.881276 Loss: 0.332591 | Val Acc: 0.165726 loss: 4.597073\n",
            "[619/3000] Train Acc: 0.882133 Loss: 0.338428 | Val Acc: 0.156250 loss: 4.691756\n",
            "[620/3000] Train Acc: 0.878806 Loss: 0.340757 | Val Acc: 0.145766 loss: 4.622620\n",
            "[621/3000] Train Acc: 0.878957 Loss: 0.340301 | Val Acc: 0.152016 loss: 4.795661\n",
            "[622/3000] Train Acc: 0.883293 Loss: 0.333990 | Val Acc: 0.173790 loss: 4.457260\n",
            "[623/3000] Train Acc: 0.878352 Loss: 0.341803 | Val Acc: 0.149597 loss: 4.536008\n",
            "[624/3000] Train Acc: 0.877143 Loss: 0.346650 | Val Acc: 0.163105 loss: 4.762995\n",
            "[625/3000] Train Acc: 0.881781 Loss: 0.334558 | Val Acc: 0.150403 loss: 4.542734\n",
            "[626/3000] Train Acc: 0.880218 Loss: 0.335446 | Val Acc: 0.177823 loss: 4.510412\n",
            "saving model with acc 0.178\n",
            "[627/3000] Train Acc: 0.883495 Loss: 0.331369 | Val Acc: 0.163911 loss: 4.510715\n",
            "[628/3000] Train Acc: 0.878554 Loss: 0.343745 | Val Acc: 0.168347 loss: 4.932540\n",
            "[629/3000] Train Acc: 0.880974 Loss: 0.334872 | Val Acc: 0.172581 loss: 4.671873\n",
            "[630/3000] Train Acc: 0.882083 Loss: 0.333250 | Val Acc: 0.156855 loss: 4.595287\n",
            "[631/3000] Train Acc: 0.884705 Loss: 0.333827 | Val Acc: 0.149597 loss: 4.851931\n",
            "[632/3000] Train Acc: 0.881781 Loss: 0.336302 | Val Acc: 0.162702 loss: 4.857962\n",
            "[633/3000] Train Acc: 0.881529 Loss: 0.340969 | Val Acc: 0.171976 loss: 4.560305\n",
            "[634/3000] Train Acc: 0.882436 Loss: 0.335790 | Val Acc: 0.165524 loss: 4.765834\n",
            "[635/3000] Train Acc: 0.882083 Loss: 0.336129 | Val Acc: 0.182661 loss: 4.669474\n",
            "saving model with acc 0.183\n",
            "[636/3000] Train Acc: 0.882285 Loss: 0.331623 | Val Acc: 0.163710 loss: 4.608275\n",
            "[637/3000] Train Acc: 0.884402 Loss: 0.328660 | Val Acc: 0.148790 loss: 4.768756\n",
            "[638/3000] Train Acc: 0.879210 Loss: 0.338665 | Val Acc: 0.156452 loss: 4.756962\n",
            "[639/3000] Train Acc: 0.883243 Loss: 0.330951 | Val Acc: 0.167540 loss: 4.712198\n",
            "[640/3000] Train Acc: 0.883192 Loss: 0.335202 | Val Acc: 0.167339 loss: 4.541761\n",
            "[641/3000] Train Acc: 0.879058 Loss: 0.337437 | Val Acc: 0.155040 loss: 4.740175\n",
            "[642/3000] Train Acc: 0.882991 Loss: 0.331981 | Val Acc: 0.157863 loss: 4.612587\n",
            "[643/3000] Train Acc: 0.883243 Loss: 0.335099 | Val Acc: 0.161895 loss: 4.788855\n",
            "[644/3000] Train Acc: 0.883999 Loss: 0.335701 | Val Acc: 0.165927 loss: 4.531912\n",
            "[645/3000] Train Acc: 0.881781 Loss: 0.329248 | Val Acc: 0.167540 loss: 4.569074\n",
            "[646/3000] Train Acc: 0.879663 Loss: 0.341328 | Val Acc: 0.174395 loss: 4.490943\n",
            "[647/3000] Train Acc: 0.882688 Loss: 0.333970 | Val Acc: 0.177218 loss: 4.710170\n",
            "[648/3000] Train Acc: 0.883595 Loss: 0.333644 | Val Acc: 0.162298 loss: 4.784196\n",
            "[649/3000] Train Acc: 0.880067 Loss: 0.338741 | Val Acc: 0.175605 loss: 4.601058\n",
            "[650/3000] Train Acc: 0.882083 Loss: 0.336393 | Val Acc: 0.175605 loss: 4.576847\n",
            "[651/3000] Train Acc: 0.883343 Loss: 0.329609 | Val Acc: 0.163710 loss: 4.465350\n",
            "[652/3000] Train Acc: 0.880167 Loss: 0.336056 | Val Acc: 0.140524 loss: 4.887747\n",
            "[653/3000] Train Acc: 0.887225 Loss: 0.325303 | Val Acc: 0.167944 loss: 4.703333\n",
            "[654/3000] Train Acc: 0.885461 Loss: 0.324297 | Val Acc: 0.165726 loss: 4.700042\n",
            "[655/3000] Train Acc: 0.886066 Loss: 0.328247 | Val Acc: 0.165927 loss: 4.895387\n",
            "[656/3000] Train Acc: 0.880117 Loss: 0.336879 | Val Acc: 0.160282 loss: 4.946028\n",
            "[657/3000] Train Acc: 0.881831 Loss: 0.326673 | Val Acc: 0.163508 loss: 4.741286\n",
            "[658/3000] Train Acc: 0.884301 Loss: 0.326981 | Val Acc: 0.159879 loss: 4.856804\n",
            "[659/3000] Train Acc: 0.882033 Loss: 0.329672 | Val Acc: 0.161895 loss: 4.875659\n",
            "[660/3000] Train Acc: 0.883545 Loss: 0.333003 | Val Acc: 0.173790 loss: 4.657614\n",
            "[661/3000] Train Acc: 0.885057 Loss: 0.325629 | Val Acc: 0.171774 loss: 4.631490\n",
            "[662/3000] Train Acc: 0.884150 Loss: 0.326729 | Val Acc: 0.181653 loss: 4.843482\n",
            "[663/3000] Train Acc: 0.879159 Loss: 0.334336 | Val Acc: 0.140927 loss: 4.496841\n",
            "[664/3000] Train Acc: 0.887175 Loss: 0.320929 | Val Acc: 0.167137 loss: 4.794799\n",
            "[665/3000] Train Acc: 0.883293 Loss: 0.330060 | Val Acc: 0.168145 loss: 4.757868\n",
            "[666/3000] Train Acc: 0.885007 Loss: 0.327981 | Val Acc: 0.161694 loss: 4.697749\n",
            "[667/3000] Train Acc: 0.883898 Loss: 0.331830 | Val Acc: 0.161895 loss: 4.664367\n",
            "[668/3000] Train Acc: 0.883091 Loss: 0.328855 | Val Acc: 0.173387 loss: 4.761037\n",
            "[669/3000] Train Acc: 0.886469 Loss: 0.324762 | Val Acc: 0.167742 loss: 4.662898\n",
            "[670/3000] Train Acc: 0.885562 Loss: 0.326705 | Val Acc: 0.178226 loss: 4.483897\n",
            "[671/3000] Train Acc: 0.883545 Loss: 0.325591 | Val Acc: 0.160484 loss: 4.508557\n",
            "[672/3000] Train Acc: 0.883797 Loss: 0.324060 | Val Acc: 0.159879 loss: 4.426589\n",
            "[673/3000] Train Acc: 0.887225 Loss: 0.320941 | Val Acc: 0.163508 loss: 4.752525\n",
            "[674/3000] Train Acc: 0.885310 Loss: 0.324272 | Val Acc: 0.170766 loss: 4.663646\n",
            "[675/3000] Train Acc: 0.885662 Loss: 0.324352 | Val Acc: 0.170565 loss: 4.575915\n",
            "[676/3000] Train Acc: 0.887729 Loss: 0.322409 | Val Acc: 0.175000 loss: 4.715865\n",
            "[677/3000] Train Acc: 0.881327 Loss: 0.329876 | Val Acc: 0.155242 loss: 4.786471\n",
            "[678/3000] Train Acc: 0.882234 Loss: 0.332380 | Val Acc: 0.148185 loss: 4.651344\n",
            "[679/3000] Train Acc: 0.883848 Loss: 0.324587 | Val Acc: 0.162903 loss: 4.913132\n",
            "[680/3000] Train Acc: 0.885914 Loss: 0.318180 | Val Acc: 0.178024 loss: 4.509093\n",
            "[681/3000] Train Acc: 0.881579 Loss: 0.325827 | Val Acc: 0.172782 loss: 4.633360\n",
            "[682/3000] Train Acc: 0.886822 Loss: 0.321072 | Val Acc: 0.170766 loss: 4.731573\n",
            "[683/3000] Train Acc: 0.884856 Loss: 0.327095 | Val Acc: 0.173185 loss: 4.512301\n",
            "[684/3000] Train Acc: 0.885007 Loss: 0.325800 | Val Acc: 0.164919 loss: 4.643822\n",
            "[685/3000] Train Acc: 0.889393 Loss: 0.316616 | Val Acc: 0.167944 loss: 4.625668\n",
            "[686/3000] Train Acc: 0.887427 Loss: 0.320098 | Val Acc: 0.156048 loss: 4.776200\n",
            "[687/3000] Train Acc: 0.886923 Loss: 0.315720 | Val Acc: 0.160887 loss: 4.672720\n",
            "[688/3000] Train Acc: 0.887881 Loss: 0.314707 | Val Acc: 0.164113 loss: 5.005607\n",
            "[689/3000] Train Acc: 0.887780 Loss: 0.319673 | Val Acc: 0.176210 loss: 4.725174\n",
            "[690/3000] Train Acc: 0.888183 Loss: 0.321229 | Val Acc: 0.162903 loss: 4.997124\n",
            "[691/3000] Train Acc: 0.883293 Loss: 0.324052 | Val Acc: 0.172379 loss: 4.762833\n",
            "[692/3000] Train Acc: 0.887729 Loss: 0.321084 | Val Acc: 0.177218 loss: 4.892089\n",
            "[693/3000] Train Acc: 0.884301 Loss: 0.325067 | Val Acc: 0.173589 loss: 4.827997\n",
            "[694/3000] Train Acc: 0.887629 Loss: 0.318476 | Val Acc: 0.162097 loss: 4.765354\n",
            "[695/3000] Train Acc: 0.889595 Loss: 0.315207 | Val Acc: 0.152016 loss: 4.598759\n",
            "[696/3000] Train Acc: 0.884251 Loss: 0.321915 | Val Acc: 0.164516 loss: 4.812508\n",
            "[697/3000] Train Acc: 0.883999 Loss: 0.326306 | Val Acc: 0.161290 loss: 4.864772\n",
            "[698/3000] Train Acc: 0.890099 Loss: 0.315039 | Val Acc: 0.167137 loss: 4.477284\n",
            "[699/3000] Train Acc: 0.886973 Loss: 0.314126 | Val Acc: 0.164315 loss: 4.525963\n",
            "[700/3000] Train Acc: 0.886217 Loss: 0.316199 | Val Acc: 0.151210 loss: 4.851218\n",
            "[701/3000] Train Acc: 0.882133 Loss: 0.330749 | Val Acc: 0.164718 loss: 4.788275\n",
            "[702/3000] Train Acc: 0.885864 Loss: 0.318286 | Val Acc: 0.150806 loss: 4.480495\n",
            "[703/3000] Train Acc: 0.890704 Loss: 0.306686 | Val Acc: 0.172177 loss: 4.716942\n",
            "[704/3000] Train Acc: 0.888687 Loss: 0.317936 | Val Acc: 0.163710 loss: 4.681967\n",
            "[705/3000] Train Acc: 0.885914 Loss: 0.324080 | Val Acc: 0.148790 loss: 4.983600\n",
            "[706/3000] Train Acc: 0.883696 Loss: 0.326441 | Val Acc: 0.161290 loss: 4.750691\n",
            "[707/3000] Train Acc: 0.886167 Loss: 0.325858 | Val Acc: 0.169355 loss: 5.043002\n",
            "[708/3000] Train Acc: 0.886620 Loss: 0.318033 | Val Acc: 0.164315 loss: 4.869210\n",
            "[709/3000] Train Acc: 0.887124 Loss: 0.318998 | Val Acc: 0.163710 loss: 4.643203\n",
            "[710/3000] Train Acc: 0.893073 Loss: 0.306735 | Val Acc: 0.172782 loss: 4.824785\n",
            "[711/3000] Train Acc: 0.888334 Loss: 0.315915 | Val Acc: 0.172581 loss: 4.497608\n",
            "[712/3000] Train Acc: 0.893275 Loss: 0.306764 | Val Acc: 0.157863 loss: 4.799074\n",
            "[713/3000] Train Acc: 0.890704 Loss: 0.311256 | Val Acc: 0.148185 loss: 4.863564\n",
            "[714/3000] Train Acc: 0.891561 Loss: 0.305191 | Val Acc: 0.161694 loss: 4.881574\n",
            "[715/3000] Train Acc: 0.892015 Loss: 0.311935 | Val Acc: 0.170161 loss: 4.654005\n",
            "[716/3000] Train Acc: 0.887629 Loss: 0.313756 | Val Acc: 0.161895 loss: 4.953973\n",
            "[717/3000] Train Acc: 0.887175 Loss: 0.318852 | Val Acc: 0.183468 loss: 4.635305\n",
            "saving model with acc 0.183\n",
            "[718/3000] Train Acc: 0.890351 Loss: 0.313808 | Val Acc: 0.168347 loss: 4.943385\n",
            "[719/3000] Train Acc: 0.887326 Loss: 0.317265 | Val Acc: 0.155242 loss: 4.697961\n",
            "[720/3000] Train Acc: 0.886116 Loss: 0.320969 | Val Acc: 0.150806 loss: 4.933418\n",
            "[721/3000] Train Acc: 0.888536 Loss: 0.312322 | Val Acc: 0.169355 loss: 4.903709\n",
            "[722/3000] Train Acc: 0.888536 Loss: 0.319221 | Val Acc: 0.162298 loss: 4.926486\n",
            "[723/3000] Train Acc: 0.889242 Loss: 0.314609 | Val Acc: 0.176411 loss: 4.670722\n",
            "[724/3000] Train Acc: 0.887528 Loss: 0.313171 | Val Acc: 0.173185 loss: 4.683040\n",
            "[725/3000] Train Acc: 0.887427 Loss: 0.314610 | Val Acc: 0.174798 loss: 4.805463\n",
            "[726/3000] Train Acc: 0.890149 Loss: 0.312801 | Val Acc: 0.148992 loss: 4.765190\n",
            "[727/3000] Train Acc: 0.889242 Loss: 0.315409 | Val Acc: 0.176411 loss: 4.855070\n",
            "[728/3000] Train Acc: 0.891762 Loss: 0.310830 | Val Acc: 0.153427 loss: 4.716008\n",
            "[729/3000] Train Acc: 0.886620 Loss: 0.316081 | Val Acc: 0.171573 loss: 4.935720\n",
            "[730/3000] Train Acc: 0.885007 Loss: 0.323326 | Val Acc: 0.153024 loss: 4.877369\n",
            "[731/3000] Train Acc: 0.895443 Loss: 0.300871 | Val Acc: 0.173790 loss: 4.750381\n",
            "[732/3000] Train Acc: 0.891460 Loss: 0.307829 | Val Acc: 0.170968 loss: 4.663551\n",
            "[733/3000] Train Acc: 0.889847 Loss: 0.314388 | Val Acc: 0.166129 loss: 4.956802\n",
            "[734/3000] Train Acc: 0.890704 Loss: 0.307743 | Val Acc: 0.153226 loss: 5.070351\n",
            "[735/3000] Train Acc: 0.890401 Loss: 0.315212 | Val Acc: 0.173387 loss: 4.766664\n",
            "[736/3000] Train Acc: 0.892771 Loss: 0.305924 | Val Acc: 0.145363 loss: 4.729508\n",
            "[737/3000] Train Acc: 0.892569 Loss: 0.308534 | Val Acc: 0.180040 loss: 5.114365\n",
            "[738/3000] Train Acc: 0.887780 Loss: 0.313565 | Val Acc: 0.146573 loss: 4.786315\n",
            "[739/3000] Train Acc: 0.889847 Loss: 0.308600 | Val Acc: 0.162702 loss: 4.601047\n",
            "[740/3000] Train Acc: 0.893628 Loss: 0.303767 | Val Acc: 0.181855 loss: 4.589368\n",
            "[741/3000] Train Acc: 0.891510 Loss: 0.305769 | Val Acc: 0.151411 loss: 4.748304\n",
            "[742/3000] Train Acc: 0.886822 Loss: 0.319224 | Val Acc: 0.176008 loss: 5.034130\n",
            "[743/3000] Train Acc: 0.890805 Loss: 0.310770 | Val Acc: 0.173387 loss: 4.754561\n",
            "[744/3000] Train Acc: 0.894081 Loss: 0.301736 | Val Acc: 0.167944 loss: 4.656352\n",
            "[745/3000] Train Acc: 0.895947 Loss: 0.296477 | Val Acc: 0.175806 loss: 4.511265\n",
            "[746/3000] Train Acc: 0.888082 Loss: 0.312291 | Val Acc: 0.169960 loss: 4.718289\n",
            "[747/3000] Train Acc: 0.892771 Loss: 0.306531 | Val Acc: 0.161492 loss: 4.818198\n",
            "[748/3000] Train Acc: 0.891762 Loss: 0.310289 | Val Acc: 0.129839 loss: 5.111724\n",
            "[749/3000] Train Acc: 0.894888 Loss: 0.300129 | Val Acc: 0.162097 loss: 4.967390\n",
            "[750/3000] Train Acc: 0.895846 Loss: 0.299684 | Val Acc: 0.165524 loss: 4.849188\n",
            "[751/3000] Train Acc: 0.890855 Loss: 0.309462 | Val Acc: 0.181855 loss: 4.746690\n",
            "[752/3000] Train Acc: 0.890048 Loss: 0.308091 | Val Acc: 0.137298 loss: 4.954244\n",
            "[753/3000] Train Acc: 0.893981 Loss: 0.303839 | Val Acc: 0.181653 loss: 5.004323\n",
            "[754/3000] Train Acc: 0.891611 Loss: 0.302689 | Val Acc: 0.167339 loss: 4.972264\n",
            "[755/3000] Train Acc: 0.894182 Loss: 0.304282 | Val Acc: 0.173387 loss: 4.905498\n",
            "[756/3000] Train Acc: 0.892872 Loss: 0.305065 | Val Acc: 0.149798 loss: 4.952751\n",
            "[757/3000] Train Acc: 0.896955 Loss: 0.290928 | Val Acc: 0.158669 loss: 4.945257\n",
            "[758/3000] Train Acc: 0.892872 Loss: 0.302820 | Val Acc: 0.176815 loss: 4.914251\n",
            "[759/3000] Train Acc: 0.891057 Loss: 0.302682 | Val Acc: 0.174395 loss: 4.984303\n",
            "[760/3000] Train Acc: 0.895695 Loss: 0.299581 | Val Acc: 0.167137 loss: 4.680341\n",
            "[761/3000] Train Acc: 0.890351 Loss: 0.308978 | Val Acc: 0.162702 loss: 4.690575\n",
            "[762/3000] Train Acc: 0.890200 Loss: 0.307732 | Val Acc: 0.173387 loss: 4.813021\n",
            "[763/3000] Train Acc: 0.890250 Loss: 0.307243 | Val Acc: 0.166935 loss: 4.664485\n",
            "[764/3000] Train Acc: 0.894838 Loss: 0.294933 | Val Acc: 0.173185 loss: 4.789179\n",
            "[765/3000] Train Acc: 0.896703 Loss: 0.289924 | Val Acc: 0.159677 loss: 5.112668\n",
            "[766/3000] Train Acc: 0.892872 Loss: 0.299799 | Val Acc: 0.156452 loss: 4.599670\n",
            "[767/3000] Train Acc: 0.890603 Loss: 0.308460 | Val Acc: 0.168548 loss: 4.718561\n",
            "[768/3000] Train Acc: 0.893275 Loss: 0.302630 | Val Acc: 0.155242 loss: 5.044661\n",
            "[769/3000] Train Acc: 0.891208 Loss: 0.307671 | Val Acc: 0.172379 loss: 4.837458\n",
            "[770/3000] Train Acc: 0.890553 Loss: 0.306673 | Val Acc: 0.174798 loss: 4.553578\n",
            "[771/3000] Train Acc: 0.893779 Loss: 0.298650 | Val Acc: 0.171169 loss: 4.646200\n",
            "[772/3000] Train Acc: 0.894233 Loss: 0.300253 | Val Acc: 0.158871 loss: 5.046775\n",
            "[773/3000] Train Acc: 0.894081 Loss: 0.301990 | Val Acc: 0.167944 loss: 4.727579\n",
            "[774/3000] Train Acc: 0.901291 Loss: 0.285169 | Val Acc: 0.171976 loss: 4.512241\n",
            "[775/3000] Train Acc: 0.894233 Loss: 0.299588 | Val Acc: 0.184476 loss: 4.857307\n",
            "saving model with acc 0.184\n",
            "[776/3000] Train Acc: 0.894434 Loss: 0.294961 | Val Acc: 0.177419 loss: 5.017023\n",
            "[777/3000] Train Acc: 0.890250 Loss: 0.304991 | Val Acc: 0.159476 loss: 4.936457\n",
            "[778/3000] Train Acc: 0.890099 Loss: 0.305386 | Val Acc: 0.175403 loss: 4.912807\n",
            "[779/3000] Train Acc: 0.894132 Loss: 0.297896 | Val Acc: 0.166734 loss: 5.241467\n",
            "[780/3000] Train Acc: 0.897862 Loss: 0.290974 | Val Acc: 0.167339 loss: 4.940920\n",
            "[781/3000] Train Acc: 0.895695 Loss: 0.295787 | Val Acc: 0.159879 loss: 4.814407\n",
            "[782/3000] Train Acc: 0.896451 Loss: 0.292492 | Val Acc: 0.165121 loss: 5.066523\n",
            "[783/3000] Train Acc: 0.894132 Loss: 0.298346 | Val Acc: 0.172177 loss: 4.570319\n",
            "[784/3000] Train Acc: 0.896148 Loss: 0.290422 | Val Acc: 0.168750 loss: 4.891957\n",
            "[785/3000] Train Acc: 0.894081 Loss: 0.299452 | Val Acc: 0.163508 loss: 4.823171\n",
            "[786/3000] Train Acc: 0.895090 Loss: 0.299557 | Val Acc: 0.163911 loss: 4.753769\n",
            "[787/3000] Train Acc: 0.894434 Loss: 0.299966 | Val Acc: 0.156250 loss: 5.086941\n",
            "[788/3000] Train Acc: 0.895392 Loss: 0.296203 | Val Acc: 0.160685 loss: 4.994676\n",
            "[789/3000] Train Acc: 0.895947 Loss: 0.295075 | Val Acc: 0.176008 loss: 4.795397\n",
            "[790/3000] Train Acc: 0.896048 Loss: 0.295286 | Val Acc: 0.168347 loss: 4.894944\n",
            "[791/3000] Train Acc: 0.891258 Loss: 0.300649 | Val Acc: 0.172984 loss: 4.804059\n",
            "[792/3000] Train Acc: 0.895140 Loss: 0.299613 | Val Acc: 0.171169 loss: 4.869724\n",
            "[793/3000] Train Acc: 0.896653 Loss: 0.294397 | Val Acc: 0.172177 loss: 4.765728\n",
            "[794/3000] Train Acc: 0.894132 Loss: 0.297250 | Val Acc: 0.167339 loss: 4.832237\n",
            "[795/3000] Train Acc: 0.894737 Loss: 0.295913 | Val Acc: 0.145363 loss: 4.799144\n",
            "[796/3000] Train Acc: 0.892821 Loss: 0.300327 | Val Acc: 0.179637 loss: 4.936380\n",
            "[797/3000] Train Acc: 0.893779 Loss: 0.295960 | Val Acc: 0.172177 loss: 5.020785\n",
            "[798/3000] Train Acc: 0.895947 Loss: 0.294137 | Val Acc: 0.180040 loss: 4.844583\n",
            "[799/3000] Train Acc: 0.898669 Loss: 0.291780 | Val Acc: 0.151613 loss: 4.817843\n",
            "[800/3000] Train Acc: 0.894737 Loss: 0.297477 | Val Acc: 0.170968 loss: 5.093471\n",
            "[801/3000] Train Acc: 0.896451 Loss: 0.294315 | Val Acc: 0.165927 loss: 4.868127\n",
            "[802/3000] Train Acc: 0.901543 Loss: 0.283550 | Val Acc: 0.169758 loss: 4.547773\n",
            "[803/3000] Train Acc: 0.894989 Loss: 0.299246 | Val Acc: 0.163105 loss: 5.106403\n",
            "[804/3000] Train Acc: 0.893426 Loss: 0.296396 | Val Acc: 0.174395 loss: 4.832255\n",
            "[805/3000] Train Acc: 0.897711 Loss: 0.290872 | Val Acc: 0.167944 loss: 4.998126\n",
            "[806/3000] Train Acc: 0.894888 Loss: 0.297594 | Val Acc: 0.175403 loss: 4.554699\n",
            "[807/3000] Train Acc: 0.900232 Loss: 0.281848 | Val Acc: 0.171371 loss: 4.816961\n",
            "[808/3000] Train Acc: 0.894132 Loss: 0.301858 | Val Acc: 0.176008 loss: 4.977456\n",
            "[809/3000] Train Acc: 0.901896 Loss: 0.281502 | Val Acc: 0.179435 loss: 4.808702\n",
            "[810/3000] Train Acc: 0.898266 Loss: 0.288347 | Val Acc: 0.174395 loss: 5.024855\n",
            "[811/3000] Train Acc: 0.900786 Loss: 0.284437 | Val Acc: 0.178024 loss: 4.769536\n",
            "[812/3000] Train Acc: 0.895543 Loss: 0.295250 | Val Acc: 0.144556 loss: 5.124934\n",
            "[813/3000] Train Acc: 0.896098 Loss: 0.294841 | Val Acc: 0.179435 loss: 4.781785\n",
            "[814/3000] Train Acc: 0.898921 Loss: 0.285514 | Val Acc: 0.160081 loss: 4.921275\n",
            "[815/3000] Train Acc: 0.897056 Loss: 0.290897 | Val Acc: 0.165927 loss: 4.811377\n",
            "[816/3000] Train Acc: 0.898215 Loss: 0.281173 | Val Acc: 0.175202 loss: 4.929025\n",
            "[817/3000] Train Acc: 0.897610 Loss: 0.286947 | Val Acc: 0.162903 loss: 4.966943\n",
            "[818/3000] Train Acc: 0.898165 Loss: 0.289560 | Val Acc: 0.173992 loss: 4.818321\n",
            "[819/3000] Train Acc: 0.899677 Loss: 0.286656 | Val Acc: 0.179234 loss: 4.624049\n",
            "[820/3000] Train Acc: 0.898719 Loss: 0.284506 | Val Acc: 0.158468 loss: 4.845787\n",
            "[821/3000] Train Acc: 0.897963 Loss: 0.288799 | Val Acc: 0.171573 loss: 4.909563\n",
            "[822/3000] Train Acc: 0.895039 Loss: 0.295528 | Val Acc: 0.172984 loss: 4.671850\n",
            "[823/3000] Train Acc: 0.900635 Loss: 0.283406 | Val Acc: 0.179637 loss: 4.961921\n",
            "[824/3000] Train Acc: 0.901039 Loss: 0.277906 | Val Acc: 0.172782 loss: 4.682313\n",
            "[825/3000] Train Acc: 0.897308 Loss: 0.290509 | Val Acc: 0.177823 loss: 4.887456\n",
            "[826/3000] Train Acc: 0.900232 Loss: 0.279100 | Val Acc: 0.163911 loss: 4.762740\n",
            "[827/3000] Train Acc: 0.900786 Loss: 0.281017 | Val Acc: 0.165323 loss: 4.902475\n",
            "[828/3000] Train Acc: 0.897560 Loss: 0.287634 | Val Acc: 0.165121 loss: 4.737742\n",
            "[829/3000] Train Acc: 0.899778 Loss: 0.288268 | Val Acc: 0.152016 loss: 5.012807\n",
            "[830/3000] Train Acc: 0.899879 Loss: 0.283703 | Val Acc: 0.165323 loss: 5.162840\n",
            "[831/3000] Train Acc: 0.900887 Loss: 0.283441 | Val Acc: 0.159274 loss: 5.185022\n",
            "[832/3000] Train Acc: 0.897610 Loss: 0.288314 | Val Acc: 0.166129 loss: 5.131953\n",
            "[833/3000] Train Acc: 0.901593 Loss: 0.284022 | Val Acc: 0.178831 loss: 4.877437\n",
            "[834/3000] Train Acc: 0.903761 Loss: 0.280014 | Val Acc: 0.159879 loss: 4.928256\n",
            "[835/3000] Train Acc: 0.900837 Loss: 0.284295 | Val Acc: 0.171573 loss: 4.654913\n",
            "[836/3000] Train Acc: 0.897812 Loss: 0.287006 | Val Acc: 0.173387 loss: 4.816224\n",
            "[837/3000] Train Acc: 0.904971 Loss: 0.274821 | Val Acc: 0.165524 loss: 4.756147\n",
            "[838/3000] Train Acc: 0.897308 Loss: 0.287136 | Val Acc: 0.162097 loss: 5.003118\n",
            "[839/3000] Train Acc: 0.899677 Loss: 0.285020 | Val Acc: 0.164516 loss: 5.104905\n",
            "[840/3000] Train Acc: 0.900333 Loss: 0.286402 | Val Acc: 0.171976 loss: 5.012161\n",
            "[841/3000] Train Acc: 0.900232 Loss: 0.285337 | Val Acc: 0.160484 loss: 4.732578\n",
            "[842/3000] Train Acc: 0.900786 Loss: 0.279296 | Val Acc: 0.153831 loss: 5.002533\n",
            "[843/3000] Train Acc: 0.894485 Loss: 0.291350 | Val Acc: 0.171774 loss: 5.042946\n",
            "[844/3000] Train Acc: 0.901089 Loss: 0.279773 | Val Acc: 0.175605 loss: 4.841001\n",
            "[845/3000] Train Acc: 0.897862 Loss: 0.283955 | Val Acc: 0.160887 loss: 5.067385\n",
            "[846/3000] Train Acc: 0.899476 Loss: 0.286649 | Val Acc: 0.138508 loss: 5.128080\n",
            "[847/3000] Train Acc: 0.898014 Loss: 0.284759 | Val Acc: 0.170968 loss: 4.970693\n",
            "[848/3000] Train Acc: 0.900837 Loss: 0.281627 | Val Acc: 0.171774 loss: 4.993355\n",
            "[849/3000] Train Acc: 0.898014 Loss: 0.287392 | Val Acc: 0.157661 loss: 4.750425\n",
            "[850/3000] Train Acc: 0.899778 Loss: 0.283138 | Val Acc: 0.157863 loss: 4.959458\n",
            "[851/3000] Train Acc: 0.903358 Loss: 0.274315 | Val Acc: 0.162903 loss: 5.060369\n",
            "[852/3000] Train Acc: 0.901492 Loss: 0.276066 | Val Acc: 0.165323 loss: 4.969961\n",
            "[853/3000] Train Acc: 0.900686 Loss: 0.287541 | Val Acc: 0.171169 loss: 4.980174\n",
            "[854/3000] Train Acc: 0.902904 Loss: 0.279686 | Val Acc: 0.162298 loss: 4.980300\n",
            "[855/3000] Train Acc: 0.899577 Loss: 0.284455 | Val Acc: 0.168750 loss: 5.000366\n",
            "[856/3000] Train Acc: 0.899677 Loss: 0.280735 | Val Acc: 0.183065 loss: 4.598692\n",
            "[857/3000] Train Acc: 0.903005 Loss: 0.280999 | Val Acc: 0.181048 loss: 5.017008\n",
            "[858/3000] Train Acc: 0.899577 Loss: 0.283510 | Val Acc: 0.175202 loss: 5.128177\n",
            "[859/3000] Train Acc: 0.900534 Loss: 0.278845 | Val Acc: 0.164113 loss: 4.919744\n",
            "[860/3000] Train Acc: 0.904114 Loss: 0.274786 | Val Acc: 0.172177 loss: 4.869933\n",
            "[861/3000] Train Acc: 0.904618 Loss: 0.272479 | Val Acc: 0.164315 loss: 4.969060\n",
            "[862/3000] Train Acc: 0.903156 Loss: 0.277012 | Val Acc: 0.163710 loss: 4.965922\n",
            "[863/3000] Train Acc: 0.899324 Loss: 0.289883 | Val Acc: 0.184073 loss: 4.894221\n",
            "[864/3000] Train Acc: 0.905324 Loss: 0.270357 | Val Acc: 0.164315 loss: 4.830130\n",
            "[865/3000] Train Acc: 0.903408 Loss: 0.275197 | Val Acc: 0.163105 loss: 4.992055\n",
            "[866/3000] Train Acc: 0.901845 Loss: 0.277645 | Val Acc: 0.163710 loss: 5.229281\n",
            "[867/3000] Train Acc: 0.898669 Loss: 0.281930 | Val Acc: 0.171169 loss: 4.682798\n",
            "[868/3000] Train Acc: 0.905727 Loss: 0.270203 | Val Acc: 0.181250 loss: 4.967831\n",
            "[869/3000] Train Acc: 0.903458 Loss: 0.276266 | Val Acc: 0.168347 loss: 4.545751\n",
            "[870/3000] Train Acc: 0.899072 Loss: 0.282407 | Val Acc: 0.169960 loss: 4.831848\n",
            "[871/3000] Train Acc: 0.904668 Loss: 0.273038 | Val Acc: 0.175605 loss: 5.372860\n",
            "[872/3000] Train Acc: 0.901291 Loss: 0.281277 | Val Acc: 0.159879 loss: 4.925498\n",
            "[873/3000] Train Acc: 0.902652 Loss: 0.276561 | Val Acc: 0.168145 loss: 4.702357\n",
            "[874/3000] Train Acc: 0.900383 Loss: 0.278396 | Val Acc: 0.166734 loss: 5.022135\n",
            "[875/3000] Train Acc: 0.901643 Loss: 0.278535 | Val Acc: 0.168952 loss: 5.004137\n",
            "[876/3000] Train Acc: 0.905223 Loss: 0.269861 | Val Acc: 0.160282 loss: 5.058149\n",
            "[877/3000] Train Acc: 0.901492 Loss: 0.278304 | Val Acc: 0.165121 loss: 5.217466\n",
            "[878/3000] Train Acc: 0.901139 Loss: 0.278241 | Val Acc: 0.167540 loss: 4.979970\n",
            "[879/3000] Train Acc: 0.902450 Loss: 0.279229 | Val Acc: 0.170161 loss: 5.127106\n",
            "[880/3000] Train Acc: 0.898014 Loss: 0.291807 | Val Acc: 0.163105 loss: 4.779381\n",
            "[881/3000] Train Acc: 0.902148 Loss: 0.276018 | Val Acc: 0.183468 loss: 5.055656\n",
            "[882/3000] Train Acc: 0.902904 Loss: 0.272551 | Val Acc: 0.156250 loss: 5.054933\n",
            "[883/3000] Train Acc: 0.904920 Loss: 0.273158 | Val Acc: 0.159274 loss: 4.946061\n",
            "[884/3000] Train Acc: 0.900282 Loss: 0.280945 | Val Acc: 0.175605 loss: 4.631145\n",
            "[885/3000] Train Acc: 0.903811 Loss: 0.270535 | Val Acc: 0.169960 loss: 4.951118\n",
            "[886/3000] Train Acc: 0.901643 Loss: 0.278196 | Val Acc: 0.179234 loss: 5.005625\n",
            "[887/3000] Train Acc: 0.902299 Loss: 0.273174 | Val Acc: 0.177621 loss: 5.144491\n",
            "[888/3000] Train Acc: 0.902954 Loss: 0.273903 | Val Acc: 0.173185 loss: 4.956987\n",
            "[889/3000] Train Acc: 0.900081 Loss: 0.279161 | Val Acc: 0.151411 loss: 5.088451\n",
            "[890/3000] Train Acc: 0.901643 Loss: 0.278697 | Val Acc: 0.162702 loss: 4.761061\n",
            "[891/3000] Train Acc: 0.899879 Loss: 0.286338 | Val Acc: 0.158468 loss: 5.070449\n",
            "[892/3000] Train Acc: 0.898518 Loss: 0.283448 | Val Acc: 0.161895 loss: 4.834539\n",
            "[893/3000] Train Acc: 0.902198 Loss: 0.275771 | Val Acc: 0.167339 loss: 5.160171\n",
            "[894/3000] Train Acc: 0.900786 Loss: 0.272729 | Val Acc: 0.169556 loss: 5.032163\n",
            "[895/3000] Train Acc: 0.899879 Loss: 0.282282 | Val Acc: 0.177016 loss: 4.930623\n",
            "[896/3000] Train Acc: 0.903710 Loss: 0.275225 | Val Acc: 0.167137 loss: 5.007065\n",
            "[897/3000] Train Acc: 0.906382 Loss: 0.267080 | Val Acc: 0.178629 loss: 5.069831\n",
            "[898/3000] Train Acc: 0.899980 Loss: 0.274429 | Val Acc: 0.173992 loss: 4.931319\n",
            "[899/3000] Train Acc: 0.905021 Loss: 0.269492 | Val Acc: 0.172379 loss: 4.915354\n",
            "[900/3000] Train Acc: 0.901996 Loss: 0.274548 | Val Acc: 0.168750 loss: 5.162876\n",
            "[901/3000] Train Acc: 0.896249 Loss: 0.289837 | Val Acc: 0.147177 loss: 4.927544\n",
            "[902/3000] Train Acc: 0.905324 Loss: 0.269712 | Val Acc: 0.188710 loss: 4.999592\n",
            "saving model with acc 0.189\n",
            "[903/3000] Train Acc: 0.905424 Loss: 0.265107 | Val Acc: 0.158468 loss: 5.278188\n",
            "[904/3000] Train Acc: 0.905677 Loss: 0.266351 | Val Acc: 0.156452 loss: 5.012835\n",
            "[905/3000] Train Acc: 0.906786 Loss: 0.264527 | Val Acc: 0.184073 loss: 4.998067\n",
            "[906/3000] Train Acc: 0.905072 Loss: 0.269763 | Val Acc: 0.175000 loss: 5.126628\n",
            "[907/3000] Train Acc: 0.903710 Loss: 0.274325 | Val Acc: 0.167944 loss: 5.117155\n",
            "[908/3000] Train Acc: 0.902097 Loss: 0.276877 | Val Acc: 0.137298 loss: 5.376800\n",
            "[909/3000] Train Acc: 0.894989 Loss: 0.292332 | Val Acc: 0.171774 loss: 5.144790\n",
            "[910/3000] Train Acc: 0.901643 Loss: 0.279013 | Val Acc: 0.182460 loss: 5.317000\n",
            "[911/3000] Train Acc: 0.905172 Loss: 0.269907 | Val Acc: 0.170161 loss: 5.074107\n",
            "[912/3000] Train Acc: 0.904618 Loss: 0.268242 | Val Acc: 0.171774 loss: 4.967886\n",
            "[913/3000] Train Acc: 0.905626 Loss: 0.267432 | Val Acc: 0.176210 loss: 5.003683\n",
            "[914/3000] Train Acc: 0.908096 Loss: 0.267294 | Val Acc: 0.176815 loss: 4.859819\n",
            "[915/3000] Train Acc: 0.907391 Loss: 0.265421 | Val Acc: 0.167339 loss: 5.251373\n",
            "[916/3000] Train Acc: 0.902803 Loss: 0.272355 | Val Acc: 0.179839 loss: 4.882628\n",
            "[917/3000] Train Acc: 0.903509 Loss: 0.276218 | Val Acc: 0.172379 loss: 5.105518\n",
            "[918/3000] Train Acc: 0.904820 Loss: 0.268250 | Val Acc: 0.176210 loss: 5.097240\n",
            "[919/3000] Train Acc: 0.907038 Loss: 0.265518 | Val Acc: 0.172782 loss: 5.150454\n",
            "[920/3000] Train Acc: 0.903610 Loss: 0.270475 | Val Acc: 0.177823 loss: 5.009612\n",
            "[921/3000] Train Acc: 0.905324 Loss: 0.269634 | Val Acc: 0.174597 loss: 5.276515\n",
            "[922/3000] Train Acc: 0.905374 Loss: 0.269094 | Val Acc: 0.167944 loss: 4.912819\n",
            "[923/3000] Train Acc: 0.908601 Loss: 0.262503 | Val Acc: 0.179435 loss: 5.063159\n",
            "[924/3000] Train Acc: 0.902904 Loss: 0.273646 | Val Acc: 0.170968 loss: 4.687600\n",
            "[925/3000] Train Acc: 0.905424 Loss: 0.272296 | Val Acc: 0.175403 loss: 5.118055\n",
            "[926/3000] Train Acc: 0.903509 Loss: 0.274718 | Val Acc: 0.194758 loss: 5.071350\n",
            "saving model with acc 0.195\n",
            "[927/3000] Train Acc: 0.905576 Loss: 0.266019 | Val Acc: 0.161694 loss: 5.352954\n",
            "[928/3000] Train Acc: 0.908046 Loss: 0.259955 | Val Acc: 0.149597 loss: 4.966983\n",
            "[929/3000] Train Acc: 0.908802 Loss: 0.261577 | Val Acc: 0.181250 loss: 4.813565\n",
            "[930/3000] Train Acc: 0.905727 Loss: 0.268947 | Val Acc: 0.160484 loss: 5.269695\n",
            "[931/3000] Train Acc: 0.907592 Loss: 0.264112 | Val Acc: 0.182661 loss: 5.045796\n",
            "[932/3000] Train Acc: 0.906282 Loss: 0.264522 | Val Acc: 0.180242 loss: 4.840831\n",
            "[933/3000] Train Acc: 0.904114 Loss: 0.270700 | Val Acc: 0.174395 loss: 5.027373\n",
            "[934/3000] Train Acc: 0.909508 Loss: 0.262458 | Val Acc: 0.177218 loss: 4.919163\n",
            "[935/3000] Train Acc: 0.902097 Loss: 0.274999 | Val Acc: 0.162097 loss: 5.047040\n",
            "[936/3000] Train Acc: 0.900282 Loss: 0.280373 | Val Acc: 0.181250 loss: 5.130561\n",
            "[937/3000] Train Acc: 0.906080 Loss: 0.268922 | Val Acc: 0.173185 loss: 5.024746\n",
            "[938/3000] Train Acc: 0.907441 Loss: 0.267454 | Val Acc: 0.173790 loss: 4.376410\n",
            "[939/3000] Train Acc: 0.910264 Loss: 0.256537 | Val Acc: 0.164315 loss: 4.858877\n",
            "[940/3000] Train Acc: 0.904517 Loss: 0.266558 | Val Acc: 0.173992 loss: 4.967568\n",
            "[941/3000] Train Acc: 0.907491 Loss: 0.263218 | Val Acc: 0.186492 loss: 5.222861\n",
            "[942/3000] Train Acc: 0.906282 Loss: 0.265245 | Val Acc: 0.180040 loss: 5.364090\n",
            "[943/3000] Train Acc: 0.899173 Loss: 0.278572 | Val Acc: 0.149798 loss: 5.154991\n",
            "[944/3000] Train Acc: 0.910869 Loss: 0.257037 | Val Acc: 0.175202 loss: 4.988120\n",
            "[945/3000] Train Acc: 0.905122 Loss: 0.270067 | Val Acc: 0.156452 loss: 4.943855\n",
            "[946/3000] Train Acc: 0.904567 Loss: 0.274201 | Val Acc: 0.168548 loss: 5.077445\n",
            "[947/3000] Train Acc: 0.905223 Loss: 0.268646 | Val Acc: 0.174597 loss: 4.923636\n",
            "[948/3000] Train Acc: 0.906282 Loss: 0.264819 | Val Acc: 0.189113 loss: 4.994274\n",
            "[949/3000] Train Acc: 0.905979 Loss: 0.265638 | Val Acc: 0.160282 loss: 5.119105\n",
            "[950/3000] Train Acc: 0.906282 Loss: 0.264777 | Val Acc: 0.164113 loss: 5.167119\n",
            "[951/3000] Train Acc: 0.906685 Loss: 0.259463 | Val Acc: 0.201210 loss: 4.793537\n",
            "saving model with acc 0.201\n",
            "[952/3000] Train Acc: 0.905878 Loss: 0.265228 | Val Acc: 0.168145 loss: 5.015605\n",
            "[953/3000] Train Acc: 0.903257 Loss: 0.271438 | Val Acc: 0.167339 loss: 5.242141\n",
            "[954/3000] Train Acc: 0.907743 Loss: 0.263838 | Val Acc: 0.160282 loss: 5.322606\n",
            "[955/3000] Train Acc: 0.907693 Loss: 0.260497 | Val Acc: 0.183669 loss: 5.416679\n",
            "[956/3000] Train Acc: 0.903912 Loss: 0.270306 | Val Acc: 0.167137 loss: 4.904147\n",
            "[957/3000] Train Acc: 0.907794 Loss: 0.261863 | Val Acc: 0.183871 loss: 4.937126\n",
            "[958/3000] Train Acc: 0.909911 Loss: 0.257294 | Val Acc: 0.164516 loss: 4.993900\n",
            "[959/3000] Train Acc: 0.911121 Loss: 0.255355 | Val Acc: 0.174597 loss: 5.005759\n",
            "[960/3000] Train Acc: 0.907895 Loss: 0.260961 | Val Acc: 0.186895 loss: 4.729603\n",
            "[961/3000] Train Acc: 0.903660 Loss: 0.268628 | Val Acc: 0.181452 loss: 4.970916\n",
            "[962/3000] Train Acc: 0.906685 Loss: 0.263917 | Val Acc: 0.158266 loss: 5.385478\n",
            "[963/3000] Train Acc: 0.908500 Loss: 0.256970 | Val Acc: 0.181452 loss: 4.991520\n",
            "[964/3000] Train Acc: 0.907239 Loss: 0.263068 | Val Acc: 0.168952 loss: 4.906218\n",
            "[965/3000] Train Acc: 0.906130 Loss: 0.263561 | Val Acc: 0.164919 loss: 4.919041\n",
            "[966/3000] Train Acc: 0.904920 Loss: 0.262761 | Val Acc: 0.165121 loss: 4.976118\n",
            "[967/3000] Train Acc: 0.904063 Loss: 0.270046 | Val Acc: 0.159677 loss: 5.207754\n",
            "[968/3000] Train Acc: 0.910264 Loss: 0.259191 | Val Acc: 0.187500 loss: 5.067541\n",
            "[969/3000] Train Acc: 0.906282 Loss: 0.262317 | Val Acc: 0.171976 loss: 5.233972\n",
            "[970/3000] Train Acc: 0.910264 Loss: 0.257443 | Val Acc: 0.164516 loss: 4.861183\n",
            "[971/3000] Train Acc: 0.909105 Loss: 0.259606 | Val Acc: 0.177218 loss: 5.040990\n",
            "[972/3000] Train Acc: 0.903105 Loss: 0.267662 | Val Acc: 0.168347 loss: 5.372079\n",
            "[973/3000] Train Acc: 0.908853 Loss: 0.260280 | Val Acc: 0.175403 loss: 5.093285\n",
            "[974/3000] Train Acc: 0.907340 Loss: 0.264547 | Val Acc: 0.182258 loss: 4.971193\n",
            "[975/3000] Train Acc: 0.908550 Loss: 0.260527 | Val Acc: 0.181048 loss: 5.065771\n",
            "[976/3000] Train Acc: 0.910466 Loss: 0.252187 | Val Acc: 0.180847 loss: 4.837297\n",
            "[977/3000] Train Acc: 0.907038 Loss: 0.263878 | Val Acc: 0.150806 loss: 5.085848\n",
            "[978/3000] Train Acc: 0.908147 Loss: 0.257676 | Val Acc: 0.185081 loss: 4.910353\n",
            "[979/3000] Train Acc: 0.907895 Loss: 0.257688 | Val Acc: 0.174597 loss: 4.977401\n",
            "[980/3000] Train Acc: 0.906029 Loss: 0.267339 | Val Acc: 0.181855 loss: 4.911092\n",
            "[981/3000] Train Acc: 0.911222 Loss: 0.250804 | Val Acc: 0.156250 loss: 5.247869\n",
            "[982/3000] Train Acc: 0.908096 Loss: 0.258781 | Val Acc: 0.184677 loss: 5.018902\n",
            "[983/3000] Train Acc: 0.901795 Loss: 0.269523 | Val Acc: 0.175605 loss: 5.134231\n",
            "[984/3000] Train Acc: 0.909810 Loss: 0.257574 | Val Acc: 0.175403 loss: 4.696423\n",
            "[985/3000] Train Acc: 0.907290 Loss: 0.259655 | Val Acc: 0.182056 loss: 4.903982\n",
            "[986/3000] Train Acc: 0.908500 Loss: 0.258345 | Val Acc: 0.175403 loss: 4.889898\n",
            "[987/3000] Train Acc: 0.911071 Loss: 0.255382 | Val Acc: 0.184073 loss: 5.056867\n",
            "[988/3000] Train Acc: 0.908449 Loss: 0.255357 | Val Acc: 0.185887 loss: 4.997249\n",
            "[989/3000] Train Acc: 0.910768 Loss: 0.251626 | Val Acc: 0.177621 loss: 4.770876\n",
            "[990/3000] Train Acc: 0.909962 Loss: 0.254589 | Val Acc: 0.169960 loss: 5.360942\n",
            "[991/3000] Train Acc: 0.905072 Loss: 0.271925 | Val Acc: 0.182258 loss: 5.249929\n",
            "[992/3000] Train Acc: 0.910012 Loss: 0.262384 | Val Acc: 0.169960 loss: 5.246216\n",
            "[993/3000] Train Acc: 0.908096 Loss: 0.259734 | Val Acc: 0.171976 loss: 4.925665\n",
            "[994/3000] Train Acc: 0.910466 Loss: 0.249181 | Val Acc: 0.176411 loss: 4.680682\n",
            "[995/3000] Train Acc: 0.907491 Loss: 0.258507 | Val Acc: 0.155645 loss: 5.066001\n",
            "[996/3000] Train Acc: 0.912785 Loss: 0.249010 | Val Acc: 0.153024 loss: 5.070914\n",
            "[997/3000] Train Acc: 0.908903 Loss: 0.259685 | Val Acc: 0.170565 loss: 5.406942\n",
            "[998/3000] Train Acc: 0.912029 Loss: 0.250321 | Val Acc: 0.171169 loss: 5.072243\n",
            "[999/3000] Train Acc: 0.907592 Loss: 0.262917 | Val Acc: 0.175806 loss: 5.327731\n",
            "[1000/3000] Train Acc: 0.907743 Loss: 0.260241 | Val Acc: 0.173185 loss: 4.739340\n",
            "[1001/3000] Train Acc: 0.908903 Loss: 0.256679 | Val Acc: 0.173185 loss: 5.032919\n",
            "[1002/3000] Train Acc: 0.911525 Loss: 0.250037 | Val Acc: 0.161290 loss: 5.131818\n",
            "[1003/3000] Train Acc: 0.915810 Loss: 0.247205 | Val Acc: 0.178024 loss: 5.109058\n",
            "[1004/3000] Train Acc: 0.908752 Loss: 0.258658 | Val Acc: 0.174395 loss: 5.005078\n",
            "[1005/3000] Train Acc: 0.907794 Loss: 0.259838 | Val Acc: 0.160484 loss: 5.096776\n",
            "[1006/3000] Train Acc: 0.912079 Loss: 0.251551 | Val Acc: 0.168750 loss: 5.253174\n",
            "[1007/3000] Train Acc: 0.911172 Loss: 0.253114 | Val Acc: 0.170363 loss: 5.145296\n",
            "[1008/3000] Train Acc: 0.911827 Loss: 0.252522 | Val Acc: 0.152419 loss: 5.221475\n",
            "[1009/3000] Train Acc: 0.915104 Loss: 0.244887 | Val Acc: 0.168750 loss: 5.266209\n",
            "[1010/3000] Train Acc: 0.908348 Loss: 0.257015 | Val Acc: 0.182460 loss: 4.867506\n",
            "[1011/3000] Train Acc: 0.911373 Loss: 0.250301 | Val Acc: 0.174194 loss: 5.167072\n",
            "[1012/3000] Train Acc: 0.912583 Loss: 0.250119 | Val Acc: 0.175605 loss: 5.141496\n",
            "[1013/3000] Train Acc: 0.909710 Loss: 0.254440 | Val Acc: 0.179032 loss: 5.073752\n",
            "[1014/3000] Train Acc: 0.912936 Loss: 0.247346 | Val Acc: 0.176613 loss: 5.108186\n",
            "[1015/3000] Train Acc: 0.908046 Loss: 0.256794 | Val Acc: 0.173185 loss: 4.923219\n",
            "[1016/3000] Train Acc: 0.912382 Loss: 0.250897 | Val Acc: 0.161694 loss: 5.226202\n",
            "[1017/3000] Train Acc: 0.912634 Loss: 0.249128 | Val Acc: 0.153427 loss: 5.350443\n",
            "[1018/3000] Train Acc: 0.906029 Loss: 0.264637 | Val Acc: 0.152218 loss: 5.349064\n",
            "[1019/3000] Train Acc: 0.910869 Loss: 0.256135 | Val Acc: 0.169960 loss: 5.128225\n",
            "[1020/3000] Train Acc: 0.910415 Loss: 0.254846 | Val Acc: 0.198790 loss: 4.716976\n",
            "[1021/3000] Train Acc: 0.912785 Loss: 0.247831 | Val Acc: 0.166331 loss: 5.128896\n",
            "[1022/3000] Train Acc: 0.913339 Loss: 0.247044 | Val Acc: 0.180444 loss: 5.129234\n",
            "[1023/3000] Train Acc: 0.909205 Loss: 0.257624 | Val Acc: 0.166935 loss: 4.939265\n",
            "[1024/3000] Train Acc: 0.913491 Loss: 0.248717 | Val Acc: 0.184476 loss: 5.329316\n",
            "[1025/3000] Train Acc: 0.914549 Loss: 0.249107 | Val Acc: 0.178831 loss: 5.133147\n",
            "[1026/3000] Train Acc: 0.907743 Loss: 0.261590 | Val Acc: 0.183669 loss: 5.019357\n",
            "[1027/3000] Train Acc: 0.915205 Loss: 0.241307 | Val Acc: 0.191935 loss: 4.956878\n",
            "[1028/3000] Train Acc: 0.915104 Loss: 0.244351 | Val Acc: 0.182460 loss: 5.434782\n",
            "[1029/3000] Train Acc: 0.911474 Loss: 0.250254 | Val Acc: 0.181855 loss: 5.232142\n",
            "[1030/3000] Train Acc: 0.914751 Loss: 0.247626 | Val Acc: 0.162298 loss: 4.907901\n",
            "[1031/3000] Train Acc: 0.911877 Loss: 0.247665 | Val Acc: 0.174597 loss: 5.157987\n",
            "[1032/3000] Train Acc: 0.907794 Loss: 0.260141 | Val Acc: 0.168347 loss: 5.461601\n",
            "[1033/3000] Train Acc: 0.910617 Loss: 0.252107 | Val Acc: 0.183266 loss: 4.998841\n",
            "[1034/3000] Train Acc: 0.914297 Loss: 0.246658 | Val Acc: 0.162298 loss: 5.159547\n",
            "[1035/3000] Train Acc: 0.914751 Loss: 0.241203 | Val Acc: 0.169556 loss: 5.132285\n",
            "[1036/3000] Train Acc: 0.912129 Loss: 0.248704 | Val Acc: 0.172984 loss: 5.174317\n",
            "[1037/3000] Train Acc: 0.913037 Loss: 0.247341 | Val Acc: 0.184677 loss: 5.040699\n",
            "[1038/3000] Train Acc: 0.911827 Loss: 0.247146 | Val Acc: 0.173387 loss: 4.999009\n",
            "[1039/3000] Train Acc: 0.910819 Loss: 0.254308 | Val Acc: 0.183468 loss: 4.789733\n",
            "[1040/3000] Train Acc: 0.911777 Loss: 0.249202 | Val Acc: 0.180847 loss: 5.164443\n",
            "[1041/3000] Train Acc: 0.914196 Loss: 0.244099 | Val Acc: 0.178831 loss: 4.985847\n",
            "[1042/3000] Train Acc: 0.912785 Loss: 0.244854 | Val Acc: 0.181653 loss: 4.979925\n",
            "[1043/3000] Train Acc: 0.913844 Loss: 0.246061 | Val Acc: 0.178226 loss: 4.904434\n",
            "[1044/3000] Train Acc: 0.909962 Loss: 0.256279 | Val Acc: 0.175605 loss: 5.039544\n",
            "[1045/3000] Train Acc: 0.910768 Loss: 0.253749 | Val Acc: 0.189113 loss: 4.898703\n",
            "[1046/3000] Train Acc: 0.911625 Loss: 0.247428 | Val Acc: 0.168548 loss: 5.147646\n",
            "[1047/3000] Train Acc: 0.911726 Loss: 0.246144 | Val Acc: 0.168548 loss: 5.101673\n",
            "[1048/3000] Train Acc: 0.914146 Loss: 0.239671 | Val Acc: 0.191734 loss: 4.989528\n",
            "[1049/3000] Train Acc: 0.910315 Loss: 0.251953 | Val Acc: 0.171169 loss: 4.829699\n",
            "[1050/3000] Train Acc: 0.917372 Loss: 0.237173 | Val Acc: 0.193347 loss: 4.631810\n",
            "[1051/3000] Train Acc: 0.909911 Loss: 0.252993 | Val Acc: 0.168750 loss: 5.238330\n",
            "[1052/3000] Train Acc: 0.914398 Loss: 0.243366 | Val Acc: 0.169758 loss: 5.303747\n",
            "[1053/3000] Train Acc: 0.912129 Loss: 0.245624 | Val Acc: 0.167137 loss: 5.012302\n",
            "[1054/3000] Train Acc: 0.912432 Loss: 0.249291 | Val Acc: 0.169153 loss: 5.127587\n",
            "[1055/3000] Train Acc: 0.915053 Loss: 0.245498 | Val Acc: 0.168548 loss: 5.048710\n",
            "[1056/3000] Train Acc: 0.915306 Loss: 0.242859 | Val Acc: 0.184879 loss: 5.252107\n",
            "[1057/3000] Train Acc: 0.912382 Loss: 0.246945 | Val Acc: 0.166935 loss: 5.011398\n",
            "[1058/3000] Train Acc: 0.913944 Loss: 0.242691 | Val Acc: 0.180040 loss: 5.088572\n",
            "[1059/3000] Train Acc: 0.916062 Loss: 0.239410 | Val Acc: 0.195565 loss: 5.249054\n",
            "[1060/3000] Train Acc: 0.910970 Loss: 0.249064 | Val Acc: 0.181250 loss: 5.118220\n",
            "[1061/3000] Train Acc: 0.912835 Loss: 0.256672 | Val Acc: 0.188710 loss: 5.101422\n",
            "[1062/3000] Train Acc: 0.913642 Loss: 0.245369 | Val Acc: 0.160887 loss: 5.367162\n",
            "[1063/3000] Train Acc: 0.906987 Loss: 0.258751 | Val Acc: 0.183468 loss: 5.292989\n",
            "[1064/3000] Train Acc: 0.917372 Loss: 0.234854 | Val Acc: 0.184677 loss: 5.145405\n",
            "[1065/3000] Train Acc: 0.916263 Loss: 0.236974 | Val Acc: 0.174597 loss: 5.204655\n",
            "[1066/3000] Train Acc: 0.920145 Loss: 0.234802 | Val Acc: 0.166935 loss: 5.237640\n",
            "[1067/3000] Train Acc: 0.914801 Loss: 0.243801 | Val Acc: 0.184073 loss: 5.245686\n",
            "[1068/3000] Train Acc: 0.913995 Loss: 0.242226 | Val Acc: 0.168952 loss: 5.051059\n",
            "[1069/3000] Train Acc: 0.916062 Loss: 0.239802 | Val Acc: 0.172782 loss: 4.916488\n",
            "[1070/3000] Train Acc: 0.911777 Loss: 0.246959 | Val Acc: 0.176613 loss: 5.359429\n",
            "[1071/3000] Train Acc: 0.914348 Loss: 0.242784 | Val Acc: 0.167137 loss: 5.516557\n",
            "[1072/3000] Train Acc: 0.911978 Loss: 0.251612 | Val Acc: 0.189516 loss: 5.057072\n",
            "[1073/3000] Train Acc: 0.915406 Loss: 0.240426 | Val Acc: 0.195161 loss: 4.872000\n",
            "[1074/3000] Train Acc: 0.913844 Loss: 0.240780 | Val Acc: 0.172379 loss: 5.426749\n",
            "[1075/3000] Train Acc: 0.916717 Loss: 0.241020 | Val Acc: 0.174798 loss: 5.037008\n",
            "[1076/3000] Train Acc: 0.916818 Loss: 0.238704 | Val Acc: 0.188710 loss: 5.047264\n",
            "[1077/3000] Train Acc: 0.911525 Loss: 0.249096 | Val Acc: 0.172984 loss: 5.050498\n",
            "[1078/3000] Train Acc: 0.914801 Loss: 0.241147 | Val Acc: 0.180444 loss: 5.315032\n",
            "[1079/3000] Train Acc: 0.915356 Loss: 0.240323 | Val Acc: 0.189113 loss: 5.338950\n",
            "[1080/3000] Train Acc: 0.913844 Loss: 0.246486 | Val Acc: 0.171774 loss: 5.300827\n",
            "[1081/3000] Train Acc: 0.913339 Loss: 0.245284 | Val Acc: 0.175605 loss: 4.878091\n",
            "[1082/3000] Train Acc: 0.916112 Loss: 0.239417 | Val Acc: 0.185484 loss: 5.254976\n",
            "[1083/3000] Train Acc: 0.918330 Loss: 0.235421 | Val Acc: 0.184677 loss: 5.114619\n",
            "[1084/3000] Train Acc: 0.915608 Loss: 0.235328 | Val Acc: 0.189516 loss: 5.160666\n",
            "[1085/3000] Train Acc: 0.913844 Loss: 0.243416 | Val Acc: 0.167339 loss: 5.309760\n",
            "[1086/3000] Train Acc: 0.915961 Loss: 0.239799 | Val Acc: 0.175202 loss: 5.241407\n",
            "[1087/3000] Train Acc: 0.917423 Loss: 0.234242 | Val Acc: 0.174597 loss: 5.025748\n",
            "[1088/3000] Train Acc: 0.915457 Loss: 0.239841 | Val Acc: 0.188911 loss: 5.252305\n",
            "[1089/3000] Train Acc: 0.921002 Loss: 0.230787 | Val Acc: 0.174798 loss: 4.993876\n",
            "[1090/3000] Train Acc: 0.913642 Loss: 0.243610 | Val Acc: 0.182661 loss: 5.413456\n",
            "[1091/3000] Train Acc: 0.916616 Loss: 0.237900 | Val Acc: 0.184677 loss: 5.202654\n",
            "[1092/3000] Train Acc: 0.913188 Loss: 0.245348 | Val Acc: 0.157460 loss: 5.737003\n",
            "[1093/3000] Train Acc: 0.915104 Loss: 0.237071 | Val Acc: 0.190121 loss: 4.882253\n",
            "[1094/3000] Train Acc: 0.913844 Loss: 0.241741 | Val Acc: 0.177016 loss: 5.151465\n",
            "[1095/3000] Train Acc: 0.917070 Loss: 0.234797 | Val Acc: 0.178024 loss: 5.193578\n",
            "[1096/3000] Train Acc: 0.916818 Loss: 0.231292 | Val Acc: 0.168750 loss: 5.217361\n",
            "[1097/3000] Train Acc: 0.916767 Loss: 0.241049 | Val Acc: 0.190323 loss: 5.070530\n",
            "[1098/3000] Train Acc: 0.916969 Loss: 0.244605 | Val Acc: 0.171371 loss: 4.845750\n",
            "[1099/3000] Train Acc: 0.911373 Loss: 0.248127 | Val Acc: 0.177218 loss: 5.193425\n",
            "[1100/3000] Train Acc: 0.916364 Loss: 0.237455 | Val Acc: 0.192137 loss: 5.016609\n",
            "[1101/3000] Train Acc: 0.917877 Loss: 0.232971 | Val Acc: 0.186694 loss: 5.381388\n",
            "[1102/3000] Train Acc: 0.912583 Loss: 0.245101 | Val Acc: 0.190524 loss: 5.032511\n",
            "[1103/3000] Train Acc: 0.918078 Loss: 0.230234 | Val Acc: 0.170968 loss: 5.274324\n",
            "[1104/3000] Train Acc: 0.912835 Loss: 0.242539 | Val Acc: 0.197379 loss: 4.970541\n",
            "[1105/3000] Train Acc: 0.918280 Loss: 0.233917 | Val Acc: 0.185282 loss: 4.975311\n",
            "[1106/3000] Train Acc: 0.918078 Loss: 0.233069 | Val Acc: 0.179435 loss: 5.120253\n",
            "[1107/3000] Train Acc: 0.915356 Loss: 0.238374 | Val Acc: 0.172581 loss: 5.016509\n",
            "[1108/3000] Train Acc: 0.917473 Loss: 0.232861 | Val Acc: 0.196169 loss: 5.196827\n",
            "[1109/3000] Train Acc: 0.915709 Loss: 0.238257 | Val Acc: 0.184274 loss: 5.072003\n",
            "[1110/3000] Train Acc: 0.917776 Loss: 0.238924 | Val Acc: 0.174194 loss: 5.272683\n",
            "[1111/3000] Train Acc: 0.920448 Loss: 0.232503 | Val Acc: 0.187702 loss: 5.235628\n",
            "[1112/3000] Train Acc: 0.915658 Loss: 0.245071 | Val Acc: 0.179234 loss: 5.546529\n",
            "[1113/3000] Train Acc: 0.912835 Loss: 0.245977 | Val Acc: 0.172379 loss: 5.255377\n",
            "[1114/3000] Train Acc: 0.915255 Loss: 0.237152 | Val Acc: 0.189315 loss: 5.438722\n",
            "[1115/3000] Train Acc: 0.920095 Loss: 0.228477 | Val Acc: 0.189113 loss: 4.885767\n",
            "[1116/3000] Train Acc: 0.917120 Loss: 0.233922 | Val Acc: 0.169758 loss: 5.643316\n",
            "[1117/3000] Train Acc: 0.916112 Loss: 0.238355 | Val Acc: 0.186694 loss: 5.073018\n",
            "[1118/3000] Train Acc: 0.913087 Loss: 0.248974 | Val Acc: 0.183266 loss: 5.242065\n",
            "[1119/3000] Train Acc: 0.913894 Loss: 0.239309 | Val Acc: 0.181250 loss: 5.220378\n",
            "[1120/3000] Train Acc: 0.918784 Loss: 0.231292 | Val Acc: 0.171371 loss: 5.411952\n",
            "[1121/3000] Train Acc: 0.918381 Loss: 0.233807 | Val Acc: 0.178226 loss: 5.751187\n",
            "[1122/3000] Train Acc: 0.915658 Loss: 0.237793 | Val Acc: 0.194153 loss: 5.121088\n",
            "[1123/3000] Train Acc: 0.919339 Loss: 0.231692 | Val Acc: 0.176613 loss: 5.246552\n",
            "[1124/3000] Train Acc: 0.916163 Loss: 0.230645 | Val Acc: 0.177016 loss: 4.925887\n",
            "[1125/3000] Train Acc: 0.918734 Loss: 0.234154 | Val Acc: 0.168952 loss: 5.269975\n",
            "[1126/3000] Train Acc: 0.917120 Loss: 0.233953 | Val Acc: 0.183871 loss: 5.296578\n",
            "[1127/3000] Train Acc: 0.920246 Loss: 0.228015 | Val Acc: 0.187097 loss: 5.430631\n",
            "[1128/3000] Train Acc: 0.916263 Loss: 0.239986 | Val Acc: 0.182258 loss: 5.153701\n",
            "[1129/3000] Train Acc: 0.913844 Loss: 0.240896 | Val Acc: 0.190121 loss: 5.022758\n",
            "[1130/3000] Train Acc: 0.921809 Loss: 0.227013 | Val Acc: 0.155847 loss: 5.714391\n",
            "[1131/3000] Train Acc: 0.917221 Loss: 0.234028 | Val Acc: 0.201411 loss: 5.308038\n",
            "saving model with acc 0.201\n",
            "[1132/3000] Train Acc: 0.919944 Loss: 0.233558 | Val Acc: 0.172581 loss: 5.378849\n",
            "[1133/3000] Train Acc: 0.915910 Loss: 0.232793 | Val Acc: 0.186895 loss: 5.262305\n",
            "[1134/3000] Train Acc: 0.918280 Loss: 0.235227 | Val Acc: 0.171573 loss: 5.370003\n",
            "[1135/3000] Train Acc: 0.917020 Loss: 0.237204 | Val Acc: 0.160685 loss: 4.909534\n",
            "[1136/3000] Train Acc: 0.916767 Loss: 0.235547 | Val Acc: 0.164516 loss: 5.403997\n",
            "[1137/3000] Train Acc: 0.915961 Loss: 0.236362 | Val Acc: 0.166935 loss: 5.192079\n",
            "[1138/3000] Train Acc: 0.917574 Loss: 0.233723 | Val Acc: 0.157258 loss: 5.145171\n",
            "[1139/3000] Train Acc: 0.916616 Loss: 0.235800 | Val Acc: 0.195363 loss: 4.657021\n",
            "[1140/3000] Train Acc: 0.919339 Loss: 0.226818 | Val Acc: 0.180847 loss: 5.398538\n",
            "[1141/3000] Train Acc: 0.916062 Loss: 0.240884 | Val Acc: 0.189919 loss: 4.975850\n",
            "[1142/3000] Train Acc: 0.915406 Loss: 0.239756 | Val Acc: 0.182258 loss: 5.052124\n",
            "[1143/3000] Train Acc: 0.919742 Loss: 0.227787 | Val Acc: 0.189113 loss: 5.156877\n",
            "[1144/3000] Train Acc: 0.919994 Loss: 0.228805 | Val Acc: 0.188306 loss: 5.203155\n",
            "[1145/3000] Train Acc: 0.919944 Loss: 0.226261 | Val Acc: 0.210081 loss: 4.991104\n",
            "saving model with acc 0.210\n",
            "[1146/3000] Train Acc: 0.916515 Loss: 0.236399 | Val Acc: 0.176815 loss: 5.116299\n",
            "[1147/3000] Train Acc: 0.920599 Loss: 0.229217 | Val Acc: 0.193145 loss: 4.996388\n",
            "[1148/3000] Train Acc: 0.915910 Loss: 0.236921 | Val Acc: 0.174395 loss: 5.177243\n",
            "[1149/3000] Train Acc: 0.921758 Loss: 0.222099 | Val Acc: 0.179032 loss: 5.187977\n",
            "[1150/3000] Train Acc: 0.920246 Loss: 0.230080 | Val Acc: 0.192339 loss: 5.123888\n",
            "[1151/3000] Train Acc: 0.916919 Loss: 0.236122 | Val Acc: 0.186895 loss: 4.916024\n",
            "[1152/3000] Train Acc: 0.915255 Loss: 0.239298 | Val Acc: 0.177419 loss: 5.232302\n",
            "[1153/3000] Train Acc: 0.915709 Loss: 0.238018 | Val Acc: 0.184879 loss: 5.101321\n",
            "[1154/3000] Train Acc: 0.914247 Loss: 0.239632 | Val Acc: 0.176411 loss: 5.293769\n",
            "[1155/3000] Train Acc: 0.918280 Loss: 0.237644 | Val Acc: 0.179637 loss: 5.229569\n",
            "[1156/3000] Train Acc: 0.919238 Loss: 0.227329 | Val Acc: 0.192540 loss: 5.196382\n",
            "[1157/3000] Train Acc: 0.922565 Loss: 0.222831 | Val Acc: 0.185081 loss: 4.876203\n",
            "[1158/3000] Train Acc: 0.917070 Loss: 0.238534 | Val Acc: 0.187702 loss: 5.615734\n",
            "[1159/3000] Train Acc: 0.920397 Loss: 0.223324 | Val Acc: 0.175605 loss: 5.198585\n",
            "[1160/3000] Train Acc: 0.921153 Loss: 0.227241 | Val Acc: 0.181250 loss: 5.564670\n",
            "[1161/3000] Train Acc: 0.915154 Loss: 0.235528 | Val Acc: 0.181250 loss: 5.169981\n",
            "[1162/3000] Train Acc: 0.920801 Loss: 0.226185 | Val Acc: 0.175403 loss: 5.013594\n",
            "[1163/3000] Train Acc: 0.916818 Loss: 0.238659 | Val Acc: 0.186694 loss: 5.011281\n",
            "[1164/3000] Train Acc: 0.919288 Loss: 0.228507 | Val Acc: 0.178226 loss: 5.099400\n",
            "[1165/3000] Train Acc: 0.915961 Loss: 0.240302 | Val Acc: 0.179637 loss: 5.452802\n",
            "[1166/3000] Train Acc: 0.915558 Loss: 0.238023 | Val Acc: 0.185081 loss: 5.222711\n",
            "[1167/3000] Train Acc: 0.921406 Loss: 0.221457 | Val Acc: 0.187702 loss: 5.112276\n",
            "[1168/3000] Train Acc: 0.922615 Loss: 0.220916 | Val Acc: 0.172984 loss: 5.060503\n",
            "[1169/3000] Train Acc: 0.919389 Loss: 0.229123 | Val Acc: 0.169556 loss: 5.210549\n",
            "[1170/3000] Train Acc: 0.918229 Loss: 0.231325 | Val Acc: 0.193548 loss: 5.229311\n",
            "[1171/3000] Train Acc: 0.916314 Loss: 0.232581 | Val Acc: 0.184073 loss: 5.532178\n",
            "[1172/3000] Train Acc: 0.916163 Loss: 0.235131 | Val Acc: 0.166935 loss: 5.682119\n",
            "[1173/3000] Train Acc: 0.920599 Loss: 0.227332 | Val Acc: 0.185887 loss: 5.024217\n",
            "[1174/3000] Train Acc: 0.918885 Loss: 0.229785 | Val Acc: 0.184879 loss: 5.439327\n",
            "[1175/3000] Train Acc: 0.919238 Loss: 0.228948 | Val Acc: 0.167944 loss: 5.124979\n",
            "[1176/3000] Train Acc: 0.919439 Loss: 0.227085 | Val Acc: 0.201411 loss: 4.824413\n",
            "[1177/3000] Train Acc: 0.918381 Loss: 0.233650 | Val Acc: 0.193952 loss: 4.842232\n",
            "[1178/3000] Train Acc: 0.918885 Loss: 0.229327 | Val Acc: 0.169556 loss: 4.961894\n",
            "[1179/3000] Train Acc: 0.918935 Loss: 0.236208 | Val Acc: 0.172581 loss: 5.332128\n",
            "[1180/3000] Train Acc: 0.917776 Loss: 0.232430 | Val Acc: 0.181048 loss: 5.379057\n",
            "[1181/3000] Train Acc: 0.920952 Loss: 0.226861 | Val Acc: 0.187097 loss: 5.189117\n",
            "[1182/3000] Train Acc: 0.917725 Loss: 0.227935 | Val Acc: 0.190121 loss: 5.303754\n",
            "[1183/3000] Train Acc: 0.917977 Loss: 0.227744 | Val Acc: 0.174798 loss: 5.501637\n",
            "[1184/3000] Train Acc: 0.917977 Loss: 0.231302 | Val Acc: 0.192540 loss: 5.496155\n",
            "[1185/3000] Train Acc: 0.919339 Loss: 0.228254 | Val Acc: 0.179839 loss: 5.133807\n",
            "[1186/3000] Train Acc: 0.921607 Loss: 0.223630 | Val Acc: 0.151210 loss: 5.536099\n",
            "[1187/3000] Train Acc: 0.922767 Loss: 0.219999 | Val Acc: 0.198589 loss: 4.842486\n",
            "[1188/3000] Train Acc: 0.922212 Loss: 0.222542 | Val Acc: 0.188306 loss: 5.507576\n",
            "[1189/3000] Train Acc: 0.921355 Loss: 0.223143 | Val Acc: 0.174395 loss: 5.251985\n",
            "[1190/3000] Train Acc: 0.917776 Loss: 0.230706 | Val Acc: 0.193548 loss: 5.165463\n",
            "[1191/3000] Train Acc: 0.915457 Loss: 0.241766 | Val Acc: 0.178427 loss: 5.260169\n",
            "[1192/3000] Train Acc: 0.917725 Loss: 0.231810 | Val Acc: 0.182863 loss: 5.490096\n",
            "[1193/3000] Train Acc: 0.917826 Loss: 0.230819 | Val Acc: 0.188105 loss: 5.360799\n",
            "[1194/3000] Train Acc: 0.920347 Loss: 0.226974 | Val Acc: 0.182661 loss: 5.191000\n",
            "[1195/3000] Train Acc: 0.923120 Loss: 0.223253 | Val Acc: 0.197379 loss: 5.016656\n",
            "[1196/3000] Train Acc: 0.918028 Loss: 0.226705 | Val Acc: 0.184879 loss: 5.124205\n",
            "[1197/3000] Train Acc: 0.916969 Loss: 0.237099 | Val Acc: 0.198185 loss: 5.102222\n",
            "[1198/3000] Train Acc: 0.922111 Loss: 0.220638 | Val Acc: 0.203427 loss: 5.190890\n",
            "[1199/3000] Train Acc: 0.921557 Loss: 0.224015 | Val Acc: 0.189919 loss: 4.960223\n",
            "[1200/3000] Train Acc: 0.921254 Loss: 0.224799 | Val Acc: 0.182056 loss: 5.186852\n",
            "[1201/3000] Train Acc: 0.921103 Loss: 0.222746 | Val Acc: 0.191935 loss: 5.480517\n",
            "[1202/3000] Train Acc: 0.918834 Loss: 0.232134 | Val Acc: 0.191935 loss: 5.364659\n",
            "[1203/3000] Train Acc: 0.919641 Loss: 0.226583 | Val Acc: 0.172379 loss: 5.249870\n",
            "[1204/3000] Train Acc: 0.923372 Loss: 0.216894 | Val Acc: 0.168952 loss: 5.449394\n",
            "[1205/3000] Train Acc: 0.923321 Loss: 0.217168 | Val Acc: 0.173790 loss: 5.050600\n",
            "[1206/3000] Train Acc: 0.924733 Loss: 0.217153 | Val Acc: 0.185887 loss: 5.238537\n",
            "[1207/3000] Train Acc: 0.921053 Loss: 0.225218 | Val Acc: 0.185282 loss: 5.202372\n",
            "[1208/3000] Train Acc: 0.918129 Loss: 0.231219 | Val Acc: 0.184274 loss: 5.398574\n",
            "[1209/3000] Train Acc: 0.920750 Loss: 0.224771 | Val Acc: 0.187298 loss: 4.929262\n",
            "[1210/3000] Train Acc: 0.922263 Loss: 0.223282 | Val Acc: 0.185484 loss: 5.265257\n",
            "[1211/3000] Train Acc: 0.923321 Loss: 0.218724 | Val Acc: 0.172984 loss: 5.220173\n",
            "[1212/3000] Train Acc: 0.919389 Loss: 0.225620 | Val Acc: 0.180040 loss: 5.226142\n",
            "[1213/3000] Train Acc: 0.924582 Loss: 0.217855 | Val Acc: 0.196573 loss: 5.243104\n",
            "[1214/3000] Train Acc: 0.917322 Loss: 0.229071 | Val Acc: 0.187500 loss: 5.153603\n",
            "[1215/3000] Train Acc: 0.924632 Loss: 0.213873 | Val Acc: 0.189113 loss: 5.247954\n",
            "[1216/3000] Train Acc: 0.923069 Loss: 0.219368 | Val Acc: 0.182056 loss: 5.455688\n",
            "[1217/3000] Train Acc: 0.922868 Loss: 0.220254 | Val Acc: 0.181452 loss: 5.119190\n",
            "[1218/3000] Train Acc: 0.922716 Loss: 0.219778 | Val Acc: 0.193145 loss: 5.031545\n",
            "[1219/3000] Train Acc: 0.919389 Loss: 0.226759 | Val Acc: 0.181048 loss: 5.240562\n",
            "[1220/3000] Train Acc: 0.924682 Loss: 0.215487 | Val Acc: 0.173790 loss: 5.339737\n",
            "[1221/3000] Train Acc: 0.920801 Loss: 0.223614 | Val Acc: 0.188508 loss: 5.272102\n",
            "[1222/3000] Train Acc: 0.919893 Loss: 0.228818 | Val Acc: 0.179839 loss: 5.724261\n",
            "[1223/3000] Train Acc: 0.921204 Loss: 0.221926 | Val Acc: 0.177016 loss: 5.381158\n",
            "[1224/3000] Train Acc: 0.924531 Loss: 0.216439 | Val Acc: 0.190323 loss: 5.208008\n",
            "[1225/3000] Train Acc: 0.922918 Loss: 0.218018 | Val Acc: 0.178226 loss: 5.263119\n",
            "[1226/3000] Train Acc: 0.922615 Loss: 0.219007 | Val Acc: 0.204839 loss: 5.039912\n",
            "[1227/3000] Train Acc: 0.927354 Loss: 0.207062 | Val Acc: 0.202218 loss: 4.988676\n",
            "[1228/3000] Train Acc: 0.921809 Loss: 0.219974 | Val Acc: 0.181452 loss: 5.313316\n",
            "[1229/3000] Train Acc: 0.917675 Loss: 0.234117 | Val Acc: 0.187903 loss: 5.285088\n",
            "[1230/3000] Train Acc: 0.923069 Loss: 0.220734 | Val Acc: 0.179839 loss: 5.229597\n",
            "[1231/3000] Train Acc: 0.920347 Loss: 0.224738 | Val Acc: 0.181048 loss: 5.249670\n",
            "[1232/3000] Train Acc: 0.922263 Loss: 0.220128 | Val Acc: 0.187702 loss: 5.367349\n",
            "[1233/3000] Train Acc: 0.923573 Loss: 0.220268 | Val Acc: 0.193548 loss: 5.487118\n",
            "[1234/3000] Train Acc: 0.920700 Loss: 0.222492 | Val Acc: 0.185282 loss: 5.391058\n",
            "[1235/3000] Train Acc: 0.921607 Loss: 0.221636 | Val Acc: 0.183871 loss: 5.367228\n",
            "[1236/3000] Train Acc: 0.921204 Loss: 0.218356 | Val Acc: 0.182863 loss: 5.647851\n",
            "[1237/3000] Train Acc: 0.924229 Loss: 0.217304 | Val Acc: 0.181452 loss: 5.335240\n",
            "[1238/3000] Train Acc: 0.915154 Loss: 0.238644 | Val Acc: 0.195565 loss: 5.102275\n",
            "[1239/3000] Train Acc: 0.923674 Loss: 0.214768 | Val Acc: 0.189315 loss: 5.074101\n",
            "[1240/3000] Train Acc: 0.927959 Loss: 0.209123 | Val Acc: 0.198992 loss: 5.419695\n",
            "[1241/3000] Train Acc: 0.923321 Loss: 0.217335 | Val Acc: 0.179234 loss: 4.998121\n",
            "[1242/3000] Train Acc: 0.922918 Loss: 0.220329 | Val Acc: 0.182863 loss: 5.351526\n",
            "[1243/3000] Train Acc: 0.923825 Loss: 0.217721 | Val Acc: 0.199597 loss: 5.156223\n",
            "[1244/3000] Train Acc: 0.921859 Loss: 0.223348 | Val Acc: 0.202218 loss: 4.998552\n",
            "[1245/3000] Train Acc: 0.920901 Loss: 0.225707 | Val Acc: 0.202419 loss: 4.987470\n",
            "[1246/3000] Train Acc: 0.923321 Loss: 0.218772 | Val Acc: 0.194153 loss: 5.323598\n",
            "[1247/3000] Train Acc: 0.919994 Loss: 0.224305 | Val Acc: 0.179637 loss: 5.238287\n",
            "[1248/3000] Train Acc: 0.924834 Loss: 0.216403 | Val Acc: 0.191129 loss: 5.214483\n",
            "[1249/3000] Train Acc: 0.925136 Loss: 0.212754 | Val Acc: 0.196976 loss: 5.075598\n",
            "[1250/3000] Train Acc: 0.926044 Loss: 0.211460 | Val Acc: 0.163710 loss: 5.673566\n",
            "[1251/3000] Train Acc: 0.918633 Loss: 0.227253 | Val Acc: 0.187298 loss: 5.377947\n",
            "[1252/3000] Train Acc: 0.923472 Loss: 0.217575 | Val Acc: 0.191532 loss: 5.453618\n",
            "[1253/3000] Train Acc: 0.923422 Loss: 0.218260 | Val Acc: 0.182460 loss: 5.289784\n",
            "[1254/3000] Train Acc: 0.926346 Loss: 0.210340 | Val Acc: 0.193952 loss: 5.370571\n",
            "[1255/3000] Train Acc: 0.923573 Loss: 0.215700 | Val Acc: 0.169153 loss: 5.584853\n",
            "[1256/3000] Train Acc: 0.921456 Loss: 0.222311 | Val Acc: 0.188105 loss: 5.171788\n",
            "[1257/3000] Train Acc: 0.924229 Loss: 0.216598 | Val Acc: 0.195363 loss: 5.313001\n",
            "[1258/3000] Train Acc: 0.924934 Loss: 0.214482 | Val Acc: 0.177621 loss: 5.254004\n",
            "[1259/3000] Train Acc: 0.922010 Loss: 0.225901 | Val Acc: 0.181653 loss: 5.189723\n",
            "[1260/3000] Train Acc: 0.922061 Loss: 0.221777 | Val Acc: 0.182258 loss: 5.506989\n",
            "[1261/3000] Train Acc: 0.921506 Loss: 0.222239 | Val Acc: 0.184879 loss: 5.145502\n",
            "[1262/3000] Train Acc: 0.925539 Loss: 0.215450 | Val Acc: 0.188105 loss: 4.768047\n",
            "[1263/3000] Train Acc: 0.921960 Loss: 0.224266 | Val Acc: 0.185282 loss: 5.335734\n",
            "[1264/3000] Train Acc: 0.924733 Loss: 0.211692 | Val Acc: 0.185887 loss: 5.162467\n",
            "[1265/3000] Train Acc: 0.925439 Loss: 0.208519 | Val Acc: 0.171774 loss: 5.438947\n",
            "[1266/3000] Train Acc: 0.929270 Loss: 0.205450 | Val Acc: 0.186492 loss: 5.246254\n",
            "[1267/3000] Train Acc: 0.925086 Loss: 0.215631 | Val Acc: 0.180847 loss: 5.311371\n",
            "[1268/3000] Train Acc: 0.918784 Loss: 0.229207 | Val Acc: 0.199798 loss: 4.995292\n",
            "[1269/3000] Train Acc: 0.925035 Loss: 0.212225 | Val Acc: 0.181653 loss: 5.517082\n",
            "[1270/3000] Train Acc: 0.924229 Loss: 0.218627 | Val Acc: 0.194960 loss: 5.283669\n",
            "[1271/3000] Train Acc: 0.923220 Loss: 0.215797 | Val Acc: 0.187097 loss: 5.449908\n",
            "[1272/3000] Train Acc: 0.926195 Loss: 0.212861 | Val Acc: 0.189516 loss: 5.397722\n",
            "[1273/3000] Train Acc: 0.923472 Loss: 0.216893 | Val Acc: 0.187903 loss: 5.244630\n",
            "[1274/3000] Train Acc: 0.924077 Loss: 0.213831 | Val Acc: 0.182056 loss: 5.356109\n",
            "[1275/3000] Train Acc: 0.925943 Loss: 0.206620 | Val Acc: 0.164718 loss: 5.593823\n",
            "[1276/3000] Train Acc: 0.922666 Loss: 0.217709 | Val Acc: 0.196371 loss: 5.243284\n",
            "[1277/3000] Train Acc: 0.926699 Loss: 0.209324 | Val Acc: 0.190323 loss: 5.069366\n",
            "[1278/3000] Train Acc: 0.924682 Loss: 0.214693 | Val Acc: 0.176613 loss: 5.653075\n",
            "[1279/3000] Train Acc: 0.924582 Loss: 0.213723 | Val Acc: 0.192944 loss: 5.472355\n",
            "[1280/3000] Train Acc: 0.922968 Loss: 0.219963 | Val Acc: 0.175000 loss: 5.609901\n",
            "[1281/3000] Train Acc: 0.923170 Loss: 0.218559 | Val Acc: 0.185685 loss: 5.422647\n",
            "[1282/3000] Train Acc: 0.924834 Loss: 0.214416 | Val Acc: 0.175202 loss: 5.296824\n",
            "[1283/3000] Train Acc: 0.924783 Loss: 0.214370 | Val Acc: 0.185484 loss: 5.502485\n",
            "[1284/3000] Train Acc: 0.926598 Loss: 0.209016 | Val Acc: 0.174194 loss: 5.309555\n",
            "[1285/3000] Train Acc: 0.928161 Loss: 0.202436 | Val Acc: 0.169758 loss: 5.601749\n",
            "[1286/3000] Train Acc: 0.925439 Loss: 0.211013 | Val Acc: 0.174597 loss: 5.229923\n",
            "[1287/3000] Train Acc: 0.922716 Loss: 0.213932 | Val Acc: 0.181855 loss: 5.381451\n",
            "[1288/3000] Train Acc: 0.924632 Loss: 0.213126 | Val Acc: 0.176815 loss: 5.321438\n",
            "[1289/3000] Train Acc: 0.924531 Loss: 0.216221 | Val Acc: 0.201411 loss: 5.281804\n",
            "[1290/3000] Train Acc: 0.921355 Loss: 0.219828 | Val Acc: 0.184879 loss: 5.606690\n",
            "[1291/3000] Train Acc: 0.923977 Loss: 0.216621 | Val Acc: 0.177621 loss: 5.357734\n",
            "[1292/3000] Train Acc: 0.926850 Loss: 0.211640 | Val Acc: 0.204435 loss: 5.210058\n",
            "[1293/3000] Train Acc: 0.924632 Loss: 0.212918 | Val Acc: 0.177823 loss: 5.455721\n",
            "[1294/3000] Train Acc: 0.927707 Loss: 0.205535 | Val Acc: 0.177823 loss: 5.576480\n",
            "[1295/3000] Train Acc: 0.923170 Loss: 0.217326 | Val Acc: 0.169758 loss: 5.423385\n",
            "[1296/3000] Train Acc: 0.921557 Loss: 0.222980 | Val Acc: 0.198790 loss: 5.174906\n",
            "[1297/3000] Train Acc: 0.923120 Loss: 0.217028 | Val Acc: 0.200403 loss: 5.046920\n",
            "[1298/3000] Train Acc: 0.926548 Loss: 0.209562 | Val Acc: 0.172379 loss: 5.356455\n",
            "[1299/3000] Train Acc: 0.926598 Loss: 0.207861 | Val Acc: 0.179234 loss: 5.446798\n",
            "[1300/3000] Train Acc: 0.926598 Loss: 0.207911 | Val Acc: 0.183266 loss: 5.181512\n",
            "[1301/3000] Train Acc: 0.929119 Loss: 0.202855 | Val Acc: 0.195968 loss: 5.290769\n",
            "[1302/3000] Train Acc: 0.926850 Loss: 0.204586 | Val Acc: 0.174194 loss: 5.564519\n",
            "[1303/3000] Train Acc: 0.926598 Loss: 0.206768 | Val Acc: 0.197177 loss: 5.090108\n",
            "[1304/3000] Train Acc: 0.927405 Loss: 0.207972 | Val Acc: 0.179839 loss: 5.209987\n",
            "[1305/3000] Train Acc: 0.922111 Loss: 0.221586 | Val Acc: 0.182056 loss: 5.288657\n",
            "[1306/3000] Train Acc: 0.924834 Loss: 0.212420 | Val Acc: 0.181250 loss: 5.432641\n",
            "[1307/3000] Train Acc: 0.927808 Loss: 0.207769 | Val Acc: 0.178831 loss: 5.251466\n",
            "[1308/3000] Train Acc: 0.925035 Loss: 0.209871 | Val Acc: 0.176210 loss: 5.458620\n",
            "[1309/3000] Train Acc: 0.929068 Loss: 0.203201 | Val Acc: 0.187903 loss: 5.034936\n",
            "[1310/3000] Train Acc: 0.925086 Loss: 0.212916 | Val Acc: 0.197984 loss: 5.344803\n",
            "[1311/3000] Train Acc: 0.925237 Loss: 0.211017 | Val Acc: 0.191331 loss: 5.394456\n",
            "[1312/3000] Train Acc: 0.926598 Loss: 0.207575 | Val Acc: 0.171976 loss: 5.525675\n",
            "[1313/3000] Train Acc: 0.920599 Loss: 0.218840 | Val Acc: 0.185282 loss: 5.291137\n",
            "[1314/3000] Train Acc: 0.929068 Loss: 0.200893 | Val Acc: 0.177016 loss: 5.503142\n",
            "[1315/3000] Train Acc: 0.928514 Loss: 0.205995 | Val Acc: 0.186290 loss: 5.181085\n",
            "[1316/3000] Train Acc: 0.923876 Loss: 0.214094 | Val Acc: 0.191532 loss: 5.188857\n",
            "[1317/3000] Train Acc: 0.929421 Loss: 0.207098 | Val Acc: 0.189718 loss: 5.488772\n",
            "[1318/3000] Train Acc: 0.927909 Loss: 0.209136 | Val Acc: 0.173589 loss: 5.742334\n",
            "[1319/3000] Train Acc: 0.923977 Loss: 0.215089 | Val Acc: 0.183871 loss: 5.019066\n",
            "[1320/3000] Train Acc: 0.929169 Loss: 0.202133 | Val Acc: 0.197581 loss: 5.229239\n",
            "[1321/3000] Train Acc: 0.925640 Loss: 0.210980 | Val Acc: 0.182258 loss: 5.474313\n",
            "[1322/3000] Train Acc: 0.932396 Loss: 0.193310 | Val Acc: 0.202419 loss: 5.248077\n",
            "[1323/3000] Train Acc: 0.927808 Loss: 0.205096 | Val Acc: 0.191734 loss: 5.472654\n",
            "[1324/3000] Train Acc: 0.929270 Loss: 0.206528 | Val Acc: 0.174395 loss: 5.469553\n",
            "[1325/3000] Train Acc: 0.924178 Loss: 0.212975 | Val Acc: 0.181048 loss: 5.475899\n",
            "[1326/3000] Train Acc: 0.923069 Loss: 0.215228 | Val Acc: 0.183669 loss: 5.494522\n",
            "[1327/3000] Train Acc: 0.924834 Loss: 0.211672 | Val Acc: 0.192339 loss: 4.905486\n",
            "[1328/3000] Train Acc: 0.924934 Loss: 0.211365 | Val Acc: 0.184476 loss: 5.648313\n",
            "[1329/3000] Train Acc: 0.929068 Loss: 0.206548 | Val Acc: 0.187097 loss: 5.378438\n",
            "[1330/3000] Train Acc: 0.931639 Loss: 0.196636 | Val Acc: 0.186290 loss: 5.336166\n",
            "[1331/3000] Train Acc: 0.928363 Loss: 0.203195 | Val Acc: 0.202621 loss: 5.347574\n",
            "[1332/3000] Train Acc: 0.927405 Loss: 0.205515 | Val Acc: 0.181452 loss: 5.620389\n",
            "[1333/3000] Train Acc: 0.928161 Loss: 0.199602 | Val Acc: 0.178629 loss: 5.175613\n",
            "[1334/3000] Train Acc: 0.927808 Loss: 0.204211 | Val Acc: 0.179435 loss: 5.402477\n",
            "[1335/3000] Train Acc: 0.926144 Loss: 0.209036 | Val Acc: 0.200806 loss: 5.389239\n",
            "[1336/3000] Train Acc: 0.923876 Loss: 0.213240 | Val Acc: 0.183468 loss: 5.381065\n",
            "[1337/3000] Train Acc: 0.928514 Loss: 0.204448 | Val Acc: 0.206855 loss: 4.928757\n",
            "[1338/3000] Train Acc: 0.927606 Loss: 0.207278 | Val Acc: 0.193145 loss: 5.325127\n",
            "[1339/3000] Train Acc: 0.926749 Loss: 0.207288 | Val Acc: 0.196169 loss: 5.362678\n",
            "[1340/3000] Train Acc: 0.929572 Loss: 0.199820 | Val Acc: 0.178629 loss: 5.776898\n",
            "[1341/3000] Train Acc: 0.930934 Loss: 0.201151 | Val Acc: 0.193750 loss: 5.286379\n",
            "[1342/3000] Train Acc: 0.928363 Loss: 0.200799 | Val Acc: 0.192339 loss: 5.337501\n",
            "[1343/3000] Train Acc: 0.928211 Loss: 0.203621 | Val Acc: 0.186089 loss: 5.193240\n",
            "[1344/3000] Train Acc: 0.927909 Loss: 0.206043 | Val Acc: 0.187500 loss: 5.479271\n",
            "[1345/3000] Train Acc: 0.927758 Loss: 0.199815 | Val Acc: 0.195363 loss: 5.059821\n",
            "[1346/3000] Train Acc: 0.923825 Loss: 0.215806 | Val Acc: 0.182056 loss: 6.016569\n",
            "[1347/3000] Train Acc: 0.925993 Loss: 0.206383 | Val Acc: 0.171371 loss: 5.543440\n",
            "[1348/3000] Train Acc: 0.930682 Loss: 0.195882 | Val Acc: 0.191532 loss: 5.414335\n",
            "[1349/3000] Train Acc: 0.927506 Loss: 0.203526 | Val Acc: 0.191532 loss: 5.044510\n",
            "[1350/3000] Train Acc: 0.926296 Loss: 0.208632 | Val Acc: 0.176008 loss: 5.233958\n",
            "[1351/3000] Train Acc: 0.928413 Loss: 0.199490 | Val Acc: 0.181452 loss: 5.435957\n",
            "[1352/3000] Train Acc: 0.929925 Loss: 0.201189 | Val Acc: 0.181855 loss: 5.273520\n",
            "[1353/3000] Train Acc: 0.930026 Loss: 0.203053 | Val Acc: 0.177016 loss: 5.390780\n",
            "[1354/3000] Train Acc: 0.933303 Loss: 0.190702 | Val Acc: 0.185484 loss: 5.368136\n",
            "[1355/3000] Train Acc: 0.929018 Loss: 0.206928 | Val Acc: 0.189718 loss: 5.040890\n",
            "[1356/3000] Train Acc: 0.930177 Loss: 0.197311 | Val Acc: 0.200000 loss: 4.863977\n",
            "[1357/3000] Train Acc: 0.932093 Loss: 0.195080 | Val Acc: 0.184274 loss: 5.501481\n",
            "[1358/3000] Train Acc: 0.928211 Loss: 0.206128 | Val Acc: 0.182863 loss: 5.246774\n",
            "[1359/3000] Train Acc: 0.923019 Loss: 0.219279 | Val Acc: 0.160887 loss: 5.405050\n",
            "[1360/3000] Train Acc: 0.923271 Loss: 0.214625 | Val Acc: 0.197379 loss: 5.130077\n",
            "[1361/3000] Train Acc: 0.931942 Loss: 0.194889 | Val Acc: 0.194355 loss: 5.028459\n",
            "[1362/3000] Train Acc: 0.927758 Loss: 0.205931 | Val Acc: 0.180645 loss: 5.300129\n",
            "[1363/3000] Train Acc: 0.927556 Loss: 0.204641 | Val Acc: 0.203024 loss: 5.159538\n",
            "[1364/3000] Train Acc: 0.927858 Loss: 0.202547 | Val Acc: 0.181452 loss: 5.492475\n",
            "[1365/3000] Train Acc: 0.931186 Loss: 0.197168 | Val Acc: 0.184879 loss: 5.471448\n",
            "[1366/3000] Train Acc: 0.933757 Loss: 0.191108 | Val Acc: 0.201613 loss: 5.200136\n",
            "[1367/3000] Train Acc: 0.929371 Loss: 0.197785 | Val Acc: 0.178629 loss: 5.583025\n",
            "[1368/3000] Train Acc: 0.926548 Loss: 0.211021 | Val Acc: 0.179435 loss: 5.564411\n",
            "[1369/3000] Train Acc: 0.923069 Loss: 0.218390 | Val Acc: 0.181653 loss: 5.407361\n",
            "[1370/3000] Train Acc: 0.925590 Loss: 0.209523 | Val Acc: 0.184677 loss: 5.633340\n",
            "[1371/3000] Train Acc: 0.928211 Loss: 0.201950 | Val Acc: 0.185081 loss: 5.312263\n",
            "[1372/3000] Train Acc: 0.929522 Loss: 0.202330 | Val Acc: 0.166734 loss: 5.531548\n",
            "[1373/3000] Train Acc: 0.928211 Loss: 0.203772 | Val Acc: 0.172379 loss: 5.441759\n",
            "[1374/3000] Train Acc: 0.930833 Loss: 0.201726 | Val Acc: 0.197177 loss: 5.318962\n",
            "[1375/3000] Train Acc: 0.924682 Loss: 0.211198 | Val Acc: 0.184476 loss: 5.138838\n",
            "[1376/3000] Train Acc: 0.928211 Loss: 0.209903 | Val Acc: 0.181250 loss: 5.506033\n",
            "[1377/3000] Train Acc: 0.930177 Loss: 0.198131 | Val Acc: 0.187702 loss: 5.293491\n",
            "[1378/3000] Train Acc: 0.933152 Loss: 0.193044 | Val Acc: 0.189516 loss: 5.357856\n",
            "[1379/3000] Train Acc: 0.925993 Loss: 0.204153 | Val Acc: 0.184677 loss: 5.241823\n",
            "[1380/3000] Train Acc: 0.930934 Loss: 0.199092 | Val Acc: 0.156653 loss: 5.488190\n",
            "[1381/3000] Train Acc: 0.927001 Loss: 0.207499 | Val Acc: 0.200403 loss: 5.399602\n",
            "[1382/3000] Train Acc: 0.931085 Loss: 0.193260 | Val Acc: 0.192339 loss: 5.018826\n",
            "[1383/3000] Train Acc: 0.927253 Loss: 0.206068 | Val Acc: 0.171774 loss: 5.409586\n",
            "[1384/3000] Train Acc: 0.928413 Loss: 0.203755 | Val Acc: 0.192137 loss: 5.192518\n",
            "[1385/3000] Train Acc: 0.930127 Loss: 0.200712 | Val Acc: 0.190524 loss: 5.292304\n",
            "[1386/3000] Train Acc: 0.930934 Loss: 0.198037 | Val Acc: 0.206855 loss: 4.955322\n",
            "[1387/3000] Train Acc: 0.926195 Loss: 0.205504 | Val Acc: 0.186290 loss: 5.223828\n",
            "[1388/3000] Train Acc: 0.932244 Loss: 0.194619 | Val Acc: 0.184677 loss: 5.759359\n",
            "[1389/3000] Train Acc: 0.931236 Loss: 0.198824 | Val Acc: 0.170161 loss: 5.652766\n",
            "[1390/3000] Train Acc: 0.928564 Loss: 0.203907 | Val Acc: 0.185484 loss: 5.672765\n",
            "[1391/3000] Train Acc: 0.929119 Loss: 0.201092 | Val Acc: 0.186694 loss: 5.378764\n",
            "[1392/3000] Train Acc: 0.928413 Loss: 0.205371 | Val Acc: 0.189113 loss: 5.512126\n",
            "[1393/3000] Train Acc: 0.930934 Loss: 0.200434 | Val Acc: 0.191532 loss: 5.145056\n",
            "[1394/3000] Train Acc: 0.928413 Loss: 0.207766 | Val Acc: 0.181653 loss: 5.341969\n",
            "[1395/3000] Train Acc: 0.934261 Loss: 0.189409 | Val Acc: 0.188306 loss: 5.377828\n",
            "[1396/3000] Train Acc: 0.932244 Loss: 0.191741 | Val Acc: 0.198387 loss: 4.903226\n",
            "[1397/3000] Train Acc: 0.925842 Loss: 0.203098 | Val Acc: 0.178629 loss: 5.412272\n",
            "[1398/3000] Train Acc: 0.924985 Loss: 0.209867 | Val Acc: 0.170565 loss: 5.655539\n",
            "[1399/3000] Train Acc: 0.930984 Loss: 0.195148 | Val Acc: 0.190726 loss: 5.528590\n",
            "[1400/3000] Train Acc: 0.931337 Loss: 0.194195 | Val Acc: 0.187903 loss: 5.749229\n",
            "[1401/3000] Train Acc: 0.926951 Loss: 0.207403 | Val Acc: 0.152218 loss: 5.713017\n",
            "[1402/3000] Train Acc: 0.926749 Loss: 0.207073 | Val Acc: 0.185685 loss: 5.505395\n",
            "[1403/3000] Train Acc: 0.931085 Loss: 0.195383 | Val Acc: 0.182460 loss: 5.363171\n",
            "[1404/3000] Train Acc: 0.929169 Loss: 0.201945 | Val Acc: 0.195968 loss: 5.214202\n",
            "[1405/3000] Train Acc: 0.929925 Loss: 0.197174 | Val Acc: 0.191734 loss: 5.168359\n",
            "[1406/3000] Train Acc: 0.931287 Loss: 0.193907 | Val Acc: 0.182661 loss: 5.381141\n",
            "[1407/3000] Train Acc: 0.926044 Loss: 0.211183 | Val Acc: 0.201210 loss: 5.414701\n",
            "[1408/3000] Train Acc: 0.929673 Loss: 0.199544 | Val Acc: 0.190121 loss: 4.985666\n",
            "[1409/3000] Train Acc: 0.931034 Loss: 0.193364 | Val Acc: 0.194355 loss: 5.471252\n",
            "[1410/3000] Train Acc: 0.932547 Loss: 0.191817 | Val Acc: 0.202823 loss: 5.166361\n",
            "[1411/3000] Train Acc: 0.931992 Loss: 0.194709 | Val Acc: 0.191734 loss: 5.451961\n",
            "[1412/3000] Train Acc: 0.928211 Loss: 0.200969 | Val Acc: 0.176815 loss: 5.535078\n",
            "[1413/3000] Train Acc: 0.926649 Loss: 0.208656 | Val Acc: 0.183065 loss: 5.763576\n",
            "[1414/3000] Train Acc: 0.930682 Loss: 0.197379 | Val Acc: 0.190121 loss: 5.493831\n",
            "[1415/3000] Train Acc: 0.926951 Loss: 0.207807 | Val Acc: 0.197379 loss: 5.529972\n",
            "[1416/3000] Train Acc: 0.933001 Loss: 0.190563 | Val Acc: 0.179839 loss: 5.494545\n",
            "[1417/3000] Train Acc: 0.931337 Loss: 0.197259 | Val Acc: 0.188710 loss: 5.235882\n",
            "[1418/3000] Train Acc: 0.930329 Loss: 0.198966 | Val Acc: 0.190524 loss: 5.351222\n",
            "[1419/3000] Train Acc: 0.932144 Loss: 0.191587 | Val Acc: 0.186089 loss: 5.313721\n",
            "[1420/3000] Train Acc: 0.934160 Loss: 0.188396 | Val Acc: 0.206048 loss: 4.840902\n",
            "[1421/3000] Train Acc: 0.935017 Loss: 0.184674 | Val Acc: 0.184073 loss: 5.234112\n",
            "[1422/3000] Train Acc: 0.932950 Loss: 0.195655 | Val Acc: 0.191129 loss: 5.463412\n",
            "[1423/3000] Train Acc: 0.929119 Loss: 0.197283 | Val Acc: 0.191935 loss: 5.283236\n",
            "[1424/3000] Train Acc: 0.929623 Loss: 0.199868 | Val Acc: 0.178226 loss: 5.369946\n",
            "[1425/3000] Train Acc: 0.928564 Loss: 0.199789 | Val Acc: 0.186089 loss: 5.245170\n",
            "[1426/3000] Train Acc: 0.931034 Loss: 0.192643 | Val Acc: 0.178427 loss: 5.445934\n",
            "[1427/3000] Train Acc: 0.929724 Loss: 0.198653 | Val Acc: 0.191734 loss: 5.692273\n",
            "[1428/3000] Train Acc: 0.933303 Loss: 0.187566 | Val Acc: 0.174798 loss: 5.975063\n",
            "[1429/3000] Train Acc: 0.931892 Loss: 0.193826 | Val Acc: 0.186895 loss: 5.431472\n",
            "[1430/3000] Train Acc: 0.931992 Loss: 0.191799 | Val Acc: 0.184677 loss: 5.687851\n",
            "[1431/3000] Train Acc: 0.929119 Loss: 0.199560 | Val Acc: 0.203629 loss: 5.445490\n",
            "[1432/3000] Train Acc: 0.930127 Loss: 0.200076 | Val Acc: 0.189113 loss: 5.535819\n",
            "[1433/3000] Train Acc: 0.928363 Loss: 0.197178 | Val Acc: 0.214516 loss: 4.839897\n",
            "saving model with acc 0.215\n",
            "[1434/3000] Train Acc: 0.930329 Loss: 0.198372 | Val Acc: 0.196371 loss: 5.362102\n",
            "[1435/3000] Train Acc: 0.931892 Loss: 0.191023 | Val Acc: 0.180242 loss: 5.341979\n",
            "[1436/3000] Train Acc: 0.933353 Loss: 0.189974 | Val Acc: 0.162702 loss: 5.551349\n",
            "[1437/3000] Train Acc: 0.935824 Loss: 0.183554 | Val Acc: 0.198992 loss: 4.914625\n",
            "[1438/3000] Train Acc: 0.929270 Loss: 0.196480 | Val Acc: 0.197177 loss: 5.252175\n",
            "[1439/3000] Train Acc: 0.932849 Loss: 0.195284 | Val Acc: 0.202621 loss: 5.177411\n",
            "[1440/3000] Train Acc: 0.929371 Loss: 0.198456 | Val Acc: 0.186089 loss: 5.328708\n",
            "[1441/3000] Train Acc: 0.933858 Loss: 0.193281 | Val Acc: 0.174194 loss: 5.865677\n",
            "[1442/3000] Train Acc: 0.928161 Loss: 0.200557 | Val Acc: 0.187097 loss: 5.447609\n",
            "[1443/3000] Train Acc: 0.931690 Loss: 0.195247 | Val Acc: 0.186492 loss: 5.379392\n",
            "[1444/3000] Train Acc: 0.934815 Loss: 0.184307 | Val Acc: 0.190524 loss: 5.651321\n",
            "[1445/3000] Train Acc: 0.932749 Loss: 0.190946 | Val Acc: 0.210685 loss: 5.102578\n",
            "[1446/3000] Train Acc: 0.934211 Loss: 0.188598 | Val Acc: 0.191734 loss: 5.730673\n",
            "[1447/3000] Train Acc: 0.932950 Loss: 0.191701 | Val Acc: 0.195565 loss: 5.477825\n",
            "[1448/3000] Train Acc: 0.926901 Loss: 0.203320 | Val Acc: 0.179234 loss: 5.415495\n",
            "[1449/3000] Train Acc: 0.933606 Loss: 0.188481 | Val Acc: 0.194960 loss: 5.391572\n",
            "[1450/3000] Train Acc: 0.935370 Loss: 0.185022 | Val Acc: 0.185282 loss: 5.767560\n",
            "[1451/3000] Train Acc: 0.930177 Loss: 0.197610 | Val Acc: 0.186089 loss: 5.273819\n",
            "[1452/3000] Train Acc: 0.929169 Loss: 0.197671 | Val Acc: 0.193952 loss: 5.270110\n",
            "[1453/3000] Train Acc: 0.930682 Loss: 0.195522 | Val Acc: 0.185484 loss: 5.851147\n",
            "[1454/3000] Train Acc: 0.934059 Loss: 0.192761 | Val Acc: 0.174395 loss: 5.275416\n",
            "[1455/3000] Train Acc: 0.933606 Loss: 0.187976 | Val Acc: 0.198185 loss: 5.229840\n",
            "[1456/3000] Train Acc: 0.933858 Loss: 0.193120 | Val Acc: 0.194556 loss: 5.139718\n",
            "[1457/3000] Train Acc: 0.935471 Loss: 0.185649 | Val Acc: 0.197984 loss: 5.489247\n",
            "[1458/3000] Train Acc: 0.932799 Loss: 0.188559 | Val Acc: 0.192944 loss: 5.397801\n",
            "[1459/3000] Train Acc: 0.931135 Loss: 0.193950 | Val Acc: 0.162702 loss: 5.824468\n",
            "[1460/3000] Train Acc: 0.933555 Loss: 0.190588 | Val Acc: 0.202218 loss: 5.437459\n",
            "[1461/3000] Train Acc: 0.930530 Loss: 0.195145 | Val Acc: 0.203226 loss: 5.131359\n",
            "[1462/3000] Train Acc: 0.930379 Loss: 0.197827 | Val Acc: 0.192339 loss: 5.512395\n",
            "[1463/3000] Train Acc: 0.931841 Loss: 0.194810 | Val Acc: 0.201008 loss: 5.197494\n",
            "[1464/3000] Train Acc: 0.933606 Loss: 0.188519 | Val Acc: 0.191532 loss: 5.257041\n",
            "[1465/3000] Train Acc: 0.930329 Loss: 0.197184 | Val Acc: 0.185081 loss: 5.493580\n",
            "[1466/3000] Train Acc: 0.933555 Loss: 0.191778 | Val Acc: 0.193548 loss: 5.316916\n",
            "[1467/3000] Train Acc: 0.931589 Loss: 0.191634 | Val Acc: 0.198387 loss: 5.174368\n",
            "[1468/3000] Train Acc: 0.933656 Loss: 0.191286 | Val Acc: 0.200605 loss: 5.539551\n",
            "[1469/3000] Train Acc: 0.934362 Loss: 0.187441 | Val Acc: 0.188911 loss: 5.344122\n",
            "[1470/3000] Train Acc: 0.935118 Loss: 0.183978 | Val Acc: 0.193750 loss: 5.482474\n",
            "[1471/3000] Train Acc: 0.931438 Loss: 0.192386 | Val Acc: 0.190323 loss: 5.656407\n",
            "[1472/3000] Train Acc: 0.935471 Loss: 0.181033 | Val Acc: 0.192339 loss: 5.626279\n",
            "[1473/3000] Train Acc: 0.930430 Loss: 0.194627 | Val Acc: 0.196371 loss: 5.458397\n",
            "[1474/3000] Train Acc: 0.932547 Loss: 0.195168 | Val Acc: 0.194758 loss: 5.296306\n",
            "[1475/3000] Train Acc: 0.934715 Loss: 0.185341 | Val Acc: 0.191935 loss: 5.246660\n",
            "[1476/3000] Train Acc: 0.931438 Loss: 0.194239 | Val Acc: 0.193347 loss: 5.525741\n",
            "[1477/3000] Train Acc: 0.935219 Loss: 0.182909 | Val Acc: 0.194153 loss: 5.267325\n",
            "[1478/3000] Train Acc: 0.936681 Loss: 0.182479 | Val Acc: 0.178226 loss: 5.520983\n",
            "[1479/3000] Train Acc: 0.930631 Loss: 0.195734 | Val Acc: 0.194758 loss: 5.597979\n",
            "[1480/3000] Train Acc: 0.931892 Loss: 0.193549 | Val Acc: 0.193145 loss: 5.367793\n",
            "[1481/3000] Train Acc: 0.935168 Loss: 0.182567 | Val Acc: 0.209879 loss: 5.018237\n",
            "[1482/3000] Train Acc: 0.932144 Loss: 0.195041 | Val Acc: 0.198790 loss: 5.502669\n",
            "[1483/3000] Train Acc: 0.932396 Loss: 0.186845 | Val Acc: 0.191331 loss: 5.339102\n",
            "[1484/3000] Train Acc: 0.933656 Loss: 0.188665 | Val Acc: 0.192944 loss: 5.274764\n",
            "[1485/3000] Train Acc: 0.935219 Loss: 0.185355 | Val Acc: 0.198185 loss: 5.052690\n",
            "[1486/3000] Train Acc: 0.932547 Loss: 0.191462 | Val Acc: 0.192540 loss: 5.217571\n",
            "[1487/3000] Train Acc: 0.927758 Loss: 0.197524 | Val Acc: 0.167944 loss: 5.434816\n",
            "[1488/3000] Train Acc: 0.935572 Loss: 0.187386 | Val Acc: 0.190524 loss: 5.702088\n",
            "[1489/3000] Train Acc: 0.935925 Loss: 0.182692 | Val Acc: 0.181048 loss: 5.322826\n",
            "[1490/3000] Train Acc: 0.933757 Loss: 0.191015 | Val Acc: 0.211492 loss: 4.882678\n",
            "[1491/3000] Train Acc: 0.933404 Loss: 0.190696 | Val Acc: 0.187702 loss: 5.298239\n",
            "[1492/3000] Train Acc: 0.935824 Loss: 0.182416 | Val Acc: 0.200202 loss: 5.530155\n",
            "[1493/3000] Train Acc: 0.932547 Loss: 0.194804 | Val Acc: 0.194355 loss: 5.729811\n",
            "[1494/3000] Train Acc: 0.934866 Loss: 0.183197 | Val Acc: 0.181452 loss: 5.458751\n",
            "[1495/3000] Train Acc: 0.933555 Loss: 0.195566 | Val Acc: 0.189113 loss: 5.437011\n",
            "[1496/3000] Train Acc: 0.932244 Loss: 0.194192 | Val Acc: 0.185081 loss: 5.642790\n",
            "[1497/3000] Train Acc: 0.934866 Loss: 0.186596 | Val Acc: 0.182460 loss: 5.510704\n",
            "[1498/3000] Train Acc: 0.933908 Loss: 0.185393 | Val Acc: 0.192944 loss: 5.818618\n",
            "[1499/3000] Train Acc: 0.933101 Loss: 0.188635 | Val Acc: 0.183266 loss: 5.507302\n",
            "[1500/3000] Train Acc: 0.935017 Loss: 0.185143 | Val Acc: 0.205242 loss: 5.082134\n",
            "[1501/3000] Train Acc: 0.935269 Loss: 0.184866 | Val Acc: 0.194960 loss: 5.453593\n",
            "[1502/3000] Train Acc: 0.934311 Loss: 0.184394 | Val Acc: 0.201008 loss: 5.253421\n",
            "[1503/3000] Train Acc: 0.933505 Loss: 0.187832 | Val Acc: 0.196573 loss: 5.447713\n",
            "[1504/3000] Train Acc: 0.936025 Loss: 0.180271 | Val Acc: 0.174395 loss: 5.554905\n",
            "[1505/3000] Train Acc: 0.932244 Loss: 0.192650 | Val Acc: 0.187903 loss: 5.542471\n",
            "[1506/3000] Train Acc: 0.935975 Loss: 0.181114 | Val Acc: 0.180645 loss: 5.524830\n",
            "[1507/3000] Train Acc: 0.931236 Loss: 0.193036 | Val Acc: 0.181855 loss: 5.745273\n",
            "[1508/3000] Train Acc: 0.929925 Loss: 0.197302 | Val Acc: 0.184274 loss: 5.426867\n",
            "[1509/3000] Train Acc: 0.933303 Loss: 0.186976 | Val Acc: 0.189315 loss: 5.182624\n",
            "[1510/3000] Train Acc: 0.935773 Loss: 0.182355 | Val Acc: 0.193145 loss: 5.321147\n",
            "[1511/3000] Train Acc: 0.930732 Loss: 0.194596 | Val Acc: 0.188911 loss: 5.167246\n",
            "[1512/3000] Train Acc: 0.934563 Loss: 0.189458 | Val Acc: 0.190121 loss: 5.257194\n",
            "[1513/3000] Train Acc: 0.930682 Loss: 0.194491 | Val Acc: 0.199597 loss: 5.520937\n",
            "[1514/3000] Train Acc: 0.939201 Loss: 0.175496 | Val Acc: 0.185685 loss: 5.636221\n",
            "[1515/3000] Train Acc: 0.932043 Loss: 0.191497 | Val Acc: 0.186290 loss: 5.190167\n",
            "[1516/3000] Train Acc: 0.932093 Loss: 0.189297 | Val Acc: 0.192944 loss: 5.546772\n",
            "[1517/3000] Train Acc: 0.935723 Loss: 0.180477 | Val Acc: 0.200202 loss: 5.209929\n",
            "[1518/3000] Train Acc: 0.930934 Loss: 0.190992 | Val Acc: 0.204839 loss: 5.359446\n",
            "[1519/3000] Train Acc: 0.935420 Loss: 0.180741 | Val Acc: 0.189919 loss: 5.358866\n",
            "[1520/3000] Train Acc: 0.929270 Loss: 0.197637 | Val Acc: 0.193145 loss: 5.223570\n",
            "[1521/3000] Train Acc: 0.933353 Loss: 0.187888 | Val Acc: 0.195565 loss: 5.350811\n",
            "[1522/3000] Train Acc: 0.937034 Loss: 0.179163 | Val Acc: 0.189113 loss: 5.682633\n",
            "[1523/3000] Train Acc: 0.936328 Loss: 0.179800 | Val Acc: 0.196774 loss: 5.409710\n",
            "[1524/3000] Train Acc: 0.935370 Loss: 0.177574 | Val Acc: 0.191935 loss: 5.638176\n",
            "[1525/3000] Train Acc: 0.931992 Loss: 0.194542 | Val Acc: 0.179032 loss: 5.644299\n",
            "[1526/3000] Train Acc: 0.932446 Loss: 0.187999 | Val Acc: 0.176613 loss: 5.350156\n",
            "[1527/3000] Train Acc: 0.932043 Loss: 0.193585 | Val Acc: 0.193548 loss: 5.460927\n",
            "[1528/3000] Train Acc: 0.938748 Loss: 0.180154 | Val Acc: 0.195565 loss: 5.397084\n",
            "[1529/3000] Train Acc: 0.937286 Loss: 0.177139 | Val Acc: 0.210081 loss: 4.963734\n",
            "[1530/3000] Train Acc: 0.929169 Loss: 0.199504 | Val Acc: 0.176613 loss: 5.629660\n",
            "[1531/3000] Train Acc: 0.935219 Loss: 0.182825 | Val Acc: 0.186290 loss: 5.641203\n",
            "[1532/3000] Train Acc: 0.939554 Loss: 0.177667 | Val Acc: 0.198387 loss: 5.208842\n",
            "[1533/3000] Train Acc: 0.933001 Loss: 0.190197 | Val Acc: 0.178226 loss: 5.758147\n",
            "[1534/3000] Train Acc: 0.933656 Loss: 0.191627 | Val Acc: 0.175403 loss: 5.401880\n",
            "[1535/3000] Train Acc: 0.934412 Loss: 0.184929 | Val Acc: 0.175403 loss: 5.608261\n",
            "[1536/3000] Train Acc: 0.939201 Loss: 0.177411 | Val Acc: 0.167540 loss: 5.697926\n",
            "[1537/3000] Train Acc: 0.932144 Loss: 0.191799 | Val Acc: 0.183468 loss: 5.683176\n",
            "[1538/3000] Train Acc: 0.938143 Loss: 0.176143 | Val Acc: 0.196976 loss: 5.698269\n",
            "[1539/3000] Train Acc: 0.930530 Loss: 0.191498 | Val Acc: 0.191129 loss: 5.414529\n",
            "[1540/3000] Train Acc: 0.935219 Loss: 0.184198 | Val Acc: 0.205645 loss: 5.476386\n",
            "[1541/3000] Train Acc: 0.933807 Loss: 0.185551 | Val Acc: 0.184274 loss: 5.468658\n",
            "[1542/3000] Train Acc: 0.935219 Loss: 0.180006 | Val Acc: 0.199395 loss: 5.442410\n",
            "[1543/3000] Train Acc: 0.938496 Loss: 0.175514 | Val Acc: 0.190726 loss: 5.698578\n",
            "[1544/3000] Train Acc: 0.938143 Loss: 0.175292 | Val Acc: 0.202218 loss: 5.066499\n",
            "[1545/3000] Train Acc: 0.936277 Loss: 0.185963 | Val Acc: 0.190524 loss: 5.956306\n",
            "[1546/3000] Train Acc: 0.931791 Loss: 0.193332 | Val Acc: 0.190524 loss: 5.687310\n",
            "[1547/3000] Train Acc: 0.932345 Loss: 0.193611 | Val Acc: 0.179637 loss: 5.471997\n",
            "[1548/3000] Train Acc: 0.937538 Loss: 0.176630 | Val Acc: 0.208266 loss: 5.019036\n",
            "[1549/3000] Train Acc: 0.937135 Loss: 0.177278 | Val Acc: 0.193548 loss: 5.502328\n",
            "[1550/3000] Train Acc: 0.937084 Loss: 0.182704 | Val Acc: 0.191734 loss: 5.478438\n",
            "[1551/3000] Train Acc: 0.937639 Loss: 0.182442 | Val Acc: 0.194758 loss: 5.364747\n",
            "[1552/3000] Train Acc: 0.932194 Loss: 0.195266 | Val Acc: 0.190927 loss: 5.519612\n",
            "[1553/3000] Train Acc: 0.937135 Loss: 0.177096 | Val Acc: 0.189113 loss: 5.502067\n",
            "[1554/3000] Train Acc: 0.935673 Loss: 0.180832 | Val Acc: 0.200000 loss: 5.468013\n",
            "[1555/3000] Train Acc: 0.935824 Loss: 0.183667 | Val Acc: 0.196976 loss: 5.210046\n",
            "[1556/3000] Train Acc: 0.934261 Loss: 0.189745 | Val Acc: 0.189718 loss: 5.332928\n",
            "[1557/3000] Train Acc: 0.931387 Loss: 0.187552 | Val Acc: 0.190121 loss: 5.566881\n",
            "[1558/3000] Train Acc: 0.938647 Loss: 0.173820 | Val Acc: 0.190726 loss: 5.440939\n",
            "[1559/3000] Train Acc: 0.931287 Loss: 0.193504 | Val Acc: 0.188508 loss: 5.471057\n",
            "[1560/3000] Train Acc: 0.935925 Loss: 0.181440 | Val Acc: 0.205444 loss: 5.433489\n",
            "[1561/3000] Train Acc: 0.939605 Loss: 0.172794 | Val Acc: 0.189919 loss: 5.699484\n",
            "[1562/3000] Train Acc: 0.935824 Loss: 0.182111 | Val Acc: 0.191734 loss: 5.455693\n",
            "[1563/3000] Train Acc: 0.935269 Loss: 0.180431 | Val Acc: 0.215121 loss: 5.162977\n",
            "saving model with acc 0.215\n",
            "[1564/3000] Train Acc: 0.939706 Loss: 0.172213 | Val Acc: 0.199395 loss: 5.519019\n",
            "[1565/3000] Train Acc: 0.936025 Loss: 0.183675 | Val Acc: 0.217339 loss: 5.331802\n",
            "saving model with acc 0.217\n",
            "[1566/3000] Train Acc: 0.936328 Loss: 0.182675 | Val Acc: 0.189516 loss: 5.743058\n",
            "[1567/3000] Train Acc: 0.934261 Loss: 0.181786 | Val Acc: 0.204435 loss: 5.560571\n",
            "[1568/3000] Train Acc: 0.934261 Loss: 0.180651 | Val Acc: 0.196573 loss: 5.533062\n",
            "[1569/3000] Train Acc: 0.937538 Loss: 0.176131 | Val Acc: 0.192137 loss: 5.466588\n",
            "[1570/3000] Train Acc: 0.938596 Loss: 0.172777 | Val Acc: 0.193145 loss: 5.459890\n",
            "[1571/3000] Train Acc: 0.933202 Loss: 0.191309 | Val Acc: 0.190726 loss: 5.748037\n",
            "[1572/3000] Train Acc: 0.937840 Loss: 0.179491 | Val Acc: 0.197581 loss: 5.464674\n",
            "[1573/3000] Train Acc: 0.937286 Loss: 0.179217 | Val Acc: 0.198790 loss: 5.544606\n",
            "[1574/3000] Train Acc: 0.937588 Loss: 0.177581 | Val Acc: 0.177218 loss: 5.353603\n",
            "[1575/3000] Train Acc: 0.936580 Loss: 0.174571 | Val Acc: 0.191532 loss: 5.579259\n",
            "[1576/3000] Train Acc: 0.936530 Loss: 0.179804 | Val Acc: 0.184476 loss: 5.701174\n",
            "[1577/3000] Train Acc: 0.938596 Loss: 0.170604 | Val Acc: 0.186492 loss: 5.519696\n",
            "[1578/3000] Train Acc: 0.937891 Loss: 0.177488 | Val Acc: 0.195968 loss: 5.631055\n",
            "[1579/3000] Train Acc: 0.929018 Loss: 0.202070 | Val Acc: 0.184476 loss: 5.861101\n",
            "[1580/3000] Train Acc: 0.937286 Loss: 0.177457 | Val Acc: 0.185484 loss: 6.060770\n",
            "[1581/3000] Train Acc: 0.938244 Loss: 0.172763 | Val Acc: 0.183065 loss: 5.674458\n",
            "[1582/3000] Train Acc: 0.935068 Loss: 0.184122 | Val Acc: 0.182056 loss: 5.490575\n",
            "[1583/3000] Train Acc: 0.935723 Loss: 0.182851 | Val Acc: 0.168750 loss: 5.693018\n",
            "[1584/3000] Train Acc: 0.940058 Loss: 0.173193 | Val Acc: 0.206855 loss: 5.194735\n",
            "[1585/3000] Train Acc: 0.938294 Loss: 0.175372 | Val Acc: 0.195363 loss: 5.690305\n",
            "[1586/3000] Train Acc: 0.936933 Loss: 0.175500 | Val Acc: 0.176613 loss: 5.648984\n",
            "[1587/3000] Train Acc: 0.938546 Loss: 0.177003 | Val Acc: 0.190524 loss: 5.586774\n",
            "[1588/3000] Train Acc: 0.931387 Loss: 0.194015 | Val Acc: 0.183871 loss: 5.579760\n",
            "[1589/3000] Train Acc: 0.936933 Loss: 0.179276 | Val Acc: 0.187702 loss: 5.647021\n",
            "[1590/3000] Train Acc: 0.938244 Loss: 0.174504 | Val Acc: 0.188508 loss: 5.370261\n",
            "[1591/3000] Train Acc: 0.934614 Loss: 0.185053 | Val Acc: 0.198387 loss: 5.280008\n",
            "[1592/3000] Train Acc: 0.940008 Loss: 0.170740 | Val Acc: 0.198185 loss: 5.609491\n",
            "[1593/3000] Train Acc: 0.941571 Loss: 0.165525 | Val Acc: 0.202419 loss: 5.287743\n",
            "[1594/3000] Train Acc: 0.936025 Loss: 0.179907 | Val Acc: 0.208266 loss: 5.303517\n",
            "[1595/3000] Train Acc: 0.935017 Loss: 0.188935 | Val Acc: 0.188508 loss: 5.568824\n",
            "[1596/3000] Train Acc: 0.937689 Loss: 0.181098 | Val Acc: 0.210484 loss: 5.301364\n",
            "[1597/3000] Train Acc: 0.939806 Loss: 0.170867 | Val Acc: 0.205040 loss: 5.322710\n",
            "[1598/3000] Train Acc: 0.935471 Loss: 0.182581 | Val Acc: 0.208871 loss: 5.371664\n",
            "[1599/3000] Train Acc: 0.932849 Loss: 0.189296 | Val Acc: 0.200000 loss: 5.581580\n",
            "[1600/3000] Train Acc: 0.942025 Loss: 0.165611 | Val Acc: 0.198589 loss: 5.604712\n",
            "[1601/3000] Train Acc: 0.939252 Loss: 0.172688 | Val Acc: 0.200202 loss: 5.331423\n",
            "[1602/3000] Train Acc: 0.941621 Loss: 0.167246 | Val Acc: 0.185887 loss: 5.634952\n",
            "[1603/3000] Train Acc: 0.933656 Loss: 0.186036 | Val Acc: 0.194556 loss: 5.408398\n",
            "[1604/3000] Train Acc: 0.929220 Loss: 0.198880 | Val Acc: 0.174194 loss: 5.718078\n",
            "[1605/3000] Train Acc: 0.937739 Loss: 0.175015 | Val Acc: 0.177823 loss: 5.643983\n",
            "[1606/3000] Train Acc: 0.941168 Loss: 0.169640 | Val Acc: 0.188710 loss: 5.621574\n",
            "[1607/3000] Train Acc: 0.936681 Loss: 0.179307 | Val Acc: 0.178629 loss: 5.861327\n",
            "[1608/3000] Train Acc: 0.936177 Loss: 0.177889 | Val Acc: 0.194153 loss: 5.270486\n",
            "[1609/3000] Train Acc: 0.935168 Loss: 0.178737 | Val Acc: 0.179435 loss: 5.687027\n",
            "[1610/3000] Train Acc: 0.938395 Loss: 0.171524 | Val Acc: 0.187500 loss: 5.386279\n",
            "[1611/3000] Train Acc: 0.939907 Loss: 0.169590 | Val Acc: 0.189718 loss: 5.461018\n",
            "[1612/3000] Train Acc: 0.938344 Loss: 0.174138 | Val Acc: 0.194153 loss: 5.373366\n",
            "[1613/3000] Train Acc: 0.939655 Loss: 0.171510 | Val Acc: 0.210685 loss: 5.022018\n",
            "[1614/3000] Train Acc: 0.936227 Loss: 0.179995 | Val Acc: 0.204435 loss: 5.225835\n",
            "[1615/3000] Train Acc: 0.935975 Loss: 0.179157 | Val Acc: 0.194153 loss: 5.633750\n",
            "[1616/3000] Train Acc: 0.933807 Loss: 0.185112 | Val Acc: 0.212903 loss: 5.441430\n",
            "[1617/3000] Train Acc: 0.940109 Loss: 0.174275 | Val Acc: 0.198185 loss: 5.383352\n",
            "[1618/3000] Train Acc: 0.938143 Loss: 0.174415 | Val Acc: 0.202823 loss: 5.415565\n",
            "[1619/3000] Train Acc: 0.938596 Loss: 0.177863 | Val Acc: 0.198790 loss: 5.430174\n",
            "[1620/3000] Train Acc: 0.940311 Loss: 0.171941 | Val Acc: 0.186492 loss: 5.717350\n",
            "[1621/3000] Train Acc: 0.941974 Loss: 0.167694 | Val Acc: 0.197782 loss: 5.391652\n",
            "[1622/3000] Train Acc: 0.940311 Loss: 0.170985 | Val Acc: 0.217742 loss: 5.158850\n",
            "saving model with acc 0.218\n",
            "[1623/3000] Train Acc: 0.935975 Loss: 0.177813 | Val Acc: 0.199597 loss: 5.248282\n",
            "[1624/3000] Train Acc: 0.940512 Loss: 0.174198 | Val Acc: 0.197581 loss: 5.482091\n",
            "[1625/3000] Train Acc: 0.937891 Loss: 0.172540 | Val Acc: 0.191935 loss: 5.558919\n",
            "[1626/3000] Train Acc: 0.938949 Loss: 0.169181 | Val Acc: 0.188508 loss: 5.779483\n",
            "[1627/3000] Train Acc: 0.937034 Loss: 0.181299 | Val Acc: 0.183669 loss: 5.651527\n",
            "[1628/3000] Train Acc: 0.942428 Loss: 0.166656 | Val Acc: 0.191935 loss: 5.798842\n",
            "[1629/3000] Train Acc: 0.941722 Loss: 0.170727 | Val Acc: 0.193548 loss: 5.591834\n",
            "[1630/3000] Train Acc: 0.936782 Loss: 0.176073 | Val Acc: 0.204637 loss: 5.324436\n",
            "[1631/3000] Train Acc: 0.939252 Loss: 0.173241 | Val Acc: 0.199597 loss: 5.233842\n",
            "[1632/3000] Train Acc: 0.936479 Loss: 0.179894 | Val Acc: 0.178024 loss: 5.852191\n",
            "[1633/3000] Train Acc: 0.939605 Loss: 0.174395 | Val Acc: 0.212298 loss: 5.136827\n",
            "[1634/3000] Train Acc: 0.939958 Loss: 0.171094 | Val Acc: 0.191331 loss: 5.734090\n",
            "[1635/3000] Train Acc: 0.940260 Loss: 0.174524 | Val Acc: 0.194758 loss: 5.363607\n",
            "[1636/3000] Train Acc: 0.939101 Loss: 0.177755 | Val Acc: 0.211492 loss: 5.295036\n",
            "[1637/3000] Train Acc: 0.939756 Loss: 0.172374 | Val Acc: 0.201613 loss: 5.581955\n",
            "[1638/3000] Train Acc: 0.935370 Loss: 0.181329 | Val Acc: 0.187702 loss: 5.688687\n",
            "[1639/3000] Train Acc: 0.941571 Loss: 0.169924 | Val Acc: 0.191935 loss: 5.529059\n",
            "[1640/3000] Train Acc: 0.938344 Loss: 0.174389 | Val Acc: 0.213508 loss: 5.288287\n",
            "[1641/3000] Train Acc: 0.936832 Loss: 0.179914 | Val Acc: 0.203629 loss: 5.270835\n",
            "[1642/3000] Train Acc: 0.941420 Loss: 0.165821 | Val Acc: 0.211492 loss: 5.256307\n",
            "[1643/3000] Train Acc: 0.941218 Loss: 0.168657 | Val Acc: 0.186895 loss: 6.062773\n",
            "[1644/3000] Train Acc: 0.940411 Loss: 0.169913 | Val Acc: 0.211694 loss: 5.158468\n",
            "[1645/3000] Train Acc: 0.936933 Loss: 0.176464 | Val Acc: 0.188911 loss: 5.698692\n",
            "[1646/3000] Train Acc: 0.935572 Loss: 0.178447 | Val Acc: 0.197379 loss: 5.513952\n",
            "[1647/3000] Train Acc: 0.936782 Loss: 0.177761 | Val Acc: 0.202016 loss: 5.291010\n",
            "[1648/3000] Train Acc: 0.939857 Loss: 0.172441 | Val Acc: 0.210081 loss: 5.496815\n",
            "[1649/3000] Train Acc: 0.935874 Loss: 0.179107 | Val Acc: 0.188306 loss: 5.593706\n",
            "[1650/3000] Train Acc: 0.939504 Loss: 0.169239 | Val Acc: 0.201008 loss: 5.445484\n",
            "[1651/3000] Train Acc: 0.941268 Loss: 0.166205 | Val Acc: 0.182258 loss: 5.577526\n",
            "[1652/3000] Train Acc: 0.941974 Loss: 0.168245 | Val Acc: 0.192540 loss: 5.355418\n",
            "[1653/3000] Train Acc: 0.932597 Loss: 0.186883 | Val Acc: 0.194355 loss: 5.669683\n",
            "[1654/3000] Train Acc: 0.938596 Loss: 0.173966 | Val Acc: 0.191129 loss: 5.788913\n",
            "[1655/3000] Train Acc: 0.937336 Loss: 0.174862 | Val Acc: 0.184879 loss: 5.596374\n",
            "[1656/3000] Train Acc: 0.938949 Loss: 0.171644 | Val Acc: 0.174395 loss: 5.808751\n",
            "[1657/3000] Train Acc: 0.939605 Loss: 0.172830 | Val Acc: 0.201008 loss: 5.152110\n",
            "[1658/3000] Train Acc: 0.940361 Loss: 0.169013 | Val Acc: 0.209476 loss: 5.278739\n",
            "[1659/3000] Train Acc: 0.939000 Loss: 0.172412 | Val Acc: 0.198992 loss: 5.605475\n",
            "[1660/3000] Train Acc: 0.940815 Loss: 0.166598 | Val Acc: 0.209274 loss: 5.314560\n",
            "[1661/3000] Train Acc: 0.939554 Loss: 0.171764 | Val Acc: 0.193952 loss: 5.344624\n",
            "[1662/3000] Train Acc: 0.939907 Loss: 0.173585 | Val Acc: 0.200806 loss: 5.377350\n",
            "[1663/3000] Train Acc: 0.940008 Loss: 0.170101 | Val Acc: 0.190927 loss: 5.624002\n",
            "[1664/3000] Train Acc: 0.938395 Loss: 0.175176 | Val Acc: 0.197782 loss: 5.660927\n",
            "[1665/3000] Train Acc: 0.937992 Loss: 0.180211 | Val Acc: 0.199597 loss: 5.192857\n",
            "[1666/3000] Train Acc: 0.939958 Loss: 0.173758 | Val Acc: 0.183065 loss: 5.486934\n",
            "[1667/3000] Train Acc: 0.935773 Loss: 0.181200 | Val Acc: 0.185282 loss: 5.460708\n",
            "[1668/3000] Train Acc: 0.942125 Loss: 0.164073 | Val Acc: 0.197177 loss: 5.634386\n",
            "[1669/3000] Train Acc: 0.944646 Loss: 0.160561 | Val Acc: 0.209476 loss: 5.544759\n",
            "[1670/3000] Train Acc: 0.945654 Loss: 0.162874 | Val Acc: 0.189718 loss: 5.625350\n",
            "[1671/3000] Train Acc: 0.938798 Loss: 0.171148 | Val Acc: 0.202419 loss: 5.381370\n",
            "[1672/3000] Train Acc: 0.938395 Loss: 0.174995 | Val Acc: 0.197581 loss: 5.469586\n",
            "[1673/3000] Train Acc: 0.939907 Loss: 0.169125 | Val Acc: 0.195565 loss: 5.692316\n",
            "[1674/3000] Train Acc: 0.938496 Loss: 0.171360 | Val Acc: 0.171573 loss: 5.848252\n",
            "[1675/3000] Train Acc: 0.937387 Loss: 0.177197 | Val Acc: 0.203427 loss: 5.391775\n",
            "[1676/3000] Train Acc: 0.940764 Loss: 0.170432 | Val Acc: 0.192742 loss: 5.977326\n",
            "[1677/3000] Train Acc: 0.941117 Loss: 0.168690 | Val Acc: 0.202419 loss: 5.728084\n",
            "[1678/3000] Train Acc: 0.943285 Loss: 0.166721 | Val Acc: 0.203427 loss: 5.552107\n",
            "[1679/3000] Train Acc: 0.943184 Loss: 0.163155 | Val Acc: 0.208871 loss: 5.330093\n",
            "[1680/3000] Train Acc: 0.936630 Loss: 0.178868 | Val Acc: 0.192944 loss: 5.706818\n",
            "[1681/3000] Train Acc: 0.941470 Loss: 0.165000 | Val Acc: 0.201613 loss: 5.230208\n",
            "[1682/3000] Train Acc: 0.941268 Loss: 0.163894 | Val Acc: 0.213306 loss: 5.676097\n",
            "[1683/3000] Train Acc: 0.942630 Loss: 0.163049 | Val Acc: 0.192944 loss: 5.604669\n",
            "[1684/3000] Train Acc: 0.941268 Loss: 0.168357 | Val Acc: 0.204839 loss: 5.440657\n",
            "[1685/3000] Train Acc: 0.938798 Loss: 0.172004 | Val Acc: 0.203226 loss: 5.437260\n",
            "[1686/3000] Train Acc: 0.939403 Loss: 0.170682 | Val Acc: 0.191935 loss: 5.652008\n",
            "[1687/3000] Train Acc: 0.942529 Loss: 0.165175 | Val Acc: 0.201008 loss: 5.499287\n",
            "[1688/3000] Train Acc: 0.941571 Loss: 0.166559 | Val Acc: 0.210282 loss: 5.461672\n",
            "[1689/3000] Train Acc: 0.936025 Loss: 0.182920 | Val Acc: 0.204032 loss: 5.584279\n",
            "[1690/3000] Train Acc: 0.941520 Loss: 0.163370 | Val Acc: 0.184073 loss: 5.616268\n",
            "[1691/3000] Train Acc: 0.938294 Loss: 0.175240 | Val Acc: 0.205645 loss: 5.727704\n",
            "[1692/3000] Train Acc: 0.942025 Loss: 0.165367 | Val Acc: 0.192540 loss: 5.937736\n",
            "[1693/3000] Train Acc: 0.936630 Loss: 0.178125 | Val Acc: 0.204637 loss: 5.370901\n",
            "[1694/3000] Train Acc: 0.939907 Loss: 0.171758 | Val Acc: 0.209879 loss: 5.309810\n",
            "[1695/3000] Train Acc: 0.941016 Loss: 0.167331 | Val Acc: 0.209879 loss: 5.428443\n",
            "[1696/3000] Train Acc: 0.942428 Loss: 0.164632 | Val Acc: 0.197379 loss: 5.714135\n",
            "[1697/3000] Train Acc: 0.941319 Loss: 0.165111 | Val Acc: 0.202621 loss: 5.269965\n",
            "[1698/3000] Train Acc: 0.940512 Loss: 0.166457 | Val Acc: 0.199194 loss: 5.774777\n",
            "[1699/3000] Train Acc: 0.937992 Loss: 0.177363 | Val Acc: 0.172177 loss: 5.952890\n",
            "[1700/3000] Train Acc: 0.938697 Loss: 0.172235 | Val Acc: 0.199194 loss: 5.673641\n",
            "[1701/3000] Train Acc: 0.938798 Loss: 0.169533 | Val Acc: 0.209677 loss: 5.292427\n",
            "[1702/3000] Train Acc: 0.943134 Loss: 0.163692 | Val Acc: 0.201411 loss: 5.357924\n",
            "[1703/3000] Train Acc: 0.938748 Loss: 0.172029 | Val Acc: 0.214113 loss: 5.198270\n",
            "[1704/3000] Train Acc: 0.942781 Loss: 0.160222 | Val Acc: 0.198790 loss: 5.625978\n",
            "[1705/3000] Train Acc: 0.942025 Loss: 0.164617 | Val Acc: 0.209677 loss: 5.318689\n",
            "[1706/3000] Train Acc: 0.938244 Loss: 0.175660 | Val Acc: 0.206250 loss: 5.465202\n",
            "[1707/3000] Train Acc: 0.941974 Loss: 0.166089 | Val Acc: 0.191331 loss: 5.556879\n",
            "[1708/3000] Train Acc: 0.942882 Loss: 0.164906 | Val Acc: 0.205847 loss: 5.246126\n",
            "[1709/3000] Train Acc: 0.944848 Loss: 0.160203 | Val Acc: 0.186290 loss: 5.440752\n",
            "[1710/3000] Train Acc: 0.944495 Loss: 0.160697 | Val Acc: 0.196169 loss: 5.555882\n",
            "[1711/3000] Train Acc: 0.940462 Loss: 0.169239 | Val Acc: 0.202016 loss: 5.563676\n",
            "[1712/3000] Train Acc: 0.938748 Loss: 0.178090 | Val Acc: 0.197984 loss: 5.673872\n",
            "[1713/3000] Train Acc: 0.943184 Loss: 0.164465 | Val Acc: 0.202016 loss: 5.455767\n",
            "[1714/3000] Train Acc: 0.941268 Loss: 0.167522 | Val Acc: 0.190323 loss: 5.649913\n",
            "[1715/3000] Train Acc: 0.943335 Loss: 0.159029 | Val Acc: 0.193952 loss: 5.918448\n",
            "[1716/3000] Train Acc: 0.942529 Loss: 0.162760 | Val Acc: 0.181855 loss: 5.780535\n",
            "[1717/3000] Train Acc: 0.940361 Loss: 0.169862 | Val Acc: 0.193347 loss: 5.615293\n",
            "[1718/3000] Train Acc: 0.939252 Loss: 0.169971 | Val Acc: 0.215323 loss: 5.018900\n",
            "[1719/3000] Train Acc: 0.939454 Loss: 0.173414 | Val Acc: 0.193548 loss: 5.649174\n",
            "[1720/3000] Train Acc: 0.934211 Loss: 0.179286 | Val Acc: 0.208266 loss: 5.191525\n",
            "[1721/3000] Train Acc: 0.943688 Loss: 0.159436 | Val Acc: 0.189718 loss: 5.639872\n",
            "[1722/3000] Train Acc: 0.946058 Loss: 0.152843 | Val Acc: 0.195766 loss: 5.655575\n",
            "[1723/3000] Train Acc: 0.937437 Loss: 0.172054 | Val Acc: 0.197379 loss: 5.828706\n",
            "[1724/3000] Train Acc: 0.942277 Loss: 0.164832 | Val Acc: 0.197581 loss: 5.675347\n",
            "[1725/3000] Train Acc: 0.943386 Loss: 0.161700 | Val Acc: 0.201210 loss: 5.367143\n",
            "[1726/3000] Train Acc: 0.940462 Loss: 0.170016 | Val Acc: 0.202621 loss: 5.580376\n",
            "[1727/3000] Train Acc: 0.940260 Loss: 0.171676 | Val Acc: 0.197782 loss: 5.653857\n",
            "[1728/3000] Train Acc: 0.937739 Loss: 0.180268 | Val Acc: 0.193145 loss: 5.841535\n",
            "[1729/3000] Train Acc: 0.938849 Loss: 0.174787 | Val Acc: 0.220565 loss: 5.089217\n",
            "saving model with acc 0.221\n",
            "[1730/3000] Train Acc: 0.939907 Loss: 0.168957 | Val Acc: 0.206452 loss: 5.414114\n",
            "[1731/3000] Train Acc: 0.945251 Loss: 0.160475 | Val Acc: 0.216129 loss: 5.194974\n",
            "[1732/3000] Train Acc: 0.940865 Loss: 0.165395 | Val Acc: 0.211694 loss: 5.309986\n",
            "[1733/3000] Train Acc: 0.942781 Loss: 0.163767 | Val Acc: 0.189315 loss: 5.625298\n",
            "[1734/3000] Train Acc: 0.943537 Loss: 0.161519 | Val Acc: 0.201815 loss: 5.501359\n",
            "[1735/3000] Train Acc: 0.942025 Loss: 0.162424 | Val Acc: 0.208065 loss: 5.257371\n",
            "[1736/3000] Train Acc: 0.947772 Loss: 0.153462 | Val Acc: 0.203831 loss: 5.267347\n",
            "[1737/3000] Train Acc: 0.938193 Loss: 0.170071 | Val Acc: 0.203024 loss: 5.780021\n",
            "[1738/3000] Train Acc: 0.944596 Loss: 0.158500 | Val Acc: 0.215726 loss: 5.318295\n",
            "[1739/3000] Train Acc: 0.941520 Loss: 0.166796 | Val Acc: 0.204234 loss: 5.198596\n",
            "[1740/3000] Train Acc: 0.940966 Loss: 0.165106 | Val Acc: 0.185685 loss: 5.701416\n",
            "[1741/3000] Train Acc: 0.942125 Loss: 0.164820 | Val Acc: 0.191734 loss: 5.609861\n",
            "[1742/3000] Train Acc: 0.944646 Loss: 0.157561 | Val Acc: 0.205040 loss: 5.518414\n",
            "[1743/3000] Train Acc: 0.937185 Loss: 0.178733 | Val Acc: 0.187702 loss: 5.690451\n",
            "[1744/3000] Train Acc: 0.941470 Loss: 0.167890 | Val Acc: 0.200000 loss: 5.561768\n",
            "[1745/3000] Train Acc: 0.939655 Loss: 0.169807 | Val Acc: 0.195161 loss: 5.814468\n",
            "[1746/3000] Train Acc: 0.939302 Loss: 0.172009 | Val Acc: 0.192137 loss: 5.855944\n",
            "[1747/3000] Train Acc: 0.945049 Loss: 0.158141 | Val Acc: 0.203427 loss: 5.492672\n",
            "[1748/3000] Train Acc: 0.939000 Loss: 0.168212 | Val Acc: 0.215726 loss: 5.090937\n",
            "[1749/3000] Train Acc: 0.942075 Loss: 0.167861 | Val Acc: 0.197782 loss: 5.594332\n",
            "[1750/3000] Train Acc: 0.944344 Loss: 0.158258 | Val Acc: 0.199798 loss: 5.445415\n",
            "[1751/3000] Train Acc: 0.943789 Loss: 0.162461 | Val Acc: 0.199798 loss: 5.601648\n",
            "[1752/3000] Train Acc: 0.938496 Loss: 0.169229 | Val Acc: 0.202823 loss: 5.615010\n",
            "[1753/3000] Train Acc: 0.944092 Loss: 0.159355 | Val Acc: 0.200202 loss: 5.468353\n",
            "[1754/3000] Train Acc: 0.944949 Loss: 0.162960 | Val Acc: 0.212298 loss: 5.408049\n",
            "[1755/3000] Train Acc: 0.945251 Loss: 0.155973 | Val Acc: 0.211290 loss: 5.527076\n",
            "[1756/3000] Train Acc: 0.943134 Loss: 0.162979 | Val Acc: 0.190121 loss: 5.929422\n",
            "[1757/3000] Train Acc: 0.939958 Loss: 0.170806 | Val Acc: 0.197581 loss: 5.676942\n",
            "[1758/3000] Train Acc: 0.944697 Loss: 0.157494 | Val Acc: 0.201815 loss: 5.476374\n",
            "[1759/3000] Train Acc: 0.945251 Loss: 0.159048 | Val Acc: 0.190927 loss: 5.648843\n",
            "[1760/3000] Train Acc: 0.946310 Loss: 0.156477 | Val Acc: 0.193347 loss: 5.793770\n",
            "[1761/3000] Train Acc: 0.941319 Loss: 0.166489 | Val Acc: 0.214516 loss: 5.197212\n",
            "[1762/3000] Train Acc: 0.940563 Loss: 0.163866 | Val Acc: 0.187097 loss: 5.667879\n",
            "[1763/3000] Train Acc: 0.941974 Loss: 0.166426 | Val Acc: 0.181855 loss: 5.801253\n",
            "[1764/3000] Train Acc: 0.945402 Loss: 0.158278 | Val Acc: 0.202621 loss: 5.660206\n",
            "[1765/3000] Train Acc: 0.943386 Loss: 0.161824 | Val Acc: 0.212903 loss: 5.121142\n",
            "[1766/3000] Train Acc: 0.942630 Loss: 0.161625 | Val Acc: 0.185484 loss: 5.823482\n",
            "[1767/3000] Train Acc: 0.945856 Loss: 0.153595 | Val Acc: 0.206452 loss: 5.321729\n",
            "[1768/3000] Train Acc: 0.939958 Loss: 0.171886 | Val Acc: 0.188105 loss: 5.760871\n",
            "[1769/3000] Train Acc: 0.939101 Loss: 0.172833 | Val Acc: 0.196976 loss: 5.511673\n",
            "[1770/3000] Train Acc: 0.944495 Loss: 0.157686 | Val Acc: 0.196573 loss: 5.646609\n",
            "[1771/3000] Train Acc: 0.943739 Loss: 0.159790 | Val Acc: 0.189315 loss: 5.819174\n",
            "[1772/3000] Train Acc: 0.944545 Loss: 0.158376 | Val Acc: 0.202419 loss: 5.557332\n",
            "[1773/3000] Train Acc: 0.942478 Loss: 0.165018 | Val Acc: 0.204435 loss: 5.583236\n",
            "[1774/3000] Train Acc: 0.940008 Loss: 0.168197 | Val Acc: 0.189315 loss: 5.906577\n",
            "[1775/3000] Train Acc: 0.945201 Loss: 0.154956 | Val Acc: 0.198790 loss: 5.531236\n",
            "[1776/3000] Train Acc: 0.942781 Loss: 0.164819 | Val Acc: 0.184677 loss: 6.206365\n",
            "[1777/3000] Train Acc: 0.942579 Loss: 0.164427 | Val Acc: 0.196371 loss: 5.533603\n",
            "[1778/3000] Train Acc: 0.942630 Loss: 0.159163 | Val Acc: 0.215927 loss: 5.189066\n",
            "[1779/3000] Train Acc: 0.939806 Loss: 0.167136 | Val Acc: 0.214919 loss: 5.346907\n",
            "[1780/3000] Train Acc: 0.943487 Loss: 0.162073 | Val Acc: 0.194556 loss: 5.656679\n",
            "[1781/3000] Train Acc: 0.946461 Loss: 0.150683 | Val Acc: 0.190726 loss: 5.651329\n",
            "[1782/3000] Train Acc: 0.943033 Loss: 0.167233 | Val Acc: 0.196169 loss: 5.696482\n",
            "[1783/3000] Train Acc: 0.942478 Loss: 0.167187 | Val Acc: 0.219153 loss: 5.161513\n",
            "[1784/3000] Train Acc: 0.940462 Loss: 0.167452 | Val Acc: 0.208065 loss: 5.749775\n",
            "[1785/3000] Train Acc: 0.945251 Loss: 0.158150 | Val Acc: 0.185685 loss: 5.948183\n",
            "[1786/3000] Train Acc: 0.942579 Loss: 0.163461 | Val Acc: 0.200000 loss: 5.632748\n",
            "[1787/3000] Train Acc: 0.944949 Loss: 0.156558 | Val Acc: 0.180847 loss: 5.678414\n",
            "[1788/3000] Train Acc: 0.938395 Loss: 0.171437 | Val Acc: 0.200806 loss: 5.622996\n",
            "[1789/3000] Train Acc: 0.947167 Loss: 0.149927 | Val Acc: 0.207661 loss: 5.417484\n",
            "[1790/3000] Train Acc: 0.945100 Loss: 0.155531 | Val Acc: 0.197379 loss: 5.675660\n",
            "[1791/3000] Train Acc: 0.944848 Loss: 0.157807 | Val Acc: 0.208669 loss: 5.427078\n",
            "[1792/3000] Train Acc: 0.944797 Loss: 0.159257 | Val Acc: 0.204234 loss: 5.500869\n",
            "[1793/3000] Train Acc: 0.942932 Loss: 0.161711 | Val Acc: 0.204839 loss: 5.605832\n",
            "[1794/3000] Train Acc: 0.943235 Loss: 0.164051 | Val Acc: 0.211290 loss: 5.349340\n",
            "[1795/3000] Train Acc: 0.942579 Loss: 0.163068 | Val Acc: 0.195766 loss: 5.625289\n",
            "[1796/3000] Train Acc: 0.943839 Loss: 0.159837 | Val Acc: 0.202621 loss: 5.585080\n",
            "[1797/3000] Train Acc: 0.942277 Loss: 0.162541 | Val Acc: 0.182258 loss: 5.963175\n",
            "[1798/3000] Train Acc: 0.940714 Loss: 0.168178 | Val Acc: 0.184677 loss: 5.917895\n",
            "[1799/3000] Train Acc: 0.943587 Loss: 0.161611 | Val Acc: 0.201815 loss: 5.667118\n",
            "[1800/3000] Train Acc: 0.942781 Loss: 0.160777 | Val Acc: 0.217339 loss: 5.299407\n",
            "[1801/3000] Train Acc: 0.945705 Loss: 0.159566 | Val Acc: 0.186290 loss: 5.765779\n",
            "[1802/3000] Train Acc: 0.943487 Loss: 0.165183 | Val Acc: 0.193548 loss: 5.478093\n",
            "[1803/3000] Train Acc: 0.943537 Loss: 0.158503 | Val Acc: 0.199194 loss: 5.480022\n",
            "[1804/3000] Train Acc: 0.941420 Loss: 0.166481 | Val Acc: 0.206452 loss: 5.249134\n",
            "[1805/3000] Train Acc: 0.944898 Loss: 0.156874 | Val Acc: 0.199194 loss: 5.501177\n",
            "[1806/3000] Train Acc: 0.944747 Loss: 0.156831 | Val Acc: 0.180242 loss: 5.788053\n",
            "[1807/3000] Train Acc: 0.945402 Loss: 0.154783 | Val Acc: 0.210081 loss: 5.413233\n",
            "[1808/3000] Train Acc: 0.940008 Loss: 0.168247 | Val Acc: 0.200605 loss: 5.712741\n",
            "[1809/3000] Train Acc: 0.942125 Loss: 0.166907 | Val Acc: 0.182258 loss: 5.919026\n",
            "[1810/3000] Train Acc: 0.944646 Loss: 0.157928 | Val Acc: 0.207258 loss: 5.360021\n",
            "[1811/3000] Train Acc: 0.940008 Loss: 0.167259 | Val Acc: 0.193347 loss: 5.468369\n",
            "[1812/3000] Train Acc: 0.948074 Loss: 0.152521 | Val Acc: 0.204839 loss: 5.330219\n",
            "[1813/3000] Train Acc: 0.943739 Loss: 0.160331 | Val Acc: 0.203024 loss: 5.444627\n",
            "[1814/3000] Train Acc: 0.943688 Loss: 0.162177 | Val Acc: 0.195766 loss: 5.589684\n",
            "[1815/3000] Train Acc: 0.943991 Loss: 0.161639 | Val Acc: 0.202218 loss: 5.581595\n",
            "[1816/3000] Train Acc: 0.948225 Loss: 0.148484 | Val Acc: 0.193750 loss: 6.084406\n",
            "[1817/3000] Train Acc: 0.940663 Loss: 0.164219 | Val Acc: 0.216935 loss: 5.297722\n",
            "[1818/3000] Train Acc: 0.946461 Loss: 0.150886 | Val Acc: 0.203024 loss: 5.436811\n",
            "[1819/3000] Train Acc: 0.941823 Loss: 0.162077 | Val Acc: 0.191935 loss: 5.646210\n",
            "[1820/3000] Train Acc: 0.944747 Loss: 0.156139 | Val Acc: 0.198387 loss: 5.619723\n",
            "[1821/3000] Train Acc: 0.940210 Loss: 0.169323 | Val Acc: 0.186290 loss: 5.714163\n",
            "[1822/3000] Train Acc: 0.946108 Loss: 0.153277 | Val Acc: 0.212298 loss: 5.528824\n",
            "[1823/3000] Train Acc: 0.944848 Loss: 0.160575 | Val Acc: 0.203629 loss: 5.508786\n",
            "[1824/3000] Train Acc: 0.945906 Loss: 0.158084 | Val Acc: 0.196573 loss: 5.501185\n",
            "[1825/3000] Train Acc: 0.947268 Loss: 0.148093 | Val Acc: 0.207863 loss: 5.492010\n",
            "[1826/3000] Train Acc: 0.946814 Loss: 0.153141 | Val Acc: 0.205040 loss: 5.389961\n",
            "[1827/3000] Train Acc: 0.944596 Loss: 0.156096 | Val Acc: 0.211492 loss: 5.297583\n",
            "[1828/3000] Train Acc: 0.940815 Loss: 0.166562 | Val Acc: 0.205645 loss: 5.491315\n",
            "[1829/3000] Train Acc: 0.945251 Loss: 0.159498 | Val Acc: 0.201008 loss: 5.622546\n",
            "[1830/3000] Train Acc: 0.942680 Loss: 0.163125 | Val Acc: 0.208669 loss: 5.490310\n",
            "[1831/3000] Train Acc: 0.940815 Loss: 0.167706 | Val Acc: 0.171169 loss: 6.143961\n",
            "[1832/3000] Train Acc: 0.944949 Loss: 0.157231 | Val Acc: 0.208871 loss: 5.616029\n",
            "[1833/3000] Train Acc: 0.945100 Loss: 0.155451 | Val Acc: 0.204234 loss: 5.521375\n",
            "[1834/3000] Train Acc: 0.941520 Loss: 0.163624 | Val Acc: 0.204234 loss: 5.832837\n",
            "[1835/3000] Train Acc: 0.942478 Loss: 0.161444 | Val Acc: 0.194556 loss: 5.703705\n",
            "[1836/3000] Train Acc: 0.947066 Loss: 0.149017 | Val Acc: 0.206250 loss: 5.326652\n",
            "[1837/3000] Train Acc: 0.946360 Loss: 0.152497 | Val Acc: 0.182258 loss: 5.986331\n",
            "[1838/3000] Train Acc: 0.948427 Loss: 0.150387 | Val Acc: 0.198790 loss: 5.682492\n",
            "[1839/3000] Train Acc: 0.944646 Loss: 0.160995 | Val Acc: 0.200202 loss: 5.622922\n",
            "[1840/3000] Train Acc: 0.947469 Loss: 0.155909 | Val Acc: 0.212500 loss: 5.305882\n",
            "[1841/3000] Train Acc: 0.947016 Loss: 0.151639 | Val Acc: 0.216935 loss: 5.420470\n",
            "[1842/3000] Train Acc: 0.944797 Loss: 0.157688 | Val Acc: 0.214315 loss: 5.564607\n",
            "[1843/3000] Train Acc: 0.943537 Loss: 0.162128 | Val Acc: 0.205645 loss: 5.514312\n",
            "[1844/3000] Train Acc: 0.944848 Loss: 0.158912 | Val Acc: 0.185081 loss: 5.802968\n",
            "[1845/3000] Train Acc: 0.946007 Loss: 0.155543 | Val Acc: 0.206250 loss: 5.370500\n",
            "[1846/3000] Train Acc: 0.945806 Loss: 0.153408 | Val Acc: 0.186089 loss: 5.920845\n",
            "[1847/3000] Train Acc: 0.943235 Loss: 0.162394 | Val Acc: 0.184677 loss: 5.961787\n",
            "[1848/3000] Train Acc: 0.944092 Loss: 0.162710 | Val Acc: 0.203629 loss: 5.859570\n",
            "[1849/3000] Train Acc: 0.937891 Loss: 0.174619 | Val Acc: 0.215121 loss: 5.356393\n",
            "[1850/3000] Train Acc: 0.948074 Loss: 0.156024 | Val Acc: 0.211290 loss: 5.131245\n",
            "[1851/3000] Train Acc: 0.941773 Loss: 0.164433 | Val Acc: 0.190927 loss: 5.594000\n",
            "[1852/3000] Train Acc: 0.948175 Loss: 0.147699 | Val Acc: 0.194355 loss: 5.711448\n",
            "[1853/3000] Train Acc: 0.946108 Loss: 0.152257 | Val Acc: 0.197782 loss: 5.642416\n",
            "[1854/3000] Train Acc: 0.943890 Loss: 0.159319 | Val Acc: 0.199597 loss: 5.595243\n",
            "[1855/3000] Train Acc: 0.948074 Loss: 0.149049 | Val Acc: 0.209879 loss: 5.448933\n",
            "[1856/3000] Train Acc: 0.948125 Loss: 0.150722 | Val Acc: 0.192339 loss: 5.874514\n",
            "[1857/3000] Train Acc: 0.943033 Loss: 0.162696 | Val Acc: 0.200000 loss: 5.560961\n",
            "[1858/3000] Train Acc: 0.945654 Loss: 0.155377 | Val Acc: 0.187298 loss: 6.108186\n",
            "[1859/3000] Train Acc: 0.943739 Loss: 0.157835 | Val Acc: 0.204839 loss: 5.677938\n",
            "[1860/3000] Train Acc: 0.944344 Loss: 0.156505 | Val Acc: 0.196774 loss: 5.515626\n",
            "[1861/3000] Train Acc: 0.946461 Loss: 0.151282 | Val Acc: 0.207661 loss: 5.388652\n",
            "[1862/3000] Train Acc: 0.946511 Loss: 0.156419 | Val Acc: 0.202016 loss: 5.450739\n",
            "[1863/3000] Train Acc: 0.944999 Loss: 0.157210 | Val Acc: 0.207258 loss: 5.336568\n",
            "[1864/3000] Train Acc: 0.947066 Loss: 0.153459 | Val Acc: 0.208266 loss: 5.489011\n",
            "[1865/3000] Train Acc: 0.946864 Loss: 0.153372 | Val Acc: 0.197581 loss: 5.561147\n",
            "[1866/3000] Train Acc: 0.946360 Loss: 0.153589 | Val Acc: 0.194758 loss: 5.831298\n",
            "[1867/3000] Train Acc: 0.943839 Loss: 0.156172 | Val Acc: 0.198790 loss: 5.782001\n",
            "[1868/3000] Train Acc: 0.947671 Loss: 0.149597 | Val Acc: 0.197177 loss: 5.546935\n",
            "[1869/3000] Train Acc: 0.946864 Loss: 0.153022 | Val Acc: 0.197177 loss: 5.901470\n",
            "[1870/3000] Train Acc: 0.944293 Loss: 0.157612 | Val Acc: 0.188508 loss: 5.492859\n",
            "[1871/3000] Train Acc: 0.946511 Loss: 0.154775 | Val Acc: 0.195161 loss: 5.619907\n",
            "[1872/3000] Train Acc: 0.942932 Loss: 0.161192 | Val Acc: 0.194556 loss: 5.807133\n",
            "[1873/3000] Train Acc: 0.944293 Loss: 0.155220 | Val Acc: 0.209476 loss: 5.475901\n",
            "[1874/3000] Train Acc: 0.943688 Loss: 0.157782 | Val Acc: 0.185484 loss: 6.076754\n",
            "[1875/3000] Train Acc: 0.947923 Loss: 0.149440 | Val Acc: 0.201411 loss: 5.628633\n",
            "[1876/3000] Train Acc: 0.943487 Loss: 0.157805 | Val Acc: 0.209073 loss: 5.295594\n",
            "[1877/3000] Train Acc: 0.943839 Loss: 0.163685 | Val Acc: 0.203427 loss: 5.619779\n",
            "[1878/3000] Train Acc: 0.945755 Loss: 0.152538 | Val Acc: 0.191532 loss: 5.771660\n",
            "[1879/3000] Train Acc: 0.945705 Loss: 0.154480 | Val Acc: 0.207258 loss: 5.459648\n",
            "[1880/3000] Train Acc: 0.947469 Loss: 0.149845 | Val Acc: 0.202016 loss: 5.512935\n",
            "[1881/3000] Train Acc: 0.943033 Loss: 0.162436 | Val Acc: 0.211492 loss: 5.388660\n",
            "[1882/3000] Train Acc: 0.945957 Loss: 0.152950 | Val Acc: 0.205847 loss: 5.658808\n",
            "[1883/3000] Train Acc: 0.944949 Loss: 0.154668 | Val Acc: 0.223790 loss: 5.158361\n",
            "saving model with acc 0.224\n",
            "[1884/3000] Train Acc: 0.945453 Loss: 0.154500 | Val Acc: 0.202621 loss: 5.468154\n",
            "[1885/3000] Train Acc: 0.951603 Loss: 0.142065 | Val Acc: 0.212903 loss: 5.324522\n",
            "[1886/3000] Train Acc: 0.947268 Loss: 0.147637 | Val Acc: 0.195363 loss: 5.468167\n",
            "[1887/3000] Train Acc: 0.945100 Loss: 0.158045 | Val Acc: 0.206250 loss: 5.548517\n",
            "[1888/3000] Train Acc: 0.945352 Loss: 0.153576 | Val Acc: 0.202621 loss: 5.453319\n",
            "[1889/3000] Train Acc: 0.945806 Loss: 0.154924 | Val Acc: 0.196774 loss: 5.578844\n",
            "[1890/3000] Train Acc: 0.944646 Loss: 0.158597 | Val Acc: 0.201210 loss: 5.690613\n",
            "[1891/3000] Train Acc: 0.944545 Loss: 0.157469 | Val Acc: 0.192339 loss: 5.946338\n",
            "[1892/3000] Train Acc: 0.946663 Loss: 0.152265 | Val Acc: 0.200806 loss: 5.886208\n",
            "[1893/3000] Train Acc: 0.946965 Loss: 0.148390 | Val Acc: 0.191129 loss: 5.806242\n",
            "[1894/3000] Train Acc: 0.947923 Loss: 0.149329 | Val Acc: 0.204234 loss: 5.611742\n",
            "[1895/3000] Train Acc: 0.947620 Loss: 0.146920 | Val Acc: 0.227823 loss: 5.134401\n",
            "saving model with acc 0.228\n",
            "[1896/3000] Train Acc: 0.946965 Loss: 0.149144 | Val Acc: 0.207460 loss: 5.619890\n",
            "[1897/3000] Train Acc: 0.948276 Loss: 0.148118 | Val Acc: 0.197379 loss: 5.529926\n",
            "[1898/3000] Train Acc: 0.947318 Loss: 0.151960 | Val Acc: 0.194758 loss: 5.694211\n",
            "[1899/3000] Train Acc: 0.946058 Loss: 0.155247 | Val Acc: 0.189718 loss: 5.719431\n",
            "[1900/3000] Train Acc: 0.941571 Loss: 0.170053 | Val Acc: 0.195363 loss: 5.851493\n",
            "[1901/3000] Train Acc: 0.946915 Loss: 0.153738 | Val Acc: 0.206452 loss: 5.470256\n",
            "[1902/3000] Train Acc: 0.951200 Loss: 0.142719 | Val Acc: 0.191532 loss: 5.646462\n",
            "[1903/3000] Train Acc: 0.945957 Loss: 0.155496 | Val Acc: 0.185484 loss: 5.671510\n",
            "[1904/3000] Train Acc: 0.946058 Loss: 0.151716 | Val Acc: 0.208266 loss: 5.566063\n",
            "[1905/3000] Train Acc: 0.942377 Loss: 0.164542 | Val Acc: 0.197984 loss: 5.730573\n",
            "[1906/3000] Train Acc: 0.944646 Loss: 0.157448 | Val Acc: 0.183065 loss: 5.977746\n",
            "[1907/3000] Train Acc: 0.944293 Loss: 0.153175 | Val Acc: 0.193952 loss: 5.896714\n",
            "[1908/3000] Train Acc: 0.946814 Loss: 0.152698 | Val Acc: 0.212500 loss: 5.881397\n",
            "[1909/3000] Train Acc: 0.943184 Loss: 0.158669 | Val Acc: 0.199395 loss: 5.547943\n",
            "[1910/3000] Train Acc: 0.943890 Loss: 0.159576 | Val Acc: 0.211694 loss: 5.541745\n",
            "[1911/3000] Train Acc: 0.950544 Loss: 0.141981 | Val Acc: 0.188508 loss: 5.634864\n",
            "[1912/3000] Train Acc: 0.948881 Loss: 0.148777 | Val Acc: 0.209677 loss: 5.384285\n",
            "[1913/3000] Train Acc: 0.947721 Loss: 0.150333 | Val Acc: 0.205847 loss: 5.713599\n",
            "[1914/3000] Train Acc: 0.948427 Loss: 0.146909 | Val Acc: 0.205444 loss: 5.681967\n",
            "[1915/3000] Train Acc: 0.947822 Loss: 0.147956 | Val Acc: 0.193347 loss: 5.788767\n",
            "[1916/3000] Train Acc: 0.943638 Loss: 0.156858 | Val Acc: 0.205645 loss: 5.716621\n",
            "[1917/3000] Train Acc: 0.947671 Loss: 0.150852 | Val Acc: 0.194355 loss: 5.699125\n",
            "[1918/3000] Train Acc: 0.951502 Loss: 0.137752 | Val Acc: 0.202016 loss: 5.717020\n",
            "[1919/3000] Train Acc: 0.941924 Loss: 0.161944 | Val Acc: 0.188306 loss: 5.905174\n",
            "[1920/3000] Train Acc: 0.948830 Loss: 0.145852 | Val Acc: 0.196976 loss: 5.668840\n",
            "[1921/3000] Train Acc: 0.952006 Loss: 0.135459 | Val Acc: 0.208871 loss: 5.481302\n",
            "[1922/3000] Train Acc: 0.949284 Loss: 0.144511 | Val Acc: 0.219556 loss: 5.295987\n",
            "[1923/3000] Train Acc: 0.947772 Loss: 0.149309 | Val Acc: 0.183669 loss: 5.872475\n",
            "[1924/3000] Train Acc: 0.947973 Loss: 0.151117 | Val Acc: 0.199395 loss: 5.722846\n",
            "[1925/3000] Train Acc: 0.944243 Loss: 0.152250 | Val Acc: 0.213105 loss: 5.546980\n",
            "[1926/3000] Train Acc: 0.947066 Loss: 0.150554 | Val Acc: 0.191532 loss: 6.149801\n",
            "[1927/3000] Train Acc: 0.951855 Loss: 0.139280 | Val Acc: 0.227419 loss: 5.167622\n",
            "[1928/3000] Train Acc: 0.945906 Loss: 0.154082 | Val Acc: 0.217944 loss: 5.350165\n",
            "[1929/3000] Train Acc: 0.939504 Loss: 0.167693 | Val Acc: 0.202621 loss: 5.639413\n",
            "[1930/3000] Train Acc: 0.946814 Loss: 0.152558 | Val Acc: 0.211895 loss: 5.347985\n",
            "[1931/3000] Train Acc: 0.944394 Loss: 0.155351 | Val Acc: 0.195766 loss: 5.628896\n",
            "[1932/3000] Train Acc: 0.946612 Loss: 0.152188 | Val Acc: 0.201613 loss: 5.740016\n",
            "[1933/3000] Train Acc: 0.949032 Loss: 0.144158 | Val Acc: 0.199798 loss: 5.704164\n",
            "[1934/3000] Train Acc: 0.950192 Loss: 0.142880 | Val Acc: 0.192742 loss: 5.942811\n",
            "[1935/3000] Train Acc: 0.947721 Loss: 0.145472 | Val Acc: 0.210887 loss: 5.539231\n",
            "[1936/3000] Train Acc: 0.948074 Loss: 0.148747 | Val Acc: 0.213508 loss: 5.457672\n",
            "[1937/3000] Train Acc: 0.946965 Loss: 0.152168 | Val Acc: 0.202218 loss: 5.711395\n",
            "[1938/3000] Train Acc: 0.946007 Loss: 0.151746 | Val Acc: 0.192339 loss: 5.655872\n",
            "[1939/3000] Train Acc: 0.944898 Loss: 0.152070 | Val Acc: 0.205444 loss: 5.798429\n",
            "[1940/3000] Train Acc: 0.948881 Loss: 0.148461 | Val Acc: 0.193347 loss: 6.275991\n",
            "[1941/3000] Train Acc: 0.947923 Loss: 0.148329 | Val Acc: 0.208468 loss: 5.650132\n",
            "[1942/3000] Train Acc: 0.951099 Loss: 0.139770 | Val Acc: 0.190726 loss: 6.077301\n",
            "[1943/3000] Train Acc: 0.952057 Loss: 0.139248 | Val Acc: 0.201411 loss: 5.662845\n",
            "[1944/3000] Train Acc: 0.946612 Loss: 0.152451 | Val Acc: 0.205645 loss: 5.723750\n",
            "[1945/3000] Train Acc: 0.948629 Loss: 0.146398 | Val Acc: 0.225403 loss: 5.079495\n",
            "[1946/3000] Train Acc: 0.948780 Loss: 0.143572 | Val Acc: 0.207056 loss: 5.743971\n",
            "[1947/3000] Train Acc: 0.950040 Loss: 0.144644 | Val Acc: 0.201411 loss: 5.851281\n",
            "[1948/3000] Train Acc: 0.949032 Loss: 0.144441 | Val Acc: 0.219556 loss: 5.359945\n",
            "[1949/3000] Train Acc: 0.945705 Loss: 0.151072 | Val Acc: 0.226411 loss: 5.272814\n",
            "[1950/3000] Train Acc: 0.939403 Loss: 0.170615 | Val Acc: 0.189113 loss: 5.741367\n",
            "[1951/3000] Train Acc: 0.948377 Loss: 0.145740 | Val Acc: 0.216532 loss: 5.470049\n",
            "[1952/3000] Train Acc: 0.948175 Loss: 0.146874 | Val Acc: 0.201008 loss: 5.274423\n",
            "[1953/3000] Train Acc: 0.948125 Loss: 0.148055 | Val Acc: 0.210685 loss: 5.521718\n",
            "[1954/3000] Train Acc: 0.946259 Loss: 0.154450 | Val Acc: 0.199194 loss: 5.901001\n",
            "[1955/3000] Train Acc: 0.942630 Loss: 0.157096 | Val Acc: 0.213508 loss: 5.425776\n",
            "[1956/3000] Train Acc: 0.949082 Loss: 0.143587 | Val Acc: 0.211290 loss: 5.545381\n",
            "[1957/3000] Train Acc: 0.948578 Loss: 0.148263 | Val Acc: 0.200605 loss: 5.805305\n",
            "[1958/3000] Train Acc: 0.945806 Loss: 0.151924 | Val Acc: 0.196976 loss: 5.846750\n",
            "[1959/3000] Train Acc: 0.943688 Loss: 0.160361 | Val Acc: 0.208266 loss: 5.516331\n",
            "[1960/3000] Train Acc: 0.947116 Loss: 0.147726 | Val Acc: 0.186492 loss: 6.111811\n",
            "[1961/3000] Train Acc: 0.951049 Loss: 0.139387 | Val Acc: 0.201411 loss: 5.710155\n",
            "[1962/3000] Train Acc: 0.948679 Loss: 0.147317 | Val Acc: 0.196573 loss: 5.739620\n",
            "[1963/3000] Train Acc: 0.950494 Loss: 0.137184 | Val Acc: 0.200806 loss: 5.732914\n",
            "[1964/3000] Train Acc: 0.942075 Loss: 0.165551 | Val Acc: 0.218750 loss: 5.278449\n",
            "[1965/3000] Train Acc: 0.943991 Loss: 0.159973 | Val Acc: 0.214718 loss: 5.489682\n",
            "[1966/3000] Train Acc: 0.949133 Loss: 0.145848 | Val Acc: 0.204234 loss: 5.505922\n",
            "[1967/3000] Train Acc: 0.946864 Loss: 0.150936 | Val Acc: 0.209476 loss: 5.365717\n",
            "[1968/3000] Train Acc: 0.947570 Loss: 0.151397 | Val Acc: 0.210484 loss: 5.561206\n",
            "[1969/3000] Train Acc: 0.950544 Loss: 0.141744 | Val Acc: 0.220565 loss: 5.350757\n",
            "[1970/3000] Train Acc: 0.947923 Loss: 0.145947 | Val Acc: 0.205645 loss: 5.682976\n",
            "[1971/3000] Train Acc: 0.948427 Loss: 0.145346 | Val Acc: 0.224597 loss: 5.367167\n",
            "[1972/3000] Train Acc: 0.948578 Loss: 0.144434 | Val Acc: 0.216532 loss: 5.309767\n",
            "[1973/3000] Train Acc: 0.948175 Loss: 0.146335 | Val Acc: 0.181250 loss: 6.103375\n",
            "[1974/3000] Train Acc: 0.943285 Loss: 0.160212 | Val Acc: 0.185484 loss: 5.947794\n",
            "[1975/3000] Train Acc: 0.948730 Loss: 0.149306 | Val Acc: 0.207661 loss: 5.464098\n",
            "[1976/3000] Train Acc: 0.950645 Loss: 0.141667 | Val Acc: 0.202621 loss: 5.615699\n",
            "[1977/3000] Train Acc: 0.948931 Loss: 0.144190 | Val Acc: 0.192339 loss: 5.748772\n",
            "[1978/3000] Train Acc: 0.948830 Loss: 0.144536 | Val Acc: 0.202621 loss: 5.693198\n",
            "[1979/3000] Train Acc: 0.947167 Loss: 0.148239 | Val Acc: 0.198185 loss: 5.896923\n",
            "[1980/3000] Train Acc: 0.941974 Loss: 0.162414 | Val Acc: 0.221976 loss: 5.530684\n",
            "[1981/3000] Train Acc: 0.948024 Loss: 0.148129 | Val Acc: 0.204435 loss: 5.761831\n",
            "[1982/3000] Train Acc: 0.947721 Loss: 0.145185 | Val Acc: 0.209476 loss: 5.500145\n",
            "[1983/3000] Train Acc: 0.949183 Loss: 0.145896 | Val Acc: 0.205645 loss: 5.536824\n",
            "[1984/3000] Train Acc: 0.947620 Loss: 0.148610 | Val Acc: 0.201815 loss: 5.538062\n",
            "[1985/3000] Train Acc: 0.948074 Loss: 0.148804 | Val Acc: 0.201411 loss: 5.839718\n",
            "[1986/3000] Train Acc: 0.947721 Loss: 0.146487 | Val Acc: 0.184879 loss: 6.221531\n",
            "[1987/3000] Train Acc: 0.945049 Loss: 0.152742 | Val Acc: 0.201210 loss: 5.825767\n",
            "[1988/3000] Train Acc: 0.946965 Loss: 0.149312 | Val Acc: 0.203024 loss: 5.515195\n",
            "[1989/3000] Train Acc: 0.947570 Loss: 0.149133 | Val Acc: 0.188105 loss: 5.886891\n",
            "[1990/3000] Train Acc: 0.947873 Loss: 0.147720 | Val Acc: 0.191734 loss: 5.977362\n",
            "[1991/3000] Train Acc: 0.951906 Loss: 0.134193 | Val Acc: 0.177016 loss: 6.125362\n",
            "[1992/3000] Train Acc: 0.947721 Loss: 0.152561 | Val Acc: 0.202016 loss: 5.613930\n",
            "[1993/3000] Train Acc: 0.949738 Loss: 0.143858 | Val Acc: 0.215323 loss: 5.660602\n",
            "[1994/3000] Train Acc: 0.948074 Loss: 0.149798 | Val Acc: 0.197984 loss: 5.883851\n",
            "[1995/3000] Train Acc: 0.946360 Loss: 0.144422 | Val Acc: 0.210887 loss: 5.718476\n",
            "[1996/3000] Train Acc: 0.945100 Loss: 0.151304 | Val Acc: 0.199597 loss: 5.930484\n",
            "[1997/3000] Train Acc: 0.950595 Loss: 0.141949 | Val Acc: 0.190121 loss: 6.123032\n",
            "[1998/3000] Train Acc: 0.948931 Loss: 0.142707 | Val Acc: 0.186290 loss: 6.148027\n",
            "[1999/3000] Train Acc: 0.950847 Loss: 0.139954 | Val Acc: 0.196169 loss: 5.758230\n",
            "[2000/3000] Train Acc: 0.948578 Loss: 0.144003 | Val Acc: 0.207056 loss: 5.674498\n",
            "[2001/3000] Train Acc: 0.949687 Loss: 0.145427 | Val Acc: 0.211492 loss: 5.665367\n",
            "[2002/3000] Train Acc: 0.950544 Loss: 0.138583 | Val Acc: 0.189516 loss: 6.051860\n",
            "[2003/3000] Train Acc: 0.948024 Loss: 0.146816 | Val Acc: 0.202621 loss: 5.921806\n",
            "[2004/3000] Train Acc: 0.944142 Loss: 0.157961 | Val Acc: 0.210282 loss: 5.720559\n",
            "[2005/3000] Train Acc: 0.944747 Loss: 0.153139 | Val Acc: 0.214718 loss: 5.449766\n",
            "[2006/3000] Train Acc: 0.949587 Loss: 0.143712 | Val Acc: 0.224395 loss: 5.338140\n",
            "[2007/3000] Train Acc: 0.952763 Loss: 0.138585 | Val Acc: 0.201815 loss: 5.388836\n",
            "[2008/3000] Train Acc: 0.951704 Loss: 0.140874 | Val Acc: 0.214516 loss: 5.560183\n",
            "[2009/3000] Train Acc: 0.947721 Loss: 0.147250 | Val Acc: 0.214516 loss: 5.449728\n",
            "[2010/3000] Train Acc: 0.945654 Loss: 0.156049 | Val Acc: 0.204032 loss: 5.744180\n",
            "[2011/3000] Train Acc: 0.951906 Loss: 0.137977 | Val Acc: 0.192944 loss: 5.826860\n",
            "[2012/3000] Train Acc: 0.951654 Loss: 0.140113 | Val Acc: 0.200806 loss: 5.996530\n",
            "[2013/3000] Train Acc: 0.944999 Loss: 0.154866 | Val Acc: 0.206653 loss: 5.342795\n",
            "[2014/3000] Train Acc: 0.949536 Loss: 0.144241 | Val Acc: 0.214718 loss: 5.573872\n",
            "[2015/3000] Train Acc: 0.947318 Loss: 0.148969 | Val Acc: 0.198790 loss: 5.618496\n",
            "[2016/3000] Train Acc: 0.951704 Loss: 0.136889 | Val Acc: 0.202621 loss: 5.552541\n",
            "[2017/3000] Train Acc: 0.948528 Loss: 0.144851 | Val Acc: 0.213508 loss: 5.427071\n",
            "[2018/3000] Train Acc: 0.949335 Loss: 0.145806 | Val Acc: 0.180645 loss: 6.119416\n",
            "[2019/3000] Train Acc: 0.948074 Loss: 0.148029 | Val Acc: 0.191734 loss: 5.497587\n",
            "[2020/3000] Train Acc: 0.949788 Loss: 0.147753 | Val Acc: 0.213508 loss: 5.443313\n",
            "[2021/3000] Train Acc: 0.951502 Loss: 0.141863 | Val Acc: 0.201210 loss: 5.710293\n",
            "[2022/3000] Train Acc: 0.950948 Loss: 0.142929 | Val Acc: 0.200605 loss: 5.690443\n",
            "[2023/3000] Train Acc: 0.950292 Loss: 0.138284 | Val Acc: 0.214516 loss: 5.377271\n",
            "[2024/3000] Train Acc: 0.951553 Loss: 0.140181 | Val Acc: 0.220565 loss: 5.223832\n",
            "[2025/3000] Train Acc: 0.946360 Loss: 0.149575 | Val Acc: 0.210081 loss: 5.697918\n",
            "[2026/3000] Train Acc: 0.952208 Loss: 0.137620 | Val Acc: 0.199395 loss: 5.832366\n",
            "[2027/3000] Train Acc: 0.950595 Loss: 0.141701 | Val Acc: 0.220161 loss: 5.236427\n",
            "[2028/3000] Train Acc: 0.950192 Loss: 0.143905 | Val Acc: 0.209073 loss: 5.673756\n",
            "[2029/3000] Train Acc: 0.950998 Loss: 0.142551 | Val Acc: 0.204032 loss: 5.739154\n",
            "[2030/3000] Train Acc: 0.948377 Loss: 0.146842 | Val Acc: 0.200403 loss: 5.754198\n",
            "[2031/3000] Train Acc: 0.946612 Loss: 0.151980 | Val Acc: 0.207258 loss: 5.536609\n",
            "[2032/3000] Train Acc: 0.949435 Loss: 0.142654 | Val Acc: 0.201411 loss: 5.890109\n",
            "[2033/3000] Train Acc: 0.949385 Loss: 0.139493 | Val Acc: 0.203629 loss: 5.653703\n",
            "[2034/3000] Train Acc: 0.951502 Loss: 0.140077 | Val Acc: 0.220565 loss: 5.347377\n",
            "[2035/3000] Train Acc: 0.950444 Loss: 0.137274 | Val Acc: 0.214516 loss: 5.685360\n",
            "[2036/3000] Train Acc: 0.952763 Loss: 0.137022 | Val Acc: 0.204839 loss: 5.791563\n",
            "[2037/3000] Train Acc: 0.946411 Loss: 0.151170 | Val Acc: 0.214919 loss: 5.349342\n",
            "[2038/3000] Train Acc: 0.948730 Loss: 0.147469 | Val Acc: 0.196976 loss: 5.952844\n",
            "[2039/3000] Train Acc: 0.949940 Loss: 0.143913 | Val Acc: 0.194153 loss: 5.777527\n",
            "[2040/3000] Train Acc: 0.948175 Loss: 0.147124 | Val Acc: 0.192742 loss: 5.961433\n",
            "[2041/3000] Train Acc: 0.952712 Loss: 0.133980 | Val Acc: 0.199194 loss: 5.812329\n",
            "[2042/3000] Train Acc: 0.950948 Loss: 0.141149 | Val Acc: 0.224798 loss: 5.160212\n",
            "[2043/3000] Train Acc: 0.950091 Loss: 0.143461 | Val Acc: 0.203629 loss: 5.547558\n",
            "[2044/3000] Train Acc: 0.952813 Loss: 0.140994 | Val Acc: 0.196169 loss: 5.870518\n",
            "[2045/3000] Train Acc: 0.949788 Loss: 0.142556 | Val Acc: 0.218952 loss: 5.407537\n",
            "[2046/3000] Train Acc: 0.950746 Loss: 0.141021 | Val Acc: 0.199597 loss: 5.877691\n",
            "[2047/3000] Train Acc: 0.949990 Loss: 0.144137 | Val Acc: 0.198790 loss: 5.622681\n",
            "[2048/3000] Train Acc: 0.947620 Loss: 0.150822 | Val Acc: 0.196774 loss: 5.863431\n",
            "[2049/3000] Train Acc: 0.947167 Loss: 0.149718 | Val Acc: 0.199597 loss: 5.769476\n",
            "[2050/3000] Train Acc: 0.949889 Loss: 0.140700 | Val Acc: 0.188710 loss: 6.133954\n",
            "[2051/3000] Train Acc: 0.952712 Loss: 0.134911 | Val Acc: 0.198387 loss: 5.680434\n",
            "[2052/3000] Train Acc: 0.950141 Loss: 0.135822 | Val Acc: 0.216129 loss: 5.763688\n",
            "[2053/3000] Train Acc: 0.948024 Loss: 0.148655 | Val Acc: 0.216734 loss: 5.592660\n",
            "[2054/3000] Train Acc: 0.953771 Loss: 0.131864 | Val Acc: 0.205040 loss: 5.705952\n",
            "[2055/3000] Train Acc: 0.950444 Loss: 0.140589 | Val Acc: 0.208871 loss: 5.563919\n",
            "[2056/3000] Train Acc: 0.948528 Loss: 0.144860 | Val Acc: 0.204637 loss: 5.918731\n",
            "[2057/3000] Train Acc: 0.953821 Loss: 0.132418 | Val Acc: 0.219556 loss: 5.522460\n",
            "[2058/3000] Train Acc: 0.948528 Loss: 0.150044 | Val Acc: 0.202016 loss: 5.625793\n",
            "[2059/3000] Train Acc: 0.947167 Loss: 0.151334 | Val Acc: 0.193548 loss: 5.842824\n",
            "[2060/3000] Train Acc: 0.947217 Loss: 0.150007 | Val Acc: 0.180040 loss: 6.392404\n",
            "[2061/3000] Train Acc: 0.952813 Loss: 0.140776 | Val Acc: 0.198992 loss: 5.925663\n",
            "[2062/3000] Train Acc: 0.952208 Loss: 0.135733 | Val Acc: 0.217742 loss: 5.391948\n",
            "[2063/3000] Train Acc: 0.946411 Loss: 0.150835 | Val Acc: 0.212903 loss: 5.349193\n",
            "[2064/3000] Train Acc: 0.949133 Loss: 0.146020 | Val Acc: 0.206452 loss: 5.514356\n",
            "[2065/3000] Train Acc: 0.951704 Loss: 0.136014 | Val Acc: 0.204839 loss: 5.678533\n",
            "[2066/3000] Train Acc: 0.949637 Loss: 0.145040 | Val Acc: 0.203226 loss: 5.741382\n",
            "[2067/3000] Train Acc: 0.952006 Loss: 0.136397 | Val Acc: 0.206048 loss: 5.730897\n",
            "[2068/3000] Train Acc: 0.954275 Loss: 0.133323 | Val Acc: 0.216129 loss: 5.594344\n",
            "[2069/3000] Train Acc: 0.955687 Loss: 0.130534 | Val Acc: 0.201008 loss: 5.563406\n",
            "[2070/3000] Train Acc: 0.951049 Loss: 0.138010 | Val Acc: 0.210887 loss: 5.623481\n",
            "[2071/3000] Train Acc: 0.950595 Loss: 0.138913 | Val Acc: 0.198992 loss: 5.945268\n",
            "[2072/3000] Train Acc: 0.945806 Loss: 0.153021 | Val Acc: 0.209073 loss: 5.707265\n",
            "[2073/3000] Train Acc: 0.950897 Loss: 0.142907 | Val Acc: 0.200806 loss: 5.775552\n",
            "[2074/3000] Train Acc: 0.949486 Loss: 0.145082 | Val Acc: 0.210685 loss: 5.753019\n",
            "[2075/3000] Train Acc: 0.947217 Loss: 0.151076 | Val Acc: 0.202823 loss: 5.894720\n",
            "[2076/3000] Train Acc: 0.951149 Loss: 0.139586 | Val Acc: 0.204839 loss: 6.057493\n",
            "[2077/3000] Train Acc: 0.948982 Loss: 0.146719 | Val Acc: 0.219153 loss: 5.496570\n",
            "[2078/3000] Train Acc: 0.950847 Loss: 0.140480 | Val Acc: 0.204234 loss: 5.404949\n",
            "[2079/3000] Train Acc: 0.954830 Loss: 0.131221 | Val Acc: 0.207661 loss: 5.862055\n",
            "[2080/3000] Train Acc: 0.949234 Loss: 0.143123 | Val Acc: 0.200605 loss: 6.004847\n",
            "[2081/3000] Train Acc: 0.950897 Loss: 0.139887 | Val Acc: 0.219758 loss: 5.212181\n",
            "[2082/3000] Train Acc: 0.949335 Loss: 0.143948 | Val Acc: 0.200806 loss: 5.742944\n",
            "[2083/3000] Train Acc: 0.953368 Loss: 0.133476 | Val Acc: 0.210282 loss: 5.724252\n",
            "[2084/3000] Train Acc: 0.952561 Loss: 0.135373 | Val Acc: 0.203629 loss: 5.865342\n",
            "[2085/3000] Train Acc: 0.947873 Loss: 0.147014 | Val Acc: 0.179839 loss: 6.199995\n",
            "[2086/3000] Train Acc: 0.948024 Loss: 0.148530 | Val Acc: 0.231250 loss: 5.289517\n",
            "saving model with acc 0.231\n",
            "[2087/3000] Train Acc: 0.952208 Loss: 0.133800 | Val Acc: 0.207258 loss: 5.875981\n",
            "[2088/3000] Train Acc: 0.951855 Loss: 0.135470 | Val Acc: 0.215524 loss: 5.541142\n",
            "[2089/3000] Train Acc: 0.949940 Loss: 0.149041 | Val Acc: 0.209274 loss: 5.660067\n",
            "[2090/3000] Train Acc: 0.948982 Loss: 0.145038 | Val Acc: 0.200605 loss: 5.936459\n",
            "[2091/3000] Train Acc: 0.951956 Loss: 0.138883 | Val Acc: 0.216734 loss: 5.437859\n",
            "[2092/3000] Train Acc: 0.950948 Loss: 0.138442 | Val Acc: 0.207863 loss: 5.719359\n",
            "[2093/3000] Train Acc: 0.949788 Loss: 0.145403 | Val Acc: 0.218145 loss: 5.636705\n",
            "[2094/3000] Train Acc: 0.951351 Loss: 0.140640 | Val Acc: 0.206452 loss: 6.107274\n",
            "[2095/3000] Train Acc: 0.948982 Loss: 0.145424 | Val Acc: 0.208266 loss: 5.587019\n",
            "[2096/3000] Train Acc: 0.950595 Loss: 0.138392 | Val Acc: 0.203831 loss: 5.763718\n",
            "[2097/3000] Train Acc: 0.954628 Loss: 0.132268 | Val Acc: 0.227218 loss: 5.216171\n",
            "[2098/3000] Train Acc: 0.949385 Loss: 0.143765 | Val Acc: 0.211290 loss: 5.380106\n",
            "[2099/3000] Train Acc: 0.950998 Loss: 0.139926 | Val Acc: 0.219355 loss: 5.445617\n",
            "[2100/3000] Train Acc: 0.947973 Loss: 0.142529 | Val Acc: 0.201815 loss: 5.788139\n",
            "[2101/3000] Train Acc: 0.951855 Loss: 0.138429 | Val Acc: 0.212500 loss: 5.558641\n",
            "[2102/3000] Train Acc: 0.952863 Loss: 0.137697 | Val Acc: 0.209879 loss: 5.827478\n",
            "[2103/3000] Train Acc: 0.952309 Loss: 0.135839 | Val Acc: 0.217137 loss: 5.597995\n",
            "[2104/3000] Train Acc: 0.952662 Loss: 0.133044 | Val Acc: 0.211492 loss: 5.630039\n",
            "[2105/3000] Train Acc: 0.948528 Loss: 0.146116 | Val Acc: 0.203831 loss: 5.522330\n",
            "[2106/3000] Train Acc: 0.954275 Loss: 0.131634 | Val Acc: 0.208669 loss: 5.718450\n",
            "[2107/3000] Train Acc: 0.951200 Loss: 0.141855 | Val Acc: 0.218952 loss: 5.240609\n",
            "[2108/3000] Train Acc: 0.953468 Loss: 0.131404 | Val Acc: 0.208065 loss: 5.975684\n",
            "[2109/3000] Train Acc: 0.950091 Loss: 0.142809 | Val Acc: 0.214718 loss: 5.844866\n",
            "[2110/3000] Train Acc: 0.953065 Loss: 0.135900 | Val Acc: 0.200605 loss: 5.789111\n",
            "[2111/3000] Train Acc: 0.951452 Loss: 0.136843 | Val Acc: 0.197782 loss: 5.875068\n",
            "[2112/3000] Train Acc: 0.949637 Loss: 0.141758 | Val Acc: 0.233468 loss: 5.377917\n",
            "saving model with acc 0.233\n",
            "[2113/3000] Train Acc: 0.954073 Loss: 0.133948 | Val Acc: 0.229032 loss: 5.303595\n",
            "[2114/3000] Train Acc: 0.952410 Loss: 0.134717 | Val Acc: 0.191331 loss: 5.960747\n",
            "[2115/3000] Train Acc: 0.950393 Loss: 0.140719 | Val Acc: 0.197177 loss: 5.875310\n",
            "[2116/3000] Train Acc: 0.949990 Loss: 0.139527 | Val Acc: 0.189315 loss: 6.175172\n",
            "[2117/3000] Train Acc: 0.949536 Loss: 0.147175 | Val Acc: 0.213911 loss: 5.788459\n",
            "[2118/3000] Train Acc: 0.951805 Loss: 0.138506 | Val Acc: 0.225806 loss: 5.229234\n",
            "[2119/3000] Train Acc: 0.953166 Loss: 0.132197 | Val Acc: 0.199597 loss: 5.827435\n",
            "[2120/3000] Train Acc: 0.949889 Loss: 0.143511 | Val Acc: 0.211895 loss: 5.724168\n",
            "[2121/3000] Train Acc: 0.955787 Loss: 0.129086 | Val Acc: 0.223790 loss: 5.402630\n",
            "[2122/3000] Train Acc: 0.948225 Loss: 0.145511 | Val Acc: 0.206250 loss: 5.624172\n",
            "[2123/3000] Train Acc: 0.954426 Loss: 0.132961 | Val Acc: 0.225000 loss: 5.670412\n",
            "[2124/3000] Train Acc: 0.952813 Loss: 0.138282 | Val Acc: 0.196573 loss: 6.230306\n",
            "[2125/3000] Train Acc: 0.951452 Loss: 0.137840 | Val Acc: 0.218347 loss: 5.414194\n",
            "[2126/3000] Train Acc: 0.951149 Loss: 0.142170 | Val Acc: 0.232056 loss: 5.267914\n",
            "[2127/3000] Train Acc: 0.952107 Loss: 0.130616 | Val Acc: 0.217339 loss: 5.555790\n",
            "[2128/3000] Train Acc: 0.953216 Loss: 0.130920 | Val Acc: 0.198992 loss: 6.166279\n",
            "[2129/3000] Train Acc: 0.953418 Loss: 0.133306 | Val Acc: 0.219758 loss: 5.670250\n",
            "[2130/3000] Train Acc: 0.951301 Loss: 0.138527 | Val Acc: 0.199395 loss: 5.876752\n",
            "[2131/3000] Train Acc: 0.955485 Loss: 0.128718 | Val Acc: 0.211290 loss: 5.899314\n",
            "[2132/3000] Train Acc: 0.955132 Loss: 0.129306 | Val Acc: 0.225806 loss: 5.504461\n",
            "[2133/3000] Train Acc: 0.944142 Loss: 0.158955 | Val Acc: 0.222581 loss: 5.210492\n",
            "[2134/3000] Train Acc: 0.955787 Loss: 0.129676 | Val Acc: 0.215726 loss: 5.563798\n",
            "[2135/3000] Train Acc: 0.951301 Loss: 0.142238 | Val Acc: 0.204839 loss: 5.687058\n",
            "[2136/3000] Train Acc: 0.953317 Loss: 0.133313 | Val Acc: 0.217944 loss: 5.580254\n",
            "[2137/3000] Train Acc: 0.951401 Loss: 0.136007 | Val Acc: 0.222782 loss: 5.395469\n",
            "[2138/3000] Train Acc: 0.955031 Loss: 0.130882 | Val Acc: 0.229032 loss: 5.477762\n",
            "[2139/3000] Train Acc: 0.953468 Loss: 0.136482 | Val Acc: 0.197581 loss: 5.904688\n",
            "[2140/3000] Train Acc: 0.947469 Loss: 0.148571 | Val Acc: 0.206048 loss: 5.888772\n",
            "[2141/3000] Train Acc: 0.949032 Loss: 0.141554 | Val Acc: 0.216331 loss: 5.629284\n",
            "[2142/3000] Train Acc: 0.952309 Loss: 0.131151 | Val Acc: 0.207258 loss: 5.537249\n",
            "[2143/3000] Train Acc: 0.953368 Loss: 0.133826 | Val Acc: 0.201210 loss: 5.761610\n",
            "[2144/3000] Train Acc: 0.946663 Loss: 0.146819 | Val Acc: 0.215524 loss: 5.512702\n",
            "[2145/3000] Train Acc: 0.954830 Loss: 0.129867 | Val Acc: 0.216935 loss: 5.413755\n",
            "[2146/3000] Train Acc: 0.950746 Loss: 0.139333 | Val Acc: 0.198790 loss: 5.838544\n",
            "[2147/3000] Train Acc: 0.951754 Loss: 0.135957 | Val Acc: 0.191935 loss: 5.997085\n",
            "[2148/3000] Train Acc: 0.952511 Loss: 0.135297 | Val Acc: 0.213306 loss: 5.670055\n",
            "[2149/3000] Train Acc: 0.957502 Loss: 0.125186 | Val Acc: 0.207460 loss: 5.712038\n",
            "[2150/3000] Train Acc: 0.956241 Loss: 0.126208 | Val Acc: 0.207661 loss: 5.585753\n",
            "[2151/3000] Train Acc: 0.951049 Loss: 0.142213 | Val Acc: 0.187500 loss: 5.993355\n",
            "[2152/3000] Train Acc: 0.954073 Loss: 0.134184 | Val Acc: 0.208468 loss: 5.809469\n",
            "[2153/3000] Train Acc: 0.951149 Loss: 0.145149 | Val Acc: 0.190323 loss: 5.690530\n",
            "[2154/3000] Train Acc: 0.953973 Loss: 0.128529 | Val Acc: 0.194355 loss: 5.934284\n",
            "[2155/3000] Train Acc: 0.950343 Loss: 0.140012 | Val Acc: 0.218347 loss: 5.492804\n",
            "[2156/3000] Train Acc: 0.953519 Loss: 0.134823 | Val Acc: 0.200806 loss: 6.026485\n",
            "[2157/3000] Train Acc: 0.954628 Loss: 0.130351 | Val Acc: 0.203831 loss: 5.579158\n",
            "[2158/3000] Train Acc: 0.948931 Loss: 0.143025 | Val Acc: 0.208669 loss: 5.930573\n",
            "[2159/3000] Train Acc: 0.954880 Loss: 0.133422 | Val Acc: 0.210887 loss: 5.867542\n",
            "[2160/3000] Train Acc: 0.954275 Loss: 0.131424 | Val Acc: 0.207661 loss: 5.713139\n",
            "[2161/3000] Train Acc: 0.952057 Loss: 0.134043 | Val Acc: 0.200806 loss: 5.984487\n",
            "[2162/3000] Train Acc: 0.952006 Loss: 0.138501 | Val Acc: 0.214718 loss: 5.752341\n",
            "[2163/3000] Train Acc: 0.952561 Loss: 0.135078 | Val Acc: 0.233468 loss: 5.312688\n",
            "[2164/3000] Train Acc: 0.950494 Loss: 0.139977 | Val Acc: 0.208669 loss: 5.731045\n",
            "[2165/3000] Train Acc: 0.949738 Loss: 0.142665 | Val Acc: 0.202823 loss: 5.807182\n",
            "[2166/3000] Train Acc: 0.954678 Loss: 0.131445 | Val Acc: 0.202016 loss: 6.038776\n",
            "[2167/3000] Train Acc: 0.955435 Loss: 0.128952 | Val Acc: 0.213306 loss: 5.510345\n",
            "[2168/3000] Train Acc: 0.955888 Loss: 0.127553 | Val Acc: 0.203831 loss: 6.160098\n",
            "[2169/3000] Train Acc: 0.955233 Loss: 0.129655 | Val Acc: 0.212702 loss: 5.820606\n",
            "[2170/3000] Train Acc: 0.952006 Loss: 0.135093 | Val Acc: 0.204839 loss: 5.759318\n",
            "[2171/3000] Train Acc: 0.956443 Loss: 0.121749 | Val Acc: 0.208266 loss: 5.791968\n",
            "[2172/3000] Train Acc: 0.952309 Loss: 0.136762 | Val Acc: 0.208669 loss: 5.841321\n",
            "[2173/3000] Train Acc: 0.950040 Loss: 0.144079 | Val Acc: 0.219153 loss: 5.677407\n",
            "[2174/3000] Train Acc: 0.950192 Loss: 0.141054 | Val Acc: 0.209274 loss: 6.014278\n",
            "[2175/3000] Train Acc: 0.958106 Loss: 0.120444 | Val Acc: 0.207460 loss: 6.040799\n",
            "[2176/3000] Train Acc: 0.953368 Loss: 0.135760 | Val Acc: 0.207258 loss: 6.010591\n",
            "[2177/3000] Train Acc: 0.953418 Loss: 0.134329 | Val Acc: 0.217742 loss: 5.814157\n",
            "[2178/3000] Train Acc: 0.955939 Loss: 0.124208 | Val Acc: 0.220565 loss: 5.584155\n",
            "[2179/3000] Train Acc: 0.953519 Loss: 0.135704 | Val Acc: 0.197782 loss: 5.788848\n",
            "[2180/3000] Train Acc: 0.955182 Loss: 0.127630 | Val Acc: 0.212500 loss: 5.852800\n",
            "[2181/3000] Train Acc: 0.956140 Loss: 0.128729 | Val Acc: 0.234879 loss: 5.341521\n",
            "saving model with acc 0.235\n",
            "[2182/3000] Train Acc: 0.950192 Loss: 0.141051 | Val Acc: 0.207056 loss: 5.950051\n",
            "[2183/3000] Train Acc: 0.954880 Loss: 0.132559 | Val Acc: 0.208468 loss: 5.889118\n",
            "[2184/3000] Train Acc: 0.954678 Loss: 0.129807 | Val Acc: 0.230847 loss: 5.597438\n",
            "[2185/3000] Train Acc: 0.953015 Loss: 0.132970 | Val Acc: 0.227016 loss: 5.533777\n",
            "[2186/3000] Train Acc: 0.958661 Loss: 0.122178 | Val Acc: 0.208468 loss: 5.813661\n",
            "[2187/3000] Train Acc: 0.952410 Loss: 0.132243 | Val Acc: 0.211492 loss: 5.761290\n",
            "[2188/3000] Train Acc: 0.952914 Loss: 0.133289 | Val Acc: 0.237903 loss: 5.357585\n",
            "saving model with acc 0.238\n",
            "[2189/3000] Train Acc: 0.951956 Loss: 0.138552 | Val Acc: 0.188306 loss: 6.165737\n",
            "[2190/3000] Train Acc: 0.953065 Loss: 0.137188 | Val Acc: 0.209476 loss: 5.966608\n",
            "[2191/3000] Train Acc: 0.948629 Loss: 0.142728 | Val Acc: 0.221371 loss: 5.735346\n",
            "[2192/3000] Train Acc: 0.956695 Loss: 0.122861 | Val Acc: 0.198992 loss: 5.848138\n",
            "[2193/3000] Train Acc: 0.952611 Loss: 0.134082 | Val Acc: 0.208266 loss: 5.933965\n",
            "[2194/3000] Train Acc: 0.952511 Loss: 0.131498 | Val Acc: 0.219153 loss: 5.651471\n",
            "[2195/3000] Train Acc: 0.954426 Loss: 0.128806 | Val Acc: 0.225806 loss: 5.594520\n",
            "[2196/3000] Train Acc: 0.956342 Loss: 0.124675 | Val Acc: 0.223185 loss: 5.533220\n",
            "[2197/3000] Train Acc: 0.953418 Loss: 0.131929 | Val Acc: 0.218750 loss: 5.505726\n",
            "[2198/3000] Train Acc: 0.949738 Loss: 0.143122 | Val Acc: 0.216129 loss: 5.854788\n",
            "[2199/3000] Train Acc: 0.953116 Loss: 0.132132 | Val Acc: 0.215726 loss: 5.553286\n",
            "[2200/3000] Train Acc: 0.959064 Loss: 0.118884 | Val Acc: 0.223992 loss: 5.475999\n",
            "[2201/3000] Train Acc: 0.953821 Loss: 0.131392 | Val Acc: 0.200202 loss: 6.081215\n",
            "[2202/3000] Train Acc: 0.955939 Loss: 0.122216 | Val Acc: 0.209879 loss: 5.645295\n",
            "[2203/3000] Train Acc: 0.952309 Loss: 0.135384 | Val Acc: 0.213508 loss: 5.802395\n",
            "[2204/3000] Train Acc: 0.956191 Loss: 0.125546 | Val Acc: 0.215121 loss: 5.807024\n",
            "[2205/3000] Train Acc: 0.950192 Loss: 0.136505 | Val Acc: 0.217742 loss: 5.890399\n",
            "[2206/3000] Train Acc: 0.955737 Loss: 0.126571 | Val Acc: 0.218548 loss: 5.611062\n",
            "[2207/3000] Train Acc: 0.954779 Loss: 0.127710 | Val Acc: 0.203831 loss: 6.002230\n",
            "[2208/3000] Train Acc: 0.954930 Loss: 0.131594 | Val Acc: 0.204435 loss: 6.041238\n",
            "[2209/3000] Train Acc: 0.949839 Loss: 0.142974 | Val Acc: 0.192540 loss: 6.099566\n",
            "[2210/3000] Train Acc: 0.953922 Loss: 0.131044 | Val Acc: 0.209677 loss: 5.716558\n",
            "[2211/3000] Train Acc: 0.951754 Loss: 0.138264 | Val Acc: 0.215927 loss: 5.749241\n",
            "[2212/3000] Train Acc: 0.954578 Loss: 0.131032 | Val Acc: 0.212298 loss: 5.576625\n",
            "[2213/3000] Train Acc: 0.956241 Loss: 0.125477 | Val Acc: 0.199798 loss: 5.913468\n",
            "[2214/3000] Train Acc: 0.956897 Loss: 0.125164 | Val Acc: 0.196169 loss: 6.150950\n",
            "[2215/3000] Train Acc: 0.954729 Loss: 0.130562 | Val Acc: 0.207056 loss: 5.994054\n",
            "[2216/3000] Train Acc: 0.959720 Loss: 0.114082 | Val Acc: 0.187903 loss: 6.282745\n",
            "[2217/3000] Train Acc: 0.954678 Loss: 0.126258 | Val Acc: 0.207863 loss: 5.699553\n",
            "[2218/3000] Train Acc: 0.953519 Loss: 0.129501 | Val Acc: 0.207661 loss: 5.804789\n",
            "[2219/3000] Train Acc: 0.947116 Loss: 0.151825 | Val Acc: 0.189919 loss: 6.136410\n",
            "[2220/3000] Train Acc: 0.958762 Loss: 0.120289 | Val Acc: 0.210282 loss: 5.940916\n",
            "[2221/3000] Train Acc: 0.952309 Loss: 0.133505 | Val Acc: 0.198589 loss: 6.055550\n",
            "[2222/3000] Train Acc: 0.958056 Loss: 0.119878 | Val Acc: 0.218750 loss: 5.496822\n",
            "[2223/3000] Train Acc: 0.954275 Loss: 0.132753 | Val Acc: 0.222379 loss: 5.550497\n",
            "[2224/3000] Train Acc: 0.952208 Loss: 0.135088 | Val Acc: 0.203831 loss: 5.897269\n",
            "[2225/3000] Train Acc: 0.950141 Loss: 0.139844 | Val Acc: 0.216129 loss: 5.592133\n",
            "[2226/3000] Train Acc: 0.956342 Loss: 0.126634 | Val Acc: 0.207661 loss: 5.897422\n",
            "[2227/3000] Train Acc: 0.949536 Loss: 0.142514 | Val Acc: 0.228831 loss: 5.367339\n",
            "[2228/3000] Train Acc: 0.957401 Loss: 0.123599 | Val Acc: 0.229435 loss: 5.669120\n",
            "[2229/3000] Train Acc: 0.954930 Loss: 0.128775 | Val Acc: 0.198790 loss: 5.970111\n",
            "[2230/3000] Train Acc: 0.956997 Loss: 0.121096 | Val Acc: 0.222984 loss: 5.481751\n",
            "[2231/3000] Train Acc: 0.955989 Loss: 0.122629 | Val Acc: 0.223992 loss: 5.640656\n",
            "[2232/3000] Train Acc: 0.954023 Loss: 0.131558 | Val Acc: 0.221573 loss: 5.679896\n",
            "[2233/3000] Train Acc: 0.956493 Loss: 0.125714 | Val Acc: 0.212903 loss: 5.781317\n",
            "[2234/3000] Train Acc: 0.952107 Loss: 0.134723 | Val Acc: 0.227016 loss: 5.537650\n",
            "[2235/3000] Train Acc: 0.949435 Loss: 0.141044 | Val Acc: 0.217944 loss: 5.734905\n",
            "[2236/3000] Train Acc: 0.955283 Loss: 0.126369 | Val Acc: 0.231653 loss: 5.505362\n",
            "[2237/3000] Train Acc: 0.953519 Loss: 0.135755 | Val Acc: 0.208065 loss: 5.581857\n",
            "[2238/3000] Train Acc: 0.957754 Loss: 0.121071 | Val Acc: 0.208871 loss: 5.500796\n",
            "[2239/3000] Train Acc: 0.956392 Loss: 0.127064 | Val Acc: 0.206653 loss: 5.842008\n",
            "[2240/3000] Train Acc: 0.954678 Loss: 0.127883 | Val Acc: 0.221774 loss: 5.731978\n",
            "[2241/3000] Train Acc: 0.954124 Loss: 0.133449 | Val Acc: 0.193750 loss: 6.386702\n",
            "[2242/3000] Train Acc: 0.951805 Loss: 0.137724 | Val Acc: 0.214113 loss: 5.892242\n",
            "[2243/3000] Train Acc: 0.957300 Loss: 0.122849 | Val Acc: 0.204637 loss: 5.829690\n",
            "[2244/3000] Train Acc: 0.955636 Loss: 0.128503 | Val Acc: 0.209274 loss: 5.734564\n",
            "[2245/3000] Train Acc: 0.955384 Loss: 0.131864 | Val Acc: 0.216532 loss: 5.670601\n",
            "[2246/3000] Train Acc: 0.949536 Loss: 0.140397 | Val Acc: 0.228024 loss: 5.511059\n",
            "[2247/3000] Train Acc: 0.953872 Loss: 0.131718 | Val Acc: 0.214718 loss: 5.706146\n",
            "[2248/3000] Train Acc: 0.953468 Loss: 0.135498 | Val Acc: 0.220363 loss: 5.773759\n",
            "[2249/3000] Train Acc: 0.955132 Loss: 0.128641 | Val Acc: 0.230242 loss: 5.224014\n",
            "[2250/3000] Train Acc: 0.955838 Loss: 0.129334 | Val Acc: 0.192137 loss: 6.262546\n",
            "[2251/3000] Train Acc: 0.953721 Loss: 0.128642 | Val Acc: 0.223589 loss: 5.578669\n",
            "[2252/3000] Train Acc: 0.951099 Loss: 0.141010 | Val Acc: 0.206250 loss: 5.857948\n",
            "[2253/3000] Train Acc: 0.950292 Loss: 0.140846 | Val Acc: 0.215726 loss: 5.800174\n",
            "[2254/3000] Train Acc: 0.958106 Loss: 0.124370 | Val Acc: 0.220363 loss: 5.620910\n",
            "[2255/3000] Train Acc: 0.957653 Loss: 0.121886 | Val Acc: 0.202218 loss: 6.008230\n",
            "[2256/3000] Train Acc: 0.957653 Loss: 0.122183 | Val Acc: 0.216331 loss: 5.766989\n",
            "[2257/3000] Train Acc: 0.953368 Loss: 0.133848 | Val Acc: 0.224597 loss: 5.381041\n",
            "[2258/3000] Train Acc: 0.953065 Loss: 0.135470 | Val Acc: 0.222379 loss: 5.462369\n",
            "[2259/3000] Train Acc: 0.955586 Loss: 0.127750 | Val Acc: 0.196371 loss: 6.137235\n",
            "[2260/3000] Train Acc: 0.956544 Loss: 0.128715 | Val Acc: 0.216734 loss: 5.851075\n",
            "[2261/3000] Train Acc: 0.955082 Loss: 0.134828 | Val Acc: 0.204032 loss: 5.996648\n",
            "[2262/3000] Train Acc: 0.955787 Loss: 0.126895 | Val Acc: 0.213306 loss: 5.786334\n",
            "[2263/3000] Train Acc: 0.956947 Loss: 0.123032 | Val Acc: 0.218548 loss: 5.874335\n",
            "[2264/3000] Train Acc: 0.955636 Loss: 0.124213 | Val Acc: 0.230847 loss: 5.439079\n",
            "[2265/3000] Train Acc: 0.952006 Loss: 0.133874 | Val Acc: 0.213911 loss: 5.816196\n",
            "[2266/3000] Train Acc: 0.954578 Loss: 0.127674 | Val Acc: 0.221976 loss: 5.631197\n",
            "[2267/3000] Train Acc: 0.956796 Loss: 0.125962 | Val Acc: 0.220363 loss: 5.432325\n",
            "[2268/3000] Train Acc: 0.954073 Loss: 0.133136 | Val Acc: 0.202419 loss: 5.758432\n",
            "[2269/3000] Train Acc: 0.954275 Loss: 0.129647 | Val Acc: 0.198790 loss: 6.314034\n",
            "[2270/3000] Train Acc: 0.951906 Loss: 0.140993 | Val Acc: 0.229637 loss: 5.415716\n",
            "[2271/3000] Train Acc: 0.955535 Loss: 0.126948 | Val Acc: 0.229234 loss: 5.617801\n",
            "[2272/3000] Train Acc: 0.951805 Loss: 0.132921 | Val Acc: 0.238306 loss: 5.338596\n",
            "saving model with acc 0.238\n",
            "[2273/3000] Train Acc: 0.956997 Loss: 0.123029 | Val Acc: 0.226411 loss: 5.510623\n",
            "[2274/3000] Train Acc: 0.956745 Loss: 0.121420 | Val Acc: 0.231250 loss: 5.481555\n",
            "[2275/3000] Train Acc: 0.953267 Loss: 0.134445 | Val Acc: 0.195968 loss: 6.494456\n",
            "[2276/3000] Train Acc: 0.954779 Loss: 0.127757 | Val Acc: 0.236089 loss: 5.287459\n",
            "[2277/3000] Train Acc: 0.954578 Loss: 0.126745 | Val Acc: 0.211895 loss: 5.899611\n",
            "[2278/3000] Train Acc: 0.957149 Loss: 0.121042 | Val Acc: 0.219960 loss: 5.583472\n",
            "[2279/3000] Train Acc: 0.954275 Loss: 0.130924 | Val Acc: 0.195161 loss: 6.201678\n",
            "[2280/3000] Train Acc: 0.951452 Loss: 0.138915 | Val Acc: 0.218347 loss: 5.742166\n",
            "[2281/3000] Train Acc: 0.955031 Loss: 0.130776 | Val Acc: 0.224798 loss: 5.602921\n",
            "[2282/3000] Train Acc: 0.956897 Loss: 0.125344 | Val Acc: 0.202218 loss: 6.149185\n",
            "[2283/3000] Train Acc: 0.958661 Loss: 0.115812 | Val Acc: 0.226815 loss: 5.522238\n",
            "[2284/3000] Train Acc: 0.955233 Loss: 0.122220 | Val Acc: 0.218952 loss: 5.850883\n",
            "[2285/3000] Train Acc: 0.955535 Loss: 0.126447 | Val Acc: 0.223790 loss: 5.751116\n",
            "[2286/3000] Train Acc: 0.958359 Loss: 0.116238 | Val Acc: 0.225403 loss: 5.596858\n",
            "[2287/3000] Train Acc: 0.949637 Loss: 0.141695 | Val Acc: 0.225806 loss: 5.543935\n",
            "[2288/3000] Train Acc: 0.955888 Loss: 0.123113 | Val Acc: 0.225605 loss: 5.684555\n",
            "[2289/3000] Train Acc: 0.955334 Loss: 0.132288 | Val Acc: 0.233065 loss: 5.539545\n",
            "[2290/3000] Train Acc: 0.949536 Loss: 0.142062 | Val Acc: 0.225403 loss: 5.797035\n",
            "[2291/3000] Train Acc: 0.953620 Loss: 0.131399 | Val Acc: 0.231855 loss: 5.569580\n",
            "[2292/3000] Train Acc: 0.957048 Loss: 0.121503 | Val Acc: 0.210887 loss: 5.780118\n",
            "[2293/3000] Train Acc: 0.956392 Loss: 0.128603 | Val Acc: 0.217137 loss: 5.833731\n",
            "[2294/3000] Train Acc: 0.955435 Loss: 0.127267 | Val Acc: 0.219153 loss: 5.807495\n",
            "[2295/3000] Train Acc: 0.950141 Loss: 0.142288 | Val Acc: 0.193548 loss: 6.215338\n",
            "[2296/3000] Train Acc: 0.961232 Loss: 0.115190 | Val Acc: 0.200806 loss: 6.248265\n",
            "[2297/3000] Train Acc: 0.957149 Loss: 0.123862 | Val Acc: 0.198790 loss: 6.056587\n",
            "[2298/3000] Train Acc: 0.956594 Loss: 0.125072 | Val Acc: 0.235484 loss: 5.318030\n",
            "[2299/3000] Train Acc: 0.956947 Loss: 0.122166 | Val Acc: 0.211694 loss: 5.963308\n",
            "[2300/3000] Train Acc: 0.955888 Loss: 0.122790 | Val Acc: 0.215726 loss: 5.828327\n",
            "[2301/3000] Train Acc: 0.955182 Loss: 0.127761 | Val Acc: 0.232863 loss: 5.558816\n",
            "[2302/3000] Train Acc: 0.951301 Loss: 0.142506 | Val Acc: 0.199194 loss: 6.443483\n",
            "[2303/3000] Train Acc: 0.952611 Loss: 0.134640 | Val Acc: 0.210685 loss: 5.819842\n",
            "[2304/3000] Train Acc: 0.955737 Loss: 0.126014 | Val Acc: 0.208669 loss: 6.091290\n",
            "[2305/3000] Train Acc: 0.955485 Loss: 0.124598 | Val Acc: 0.188911 loss: 6.360510\n",
            "[2306/3000] Train Acc: 0.958459 Loss: 0.117995 | Val Acc: 0.196774 loss: 6.027679\n",
            "[2307/3000] Train Acc: 0.954073 Loss: 0.129501 | Val Acc: 0.210484 loss: 6.268211\n",
            "[2308/3000] Train Acc: 0.955182 Loss: 0.128839 | Val Acc: 0.230847 loss: 5.595451\n",
            "[2309/3000] Train Acc: 0.956191 Loss: 0.125752 | Val Acc: 0.208065 loss: 6.120670\n",
            "[2310/3000] Train Acc: 0.955838 Loss: 0.128744 | Val Acc: 0.209073 loss: 5.720131\n",
            "[2311/3000] Train Acc: 0.957048 Loss: 0.123539 | Val Acc: 0.203226 loss: 5.839979\n",
            "[2312/3000] Train Acc: 0.953116 Loss: 0.126279 | Val Acc: 0.215121 loss: 5.675743\n",
            "[2313/3000] Train Acc: 0.958106 Loss: 0.120745 | Val Acc: 0.226008 loss: 5.634909\n",
            "[2314/3000] Train Acc: 0.955989 Loss: 0.123865 | Val Acc: 0.232056 loss: 5.536403\n",
            "[2315/3000] Train Acc: 0.951149 Loss: 0.140690 | Val Acc: 0.205847 loss: 5.915351\n",
            "[2316/3000] Train Acc: 0.953216 Loss: 0.127973 | Val Acc: 0.221976 loss: 5.654892\n",
            "[2317/3000] Train Acc: 0.956695 Loss: 0.123226 | Val Acc: 0.214919 loss: 5.928934\n",
            "[2318/3000] Train Acc: 0.951906 Loss: 0.136976 | Val Acc: 0.216129 loss: 5.834229\n",
            "[2319/3000] Train Acc: 0.958207 Loss: 0.118947 | Val Acc: 0.199194 loss: 6.241390\n",
            "[2320/3000] Train Acc: 0.958711 Loss: 0.118761 | Val Acc: 0.188105 loss: 6.419756\n",
            "[2321/3000] Train Acc: 0.956947 Loss: 0.123819 | Val Acc: 0.225202 loss: 5.658955\n",
            "[2322/3000] Train Acc: 0.959417 Loss: 0.117191 | Val Acc: 0.231452 loss: 5.644961\n",
            "[2323/3000] Train Acc: 0.956695 Loss: 0.121543 | Val Acc: 0.221774 loss: 5.795470\n",
            "[2324/3000] Train Acc: 0.956695 Loss: 0.123982 | Val Acc: 0.226613 loss: 5.565063\n",
            "[2325/3000] Train Acc: 0.953973 Loss: 0.129516 | Val Acc: 0.216935 loss: 5.938895\n",
            "[2326/3000] Train Acc: 0.955737 Loss: 0.124849 | Val Acc: 0.214315 loss: 5.951556\n",
            "[2327/3000] Train Acc: 0.957199 Loss: 0.120679 | Val Acc: 0.193750 loss: 6.253593\n",
            "[2328/3000] Train Acc: 0.952208 Loss: 0.134058 | Val Acc: 0.264516 loss: 4.921371\n",
            "saving model with acc 0.265\n",
            "[2329/3000] Train Acc: 0.955989 Loss: 0.126268 | Val Acc: 0.233669 loss: 5.387446\n",
            "[2330/3000] Train Acc: 0.958661 Loss: 0.122976 | Val Acc: 0.245766 loss: 5.468192\n",
            "[2331/3000] Train Acc: 0.958711 Loss: 0.117735 | Val Acc: 0.218750 loss: 5.955644\n",
            "[2332/3000] Train Acc: 0.958711 Loss: 0.117183 | Val Acc: 0.237903 loss: 5.390488\n",
            "[2333/3000] Train Acc: 0.960123 Loss: 0.114753 | Val Acc: 0.215121 loss: 5.868828\n",
            "[2334/3000] Train Acc: 0.956292 Loss: 0.125456 | Val Acc: 0.241935 loss: 5.314002\n",
            "[2335/3000] Train Acc: 0.957401 Loss: 0.121725 | Val Acc: 0.226008 loss: 5.573343\n",
            "[2336/3000] Train Acc: 0.957199 Loss: 0.124766 | Val Acc: 0.208871 loss: 5.988785\n",
            "[2337/3000] Train Acc: 0.956493 Loss: 0.120360 | Val Acc: 0.226210 loss: 5.606768\n",
            "[2338/3000] Train Acc: 0.957098 Loss: 0.120196 | Val Acc: 0.219758 loss: 5.682638\n",
            "[2339/3000] Train Acc: 0.958762 Loss: 0.118178 | Val Acc: 0.224798 loss: 5.724437\n",
            "[2340/3000] Train Acc: 0.954880 Loss: 0.130647 | Val Acc: 0.208468 loss: 6.098018\n",
            "[2341/3000] Train Acc: 0.955737 Loss: 0.126896 | Val Acc: 0.226210 loss: 5.772639\n",
            "[2342/3000] Train Acc: 0.960274 Loss: 0.112939 | Val Acc: 0.248992 loss: 5.444908\n",
            "[2343/3000] Train Acc: 0.954426 Loss: 0.126257 | Val Acc: 0.208871 loss: 6.159672\n",
            "[2344/3000] Train Acc: 0.959064 Loss: 0.115698 | Val Acc: 0.233266 loss: 5.805042\n",
            "[2345/3000] Train Acc: 0.956897 Loss: 0.121074 | Val Acc: 0.215726 loss: 6.121404\n",
            "[2346/3000] Train Acc: 0.957552 Loss: 0.121884 | Val Acc: 0.241532 loss: 5.188600\n",
            "[2347/3000] Train Acc: 0.955535 Loss: 0.128641 | Val Acc: 0.206855 loss: 5.988554\n",
            "[2348/3000] Train Acc: 0.957703 Loss: 0.120440 | Val Acc: 0.216935 loss: 5.922432\n",
            "[2349/3000] Train Acc: 0.958964 Loss: 0.118462 | Val Acc: 0.204435 loss: 5.977450\n",
            "[2350/3000] Train Acc: 0.958409 Loss: 0.122129 | Val Acc: 0.211895 loss: 6.170451\n",
            "[2351/3000] Train Acc: 0.953015 Loss: 0.133659 | Val Acc: 0.229032 loss: 5.731579\n",
            "[2352/3000] Train Acc: 0.955031 Loss: 0.125953 | Val Acc: 0.215726 loss: 5.772698\n",
            "[2353/3000] Train Acc: 0.959669 Loss: 0.114954 | Val Acc: 0.217742 loss: 5.837146\n",
            "[2354/3000] Train Acc: 0.956040 Loss: 0.127092 | Val Acc: 0.224194 loss: 5.826572\n",
            "[2355/3000] Train Acc: 0.958106 Loss: 0.115578 | Val Acc: 0.218750 loss: 5.827948\n",
            "[2356/3000] Train Acc: 0.959115 Loss: 0.115956 | Val Acc: 0.221371 loss: 5.718715\n",
            "[2357/3000] Train Acc: 0.953015 Loss: 0.133683 | Val Acc: 0.211895 loss: 5.954294\n",
            "[2358/3000] Train Acc: 0.950746 Loss: 0.141054 | Val Acc: 0.219153 loss: 5.973025\n",
            "[2359/3000] Train Acc: 0.953721 Loss: 0.130754 | Val Acc: 0.213105 loss: 5.801109\n",
            "[2360/3000] Train Acc: 0.959165 Loss: 0.116283 | Val Acc: 0.227218 loss: 5.659183\n",
            "[2361/3000] Train Acc: 0.957552 Loss: 0.121293 | Val Acc: 0.217944 loss: 5.821302\n",
            "[2362/3000] Train Acc: 0.958157 Loss: 0.120525 | Val Acc: 0.215323 loss: 5.825980\n",
            "[2363/3000] Train Acc: 0.959821 Loss: 0.114548 | Val Acc: 0.223185 loss: 5.836063\n",
            "[2364/3000] Train Acc: 0.953216 Loss: 0.128511 | Val Acc: 0.216734 loss: 5.571760\n",
            "[2365/3000] Train Acc: 0.958812 Loss: 0.118715 | Val Acc: 0.212298 loss: 5.782260\n",
            "[2366/3000] Train Acc: 0.959468 Loss: 0.115865 | Val Acc: 0.205847 loss: 6.068069\n",
            "[2367/3000] Train Acc: 0.959064 Loss: 0.116162 | Val Acc: 0.229234 loss: 5.682577\n",
            "[2368/3000] Train Acc: 0.959316 Loss: 0.117498 | Val Acc: 0.233065 loss: 5.673794\n",
            "[2369/3000] Train Acc: 0.953569 Loss: 0.130911 | Val Acc: 0.216331 loss: 6.047953\n",
            "[2370/3000] Train Acc: 0.958409 Loss: 0.122038 | Val Acc: 0.204637 loss: 6.358784\n",
            "[2371/3000] Train Acc: 0.957451 Loss: 0.122885 | Val Acc: 0.205040 loss: 6.240553\n",
            "[2372/3000] Train Acc: 0.958560 Loss: 0.125974 | Val Acc: 0.236089 loss: 5.565193\n",
            "[2373/3000] Train Acc: 0.957854 Loss: 0.122398 | Val Acc: 0.231250 loss: 5.743519\n",
            "[2374/3000] Train Acc: 0.956846 Loss: 0.120209 | Val Acc: 0.210887 loss: 6.181937\n",
            "[2375/3000] Train Acc: 0.957300 Loss: 0.121916 | Val Acc: 0.220161 loss: 5.750329\n",
            "[2376/3000] Train Acc: 0.959014 Loss: 0.116820 | Val Acc: 0.221976 loss: 5.726695\n",
            "[2377/3000] Train Acc: 0.959921 Loss: 0.113547 | Val Acc: 0.239315 loss: 5.649031\n",
            "[2378/3000] Train Acc: 0.957552 Loss: 0.120061 | Val Acc: 0.211290 loss: 5.834943\n",
            "[2379/3000] Train Acc: 0.960274 Loss: 0.112626 | Val Acc: 0.202823 loss: 6.289830\n",
            "[2380/3000] Train Acc: 0.960577 Loss: 0.114917 | Val Acc: 0.211492 loss: 6.032463\n",
            "[2381/3000] Train Acc: 0.955737 Loss: 0.127177 | Val Acc: 0.221573 loss: 5.530061\n",
            "[2382/3000] Train Acc: 0.953015 Loss: 0.131586 | Val Acc: 0.216532 loss: 5.562006\n",
            "[2383/3000] Train Acc: 0.954527 Loss: 0.130761 | Val Acc: 0.219355 loss: 5.898879\n",
            "[2384/3000] Train Acc: 0.957653 Loss: 0.119069 | Val Acc: 0.229637 loss: 5.678943\n",
            "[2385/3000] Train Acc: 0.955535 Loss: 0.125504 | Val Acc: 0.212500 loss: 6.198314\n",
            "[2386/3000] Train Acc: 0.952410 Loss: 0.134057 | Val Acc: 0.222581 loss: 5.787185\n",
            "[2387/3000] Train Acc: 0.958409 Loss: 0.116592 | Val Acc: 0.210685 loss: 5.913326\n",
            "[2388/3000] Train Acc: 0.959619 Loss: 0.112499 | Val Acc: 0.208065 loss: 6.172864\n",
            "[2389/3000] Train Acc: 0.960375 Loss: 0.115801 | Val Acc: 0.246774 loss: 5.484937\n",
            "[2390/3000] Train Acc: 0.957905 Loss: 0.120196 | Val Acc: 0.204637 loss: 6.203401\n",
            "[2391/3000] Train Acc: 0.960778 Loss: 0.115226 | Val Acc: 0.236492 loss: 5.587641\n",
            "[2392/3000] Train Acc: 0.956796 Loss: 0.124701 | Val Acc: 0.205242 loss: 6.264347\n",
            "[2393/3000] Train Acc: 0.954578 Loss: 0.129969 | Val Acc: 0.220161 loss: 5.919461\n",
            "[2394/3000] Train Acc: 0.958157 Loss: 0.120768 | Val Acc: 0.238508 loss: 5.639003\n",
            "[2395/3000] Train Acc: 0.952208 Loss: 0.135994 | Val Acc: 0.220363 loss: 6.015185\n",
            "[2396/3000] Train Acc: 0.956695 Loss: 0.125512 | Val Acc: 0.200806 loss: 6.365692\n",
            "[2397/3000] Train Acc: 0.956090 Loss: 0.126421 | Val Acc: 0.207661 loss: 6.287056\n",
            "[2398/3000] Train Acc: 0.961182 Loss: 0.115301 | Val Acc: 0.231855 loss: 5.519773\n",
            "[2399/3000] Train Acc: 0.963097 Loss: 0.109489 | Val Acc: 0.241734 loss: 5.477114\n",
            "[2400/3000] Train Acc: 0.959921 Loss: 0.112325 | Val Acc: 0.211492 loss: 5.806929\n",
            "[2401/3000] Train Acc: 0.961283 Loss: 0.112862 | Val Acc: 0.240927 loss: 5.481594\n",
            "[2402/3000] Train Acc: 0.958207 Loss: 0.119787 | Val Acc: 0.225806 loss: 5.857576\n",
            "[2403/3000] Train Acc: 0.959770 Loss: 0.118527 | Val Acc: 0.224194 loss: 5.899984\n",
            "[2404/3000] Train Acc: 0.960778 Loss: 0.114130 | Val Acc: 0.241129 loss: 5.527484\n",
            "[2405/3000] Train Acc: 0.951553 Loss: 0.133221 | Val Acc: 0.221371 loss: 5.932141\n",
            "[2406/3000] Train Acc: 0.956241 Loss: 0.120219 | Val Acc: 0.223185 loss: 5.915446\n",
            "[2407/3000] Train Acc: 0.958207 Loss: 0.121923 | Val Acc: 0.226008 loss: 5.678385\n",
            "[2408/3000] Train Acc: 0.957149 Loss: 0.122056 | Val Acc: 0.221774 loss: 5.865584\n",
            "[2409/3000] Train Acc: 0.959417 Loss: 0.118158 | Val Acc: 0.231048 loss: 5.593100\n",
            "[2410/3000] Train Acc: 0.958964 Loss: 0.116790 | Val Acc: 0.218347 loss: 5.726181\n",
            "[2411/3000] Train Acc: 0.960879 Loss: 0.112480 | Val Acc: 0.220766 loss: 5.675755\n",
            "[2412/3000] Train Acc: 0.962745 Loss: 0.106775 | Val Acc: 0.229637 loss: 5.584456\n",
            "[2413/3000] Train Acc: 0.961434 Loss: 0.108284 | Val Acc: 0.238710 loss: 5.463974\n",
            "[2414/3000] Train Acc: 0.959266 Loss: 0.116576 | Val Acc: 0.221774 loss: 5.742174\n",
            "[2415/3000] Train Acc: 0.956342 Loss: 0.130819 | Val Acc: 0.242742 loss: 5.391414\n",
            "[2416/3000] Train Acc: 0.955636 Loss: 0.128356 | Val Acc: 0.209073 loss: 5.859475\n",
            "[2417/3000] Train Acc: 0.955636 Loss: 0.122449 | Val Acc: 0.228226 loss: 5.633044\n",
            "[2418/3000] Train Acc: 0.956997 Loss: 0.121460 | Val Acc: 0.230645 loss: 5.931847\n",
            "[2419/3000] Train Acc: 0.956947 Loss: 0.120313 | Val Acc: 0.218750 loss: 6.140316\n",
            "[2420/3000] Train Acc: 0.959770 Loss: 0.113968 | Val Acc: 0.223387 loss: 5.829034\n",
            "[2421/3000] Train Acc: 0.959468 Loss: 0.114039 | Val Acc: 0.244758 loss: 5.463596\n",
            "[2422/3000] Train Acc: 0.952511 Loss: 0.137028 | Val Acc: 0.230242 loss: 5.778772\n",
            "[2423/3000] Train Acc: 0.958711 Loss: 0.118145 | Val Acc: 0.222177 loss: 6.039143\n",
            "[2424/3000] Train Acc: 0.962240 Loss: 0.111270 | Val Acc: 0.243347 loss: 5.493456\n",
            "[2425/3000] Train Acc: 0.961585 Loss: 0.112942 | Val Acc: 0.242540 loss: 5.416636\n",
            "[2426/3000] Train Acc: 0.959669 Loss: 0.113646 | Val Acc: 0.217944 loss: 5.983434\n",
            "[2427/3000] Train Acc: 0.958863 Loss: 0.112624 | Val Acc: 0.225806 loss: 5.814627\n",
            "[2428/3000] Train Acc: 0.959720 Loss: 0.117814 | Val Acc: 0.217540 loss: 6.052402\n",
            "[2429/3000] Train Acc: 0.957653 Loss: 0.120138 | Val Acc: 0.225806 loss: 5.849621\n",
            "[2430/3000] Train Acc: 0.960123 Loss: 0.117549 | Val Acc: 0.218952 loss: 5.845611\n",
            "[2431/3000] Train Acc: 0.954426 Loss: 0.129161 | Val Acc: 0.214718 loss: 5.981537\n",
            "[2432/3000] Train Acc: 0.957149 Loss: 0.122260 | Val Acc: 0.221573 loss: 5.835318\n",
            "[2433/3000] Train Acc: 0.961030 Loss: 0.112609 | Val Acc: 0.218952 loss: 5.917071\n",
            "[2434/3000] Train Acc: 0.965517 Loss: 0.103770 | Val Acc: 0.209476 loss: 5.852556\n",
            "[2435/3000] Train Acc: 0.956443 Loss: 0.121961 | Val Acc: 0.244153 loss: 5.469194\n",
            "[2436/3000] Train Acc: 0.961736 Loss: 0.110585 | Val Acc: 0.217944 loss: 5.923517\n",
            "[2437/3000] Train Acc: 0.959468 Loss: 0.113987 | Val Acc: 0.209274 loss: 6.394524\n",
            "[2438/3000] Train Acc: 0.960678 Loss: 0.112581 | Val Acc: 0.215121 loss: 6.042910\n",
            "[2439/3000] Train Acc: 0.960678 Loss: 0.110647 | Val Acc: 0.223790 loss: 5.812085\n",
            "[2440/3000] Train Acc: 0.956897 Loss: 0.120191 | Val Acc: 0.233669 loss: 5.728746\n",
            "[2441/3000] Train Acc: 0.952813 Loss: 0.134303 | Val Acc: 0.219355 loss: 6.019914\n",
            "[2442/3000] Train Acc: 0.962039 Loss: 0.110076 | Val Acc: 0.242540 loss: 5.291896\n",
            "[2443/3000] Train Acc: 0.956644 Loss: 0.120710 | Val Acc: 0.225605 loss: 5.857505\n",
            "[2444/3000] Train Acc: 0.959216 Loss: 0.116042 | Val Acc: 0.215524 loss: 6.135519\n",
            "[2445/3000] Train Acc: 0.961585 Loss: 0.114736 | Val Acc: 0.225806 loss: 5.947717\n",
            "[2446/3000] Train Acc: 0.959770 Loss: 0.113570 | Val Acc: 0.223387 loss: 5.862110\n",
            "[2447/3000] Train Acc: 0.961837 Loss: 0.112327 | Val Acc: 0.230645 loss: 5.728274\n",
            "[2448/3000] Train Acc: 0.961686 Loss: 0.110508 | Val Acc: 0.236895 loss: 5.600971\n",
            "[2449/3000] Train Acc: 0.958207 Loss: 0.115409 | Val Acc: 0.212298 loss: 6.085464\n",
            "[2450/3000] Train Acc: 0.960173 Loss: 0.114364 | Val Acc: 0.226008 loss: 5.973092\n",
            "[2451/3000] Train Acc: 0.955485 Loss: 0.127620 | Val Acc: 0.230242 loss: 5.915125\n",
            "[2452/3000] Train Acc: 0.961736 Loss: 0.110687 | Val Acc: 0.224395 loss: 5.949027\n",
            "[2453/3000] Train Acc: 0.957602 Loss: 0.118081 | Val Acc: 0.230040 loss: 5.805756\n",
            "[2454/3000] Train Acc: 0.960879 Loss: 0.107904 | Val Acc: 0.235081 loss: 5.753217\n",
            "[2455/3000] Train Acc: 0.956392 Loss: 0.122819 | Val Acc: 0.197581 loss: 6.283515\n",
            "[2456/3000] Train Acc: 0.952359 Loss: 0.131226 | Val Acc: 0.238710 loss: 5.519131\n",
            "[2457/3000] Train Acc: 0.961484 Loss: 0.109413 | Val Acc: 0.225202 loss: 5.851514\n",
            "[2458/3000] Train Acc: 0.960678 Loss: 0.115043 | Val Acc: 0.210081 loss: 6.221171\n",
            "[2459/3000] Train Acc: 0.959216 Loss: 0.116005 | Val Acc: 0.208266 loss: 6.259678\n",
            "[2460/3000] Train Acc: 0.956040 Loss: 0.122086 | Val Acc: 0.212298 loss: 5.895750\n",
            "[2461/3000] Train Acc: 0.954729 Loss: 0.131749 | Val Acc: 0.234476 loss: 5.748837\n",
            "[2462/3000] Train Acc: 0.958863 Loss: 0.116872 | Val Acc: 0.236089 loss: 5.560432\n",
            "[2463/3000] Train Acc: 0.961081 Loss: 0.111521 | Val Acc: 0.228427 loss: 6.004214\n",
            "[2464/3000] Train Acc: 0.956191 Loss: 0.121165 | Val Acc: 0.219556 loss: 5.852859\n",
            "[2465/3000] Train Acc: 0.962593 Loss: 0.106243 | Val Acc: 0.222984 loss: 6.069889\n",
            "[2466/3000] Train Acc: 0.961182 Loss: 0.110078 | Val Acc: 0.212500 loss: 5.987893\n",
            "[2467/3000] Train Acc: 0.961434 Loss: 0.112857 | Val Acc: 0.220161 loss: 5.894783\n",
            "[2468/3000] Train Acc: 0.959770 Loss: 0.118598 | Val Acc: 0.228629 loss: 5.942253\n",
            "[2469/3000] Train Acc: 0.959468 Loss: 0.116075 | Val Acc: 0.229234 loss: 5.785916\n",
            "[2470/3000] Train Acc: 0.959266 Loss: 0.117647 | Val Acc: 0.237702 loss: 5.624521\n",
            "[2471/3000] Train Acc: 0.958056 Loss: 0.122953 | Val Acc: 0.192742 loss: 6.674817\n",
            "[2472/3000] Train Acc: 0.956443 Loss: 0.126232 | Val Acc: 0.216129 loss: 5.944350\n",
            "[2473/3000] Train Acc: 0.958661 Loss: 0.117697 | Val Acc: 0.203226 loss: 5.931807\n",
            "[2474/3000] Train Acc: 0.962644 Loss: 0.110351 | Val Acc: 0.248185 loss: 5.421164\n",
            "[2475/3000] Train Acc: 0.957804 Loss: 0.119714 | Val Acc: 0.237298 loss: 5.530264\n",
            "[2476/3000] Train Acc: 0.960476 Loss: 0.108374 | Val Acc: 0.221371 loss: 5.985379\n",
            "[2477/3000] Train Acc: 0.959770 Loss: 0.112716 | Val Acc: 0.200806 loss: 6.104531\n",
            "[2478/3000] Train Acc: 0.959316 Loss: 0.113006 | Val Acc: 0.227621 loss: 5.897659\n",
            "[2479/3000] Train Acc: 0.958510 Loss: 0.114945 | Val Acc: 0.207863 loss: 6.068615\n",
            "[2480/3000] Train Acc: 0.960778 Loss: 0.110192 | Val Acc: 0.194153 loss: 6.457242\n",
            "[2481/3000] Train Acc: 0.953267 Loss: 0.132293 | Val Acc: 0.238911 loss: 5.745600\n",
            "[2482/3000] Train Acc: 0.959367 Loss: 0.115338 | Val Acc: 0.197782 loss: 6.412785\n",
            "[2483/3000] Train Acc: 0.959064 Loss: 0.118622 | Val Acc: 0.241935 loss: 5.723223\n",
            "[2484/3000] Train Acc: 0.955989 Loss: 0.129736 | Val Acc: 0.240927 loss: 5.619859\n",
            "[2485/3000] Train Acc: 0.959316 Loss: 0.116157 | Val Acc: 0.216532 loss: 5.903364\n",
            "[2486/3000] Train Acc: 0.960022 Loss: 0.113676 | Val Acc: 0.211290 loss: 6.230907\n",
            "[2487/3000] Train Acc: 0.962140 Loss: 0.110818 | Val Acc: 0.238508 loss: 5.640618\n",
            "[2488/3000] Train Acc: 0.958611 Loss: 0.120014 | Val Acc: 0.240726 loss: 5.590885\n",
            "[2489/3000] Train Acc: 0.958762 Loss: 0.115655 | Val Acc: 0.224194 loss: 5.841269\n",
            "[2490/3000] Train Acc: 0.956897 Loss: 0.123061 | Val Acc: 0.210282 loss: 6.214185\n",
            "[2491/3000] Train Acc: 0.958661 Loss: 0.118117 | Val Acc: 0.235282 loss: 5.667689\n",
            "[2492/3000] Train Acc: 0.962341 Loss: 0.109056 | Val Acc: 0.236694 loss: 5.626413\n",
            "[2493/3000] Train Acc: 0.959316 Loss: 0.113315 | Val Acc: 0.226815 loss: 5.951196\n",
            "[2494/3000] Train Acc: 0.962442 Loss: 0.107233 | Val Acc: 0.229839 loss: 5.559358\n",
            "[2495/3000] Train Acc: 0.956846 Loss: 0.120480 | Val Acc: 0.240524 loss: 5.438368\n",
            "[2496/3000] Train Acc: 0.961434 Loss: 0.111083 | Val Acc: 0.241129 loss: 5.523626\n",
            "[2497/3000] Train Acc: 0.963450 Loss: 0.104136 | Val Acc: 0.223589 loss: 5.920892\n",
            "[2498/3000] Train Acc: 0.955687 Loss: 0.126123 | Val Acc: 0.218347 loss: 5.848417\n",
            "[2499/3000] Train Acc: 0.957451 Loss: 0.123216 | Val Acc: 0.246774 loss: 5.347727\n",
            "[2500/3000] Train Acc: 0.961081 Loss: 0.108692 | Val Acc: 0.226210 loss: 5.922061\n",
            "[2501/3000] Train Acc: 0.958913 Loss: 0.115952 | Val Acc: 0.224798 loss: 5.667993\n",
            "[2502/3000] Train Acc: 0.960022 Loss: 0.113499 | Val Acc: 0.228427 loss: 5.715585\n",
            "[2503/3000] Train Acc: 0.959871 Loss: 0.115201 | Val Acc: 0.229839 loss: 5.736095\n",
            "[2504/3000] Train Acc: 0.956443 Loss: 0.125948 | Val Acc: 0.237903 loss: 5.672717\n",
            "[2505/3000] Train Acc: 0.963904 Loss: 0.105333 | Val Acc: 0.245766 loss: 5.533760\n",
            "[2506/3000] Train Acc: 0.963702 Loss: 0.106957 | Val Acc: 0.228024 loss: 6.015878\n",
            "[2507/3000] Train Acc: 0.959216 Loss: 0.118486 | Val Acc: 0.203629 loss: 6.023993\n",
            "[2508/3000] Train Acc: 0.958762 Loss: 0.116355 | Val Acc: 0.214919 loss: 6.114123\n",
            "[2509/3000] Train Acc: 0.957098 Loss: 0.122311 | Val Acc: 0.223992 loss: 6.074781\n",
            "[2510/3000] Train Acc: 0.955132 Loss: 0.125937 | Val Acc: 0.212903 loss: 6.042514\n",
            "[2511/3000] Train Acc: 0.957754 Loss: 0.123976 | Val Acc: 0.233468 loss: 5.778355\n",
            "[2512/3000] Train Acc: 0.960425 Loss: 0.113015 | Val Acc: 0.227218 loss: 5.931670\n",
            "[2513/3000] Train Acc: 0.960274 Loss: 0.110635 | Val Acc: 0.229435 loss: 5.927196\n",
            "[2514/3000] Train Acc: 0.962745 Loss: 0.107515 | Val Acc: 0.239113 loss: 5.731562\n",
            "[2515/3000] Train Acc: 0.960325 Loss: 0.114452 | Val Acc: 0.232661 loss: 5.714680\n",
            "[2516/3000] Train Acc: 0.962745 Loss: 0.106068 | Val Acc: 0.222581 loss: 6.004216\n",
            "[2517/3000] Train Acc: 0.956796 Loss: 0.122423 | Val Acc: 0.224194 loss: 5.844253\n",
            "[2518/3000] Train Acc: 0.956191 Loss: 0.123026 | Val Acc: 0.221371 loss: 5.967403\n",
            "[2519/3000] Train Acc: 0.958711 Loss: 0.119138 | Val Acc: 0.271573 loss: 5.163566\n",
            "saving model with acc 0.272\n",
            "[2520/3000] Train Acc: 0.960123 Loss: 0.113594 | Val Acc: 0.217339 loss: 5.775452\n",
            "[2521/3000] Train Acc: 0.960375 Loss: 0.112418 | Val Acc: 0.236492 loss: 5.641569\n",
            "[2522/3000] Train Acc: 0.961383 Loss: 0.108518 | Val Acc: 0.218548 loss: 6.196068\n",
            "[2523/3000] Train Acc: 0.961585 Loss: 0.111093 | Val Acc: 0.238105 loss: 5.685819\n",
            "[2524/3000] Train Acc: 0.962694 Loss: 0.107110 | Val Acc: 0.248387 loss: 5.596822\n",
            "[2525/3000] Train Acc: 0.959518 Loss: 0.112863 | Val Acc: 0.213911 loss: 6.099603\n",
            "[2526/3000] Train Acc: 0.960526 Loss: 0.111726 | Val Acc: 0.245363 loss: 5.607696\n",
            "[2527/3000] Train Acc: 0.960829 Loss: 0.111521 | Val Acc: 0.218750 loss: 6.146569\n",
            "[2528/3000] Train Acc: 0.960778 Loss: 0.111437 | Val Acc: 0.227419 loss: 5.936906\n",
            "[2529/3000] Train Acc: 0.953569 Loss: 0.131121 | Val Acc: 0.233669 loss: 5.687529\n",
            "[2530/3000] Train Acc: 0.960123 Loss: 0.111795 | Val Acc: 0.232460 loss: 5.781080\n",
            "[2531/3000] Train Acc: 0.959871 Loss: 0.115371 | Val Acc: 0.207661 loss: 6.124009\n",
            "[2532/3000] Train Acc: 0.957854 Loss: 0.117641 | Val Acc: 0.232460 loss: 5.730286\n",
            "[2533/3000] Train Acc: 0.962543 Loss: 0.102812 | Val Acc: 0.250806 loss: 5.467652\n",
            "[2534/3000] Train Acc: 0.958964 Loss: 0.114032 | Val Acc: 0.216935 loss: 6.091234\n",
            "[2535/3000] Train Acc: 0.961333 Loss: 0.111543 | Val Acc: 0.215121 loss: 6.111773\n",
            "[2536/3000] Train Acc: 0.962644 Loss: 0.106800 | Val Acc: 0.234476 loss: 5.763593\n",
            "[2537/3000] Train Acc: 0.961837 Loss: 0.109322 | Val Acc: 0.229839 loss: 5.876778\n",
            "[2538/3000] Train Acc: 0.961283 Loss: 0.111543 | Val Acc: 0.204839 loss: 6.440376\n",
            "[2539/3000] Train Acc: 0.960476 Loss: 0.114008 | Val Acc: 0.220363 loss: 6.053669\n",
            "[2540/3000] Train Acc: 0.960627 Loss: 0.114013 | Val Acc: 0.268347 loss: 5.157699\n",
            "[2541/3000] Train Acc: 0.959316 Loss: 0.118881 | Val Acc: 0.235081 loss: 5.934665\n",
            "[2542/3000] Train Acc: 0.962341 Loss: 0.107969 | Val Acc: 0.207056 loss: 6.461674\n",
            "[2543/3000] Train Acc: 0.962140 Loss: 0.108660 | Val Acc: 0.231855 loss: 5.840114\n",
            "[2544/3000] Train Acc: 0.957098 Loss: 0.118578 | Val Acc: 0.219960 loss: 6.090841\n",
            "[2545/3000] Train Acc: 0.955132 Loss: 0.130033 | Val Acc: 0.231653 loss: 5.782357\n",
            "[2546/3000] Train Acc: 0.959165 Loss: 0.115195 | Val Acc: 0.238105 loss: 5.793854\n",
            "[2547/3000] Train Acc: 0.960274 Loss: 0.110471 | Val Acc: 0.214113 loss: 6.037368\n",
            "[2548/3000] Train Acc: 0.957199 Loss: 0.118382 | Val Acc: 0.236290 loss: 5.500235\n",
            "[2549/3000] Train Acc: 0.955586 Loss: 0.121595 | Val Acc: 0.234476 loss: 5.771534\n",
            "[2550/3000] Train Acc: 0.965719 Loss: 0.098798 | Val Acc: 0.216935 loss: 6.077991\n",
            "[2551/3000] Train Acc: 0.962946 Loss: 0.104287 | Val Acc: 0.215121 loss: 6.247141\n",
            "[2552/3000] Train Acc: 0.963602 Loss: 0.105849 | Val Acc: 0.226411 loss: 5.927207\n",
            "[2553/3000] Train Acc: 0.959367 Loss: 0.115714 | Val Acc: 0.227621 loss: 5.850960\n",
            "[2554/3000] Train Acc: 0.961736 Loss: 0.110559 | Val Acc: 0.216532 loss: 6.345034\n",
            "[2555/3000] Train Acc: 0.961635 Loss: 0.113353 | Val Acc: 0.220363 loss: 5.905346\n",
            "[2556/3000] Train Acc: 0.958510 Loss: 0.115274 | Val Acc: 0.217137 loss: 5.872161\n",
            "[2557/3000] Train Acc: 0.957149 Loss: 0.119065 | Val Acc: 0.244758 loss: 5.380969\n",
            "[2558/3000] Train Acc: 0.962845 Loss: 0.106300 | Val Acc: 0.248992 loss: 5.644171\n",
            "[2559/3000] Train Acc: 0.961787 Loss: 0.109268 | Val Acc: 0.230444 loss: 5.909736\n",
            "[2560/3000] Train Acc: 0.961081 Loss: 0.110772 | Val Acc: 0.226411 loss: 6.069357\n",
            "[2561/3000] Train Acc: 0.966979 Loss: 0.097667 | Val Acc: 0.236895 loss: 5.503334\n",
            "[2562/3000] Train Acc: 0.956997 Loss: 0.122116 | Val Acc: 0.231250 loss: 6.095119\n",
            "[2563/3000] Train Acc: 0.960224 Loss: 0.115481 | Val Acc: 0.223790 loss: 6.083923\n",
            "[2564/3000] Train Acc: 0.963753 Loss: 0.106784 | Val Acc: 0.231048 loss: 5.813389\n",
            "[2565/3000] Train Acc: 0.958711 Loss: 0.118729 | Val Acc: 0.224798 loss: 5.622460\n",
            "[2566/3000] Train Acc: 0.961232 Loss: 0.112261 | Val Acc: 0.229032 loss: 5.754117\n",
            "[2567/3000] Train Acc: 0.962291 Loss: 0.109046 | Val Acc: 0.236895 loss: 5.613192\n",
            "[2568/3000] Train Acc: 0.964862 Loss: 0.099293 | Val Acc: 0.267742 loss: 5.196347\n",
            "[2569/3000] Train Acc: 0.962089 Loss: 0.110129 | Val Acc: 0.214919 loss: 6.032622\n",
            "[2570/3000] Train Acc: 0.959115 Loss: 0.115771 | Val Acc: 0.236089 loss: 5.653803\n",
            "[2571/3000] Train Acc: 0.962190 Loss: 0.107719 | Val Acc: 0.235081 loss: 5.930650\n",
            "[2572/3000] Train Acc: 0.956140 Loss: 0.126409 | Val Acc: 0.208065 loss: 6.223891\n",
            "[2573/3000] Train Acc: 0.963400 Loss: 0.104759 | Val Acc: 0.225000 loss: 5.783081\n",
            "[2574/3000] Train Acc: 0.961585 Loss: 0.111684 | Val Acc: 0.225000 loss: 5.845019\n",
            "[2575/3000] Train Acc: 0.963249 Loss: 0.104084 | Val Acc: 0.240927 loss: 5.723357\n",
            "[2576/3000] Train Acc: 0.961484 Loss: 0.109333 | Val Acc: 0.244758 loss: 5.750084\n",
            "[2577/3000] Train Acc: 0.962089 Loss: 0.107487 | Val Acc: 0.215927 loss: 6.251063\n",
            "[2578/3000] Train Acc: 0.965366 Loss: 0.102094 | Val Acc: 0.251613 loss: 5.493287\n",
            "[2579/3000] Train Acc: 0.963652 Loss: 0.103517 | Val Acc: 0.191129 loss: 6.610094\n",
            "[2580/3000] Train Acc: 0.958359 Loss: 0.121303 | Val Acc: 0.218347 loss: 6.141298\n",
            "[2581/3000] Train Acc: 0.958762 Loss: 0.115818 | Val Acc: 0.240726 loss: 5.537511\n",
            "[2582/3000] Train Acc: 0.962644 Loss: 0.109778 | Val Acc: 0.259274 loss: 5.375934\n",
            "[2583/3000] Train Acc: 0.965416 Loss: 0.100967 | Val Acc: 0.232258 loss: 5.853334\n",
            "[2584/3000] Train Acc: 0.959619 Loss: 0.115557 | Val Acc: 0.220363 loss: 6.009267\n",
            "[2585/3000] Train Acc: 0.960678 Loss: 0.114037 | Val Acc: 0.217339 loss: 6.082180\n",
            "[2586/3000] Train Acc: 0.956695 Loss: 0.128051 | Val Acc: 0.221774 loss: 5.814173\n",
            "[2587/3000] Train Acc: 0.961182 Loss: 0.108432 | Val Acc: 0.212298 loss: 6.141841\n",
            "[2588/3000] Train Acc: 0.962341 Loss: 0.109025 | Val Acc: 0.228629 loss: 5.817219\n",
            "[2589/3000] Train Acc: 0.962795 Loss: 0.106517 | Val Acc: 0.239919 loss: 5.591160\n",
            "[2590/3000] Train Acc: 0.965870 Loss: 0.100438 | Val Acc: 0.227419 loss: 6.070808\n",
            "[2591/3000] Train Acc: 0.960123 Loss: 0.112222 | Val Acc: 0.213710 loss: 6.301318\n",
            "[2592/3000] Train Acc: 0.961938 Loss: 0.110589 | Val Acc: 0.242137 loss: 5.856730\n",
            "[2593/3000] Train Acc: 0.961535 Loss: 0.109685 | Val Acc: 0.199798 loss: 6.682710\n",
            "[2594/3000] Train Acc: 0.963854 Loss: 0.102269 | Val Acc: 0.242742 loss: 5.708280\n",
            "[2595/3000] Train Acc: 0.961686 Loss: 0.112333 | Val Acc: 0.219153 loss: 6.432878\n",
            "[2596/3000] Train Acc: 0.957300 Loss: 0.120778 | Val Acc: 0.200403 loss: 6.683889\n",
            "[2597/3000] Train Acc: 0.962089 Loss: 0.109681 | Val Acc: 0.249194 loss: 5.622327\n",
            "[2598/3000] Train Acc: 0.961030 Loss: 0.108448 | Val Acc: 0.237903 loss: 5.898774\n",
            "[2599/3000] Train Acc: 0.966173 Loss: 0.098558 | Val Acc: 0.250806 loss: 5.480979\n",
            "[2600/3000] Train Acc: 0.964509 Loss: 0.102928 | Val Acc: 0.239315 loss: 5.837331\n",
            "[2601/3000] Train Acc: 0.961081 Loss: 0.111472 | Val Acc: 0.230645 loss: 6.042098\n",
            "[2602/3000] Train Acc: 0.958762 Loss: 0.115267 | Val Acc: 0.234476 loss: 5.874803\n",
            "[2603/3000] Train Acc: 0.961383 Loss: 0.109022 | Val Acc: 0.253629 loss: 5.438422\n",
            "[2604/3000] Train Acc: 0.964761 Loss: 0.099658 | Val Acc: 0.248387 loss: 5.743729\n",
            "[2605/3000] Train Acc: 0.964307 Loss: 0.106140 | Val Acc: 0.229032 loss: 6.154059\n",
            "[2606/3000] Train Acc: 0.960425 Loss: 0.110275 | Val Acc: 0.245363 loss: 5.806659\n",
            "[2607/3000] Train Acc: 0.960224 Loss: 0.110754 | Val Acc: 0.245565 loss: 5.548960\n",
            "[2608/3000] Train Acc: 0.964963 Loss: 0.103332 | Val Acc: 0.230040 loss: 6.226304\n",
            "[2609/3000] Train Acc: 0.961283 Loss: 0.109236 | Val Acc: 0.225000 loss: 5.939151\n",
            "[2610/3000] Train Acc: 0.963047 Loss: 0.104611 | Val Acc: 0.251210 loss: 5.681386\n",
            "[2611/3000] Train Acc: 0.963097 Loss: 0.104154 | Val Acc: 0.219355 loss: 6.214708\n",
            "[2612/3000] Train Acc: 0.961887 Loss: 0.108797 | Val Acc: 0.239315 loss: 5.844123\n",
            "[2613/3000] Train Acc: 0.961131 Loss: 0.110729 | Val Acc: 0.245565 loss: 5.605857\n",
            "[2614/3000] Train Acc: 0.957754 Loss: 0.118963 | Val Acc: 0.213710 loss: 6.191711\n",
            "[2615/3000] Train Acc: 0.964761 Loss: 0.103308 | Val Acc: 0.213911 loss: 6.317416\n",
            "[2616/3000] Train Acc: 0.962392 Loss: 0.108921 | Val Acc: 0.258871 loss: 5.423628\n",
            "[2617/3000] Train Acc: 0.965265 Loss: 0.101117 | Val Acc: 0.249597 loss: 5.692922\n",
            "[2618/3000] Train Acc: 0.962795 Loss: 0.107272 | Val Acc: 0.222984 loss: 5.947164\n",
            "[2619/3000] Train Acc: 0.962039 Loss: 0.111508 | Val Acc: 0.218548 loss: 6.322443\n",
            "[2620/3000] Train Acc: 0.958661 Loss: 0.116373 | Val Acc: 0.228226 loss: 6.248905\n",
            "[2621/3000] Train Acc: 0.962845 Loss: 0.102997 | Val Acc: 0.223185 loss: 6.105536\n",
            "[2622/3000] Train Acc: 0.964711 Loss: 0.102870 | Val Acc: 0.220565 loss: 6.460395\n",
            "[2623/3000] Train Acc: 0.963854 Loss: 0.104785 | Val Acc: 0.223185 loss: 6.116777\n",
            "[2624/3000] Train Acc: 0.962442 Loss: 0.106572 | Val Acc: 0.210887 loss: 6.372300\n",
            "[2625/3000] Train Acc: 0.959821 Loss: 0.114247 | Val Acc: 0.212500 loss: 6.352010\n",
            "[2626/3000] Train Acc: 0.957804 Loss: 0.121211 | Val Acc: 0.230040 loss: 6.162431\n",
            "[2627/3000] Train Acc: 0.963097 Loss: 0.102716 | Val Acc: 0.225202 loss: 6.184324\n",
            "[2628/3000] Train Acc: 0.965366 Loss: 0.099971 | Val Acc: 0.261089 loss: 5.410181\n",
            "[2629/3000] Train Acc: 0.959266 Loss: 0.110796 | Val Acc: 0.213710 loss: 6.120389\n",
            "[2630/3000] Train Acc: 0.959014 Loss: 0.117263 | Val Acc: 0.229637 loss: 5.946669\n",
            "[2631/3000] Train Acc: 0.960274 Loss: 0.115947 | Val Acc: 0.233871 loss: 5.997459\n",
            "[2632/3000] Train Acc: 0.959367 Loss: 0.118547 | Val Acc: 0.224597 loss: 6.136617\n",
            "[2633/3000] Train Acc: 0.959115 Loss: 0.113813 | Val Acc: 0.237097 loss: 6.082266\n",
            "[2634/3000] Train Acc: 0.960930 Loss: 0.109019 | Val Acc: 0.230040 loss: 5.757150\n",
            "[2635/3000] Train Acc: 0.967786 Loss: 0.094619 | Val Acc: 0.233468 loss: 6.029669\n",
            "[2636/3000] Train Acc: 0.966072 Loss: 0.097121 | Val Acc: 0.225403 loss: 6.060490\n",
            "[2637/3000] Train Acc: 0.964156 Loss: 0.100825 | Val Acc: 0.245968 loss: 5.519683\n",
            "[2638/3000] Train Acc: 0.966223 Loss: 0.098299 | Val Acc: 0.221371 loss: 6.122705\n",
            "[2639/3000] Train Acc: 0.958913 Loss: 0.117795 | Val Acc: 0.232258 loss: 5.964531\n",
            "[2640/3000] Train Acc: 0.960375 Loss: 0.115726 | Val Acc: 0.245565 loss: 5.627706\n",
            "[2641/3000] Train Acc: 0.960728 Loss: 0.111066 | Val Acc: 0.225806 loss: 6.236362\n",
            "[2642/3000] Train Acc: 0.959619 Loss: 0.112813 | Val Acc: 0.221371 loss: 6.165653\n",
            "[2643/3000] Train Acc: 0.962291 Loss: 0.104510 | Val Acc: 0.271573 loss: 5.228975\n",
            "[2644/3000] Train Acc: 0.956140 Loss: 0.118975 | Val Acc: 0.228831 loss: 6.169513\n",
            "[2645/3000] Train Acc: 0.960577 Loss: 0.116029 | Val Acc: 0.237702 loss: 5.738071\n",
            "[2646/3000] Train Acc: 0.965719 Loss: 0.097844 | Val Acc: 0.222782 loss: 6.024627\n",
            "[2647/3000] Train Acc: 0.965719 Loss: 0.097671 | Val Acc: 0.233871 loss: 5.914168\n",
            "[2648/3000] Train Acc: 0.960829 Loss: 0.109326 | Val Acc: 0.245161 loss: 5.822172\n",
            "[2649/3000] Train Acc: 0.965820 Loss: 0.100599 | Val Acc: 0.233065 loss: 5.894795\n",
            "[2650/3000] Train Acc: 0.962593 Loss: 0.103262 | Val Acc: 0.232460 loss: 5.944932\n",
            "[2651/3000] Train Acc: 0.962997 Loss: 0.107984 | Val Acc: 0.222782 loss: 6.099785\n",
            "[2652/3000] Train Acc: 0.961383 Loss: 0.112396 | Val Acc: 0.242339 loss: 5.728323\n",
            "[2653/3000] Train Acc: 0.956644 Loss: 0.124199 | Val Acc: 0.253226 loss: 5.594763\n",
            "[2654/3000] Train Acc: 0.961333 Loss: 0.113471 | Val Acc: 0.211694 loss: 6.536069\n",
            "[2655/3000] Train Acc: 0.960123 Loss: 0.112704 | Val Acc: 0.203024 loss: 6.232118\n",
            "[2656/3000] Train Acc: 0.965316 Loss: 0.097296 | Val Acc: 0.229234 loss: 6.201847\n",
            "[2657/3000] Train Acc: 0.962997 Loss: 0.104326 | Val Acc: 0.239113 loss: 5.812564\n",
            "[2658/3000] Train Acc: 0.961585 Loss: 0.106809 | Val Acc: 0.184073 loss: 6.611270\n",
            "[2659/3000] Train Acc: 0.962190 Loss: 0.105448 | Val Acc: 0.194355 loss: 6.936210\n",
            "[2660/3000] Train Acc: 0.960375 Loss: 0.114138 | Val Acc: 0.240121 loss: 5.706603\n",
            "[2661/3000] Train Acc: 0.956241 Loss: 0.120733 | Val Acc: 0.217137 loss: 6.422934\n",
            "[2662/3000] Train Acc: 0.965164 Loss: 0.100450 | Val Acc: 0.227016 loss: 6.168641\n",
            "[2663/3000] Train Acc: 0.968492 Loss: 0.094601 | Val Acc: 0.241331 loss: 5.782414\n",
            "[2664/3000] Train Acc: 0.967635 Loss: 0.091461 | Val Acc: 0.214919 loss: 6.422567\n",
            "[2665/3000] Train Acc: 0.963753 Loss: 0.104243 | Val Acc: 0.213508 loss: 6.429262\n",
            "[2666/3000] Train Acc: 0.959669 Loss: 0.113876 | Val Acc: 0.207661 loss: 6.536095\n",
            "[2667/3000] Train Acc: 0.962543 Loss: 0.108024 | Val Acc: 0.220766 loss: 6.154710\n",
            "[2668/3000] Train Acc: 0.960375 Loss: 0.112788 | Val Acc: 0.206452 loss: 6.700556\n",
            "[2669/3000] Train Acc: 0.963148 Loss: 0.104320 | Val Acc: 0.251815 loss: 5.602620\n",
            "[2670/3000] Train Acc: 0.962644 Loss: 0.104172 | Val Acc: 0.248185 loss: 5.549298\n",
            "[2671/3000] Train Acc: 0.963803 Loss: 0.104831 | Val Acc: 0.235081 loss: 5.933620\n",
            "[2672/3000] Train Acc: 0.961887 Loss: 0.108576 | Val Acc: 0.228226 loss: 6.027115\n",
            "[2673/3000] Train Acc: 0.964156 Loss: 0.100432 | Val Acc: 0.211089 loss: 6.376130\n",
            "[2674/3000] Train Acc: 0.955031 Loss: 0.128698 | Val Acc: 0.216935 loss: 6.311519\n",
            "[2675/3000] Train Acc: 0.966273 Loss: 0.096596 | Val Acc: 0.235484 loss: 6.155919\n",
            "[2676/3000] Train Acc: 0.966828 Loss: 0.097514 | Val Acc: 0.233669 loss: 6.047015\n",
            "[2677/3000] Train Acc: 0.962543 Loss: 0.105303 | Val Acc: 0.206452 loss: 6.460491\n",
            "[2678/3000] Train Acc: 0.961736 Loss: 0.108628 | Val Acc: 0.216734 loss: 6.575117\n",
            "[2679/3000] Train Acc: 0.960224 Loss: 0.114392 | Val Acc: 0.248185 loss: 5.710712\n",
            "[2680/3000] Train Acc: 0.965618 Loss: 0.098510 | Val Acc: 0.213911 loss: 6.302429\n",
            "[2681/3000] Train Acc: 0.962745 Loss: 0.101983 | Val Acc: 0.233065 loss: 5.958063\n",
            "[2682/3000] Train Acc: 0.964610 Loss: 0.103484 | Val Acc: 0.250605 loss: 5.772995\n",
            "[2683/3000] Train Acc: 0.965719 Loss: 0.096958 | Val Acc: 0.236290 loss: 5.956414\n",
            "[2684/3000] Train Acc: 0.963450 Loss: 0.105864 | Val Acc: 0.218750 loss: 6.449068\n",
            "[2685/3000] Train Acc: 0.961383 Loss: 0.111151 | Val Acc: 0.220766 loss: 6.195972\n",
            "[2686/3000] Train Acc: 0.961837 Loss: 0.108963 | Val Acc: 0.236290 loss: 5.920424\n",
            "[2687/3000] Train Acc: 0.965668 Loss: 0.102067 | Val Acc: 0.221169 loss: 6.102981\n",
            "[2688/3000] Train Acc: 0.953721 Loss: 0.134914 | Val Acc: 0.228226 loss: 6.500012\n",
            "[2689/3000] Train Acc: 0.961736 Loss: 0.111426 | Val Acc: 0.233065 loss: 5.901415\n",
            "[2690/3000] Train Acc: 0.964358 Loss: 0.102666 | Val Acc: 0.263105 loss: 5.380335\n",
            "[2691/3000] Train Acc: 0.972474 Loss: 0.086116 | Val Acc: 0.247782 loss: 5.772736\n",
            "[2692/3000] Train Acc: 0.963551 Loss: 0.106068 | Val Acc: 0.240524 loss: 5.687610\n",
            "[2693/3000] Train Acc: 0.961686 Loss: 0.106100 | Val Acc: 0.217339 loss: 6.178151\n",
            "[2694/3000] Train Acc: 0.955182 Loss: 0.124557 | Val Acc: 0.220161 loss: 6.179225\n",
            "[2695/3000] Train Acc: 0.968290 Loss: 0.090513 | Val Acc: 0.227419 loss: 6.123915\n",
            "[2696/3000] Train Acc: 0.966173 Loss: 0.096214 | Val Acc: 0.235282 loss: 6.001146\n",
            "[2697/3000] Train Acc: 0.955485 Loss: 0.123325 | Val Acc: 0.227016 loss: 6.142221\n",
            "[2698/3000] Train Acc: 0.966122 Loss: 0.096276 | Val Acc: 0.230444 loss: 6.326372\n",
            "[2699/3000] Train Acc: 0.968592 Loss: 0.093473 | Val Acc: 0.233468 loss: 5.863196\n",
            "[2700/3000] Train Acc: 0.958711 Loss: 0.115171 | Val Acc: 0.208669 loss: 6.400034\n",
            "[2701/3000] Train Acc: 0.962291 Loss: 0.108448 | Val Acc: 0.195766 loss: 6.784820\n",
            "[2702/3000] Train Acc: 0.961585 Loss: 0.109625 | Val Acc: 0.209677 loss: 6.341863\n",
            "[2703/3000] Train Acc: 0.966021 Loss: 0.099147 | Val Acc: 0.225605 loss: 6.097475\n",
            "[2704/3000] Train Acc: 0.963148 Loss: 0.105630 | Val Acc: 0.214113 loss: 6.406608\n",
            "[2705/3000] Train Acc: 0.968895 Loss: 0.095535 | Val Acc: 0.229637 loss: 6.127800\n",
            "[2706/3000] Train Acc: 0.959014 Loss: 0.114106 | Val Acc: 0.234274 loss: 5.893112\n",
            "[2707/3000] Train Acc: 0.966475 Loss: 0.099816 | Val Acc: 0.225605 loss: 6.057500\n",
            "[2708/3000] Train Acc: 0.966778 Loss: 0.096299 | Val Acc: 0.214718 loss: 6.238969\n",
            "[2709/3000] Train Acc: 0.963854 Loss: 0.103325 | Val Acc: 0.218750 loss: 6.021359\n",
            "[2710/3000] Train Acc: 0.959468 Loss: 0.112015 | Val Acc: 0.226815 loss: 6.079534\n",
            "[2711/3000] Train Acc: 0.964408 Loss: 0.102373 | Val Acc: 0.250202 loss: 5.686265\n",
            "[2712/3000] Train Acc: 0.962140 Loss: 0.110290 | Val Acc: 0.236290 loss: 5.959572\n",
            "[2713/3000] Train Acc: 0.961232 Loss: 0.106514 | Val Acc: 0.236290 loss: 5.889942\n",
            "[2714/3000] Train Acc: 0.964358 Loss: 0.102201 | Val Acc: 0.242137 loss: 5.842429\n",
            "[2715/3000] Train Acc: 0.964811 Loss: 0.098571 | Val Acc: 0.233266 loss: 6.111152\n",
            "[2716/3000] Train Acc: 0.964156 Loss: 0.102058 | Val Acc: 0.232460 loss: 5.943956\n",
            "[2717/3000] Train Acc: 0.964307 Loss: 0.100238 | Val Acc: 0.190726 loss: 6.906201\n",
            "[2718/3000] Train Acc: 0.964509 Loss: 0.104303 | Val Acc: 0.243347 loss: 5.944897\n",
            "[2719/3000] Train Acc: 0.962240 Loss: 0.108993 | Val Acc: 0.223185 loss: 6.351012\n",
            "[2720/3000] Train Acc: 0.962694 Loss: 0.106029 | Val Acc: 0.222379 loss: 6.196702\n",
            "[2721/3000] Train Acc: 0.962997 Loss: 0.103282 | Val Acc: 0.204637 loss: 6.554007\n",
            "[2722/3000] Train Acc: 0.969349 Loss: 0.089935 | Val Acc: 0.240524 loss: 5.820038\n",
            "[2723/3000] Train Acc: 0.962492 Loss: 0.106914 | Val Acc: 0.231048 loss: 6.028272\n",
            "[2724/3000] Train Acc: 0.963349 Loss: 0.103113 | Val Acc: 0.253226 loss: 5.535003\n",
            "[2725/3000] Train Acc: 0.960778 Loss: 0.114159 | Val Acc: 0.230444 loss: 6.065572\n",
            "[2726/3000] Train Acc: 0.963198 Loss: 0.106816 | Val Acc: 0.237097 loss: 5.857312\n",
            "[2727/3000] Train Acc: 0.961635 Loss: 0.109576 | Val Acc: 0.235282 loss: 5.789546\n",
            "[2728/3000] Train Acc: 0.969349 Loss: 0.090243 | Val Acc: 0.220565 loss: 6.205537\n",
            "[2729/3000] Train Acc: 0.964761 Loss: 0.099913 | Val Acc: 0.209073 loss: 6.489324\n",
            "[2730/3000] Train Acc: 0.965467 Loss: 0.098779 | Val Acc: 0.232460 loss: 5.987333\n",
            "[2731/3000] Train Acc: 0.966475 Loss: 0.095781 | Val Acc: 0.242339 loss: 5.763997\n",
            "[2732/3000] Train Acc: 0.962694 Loss: 0.101020 | Val Acc: 0.248790 loss: 5.719935\n",
            "[2733/3000] Train Acc: 0.959367 Loss: 0.113798 | Val Acc: 0.240524 loss: 5.788231\n",
            "[2734/3000] Train Acc: 0.962341 Loss: 0.107376 | Val Acc: 0.232258 loss: 6.007232\n",
            "[2735/3000] Train Acc: 0.965719 Loss: 0.099115 | Val Acc: 0.222782 loss: 6.261867\n",
            "[2736/3000] Train Acc: 0.965517 Loss: 0.096615 | Val Acc: 0.225806 loss: 6.192329\n",
            "[2737/3000] Train Acc: 0.964106 Loss: 0.100136 | Val Acc: 0.220363 loss: 6.466654\n",
            "[2738/3000] Train Acc: 0.966324 Loss: 0.097889 | Val Acc: 0.220968 loss: 6.268867\n",
            "[2739/3000] Train Acc: 0.964156 Loss: 0.101294 | Val Acc: 0.237097 loss: 5.803930\n",
            "[2740/3000] Train Acc: 0.964307 Loss: 0.101414 | Val Acc: 0.229839 loss: 6.205014\n",
            "[2741/3000] Train Acc: 0.965568 Loss: 0.099070 | Val Acc: 0.228226 loss: 6.134834\n",
            "[2742/3000] Train Acc: 0.964307 Loss: 0.103959 | Val Acc: 0.215927 loss: 6.384818\n",
            "[2743/3000] Train Acc: 0.963702 Loss: 0.104132 | Val Acc: 0.248185 loss: 5.692156\n",
            "[2744/3000] Train Acc: 0.964005 Loss: 0.105785 | Val Acc: 0.238105 loss: 5.775584\n",
            "[2745/3000] Train Acc: 0.964408 Loss: 0.101275 | Val Acc: 0.228024 loss: 6.207254\n",
            "[2746/3000] Train Acc: 0.964257 Loss: 0.103622 | Val Acc: 0.229234 loss: 6.197421\n",
            "[2747/3000] Train Acc: 0.955989 Loss: 0.127689 | Val Acc: 0.234073 loss: 5.859893\n",
            "[2748/3000] Train Acc: 0.964307 Loss: 0.099238 | Val Acc: 0.252823 loss: 5.654536\n",
            "[2749/3000] Train Acc: 0.967735 Loss: 0.093666 | Val Acc: 0.218750 loss: 6.335538\n",
            "[2750/3000] Train Acc: 0.966576 Loss: 0.094758 | Val Acc: 0.240927 loss: 5.960449\n",
            "[2751/3000] Train Acc: 0.965114 Loss: 0.099457 | Val Acc: 0.221371 loss: 6.210327\n",
            "[2752/3000] Train Acc: 0.963803 Loss: 0.102872 | Val Acc: 0.215726 loss: 6.413688\n",
            "[2753/3000] Train Acc: 0.965870 Loss: 0.092964 | Val Acc: 0.207056 loss: 6.849787\n",
            "[2754/3000] Train Acc: 0.963702 Loss: 0.102489 | Val Acc: 0.225806 loss: 6.174269\n",
            "[2755/3000] Train Acc: 0.966425 Loss: 0.096915 | Val Acc: 0.228629 loss: 6.288318\n",
            "[2756/3000] Train Acc: 0.962946 Loss: 0.102231 | Val Acc: 0.235081 loss: 6.316132\n",
            "[2757/3000] Train Acc: 0.959468 Loss: 0.115496 | Val Acc: 0.234274 loss: 6.190279\n",
            "[2758/3000] Train Acc: 0.962140 Loss: 0.105481 | Val Acc: 0.240927 loss: 5.973263\n",
            "[2759/3000] Train Acc: 0.968492 Loss: 0.090703 | Val Acc: 0.242742 loss: 5.860548\n",
            "[2760/3000] Train Acc: 0.965870 Loss: 0.098004 | Val Acc: 0.254234 loss: 5.860404\n",
            "[2761/3000] Train Acc: 0.965971 Loss: 0.098557 | Val Acc: 0.218952 loss: 6.312547\n",
            "[2762/3000] Train Acc: 0.958913 Loss: 0.115384 | Val Acc: 0.210887 loss: 6.380057\n",
            "[2763/3000] Train Acc: 0.963249 Loss: 0.104519 | Val Acc: 0.218952 loss: 6.382572\n",
            "[2764/3000] Train Acc: 0.964660 Loss: 0.099330 | Val Acc: 0.223790 loss: 6.212528\n",
            "[2765/3000] Train Acc: 0.966727 Loss: 0.098836 | Val Acc: 0.250202 loss: 5.812072\n",
            "[2766/3000] Train Acc: 0.960476 Loss: 0.109748 | Val Acc: 0.250605 loss: 5.874319\n",
            "[2767/3000] Train Acc: 0.962291 Loss: 0.105058 | Val Acc: 0.237298 loss: 6.216921\n",
            "[2768/3000] Train Acc: 0.965517 Loss: 0.094746 | Val Acc: 0.235685 loss: 6.025879\n",
            "[2769/3000] Train Acc: 0.969197 Loss: 0.086535 | Val Acc: 0.239919 loss: 5.941704\n",
            "[2770/3000] Train Acc: 0.963551 Loss: 0.101702 | Val Acc: 0.239315 loss: 6.226846\n",
            "[2771/3000] Train Acc: 0.961787 Loss: 0.108202 | Val Acc: 0.222581 loss: 6.357916\n",
            "[2772/3000] Train Acc: 0.963299 Loss: 0.104193 | Val Acc: 0.205645 loss: 6.689333\n",
            "[2773/3000] Train Acc: 0.960425 Loss: 0.112448 | Val Acc: 0.206653 loss: 6.737141\n",
            "[2774/3000] Train Acc: 0.966727 Loss: 0.096969 | Val Acc: 0.251411 loss: 5.873208\n",
            "[2775/3000] Train Acc: 0.963501 Loss: 0.102340 | Val Acc: 0.234879 loss: 5.892943\n",
            "[2776/3000] Train Acc: 0.965114 Loss: 0.100521 | Val Acc: 0.222782 loss: 5.961421\n",
            "[2777/3000] Train Acc: 0.965719 Loss: 0.097776 | Val Acc: 0.210887 loss: 6.774826\n",
            "[2778/3000] Train Acc: 0.964358 Loss: 0.098519 | Val Acc: 0.210484 loss: 6.376078\n",
            "[2779/3000] Train Acc: 0.965568 Loss: 0.097289 | Val Acc: 0.267137 loss: 5.398070\n",
            "[2780/3000] Train Acc: 0.964307 Loss: 0.101395 | Val Acc: 0.207863 loss: 6.746980\n",
            "[2781/3000] Train Acc: 0.965769 Loss: 0.098764 | Val Acc: 0.222984 loss: 6.456974\n",
            "[2782/3000] Train Acc: 0.964257 Loss: 0.108973 | Val Acc: 0.242742 loss: 5.832989\n",
            "[2783/3000] Train Acc: 0.964257 Loss: 0.102747 | Val Acc: 0.234879 loss: 6.089421\n",
            "[2784/3000] Train Acc: 0.967080 Loss: 0.096208 | Val Acc: 0.232258 loss: 5.967117\n",
            "[2785/3000] Train Acc: 0.961988 Loss: 0.107685 | Val Acc: 0.212298 loss: 6.376681\n",
            "[2786/3000] Train Acc: 0.960778 Loss: 0.113931 | Val Acc: 0.237298 loss: 6.087881\n",
            "[2787/3000] Train Acc: 0.965668 Loss: 0.099053 | Val Acc: 0.216935 loss: 6.553859\n",
            "[2788/3000] Train Acc: 0.962240 Loss: 0.107970 | Val Acc: 0.231048 loss: 6.329931\n",
            "[2789/3000] Train Acc: 0.968744 Loss: 0.090259 | Val Acc: 0.219960 loss: 6.457768\n",
            "[2790/3000] Train Acc: 0.964307 Loss: 0.101283 | Val Acc: 0.224395 loss: 6.387923\n",
            "[2791/3000] Train Acc: 0.965215 Loss: 0.098388 | Val Acc: 0.210887 loss: 6.692554\n",
            "[2792/3000] Train Acc: 0.965366 Loss: 0.097710 | Val Acc: 0.237903 loss: 5.782553\n",
            "[2793/3000] Train Acc: 0.962997 Loss: 0.102440 | Val Acc: 0.258468 loss: 5.605142\n",
            "[2794/3000] Train Acc: 0.965215 Loss: 0.097079 | Val Acc: 0.221371 loss: 6.260054\n",
            "[2795/3000] Train Acc: 0.966475 Loss: 0.098239 | Val Acc: 0.246371 loss: 5.930612\n",
            "[2796/3000] Train Acc: 0.966828 Loss: 0.097816 | Val Acc: 0.238911 loss: 6.222942\n",
            "[2797/3000] Train Acc: 0.962845 Loss: 0.102175 | Val Acc: 0.241532 loss: 5.940508\n",
            "[2798/3000] Train Acc: 0.965820 Loss: 0.095921 | Val Acc: 0.215726 loss: 6.448800\n",
            "[2799/3000] Train Acc: 0.965618 Loss: 0.099548 | Val Acc: 0.234476 loss: 6.156157\n",
            "[2800/3000] Train Acc: 0.963551 Loss: 0.109527 | Val Acc: 0.224395 loss: 6.450904\n",
            "[2801/3000] Train Acc: 0.964459 Loss: 0.099258 | Val Acc: 0.255040 loss: 5.808921\n",
            "[2802/3000] Train Acc: 0.968492 Loss: 0.089867 | Val Acc: 0.252823 loss: 5.856150\n",
            "[2803/3000] Train Acc: 0.963854 Loss: 0.103692 | Val Acc: 0.250403 loss: 5.914729\n",
            "[2804/3000] Train Acc: 0.965820 Loss: 0.096781 | Val Acc: 0.232258 loss: 6.139033\n",
            "[2805/3000] Train Acc: 0.961081 Loss: 0.107129 | Val Acc: 0.211694 loss: 6.394089\n",
            "[2806/3000] Train Acc: 0.962190 Loss: 0.105526 | Val Acc: 0.232460 loss: 6.218240\n",
            "[2807/3000] Train Acc: 0.967685 Loss: 0.093103 | Val Acc: 0.220565 loss: 6.535269\n",
            "[2808/3000] Train Acc: 0.964106 Loss: 0.102901 | Val Acc: 0.209073 loss: 6.472111\n",
            "[2809/3000] Train Acc: 0.963047 Loss: 0.109761 | Val Acc: 0.228629 loss: 6.401625\n",
            "[2810/3000] Train Acc: 0.968845 Loss: 0.090491 | Val Acc: 0.235887 loss: 6.154474\n",
            "[2811/3000] Train Acc: 0.967987 Loss: 0.089940 | Val Acc: 0.240323 loss: 5.847743\n",
            "[2812/3000] Train Acc: 0.961030 Loss: 0.111189 | Val Acc: 0.206452 loss: 6.607840\n",
            "[2813/3000] Train Acc: 0.967433 Loss: 0.093483 | Val Acc: 0.216734 loss: 6.642420\n",
            "[2814/3000] Train Acc: 0.964912 Loss: 0.101017 | Val Acc: 0.218548 loss: 6.375471\n",
            "[2815/3000] Train Acc: 0.962089 Loss: 0.109546 | Val Acc: 0.262903 loss: 5.721728\n",
            "[2816/3000] Train Acc: 0.965568 Loss: 0.099524 | Val Acc: 0.241129 loss: 6.042336\n",
            "[2817/3000] Train Acc: 0.967130 Loss: 0.095197 | Val Acc: 0.232056 loss: 5.953431\n",
            "[2818/3000] Train Acc: 0.965921 Loss: 0.099361 | Val Acc: 0.221774 loss: 6.275243\n",
            "[2819/3000] Train Acc: 0.968845 Loss: 0.088170 | Val Acc: 0.230645 loss: 6.344399\n",
            "[2820/3000] Train Acc: 0.967483 Loss: 0.090096 | Val Acc: 0.233468 loss: 6.289824\n",
            "[2821/3000] Train Acc: 0.965618 Loss: 0.096073 | Val Acc: 0.213710 loss: 6.679066\n",
            "[2822/3000] Train Acc: 0.957804 Loss: 0.122891 | Val Acc: 0.245968 loss: 6.122173\n",
            "[2823/3000] Train Acc: 0.966374 Loss: 0.096748 | Val Acc: 0.217339 loss: 6.628818\n",
            "[2824/3000] Train Acc: 0.967685 Loss: 0.092321 | Val Acc: 0.223589 loss: 6.483402\n",
            "[2825/3000] Train Acc: 0.964862 Loss: 0.099708 | Val Acc: 0.233468 loss: 6.236689\n",
            "[2826/3000] Train Acc: 0.964459 Loss: 0.100089 | Val Acc: 0.233065 loss: 6.312529\n",
            "[2827/3000] Train Acc: 0.966526 Loss: 0.092405 | Val Acc: 0.227419 loss: 6.536720\n",
            "[2828/3000] Train Acc: 0.965114 Loss: 0.098762 | Val Acc: 0.211492 loss: 6.664535\n",
            "[2829/3000] Train Acc: 0.968693 Loss: 0.090687 | Val Acc: 0.237903 loss: 6.170374\n",
            "[2830/3000] Train Acc: 0.962795 Loss: 0.104509 | Val Acc: 0.226411 loss: 6.436967\n",
            "[2831/3000] Train Acc: 0.960627 Loss: 0.115137 | Val Acc: 0.250806 loss: 5.791185\n",
            "[2832/3000] Train Acc: 0.963954 Loss: 0.102422 | Val Acc: 0.222782 loss: 6.579719\n",
            "[2833/3000] Train Acc: 0.966425 Loss: 0.092987 | Val Acc: 0.229839 loss: 6.072833\n",
            "[2834/3000] Train Acc: 0.967534 Loss: 0.089909 | Val Acc: 0.224395 loss: 6.365050\n",
            "[2835/3000] Train Acc: 0.967181 Loss: 0.093931 | Val Acc: 0.257863 loss: 5.896866\n",
            "[2836/3000] Train Acc: 0.963148 Loss: 0.100920 | Val Acc: 0.244556 loss: 6.085146\n",
            "[2837/3000] Train Acc: 0.966576 Loss: 0.097950 | Val Acc: 0.245565 loss: 6.175985\n",
            "[2838/3000] Train Acc: 0.970407 Loss: 0.085833 | Val Acc: 0.268750 loss: 5.520309\n",
            "[2839/3000] Train Acc: 0.963753 Loss: 0.100592 | Val Acc: 0.232661 loss: 6.291344\n",
            "[2840/3000] Train Acc: 0.965618 Loss: 0.099973 | Val Acc: 0.226411 loss: 6.263444\n",
            "[2841/3000] Train Acc: 0.963904 Loss: 0.096704 | Val Acc: 0.226613 loss: 6.298768\n",
            "[2842/3000] Train Acc: 0.966021 Loss: 0.096314 | Val Acc: 0.230242 loss: 6.282155\n",
            "[2843/3000] Train Acc: 0.965870 Loss: 0.102149 | Val Acc: 0.232460 loss: 6.301519\n",
            "[2844/3000] Train Acc: 0.967332 Loss: 0.093352 | Val Acc: 0.243750 loss: 5.879166\n",
            "[2845/3000] Train Acc: 0.965769 Loss: 0.097553 | Val Acc: 0.250202 loss: 5.950375\n",
            "[2846/3000] Train Acc: 0.965013 Loss: 0.097692 | Val Acc: 0.220363 loss: 6.495817\n",
            "[2847/3000] Train Acc: 0.964206 Loss: 0.100776 | Val Acc: 0.222581 loss: 6.337863\n",
            "[2848/3000] Train Acc: 0.966778 Loss: 0.096034 | Val Acc: 0.238508 loss: 6.095294\n",
            "[2849/3000] Train Acc: 0.968391 Loss: 0.091300 | Val Acc: 0.229637 loss: 6.351768\n",
            "[2850/3000] Train Acc: 0.968340 Loss: 0.089600 | Val Acc: 0.218548 loss: 6.554368\n",
            "[2851/3000] Train Acc: 0.961988 Loss: 0.102955 | Val Acc: 0.251613 loss: 5.869579\n",
            "[2852/3000] Train Acc: 0.963602 Loss: 0.104308 | Val Acc: 0.233065 loss: 6.046574\n",
            "[2853/3000] Train Acc: 0.962644 Loss: 0.100417 | Val Acc: 0.230040 loss: 6.504173\n",
            "[2854/3000] Train Acc: 0.967786 Loss: 0.093310 | Val Acc: 0.234073 loss: 6.216070\n",
            "[2855/3000] Train Acc: 0.966173 Loss: 0.097412 | Val Acc: 0.245363 loss: 5.943166\n",
            "[2856/3000] Train Acc: 0.962997 Loss: 0.100964 | Val Acc: 0.232863 loss: 6.259268\n",
            "[2857/3000] Train Acc: 0.964307 Loss: 0.105448 | Val Acc: 0.225605 loss: 6.430056\n",
            "[2858/3000] Train Acc: 0.961837 Loss: 0.111157 | Val Acc: 0.230242 loss: 6.088321\n",
            "[2859/3000] Train Acc: 0.969298 Loss: 0.087319 | Val Acc: 0.244355 loss: 6.268576\n",
            "[2860/3000] Train Acc: 0.965971 Loss: 0.099505 | Val Acc: 0.247581 loss: 5.797434\n",
            "[2861/3000] Train Acc: 0.967080 Loss: 0.095373 | Val Acc: 0.227218 loss: 6.328504\n",
            "[2862/3000] Train Acc: 0.966374 Loss: 0.096543 | Val Acc: 0.254234 loss: 5.569465\n",
            "[2863/3000] Train Acc: 0.968088 Loss: 0.090686 | Val Acc: 0.219355 loss: 6.553814\n",
            "[2864/3000] Train Acc: 0.965467 Loss: 0.098162 | Val Acc: 0.240323 loss: 5.912322\n",
            "[2865/3000] Train Acc: 0.965265 Loss: 0.095731 | Val Acc: 0.227016 loss: 6.395794\n",
            "[2866/3000] Train Acc: 0.964761 Loss: 0.101787 | Val Acc: 0.203427 loss: 6.896290\n",
            "[2867/3000] Train Acc: 0.965467 Loss: 0.097090 | Val Acc: 0.271371 loss: 5.595246\n",
            "[2868/3000] Train Acc: 0.966223 Loss: 0.096895 | Val Acc: 0.243347 loss: 6.105117\n",
            "[2869/3000] Train Acc: 0.962392 Loss: 0.110731 | Val Acc: 0.243952 loss: 5.942466\n",
            "[2870/3000] Train Acc: 0.970609 Loss: 0.084045 | Val Acc: 0.251210 loss: 5.949802\n",
            "[2871/3000] Train Acc: 0.969651 Loss: 0.088500 | Val Acc: 0.231653 loss: 6.239732\n",
            "[2872/3000] Train Acc: 0.966324 Loss: 0.097564 | Val Acc: 0.241532 loss: 6.035357\n",
            "[2873/3000] Train Acc: 0.960728 Loss: 0.113022 | Val Acc: 0.249798 loss: 5.795619\n",
            "[2874/3000] Train Acc: 0.964055 Loss: 0.103279 | Val Acc: 0.221169 loss: 6.488797\n",
            "[2875/3000] Train Acc: 0.966122 Loss: 0.095040 | Val Acc: 0.232056 loss: 6.331840\n",
            "[2876/3000] Train Acc: 0.968240 Loss: 0.090283 | Val Acc: 0.250605 loss: 6.077795\n",
            "[2877/3000] Train Acc: 0.964156 Loss: 0.097373 | Val Acc: 0.230040 loss: 6.461291\n",
            "[2878/3000] Train Acc: 0.966475 Loss: 0.091224 | Val Acc: 0.233065 loss: 6.340477\n",
            "[2879/3000] Train Acc: 0.964610 Loss: 0.100192 | Val Acc: 0.235282 loss: 6.452351\n",
            "[2880/3000] Train Acc: 0.962795 Loss: 0.104665 | Val Acc: 0.246169 loss: 5.845260\n",
            "[2881/3000] Train Acc: 0.966425 Loss: 0.095190 | Val Acc: 0.250202 loss: 6.134815\n",
            "[2882/3000] Train Acc: 0.969954 Loss: 0.085433 | Val Acc: 0.252419 loss: 5.904555\n",
            "[2883/3000] Train Acc: 0.966475 Loss: 0.097415 | Val Acc: 0.235282 loss: 6.357691\n",
            "[2884/3000] Train Acc: 0.965114 Loss: 0.100731 | Val Acc: 0.215121 loss: 6.744559\n",
            "[2885/3000] Train Acc: 0.963450 Loss: 0.101406 | Val Acc: 0.227016 loss: 6.626443\n",
            "[2886/3000] Train Acc: 0.966374 Loss: 0.095878 | Val Acc: 0.223185 loss: 6.876789\n",
            "[2887/3000] Train Acc: 0.966425 Loss: 0.097818 | Val Acc: 0.272782 loss: 5.500303\n",
            "saving model with acc 0.273\n",
            "[2888/3000] Train Acc: 0.966576 Loss: 0.093346 | Val Acc: 0.237500 loss: 6.152866\n",
            "[2889/3000] Train Acc: 0.965971 Loss: 0.097146 | Val Acc: 0.220766 loss: 6.693509\n",
            "[2890/3000] Train Acc: 0.969651 Loss: 0.086775 | Val Acc: 0.217137 loss: 6.533549\n",
            "[2891/3000] Train Acc: 0.966273 Loss: 0.097416 | Val Acc: 0.259677 loss: 6.022900\n",
            "[2892/3000] Train Acc: 0.965769 Loss: 0.093922 | Val Acc: 0.227823 loss: 6.635112\n",
            "[2893/3000] Train Acc: 0.965870 Loss: 0.095662 | Val Acc: 0.204435 loss: 7.058002\n",
            "[2894/3000] Train Acc: 0.965215 Loss: 0.101640 | Val Acc: 0.249194 loss: 5.911341\n",
            "[2895/3000] Train Acc: 0.964358 Loss: 0.101050 | Val Acc: 0.240524 loss: 6.389292\n",
            "[2896/3000] Train Acc: 0.966878 Loss: 0.094772 | Val Acc: 0.233065 loss: 6.255567\n",
            "[2897/3000] Train Acc: 0.967937 Loss: 0.092919 | Val Acc: 0.239516 loss: 6.247563\n",
            "[2898/3000] Train Acc: 0.965971 Loss: 0.096853 | Val Acc: 0.205444 loss: 6.644247\n",
            "[2899/3000] Train Acc: 0.965719 Loss: 0.097152 | Val Acc: 0.222581 loss: 6.503569\n",
            "[2900/3000] Train Acc: 0.969298 Loss: 0.091332 | Val Acc: 0.223185 loss: 6.713848\n",
            "[2901/3000] Train Acc: 0.963047 Loss: 0.106600 | Val Acc: 0.232258 loss: 6.426259\n",
            "[2902/3000] Train Acc: 0.967433 Loss: 0.091675 | Val Acc: 0.221976 loss: 6.447615\n",
            "[2903/3000] Train Acc: 0.968088 Loss: 0.091984 | Val Acc: 0.230040 loss: 6.192159\n",
            "[2904/3000] Train Acc: 0.966626 Loss: 0.100358 | Val Acc: 0.222379 loss: 6.620494\n",
            "[2905/3000] Train Acc: 0.968542 Loss: 0.089157 | Val Acc: 0.231653 loss: 6.394608\n",
            "[2906/3000] Train Acc: 0.965416 Loss: 0.098001 | Val Acc: 0.241734 loss: 5.971607\n",
            "[2907/3000] Train Acc: 0.959770 Loss: 0.113124 | Val Acc: 0.242944 loss: 5.955170\n",
            "[2908/3000] Train Acc: 0.967383 Loss: 0.092718 | Val Acc: 0.237702 loss: 6.206030\n",
            "[2909/3000] Train Acc: 0.969954 Loss: 0.086206 | Val Acc: 0.222782 loss: 6.418293\n",
            "[2910/3000] Train Acc: 0.965215 Loss: 0.102956 | Val Acc: 0.234476 loss: 6.328201\n",
            "[2911/3000] Train Acc: 0.971264 Loss: 0.084337 | Val Acc: 0.228226 loss: 6.398821\n",
            "[2912/3000] Train Acc: 0.970508 Loss: 0.086218 | Val Acc: 0.251815 loss: 6.005467\n",
            "[2913/3000] Train Acc: 0.970004 Loss: 0.087321 | Val Acc: 0.231452 loss: 6.430448\n",
            "[2914/3000] Train Acc: 0.966223 Loss: 0.095821 | Val Acc: 0.229637 loss: 6.452366\n",
            "[2915/3000] Train Acc: 0.959972 Loss: 0.112694 | Val Acc: 0.215121 loss: 6.518392\n",
            "[2916/3000] Train Acc: 0.964862 Loss: 0.096627 | Val Acc: 0.218347 loss: 6.479373\n",
            "[2917/3000] Train Acc: 0.963551 Loss: 0.099670 | Val Acc: 0.244153 loss: 6.098771\n",
            "[2918/3000] Train Acc: 0.967483 Loss: 0.090968 | Val Acc: 0.232056 loss: 6.496166\n",
            "[2919/3000] Train Acc: 0.966979 Loss: 0.095277 | Val Acc: 0.212903 loss: 6.668409\n",
            "[2920/3000] Train Acc: 0.965164 Loss: 0.097491 | Val Acc: 0.223387 loss: 6.590299\n",
            "[2921/3000] Train Acc: 0.965316 Loss: 0.100506 | Val Acc: 0.212702 loss: 7.018791\n",
            "[2922/3000] Train Acc: 0.961484 Loss: 0.111145 | Val Acc: 0.235887 loss: 6.315987\n",
            "[2923/3000] Train Acc: 0.967483 Loss: 0.091612 | Val Acc: 0.202218 loss: 6.944419\n",
            "[2924/3000] Train Acc: 0.967584 Loss: 0.091652 | Val Acc: 0.209476 loss: 6.979034\n",
            "[2925/3000] Train Acc: 0.963753 Loss: 0.099694 | Val Acc: 0.239113 loss: 6.185943\n",
            "[2926/3000] Train Acc: 0.969399 Loss: 0.084763 | Val Acc: 0.229032 loss: 6.437001\n",
            "[2927/3000] Train Acc: 0.970105 Loss: 0.086675 | Val Acc: 0.231452 loss: 6.302395\n",
            "[2928/3000] Train Acc: 0.970054 Loss: 0.085625 | Val Acc: 0.208266 loss: 6.654408\n",
            "[2929/3000] Train Acc: 0.959669 Loss: 0.108844 | Val Acc: 0.277621 loss: 5.536397\n",
            "saving model with acc 0.278\n",
            "[2930/3000] Train Acc: 0.965366 Loss: 0.099956 | Val Acc: 0.247984 loss: 6.086383\n",
            "[2931/3000] Train Acc: 0.967887 Loss: 0.094210 | Val Acc: 0.235282 loss: 6.477875\n",
            "[2932/3000] Train Acc: 0.971365 Loss: 0.084236 | Val Acc: 0.228226 loss: 6.537352\n",
            "[2933/3000] Train Acc: 0.965013 Loss: 0.100616 | Val Acc: 0.217742 loss: 6.618260\n",
            "[2934/3000] Train Acc: 0.970105 Loss: 0.086855 | Val Acc: 0.238306 loss: 6.174080\n",
            "[2935/3000] Train Acc: 0.967836 Loss: 0.089996 | Val Acc: 0.214516 loss: 6.965246\n",
            "[2936/3000] Train Acc: 0.966374 Loss: 0.094903 | Val Acc: 0.223185 loss: 6.409578\n",
            "[2937/3000] Train Acc: 0.967887 Loss: 0.091777 | Val Acc: 0.252218 loss: 6.166680\n",
            "[2938/3000] Train Acc: 0.968945 Loss: 0.087318 | Val Acc: 0.244153 loss: 6.204058\n",
            "[2939/3000] Train Acc: 0.962946 Loss: 0.106486 | Val Acc: 0.211089 loss: 6.855806\n",
            "[2940/3000] Train Acc: 0.965769 Loss: 0.096873 | Val Acc: 0.240121 loss: 6.348252\n",
            "[2941/3000] Train Acc: 0.967130 Loss: 0.092435 | Val Acc: 0.244556 loss: 6.247896\n",
            "[2942/3000] Train Acc: 0.967987 Loss: 0.090090 | Val Acc: 0.209274 loss: 6.924559\n",
            "[2943/3000] Train Acc: 0.965820 Loss: 0.096077 | Val Acc: 0.214718 loss: 6.982461\n",
            "[2944/3000] Train Acc: 0.966122 Loss: 0.098918 | Val Acc: 0.226613 loss: 6.711484\n",
            "[2945/3000] Train Acc: 0.966727 Loss: 0.093889 | Val Acc: 0.222177 loss: 6.317145\n",
            "[2946/3000] Train Acc: 0.968693 Loss: 0.090942 | Val Acc: 0.233871 loss: 6.511186\n",
            "[2947/3000] Train Acc: 0.964811 Loss: 0.099705 | Val Acc: 0.228024 loss: 6.235423\n",
            "[2948/3000] Train Acc: 0.966475 Loss: 0.093396 | Val Acc: 0.207460 loss: 6.793880\n",
            "[2949/3000] Train Acc: 0.962140 Loss: 0.108823 | Val Acc: 0.223589 loss: 6.233505\n",
            "[2950/3000] Train Acc: 0.959165 Loss: 0.115383 | Val Acc: 0.218145 loss: 6.766675\n",
            "[2951/3000] Train Acc: 0.968340 Loss: 0.089931 | Val Acc: 0.234073 loss: 6.332999\n",
            "[2952/3000] Train Acc: 0.970710 Loss: 0.084300 | Val Acc: 0.226210 loss: 6.404152\n",
            "[2953/3000] Train Acc: 0.967635 Loss: 0.090422 | Val Acc: 0.204435 loss: 7.346018\n",
            "[2954/3000] Train Acc: 0.966626 Loss: 0.093008 | Val Acc: 0.205444 loss: 6.807647\n",
            "[2955/3000] Train Acc: 0.964156 Loss: 0.097623 | Val Acc: 0.244355 loss: 6.128234\n",
            "[2956/3000] Train Acc: 0.968088 Loss: 0.092557 | Val Acc: 0.238911 loss: 6.215320\n",
            "[2957/3000] Train Acc: 0.967735 Loss: 0.088735 | Val Acc: 0.239516 loss: 6.195771\n",
            "[2958/3000] Train Acc: 0.969954 Loss: 0.087562 | Val Acc: 0.237500 loss: 6.215231\n",
            "[2959/3000] Train Acc: 0.967685 Loss: 0.090880 | Val Acc: 0.243347 loss: 6.167310\n",
            "[2960/3000] Train Acc: 0.968492 Loss: 0.090459 | Val Acc: 0.250202 loss: 6.117735\n",
            "[2961/3000] Train Acc: 0.970307 Loss: 0.082924 | Val Acc: 0.220161 loss: 6.681276\n",
            "[2962/3000] Train Acc: 0.967786 Loss: 0.090734 | Val Acc: 0.251815 loss: 6.028553\n",
            "[2963/3000] Train Acc: 0.972474 Loss: 0.079403 | Val Acc: 0.233871 loss: 6.573476\n",
            "[2964/3000] Train Acc: 0.965517 Loss: 0.099911 | Val Acc: 0.244355 loss: 6.277645\n",
            "[2965/3000] Train Acc: 0.963854 Loss: 0.103937 | Val Acc: 0.250000 loss: 6.169946\n",
            "[2966/3000] Train Acc: 0.967130 Loss: 0.094461 | Val Acc: 0.208669 loss: 7.147316\n",
            "[2967/3000] Train Acc: 0.964811 Loss: 0.100034 | Val Acc: 0.238105 loss: 6.351115\n",
            "[2968/3000] Train Acc: 0.970659 Loss: 0.084891 | Val Acc: 0.221976 loss: 6.690542\n",
            "[2969/3000] Train Acc: 0.967987 Loss: 0.087351 | Val Acc: 0.238911 loss: 6.520976\n",
            "[2970/3000] Train Acc: 0.969500 Loss: 0.087985 | Val Acc: 0.223992 loss: 6.835822\n",
            "[2971/3000] Train Acc: 0.969500 Loss: 0.084135 | Val Acc: 0.231452 loss: 6.666794\n",
            "[2972/3000] Train Acc: 0.966576 Loss: 0.094782 | Val Acc: 0.211492 loss: 6.800153\n",
            "[2973/3000] Train Acc: 0.963501 Loss: 0.098168 | Val Acc: 0.247581 loss: 6.100406\n",
            "[2974/3000] Train Acc: 0.970105 Loss: 0.085723 | Val Acc: 0.249194 loss: 6.192372\n",
            "[2975/3000] Train Acc: 0.968038 Loss: 0.090489 | Val Acc: 0.204435 loss: 7.150804\n",
            "[2976/3000] Train Acc: 0.966122 Loss: 0.096615 | Val Acc: 0.198387 loss: 7.111620\n",
            "[2977/3000] Train Acc: 0.960879 Loss: 0.111554 | Val Acc: 0.221774 loss: 6.793461\n",
            "[2978/3000] Train Acc: 0.967433 Loss: 0.093364 | Val Acc: 0.255444 loss: 6.057348\n",
            "[2979/3000] Train Acc: 0.968794 Loss: 0.086440 | Val Acc: 0.250605 loss: 6.133560\n",
            "[2980/3000] Train Acc: 0.965215 Loss: 0.097268 | Val Acc: 0.216935 loss: 6.812692\n",
            "[2981/3000] Train Acc: 0.968240 Loss: 0.087575 | Val Acc: 0.262298 loss: 6.019522\n",
            "[2982/3000] Train Acc: 0.967937 Loss: 0.092955 | Val Acc: 0.232863 loss: 6.513926\n",
            "[2983/3000] Train Acc: 0.969702 Loss: 0.085359 | Val Acc: 0.252621 loss: 6.233980\n",
            "[2984/3000] Train Acc: 0.970508 Loss: 0.082418 | Val Acc: 0.241935 loss: 6.534184\n",
            "[2985/3000] Train Acc: 0.972827 Loss: 0.079514 | Val Acc: 0.255444 loss: 6.235073\n",
            "[2986/3000] Train Acc: 0.970407 Loss: 0.083489 | Val Acc: 0.218548 loss: 6.874433\n",
            "[2987/3000] Train Acc: 0.966979 Loss: 0.094630 | Val Acc: 0.207661 loss: 7.095743\n",
            "[2988/3000] Train Acc: 0.963148 Loss: 0.099372 | Val Acc: 0.231048 loss: 6.533555\n",
            "[2989/3000] Train Acc: 0.969298 Loss: 0.085426 | Val Acc: 0.235484 loss: 6.825732\n",
            "[2990/3000] Train Acc: 0.960728 Loss: 0.109742 | Val Acc: 0.250806 loss: 6.326282\n",
            "[2991/3000] Train Acc: 0.965215 Loss: 0.099078 | Val Acc: 0.205847 loss: 7.153301\n",
            "[2992/3000] Train Acc: 0.968441 Loss: 0.086400 | Val Acc: 0.229435 loss: 6.512721\n",
            "[2993/3000] Train Acc: 0.969097 Loss: 0.087897 | Val Acc: 0.226613 loss: 6.756474\n",
            "[2994/3000] Train Acc: 0.968441 Loss: 0.090583 | Val Acc: 0.221774 loss: 6.900858\n",
            "[2995/3000] Train Acc: 0.966828 Loss: 0.092823 | Val Acc: 0.242742 loss: 6.216467\n",
            "[2996/3000] Train Acc: 0.967080 Loss: 0.096389 | Val Acc: 0.225605 loss: 6.593963\n",
            "[2997/3000] Train Acc: 0.966929 Loss: 0.090907 | Val Acc: 0.245363 loss: 6.230551\n",
            "[2998/3000] Train Acc: 0.969550 Loss: 0.086257 | Val Acc: 0.239516 loss: 6.501455\n",
            "[2999/3000] Train Acc: 0.966425 Loss: 0.096907 | Val Acc: 0.238508 loss: 6.461911\n",
            "[3000/3000] Train Acc: 0.968340 Loss: 0.088881 | Val Acc: 0.235282 loss: 6.579357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training use {round(end_time - start_time, 3)}s')"
      ],
      "metadata": {
        "id": "NLnpYLpwYlop",
        "outputId": "0f904ad6-be86-4fef-ce02-2df299b82683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training use 2951.117s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create testing dataset\n",
        "test_set = IBMDataset(X_test.values, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# create model and load weights from checkpoint\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "id": "lukrC4MJWTjM",
        "outputId": "f9a67e25-b5a9-4c01-8e78-d73387e6a67a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = []\n",
        "model.eval() # set the model to evaluation mode\n",
        "for i, data in enumerate(test_loader):\n",
        "    inputs = data\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "    for y in test_pred.cpu().numpy():\n",
        "        predict.append(y)"
      ],
      "metadata": {
        "id": "OlQ1d1fdVt_V"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_result = './dnn_result.csv'\n",
        "\n",
        "new_encoder_map = {'No Churn':0, 'Competitor': 1, 'Dissatisfaction':2, 'Attitude': 3, 'Price':4, 'Other':5}\n",
        "\n",
        "with open(submit_result, 'w') as f:\n",
        "    f.write('Customer ID,Churn Category\\n')\n",
        "    for i in range(len(df_test.values)):\n",
        "        id = str(df_test.values[i]).replace('[\\'', '')\n",
        "        id = id.replace('\\']', '')\n",
        "        pred = new_encoder_map.get(list(encoder_map.keys())[list(encoder_map.values()).index(predict[i])])\n",
        "        f.write(f'{id},{pred}\\n')"
      ],
      "metadata": {
        "id": "11ImkbPjn6qP"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(submit_result)"
      ],
      "metadata": {
        "id": "YICyBRaGo43O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}