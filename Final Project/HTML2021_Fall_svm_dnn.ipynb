{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTML2021_Fall.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Offliners/HTML_2021Fall/blob/main/Final%20Project/HTML2021_Fall_svm_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Directory**\n",
        "\n",
        "```\n",
        "data_dir\n",
        "    ├── data\n",
        "    │   ├── Test_IDs.csv\n",
        "    │   ├── ...\n",
        "    │   ├── status.csv\n",
        "    ├── statistics\n",
        "    │   ├── Churn Category_stat.png\n",
        "    │   ├── ...\n",
        "    │   ├── miss rate_stat.png\n",
        "```"
      ],
      "metadata": {
        "id": "PD40tT3p379e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Display information of GPU**"
      ],
      "metadata": {
        "id": "ldW8_oif3EEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf0PLuNJf95W",
        "outputId": "ad7b4651-8dd6-424f-e8e7-8615e4e1a645"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 12 15:05:55 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Download Dataset**"
      ],
      "metadata": {
        "id": "JxUhMWWmJPHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"./data\"\n",
        "!mkdir \"./statistics\"\n",
        "!gdown --id 1X5yz7QLAu4nttnCea4ALf6alae6Clv_o --output \"./data/dataset.zip\"\n",
        "!unzip -q \"./data/dataset.zip\" -d \"./data\"\n",
        "!rm \"./data/dataset.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjX-fvNeKG3p",
        "outputId": "6546302d-8a93-45bb-ea6b-194eb451dfe6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1X5yz7QLAu4nttnCea4ALf6alae6Clv_o\n",
            "To: /content/data/dataset.zip\n",
            "\r  0% 0.00/660k [00:00<?, ?B/s]\r100% 660k/660k [00:00<00:00, 24.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Some Packages**"
      ],
      "metadata": {
        "id": "hosMVZZWI_6B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-lrHo2qeI-p9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set a Random Seed**"
      ],
      "metadata": {
        "id": "HH36XbKB0P3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for reproducibility\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  \n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "sM7IyXfL0ekd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CSV Files Combination**"
      ],
      "metadata": {
        "id": "Q69ecrSlJpyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = './data/Train_IDs.csv'  # path to training data\n",
        "test_path = './data/Test_IDs.csv'    # path to testing data\n",
        "\n",
        "files = glob('./data/*.csv')\n",
        "data_csv = []\n",
        "data_csv.append(train_path)\n",
        "for csv in files:\n",
        "    if ('IDs' not in csv) and ('sample' not in csv) and ('population' not in csv) and ('result' not in csv):\n",
        "        data_csv.append(csv)\n",
        "  \n",
        "print(data_csv)\n",
        "df_list = [pd.read_csv(file) for file in data_csv]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PubV0z-fNFWK",
        "outputId": "5818a875-f1d7-4d1d-8ea6-1a9e56a3d80e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./data/Train_IDs.csv', './data/services.csv', './data/status.csv', './data/satisfaction.csv', './data/demographics.csv', './data/location.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_total = df_list[0]\n",
        "for df in df_list[1:]:\n",
        "    result_total = pd.merge(result_total, df, how='outer', on='Customer ID')\n",
        "\n",
        "result_total.to_csv('./data/result_total.csv') # Save combined all result to result_total.csv"
      ],
      "metadata": {
        "id": "gsRnzcD243J2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 7043 total customer data\n",
        "print(result_total)"
      ],
      "metadata": {
        "id": "HmdXTPLLuLnc",
        "outputId": "41716437-1954-4e64-afd3-9ed66cbde1b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Count_x  ...   Latitude   Longitude\n",
            "0     0650-BWOZN      1.0  ...        NaN         NaN\n",
            "1     0562-FGDCR      1.0  ...  34.903052 -118.411251\n",
            "2     6688-UZPWD      1.0  ...  33.721917 -118.043237\n",
            "3     2905-KFQUV      1.0  ...        NaN -122.000887\n",
            "4     9720-JJJOR      1.0  ...  39.672813 -120.456699\n",
            "...          ...      ...  ...        ...         ...\n",
            "7038  6485-QXWWE      NaN  ...        NaN -118.149953\n",
            "7039  9408-SSNVZ      NaN  ...  33.818477 -118.038307\n",
            "7040  3426-NIYYL      NaN  ...        NaN         NaN\n",
            "7041  8231-BSWXX      NaN  ...  34.097863 -116.594561\n",
            "7042  4482-EWFMI      NaN  ...        NaN -120.132870\n",
            "\n",
            "[7043 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train_IDs has 5634 customer data\n",
        "result_train = df_list[0]\n",
        "for df in df_list[1:]:\n",
        "    result_train = pd.merge(result_train, df, how='left', on='Customer ID')\n",
        "\n",
        "print(result_train)"
      ],
      "metadata": {
        "id": "XC9OTia4vQyw",
        "outputId": "7e2dda51-0279-4fd1-80fd-ed25f36c6054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Count_x  ...   Latitude   Longitude\n",
            "0     0650-BWOZN      1.0  ...        NaN         NaN\n",
            "1     0562-FGDCR      1.0  ...  34.903052 -118.411251\n",
            "2     6688-UZPWD      1.0  ...  33.721917 -118.043237\n",
            "3     2905-KFQUV      1.0  ...        NaN -122.000887\n",
            "4     9720-JJJOR      1.0  ...  39.672813 -120.456699\n",
            "...          ...      ...  ...        ...         ...\n",
            "5629  1178-PZGAB      1.0  ...        NaN         NaN\n",
            "5630  4806-KEXQR      1.0  ...  37.140104 -119.657092\n",
            "5631  8809-RIHDD      1.0  ...        NaN         NaN\n",
            "5632  6663-JOCQO      1.0  ...        NaN         NaN\n",
            "5633  7010-ZMVBF      1.0  ...  36.623632 -119.741322\n",
            "\n",
            "[5634 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test_Ids has 1409 customer data\n",
        "df_test = pd.read_csv(test_path)\n",
        "result_test = df_test\n",
        "for df in df_list[1:]:\n",
        "    result_test = pd.merge(result_test, df, how='left', on='Customer ID')\n",
        "\n",
        "print(result_test)"
      ],
      "metadata": {
        "id": "fE-wQXgit9JQ",
        "outputId": "0243f579-7d7d-4a37-855a-0c79efb1ebd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Count_x  ...   Latitude   Longitude\n",
            "0     9938-EKRGF      1.0  ...  33.141265 -116.967221\n",
            "1     7379-POKDZ      1.0  ...  34.231318 -117.662032\n",
            "2     0654-HMSHN      1.0  ...  32.802959 -117.027095\n",
            "3     2045-BMBTJ      1.0  ...        NaN         NaN\n",
            "4     0701-TJSEF      1.0  ...  33.581045 -117.147190\n",
            "...          ...      ...  ...        ...         ...\n",
            "1404  4587-VVTOX      1.0  ...  37.871416         NaN\n",
            "1405  7716-YTYHG      NaN  ...  40.448632         NaN\n",
            "1406  7649-PHJVR      NaN  ...        NaN         NaN\n",
            "1407  7855-DIWPO      1.0  ...  33.688546         NaN\n",
            "1408  8197-BFWVU      1.0  ...  33.956445 -118.358634\n",
            "\n",
            "[1409 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_total.dropna()) # Find customer with full data infomation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wbcLdCPLMBV",
        "outputId": "7db21cdf-b6ea-4781-e674-5be54cc257c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Count_x  ...   Latitude   Longitude\n",
            "666   0454-OKRCT      1.0  ...  38.425280 -119.475741\n",
            "678   1735-XMJVH      1.0  ...  38.809175 -121.171375\n",
            "1799  1245-HARPS      1.0  ...  40.587919 -122.464732\n",
            "2805  8445-DNBAE      1.0  ...  41.212695 -122.392067\n",
            "2883  8708-XPXHZ      1.0  ...  40.342928 -124.063329\n",
            "3062  9522-ZSINC      1.0  ...  34.128284 -118.047732\n",
            "4297  0836-SEYLU      1.0  ...  36.414611 -121.638600\n",
            "5146  7274-RTAPZ      1.0  ...  36.657462 -119.595293\n",
            "\n",
            "[8 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_cols = result_total.columns\n",
        "print(result_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h42U-NQJkntr",
        "outputId": "8699b46b-986d-49d0-e59a-2b714b90d3fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Customer ID', 'Count_x', 'Quarter', 'Referred a Friend',\n",
            "       'Number of Referrals', 'Tenure in Months', 'Offer', 'Phone Service',\n",
            "       'Avg Monthly Long Distance Charges', 'Multiple Lines',\n",
            "       'Internet Service', 'Internet Type', 'Avg Monthly GB Download',\n",
            "       'Online Security', 'Online Backup', 'Device Protection Plan',\n",
            "       'Premium Tech Support', 'Streaming TV', 'Streaming Movies',\n",
            "       'Streaming Music', 'Unlimited Data', 'Contract', 'Paperless Billing',\n",
            "       'Payment Method', 'Monthly Charge', 'Total Charges', 'Total Refunds',\n",
            "       'Total Extra Data Charges', 'Total Long Distance Charges',\n",
            "       'Total Revenue', 'Churn Category', 'Satisfaction Score', 'Count_y',\n",
            "       'Gender', 'Age', 'Under 30', 'Senior Citizen', 'Married', 'Dependents',\n",
            "       'Number of Dependents', 'Count', 'Country', 'State', 'City', 'Zip Code',\n",
            "       'Lat Long', 'Latitude', 'Longitude'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing = result_train.isnull().sum().reset_index().rename(columns={0:'missNum'})\n",
        "missing['missRate'] = missing['missNum'] / result_train.shape[0]\n",
        "miss_analy = missing[missing.missRate > 0].sort_values(by='missRate', ascending=False)\n",
        "\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "plt.bar(np.arange(miss_analy.shape[0]), list(miss_analy.missRate.values), align='center')\n",
        "\n",
        "plt.title('Histogram of missing value of variables of training dataset')\n",
        "plt.xlabel('variables names')\n",
        "plt.ylabel('missing rate')\n",
        "plt.xticks(np.arange(miss_analy.shape[0]), list(miss_analy['index']))\n",
        "plt.xticks(rotation=90)\n",
        "for x, y in enumerate(list(miss_analy.missRate.values)):\n",
        "    plt.text(x, y + 0.12, '{:.2%}'.format(y), ha='center', rotation=90)    \n",
        "\n",
        "plt.ylim([0, 1.2])  \n",
        "plt.savefig(f'./statistics/miss rate_train_stat.png')  \n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "HDjocf2IYbFs",
        "outputId": "192ddf97-bbfb-4abf-e855-5fc42b012668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing = result_test.isnull().sum().reset_index().rename(columns={0:'missNum'})\n",
        "missing['missRate'] = missing['missNum'] / result_test.shape[0]\n",
        "miss_analy = missing[missing.missRate > 0].sort_values(by='missRate', ascending=False)\n",
        "\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "plt.bar(np.arange(miss_analy.shape[0]), list(miss_analy.missRate.values), align='center')\n",
        "\n",
        "plt.title('Histogram of missing value of variables of test dataset')\n",
        "plt.xlabel('variables names')\n",
        "plt.ylabel('missing rate')\n",
        "plt.xticks(np.arange(miss_analy.shape[0]), list(miss_analy['index']))\n",
        "plt.xticks(rotation=90)\n",
        "for x, y in enumerate(list(miss_analy.missRate.values)):\n",
        "    plt.text(x, y + 0.12, '{:.2%}'.format(y), ha='center', rotation=90)    \n",
        "\n",
        "plt.ylim([0, 1.4])  \n",
        "plt.savefig(f'./statistics/miss rate_test_stat.png')  \n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "BVN8BclJkD1J",
        "outputId": "f6b6a80c-e913-4c22-a007-3baec230a3bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Statistics and Data Preprocessing**"
      ],
      "metadata": {
        "id": "eYyJOoclqCFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_train_copy = result_train.copy(deep=True)\n",
        "result_test_copy = result_test.copy(deep=True)\n",
        "def label_statistics(label):\n",
        "    freq = result_train.groupby(label).size() \n",
        "\n",
        "    names = [name for name, _ in freq.items()]\n",
        "    counts = [count for _, count in freq.items()]\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    x = np.arange(len(names))\n",
        "    plt.bar(x, counts)\n",
        "    plt.xticks(x, names, rotation=15)\n",
        "    plt.title(f'Statistics of {label}')\n",
        "    plt.savefig(f'./statistics/Statistics of {label}.png')\n",
        "    print(f'Statistics of {label}.png saved')\n",
        "    plt.close()\n",
        "\n",
        "    # Replace NaN with random choice label with the original distribution\n",
        "    probability = [p / np.sum(counts) for p in counts]\n",
        "    result_train_copy[label] = result_train_copy[label].apply(lambda x: np.random.choice(names, p=probability) if pd.isnull(x) else x)\n",
        "    result_test_copy[label] = result_test_copy[label].apply(lambda x: np.random.choice(names, p=probability) if pd.isnull(x) else x)"
      ],
      "metadata": {
        "id": "ho-LNzp4g_Eb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "need_statistics_col = ['Churn Category', 'Satisfaction Score', \n",
        "       'Gender', 'Under 30', 'Senior Citizen', 'Married', 'Dependents',\n",
        "       'Number of Dependents', 'Country', 'State', 'City', 'Quarter',\n",
        "       'Referred a Friend', 'Number of Referrals', 'Offer',\n",
        "       'Phone Service', 'Multiple Lines', 'Internet Service', 'Internet Type',\n",
        "       'Online Security', 'Online Backup', 'Device Protection Plan',\n",
        "       'Premium Tech Support', 'Streaming TV', 'Streaming Movies',\n",
        "       'Streaming Music', 'Unlimited Data', 'Contract', 'Paperless Billing',\n",
        "       'Payment Method']\n",
        "\n",
        "# Replace NaN with the most frequent label\n",
        "for need_col in need_statistics_col:\n",
        "    label_statistics(need_col)\n",
        "\n",
        "    # Encode target labels with value\n",
        "    le = LabelEncoder()\n",
        "    result_train_copy[need_col] = le.fit_transform(result_train_copy[need_col])\n",
        "    result_test_copy[need_col] = le.fit_transform(result_test_copy[need_col])\n",
        "\n",
        "    if need_col == 'Churn Category':\n",
        "        encoder_map = dict(zip(le.classes_, le.transform(le.classes_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl4omt-mIGDW",
        "outputId": "68ccdef3-0e50-444c-e505-573a1ef348fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics of Churn Category.png saved\n",
            "Statistics of Satisfaction Score.png saved\n",
            "Statistics of Gender.png saved\n",
            "Statistics of Under 30.png saved\n",
            "Statistics of Senior Citizen.png saved\n",
            "Statistics of Married.png saved\n",
            "Statistics of Dependents.png saved\n",
            "Statistics of Number of Dependents.png saved\n",
            "Statistics of Country.png saved\n",
            "Statistics of State.png saved\n",
            "Statistics of City.png saved\n",
            "Statistics of Quarter.png saved\n",
            "Statistics of Referred a Friend.png saved\n",
            "Statistics of Number of Referrals.png saved\n",
            "Statistics of Offer.png saved\n",
            "Statistics of Phone Service.png saved\n",
            "Statistics of Multiple Lines.png saved\n",
            "Statistics of Internet Service.png saved\n",
            "Statistics of Internet Type.png saved\n",
            "Statistics of Online Security.png saved\n",
            "Statistics of Online Backup.png saved\n",
            "Statistics of Device Protection Plan.png saved\n",
            "Statistics of Premium Tech Support.png saved\n",
            "Statistics of Streaming TV.png saved\n",
            "Statistics of Streaming Movies.png saved\n",
            "Statistics of Streaming Music.png saved\n",
            "Statistics of Unlimited Data.png saved\n",
            "Statistics of Contract.png saved\n",
            "Statistics of Paperless Billing.png saved\n",
            "Statistics of Payment Method.png saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "need_avg_col = [item for item in result_cols if item not in need_statistics_col]\n",
        "\n",
        "# Replace NaN with median value or 0\n",
        "for avg_col in need_avg_col[1:]:\n",
        "    if avg_col == 'Zip Code' or avg_col == 'Lat Long':\n",
        "        continue\n",
        "    elif 'Count' in avg_col:\n",
        "        result_train_copy[avg_col] = result_train_copy[avg_col].fillna(0)\n",
        "        result_test_copy[avg_col] = result_test_copy[avg_col].fillna(0)\n",
        "    else:\n",
        "        result_train_copy[avg_col] = result_train_copy[avg_col].fillna(result_train_copy[avg_col].median()) \n",
        "        result_test_copy[avg_col] = result_test_copy[avg_col].fillna(result_train_copy[avg_col].median())"
      ],
      "metadata": {
        "id": "hjvCj4CgJPoJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the correlation of columns\n",
        "cor_matrix = result_train_copy.corr().abs()\n",
        "print(cor_matrix['Churn Category'])"
      ],
      "metadata": {
        "id": "WdnuvMdMS7_L",
        "outputId": "030cd38e-7b28-4521-83c8-1d323710af09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count_x                              0.001317\n",
            "Quarter                                   NaN\n",
            "Referred a Friend                    0.039161\n",
            "Number of Referrals                  0.081623\n",
            "Tenure in Months                     0.124967\n",
            "Offer                                0.064084\n",
            "Phone Service                        0.007903\n",
            "Avg Monthly Long Distance Charges    0.012097\n",
            "Multiple Lines                       0.025724\n",
            "Internet Service                     0.093695\n",
            "Internet Type                        0.041499\n",
            "Avg Monthly GB Download              0.040774\n",
            "Online Security                      0.057228\n",
            "Online Backup                        0.013486\n",
            "Device Protection Plan               0.003886\n",
            "Premium Tech Support                 0.065226\n",
            "Streaming TV                         0.011442\n",
            "Streaming Movies                     0.038226\n",
            "Streaming Music                      0.020193\n",
            "Unlimited Data                       0.069493\n",
            "Contract                             0.137617\n",
            "Paperless Billing                    0.078954\n",
            "Payment Method                       0.035229\n",
            "Monthly Charge                       0.092739\n",
            "Total Charges                        0.058857\n",
            "Total Refunds                        0.014575\n",
            "Total Extra Data Charges             0.015636\n",
            "Total Long Distance Charges          0.092469\n",
            "Total Revenue                        0.080331\n",
            "Churn Category                       1.000000\n",
            "Satisfaction Score                   0.254697\n",
            "Count_y                              0.040754\n",
            "Gender                               0.001889\n",
            "Age                                  0.046805\n",
            "Under 30                             0.024823\n",
            "Senior Citizen                       0.059089\n",
            "Married                              0.018871\n",
            "Dependents                           0.074275\n",
            "Number of Dependents                 0.053742\n",
            "Count                                0.024353\n",
            "Country                                   NaN\n",
            "State                                     NaN\n",
            "City                                 0.001694\n",
            "Zip Code                             0.016380\n",
            "Latitude                             0.050255\n",
            "Longitude                            0.029237\n",
            "Name: Churn Category, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dropColumns(label):\n",
        "    global result_train_copy, result_test_copy\n",
        "    result_train_copy = result_train_copy.drop(label, axis=1)\n",
        "    result_test_copy = result_test_copy.drop(label, axis=1)"
      ],
      "metadata": {
        "id": "K5quNy8vHQzb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Throw away the data columns I think is useless\n",
        "useless = ['Count_x', 'Count_y', 'Country', 'State', 'City', 'Zip Code', 'Lat Long', 'Latitude', 'Longitude', 'Count', 'Quarter']\n",
        "\n",
        "for item in useless:\n",
        "    dropColumns(item)"
      ],
      "metadata": {
        "id": "Cis3gTDOG9Im"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_train_copy.to_csv('./data/result_after_preprocessing.csv') # Save after preprocessing result to result_after_preprocessing.csv\n",
        "\n",
        "print(result_train_copy)\n",
        "print(result_test_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DsDpzq_Lgp3",
        "outputId": "aeca00fb-fa20-4c78-9cdd-55ce209653a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Customer ID  Referred a Friend  ...  Dependents  Number of Dependents\n",
            "0     0650-BWOZN                  0  ...           0                     0\n",
            "1     0562-FGDCR                  0  ...           0                     0\n",
            "2     6688-UZPWD                  1  ...           1                     0\n",
            "3     2905-KFQUV                  0  ...           0                     0\n",
            "4     9720-JJJOR                  1  ...           0                     0\n",
            "...          ...                ...  ...         ...                   ...\n",
            "5629  1178-PZGAB                  0  ...           0                     0\n",
            "5630  4806-KEXQR                  0  ...           0                     0\n",
            "5631  8809-RIHDD                  0  ...           1                     2\n",
            "5632  6663-JOCQO                  0  ...           1                     3\n",
            "5633  7010-ZMVBF                  1  ...           0                     0\n",
            "\n",
            "[5634 rows x 37 columns]\n",
            "     Customer ID  Referred a Friend  ...  Dependents  Number of Dependents\n",
            "0     9938-EKRGF                  1  ...           0                     0\n",
            "1     7379-POKDZ                  0  ...           0                     0\n",
            "2     0654-HMSHN                  1  ...           0                     0\n",
            "3     2045-BMBTJ                  1  ...           1                     3\n",
            "4     0701-TJSEF                  1  ...           0                     0\n",
            "...          ...                ...  ...         ...                   ...\n",
            "1404  4587-VVTOX                  0  ...           0                     0\n",
            "1405  7716-YTYHG                  1  ...           0                     0\n",
            "1406  7649-PHJVR                  0  ...           0                     0\n",
            "1407  7855-DIWPO                  1  ...           0                     3\n",
            "1408  8197-BFWVU                  0  ...           0                     0\n",
            "\n",
            "[1409 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Balance Data**"
      ],
      "metadata": {
        "id": "bPTqADO2Ox2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = result_train_copy['Churn Category'].values\n",
        "X_train = result_train_copy.drop('Customer ID', axis=1)\n",
        "X_train = X_train.drop('Churn Category', axis=1)"
      ],
      "metadata": {
        "id": "RiyIrSnaNq6F"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"normal data distribution: {Counter(y_train)}\")\n",
        "\n",
        "smo = ADASYN(random_state=seed)\n",
        "X_train, y_train = smo.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"SMOTE data distribution: {Counter(y_train)}\")"
      ],
      "metadata": {
        "id": "LmlxI28WQUG2",
        "outputId": "691d1b48-7b15-4558-a186-d4a7501bf745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal data distribution: Counter({3: 4133, 1: 662, 0: 271, 2: 222, 4: 175, 5: 171})\n",
            "SMOTE data distribution: Counter({5: 4185, 2: 4172, 3: 4133, 4: 4132, 1: 4120, 0: 4054})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM Train**"
      ],
      "metadata": {
        "id": "3HpyuY-RQEz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "ss = StandardScaler().fit(X_train)\n",
        "X_train_std = ss.transform(X_train)\n",
        "mms = MinMaxScaler(feature_range=(0, 1)).fit(X_train_std)\n",
        "X_train_std = mms.transform(X_train_std)"
      ],
      "metadata": {
        "id": "euCLdtvkO-nO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf', gamma=0.7, C=10, decision_function_shape='ovr')\n",
        "\n",
        "# SVM with class weight\n",
        "# svm = SVC(kernel='rbf', gamma=0.7, class_weight={0:10, 1:10, 2:10, 3:1, 4:10, 5:10})\n",
        "\n",
        "start_time = time.time()\n",
        "model = svm.fit(X_train_std, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f'Training use {round(end_time - start_time, 3)}s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXuL_lKqW_mD",
        "outputId": "2b56fdd8-2677-4039-a6a0-92cc9512c6e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training use 45.404s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_predict = svm.predict(X_train_std)\n",
        "Ein = np.mean(np.array(y_train_predict) != y_train)\n",
        "F1in = metrics.f1_score(y_train, y_train_predict, average='macro')  \n",
        "print(f'Ein = {round(Ein, 5)}')\n",
        "print(f'F1_in = {round(F1in, 5)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WivcNevbY1lB",
        "outputId": "a2ea1981-c516-4437-9135-547ec7d038af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ein = 0.01391\n",
            "F1_in = 0.98606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model, X_train_std, y_train)\n",
        "print(encoder_map)"
      ],
      "metadata": {
        "id": "yWM9fKw1MLr1",
        "outputId": "38448368-29bc-4566-abe8-1d7089d4883a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Attitude': 0, 'Competitor': 1, 'Dissatisfaction': 2, 'No Churn': 3, 'Other': 4, 'Price': 5}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_train_predict))"
      ],
      "metadata": {
        "id": "LMiWePsbSW4Y",
        "outputId": "f4d24438-550e-4322-ac7b-1902549144f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      4054\n",
            "           1       0.99      0.96      0.98      4120\n",
            "           2       0.98      0.99      0.98      4172\n",
            "           3       1.00      1.00      1.00      4133\n",
            "           4       0.99      0.99      0.99      4132\n",
            "           5       0.98      0.99      0.99      4185\n",
            "\n",
            "    accuracy                           0.99     24796\n",
            "   macro avg       0.99      0.99      0.99     24796\n",
            "weighted avg       0.99      0.99      0.99     24796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM Test**"
      ],
      "metadata": {
        "id": "ViqMiLyMavbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = result_test_copy.drop('Customer ID', axis=1)\n",
        "X_test = X_test.drop('Churn Category', axis=1)\n",
        "ss = StandardScaler().fit(X_test)\n",
        "X_test_std = ss.transform(X_test)\n",
        "mms = MinMaxScaler(feature_range=(0, 1)).fit(X_test_std)\n",
        "X_test_std = mms.transform(X_test_std)\n",
        "y_test = svm.predict(X_test_std)"
      ],
      "metadata": {
        "id": "dxd93_hUauU5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model, X_test_std, y_test)\n",
        "print(encoder_map)"
      ],
      "metadata": {
        "id": "098w16TfMkqn",
        "outputId": "b6d678e6-915c-4c40-bda7-895f91b722e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Attitude': 0, 'Competitor': 1, 'Dissatisfaction': 2, 'No Churn': 3, 'Other': 4, 'Price': 5}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit_result = './svm_result.csv'\n",
        "\n",
        "new_encoder_map = {'No Churn':0, 'Competitor': 1, 'Dissatisfaction':2, 'Attitude': 3, 'Price':4, 'Other':5}\n",
        "\n",
        "with open(submit_result, 'w') as f:\n",
        "    f.write('Customer ID,Churn Category\\n')\n",
        "    for i in range(len(df_test.values)):\n",
        "        id = str(df_test.values[i]).replace('[\\'', '')\n",
        "        id = id.replace('\\']', '')\n",
        "        pred = new_encoder_map.get(list(encoder_map.keys())[list(encoder_map.values()).index(y_test[i])])\n",
        "        f.write(f'{id},{pred}\\n')"
      ],
      "metadata": {
        "id": "6N35sOjrcpNd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(submit_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0tLUThI7nWnj",
        "outputId": "7a78d6da-077b-4cef-c445-6ded2577362e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9a7e7e2c-6968-4c5e-ab33-23085be81904\", \"svm_result.csv\", 18344)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Neural Network Train**"
      ],
      "metadata": {
        "id": "ZFjmDSVGQPwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IBMDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(np.int)\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "G5F9W_RkSub3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(35, 512)\n",
        "        self.layer2 = nn.Linear(512, 256)\n",
        "        self.layer3 = nn.Linear(256, 128)\n",
        "        self.out = nn.Linear(128, 6) \n",
        "        self.act_fn = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "classifier = Classifier()\n",
        "summary(classifier, X_train.shape, device=\"cpu\")"
      ],
      "metadata": {
        "id": "K_ofbzUUQdOX",
        "outputId": "79c99a15-73b0-44d8-86fb-eacb8c716b66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1           [-1, 24796, 512]          18,432\n",
            "           Sigmoid-2           [-1, 24796, 512]               0\n",
            "            Linear-3           [-1, 24796, 256]         131,328\n",
            "           Sigmoid-4           [-1, 24796, 256]               0\n",
            "            Linear-5           [-1, 24796, 128]          32,896\n",
            "           Sigmoid-6           [-1, 24796, 128]               0\n",
            "            Linear-7             [-1, 24796, 6]             774\n",
            "================================================================\n",
            "Total params: 183,430\n",
            "Trainable params: 183,430\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.31\n",
            "Forward/backward pass size (MB): 340.14\n",
            "Params size (MB): 0.70\n",
            "Estimated Total Size (MB): 344.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_RATIO = 0.2\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "sc = StandardScaler()\n",
        "ss = StandardScaler().fit(X_train)\n",
        "X_train_std = ss.transform(X_train)\n",
        "\n",
        "percent = int(X_train_std.shape[0] * (1 - VAL_RATIO))\n",
        "train_x, train_y, val_x, val_y = X_train_std[:percent], y_train[:percent], X_train_std[percent:], y_train[percent:]\n",
        "print('Size of training set: {}'.format(train_x.shape))\n",
        "print('Size of validation set: {}'.format(val_x.shape))"
      ],
      "metadata": {
        "id": "3lDEMsTdTVd3",
        "outputId": "d03c8713-f51f-429b-e9cc-2c96962cd533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: (19836, 35)\n",
            "Size of validation set: (4960, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = IBMDataset(train_x, train_y)\n",
        "val_set = IBMDataset(val_x, val_y)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) # only shuffle the training data\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "RaPDAgDzTcrs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get device \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# training parameters\n",
        "num_epoch = 3000             # number of training epoch\n",
        "learning_rate = 0.0001       # learning rate\n",
        "\n",
        "# the path where checkpoint saved\n",
        "model_path = './best_model.ckpt'\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "CMbU0r5fRwai",
        "outputId": "24bd10af-24f4-434c-fa6a-ed77b64c766d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(inputs) \n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        batch_loss.backward() \n",
        "        optimizer.step() \n",
        "\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                batch_loss = criterion(outputs, labels) \n",
        "                _, val_pred = torch.max(outputs, 1) \n",
        "            \n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            # if the model improves, save a checkpoint at this epoch\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
        "    else:\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "\n",
        "# if not validating, save the last epoch\n",
        "if len(val_set) == 0:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('saving model at last epoch')\n",
        "\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "zYGRiadPSNDo",
        "outputId": "ddc8fd56-eddd-4659-cebd-797c4f8c7a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/3000] Train Acc: 0.260184 Loss: 1.655214 | Val Acc: 0.000000 loss: 3.713485\n",
            "[002/3000] Train Acc: 0.358137 Loss: 1.497461 | Val Acc: 0.000000 loss: 3.696766\n",
            "[003/3000] Train Acc: 0.380470 Loss: 1.374124 | Val Acc: 0.000000 loss: 4.031755\n",
            "[004/3000] Train Acc: 0.390200 Loss: 1.350350 | Val Acc: 0.000000 loss: 4.144799\n",
            "[005/3000] Train Acc: 0.394182 Loss: 1.341906 | Val Acc: 0.000000 loss: 4.296327\n",
            "[006/3000] Train Acc: 0.404719 Loss: 1.336675 | Val Acc: 0.000000 loss: 4.357436\n",
            "[007/3000] Train Acc: 0.409558 Loss: 1.331423 | Val Acc: 0.000000 loss: 4.448160\n",
            "[008/3000] Train Acc: 0.421607 Loss: 1.325004 | Val Acc: 0.000000 loss: 4.445370\n",
            "[009/3000] Train Acc: 0.428463 Loss: 1.316984 | Val Acc: 0.000202 loss: 4.443151\n",
            "saving model with acc 0.000\n",
            "[010/3000] Train Acc: 0.431135 Loss: 1.309080 | Val Acc: 0.001008 loss: 4.482286\n",
            "saving model with acc 0.001\n",
            "[011/3000] Train Acc: 0.436429 Loss: 1.300891 | Val Acc: 0.000605 loss: 4.585510\n",
            "[012/3000] Train Acc: 0.440311 Loss: 1.294137 | Val Acc: 0.024798 loss: 4.583789\n",
            "saving model with acc 0.025\n",
            "[013/3000] Train Acc: 0.445453 Loss: 1.289314 | Val Acc: 0.001008 loss: 4.729612\n",
            "[014/3000] Train Acc: 0.450343 Loss: 1.285409 | Val Acc: 0.005444 loss: 4.670357\n",
            "[015/3000] Train Acc: 0.452662 Loss: 1.281309 | Val Acc: 0.016935 loss: 4.578643\n",
            "[016/3000] Train Acc: 0.456594 Loss: 1.278282 | Val Acc: 0.031250 loss: 4.748064\n",
            "saving model with acc 0.031\n",
            "[017/3000] Train Acc: 0.459770 Loss: 1.276470 | Val Acc: 0.025202 loss: 4.765748\n",
            "[018/3000] Train Acc: 0.461232 Loss: 1.275049 | Val Acc: 0.022379 loss: 4.759954\n",
            "[019/3000] Train Acc: 0.460778 Loss: 1.273593 | Val Acc: 0.017944 loss: 4.806038\n",
            "[020/3000] Train Acc: 0.463400 Loss: 1.271498 | Val Acc: 0.023387 loss: 4.819805\n",
            "[021/3000] Train Acc: 0.463954 Loss: 1.270460 | Val Acc: 0.018750 loss: 4.738979\n",
            "[022/3000] Train Acc: 0.464559 Loss: 1.269059 | Val Acc: 0.031250 loss: 4.862991\n",
            "[023/3000] Train Acc: 0.465316 Loss: 1.268033 | Val Acc: 0.034879 loss: 4.976254\n",
            "saving model with acc 0.035\n",
            "[024/3000] Train Acc: 0.466526 Loss: 1.266855 | Val Acc: 0.035685 loss: 4.837236\n",
            "saving model with acc 0.036\n",
            "[025/3000] Train Acc: 0.465618 Loss: 1.265939 | Val Acc: 0.038508 loss: 4.925928\n",
            "saving model with acc 0.039\n",
            "[026/3000] Train Acc: 0.468290 Loss: 1.264367 | Val Acc: 0.029637 loss: 4.836888\n",
            "[027/3000] Train Acc: 0.469147 Loss: 1.263368 | Val Acc: 0.024395 loss: 5.013162\n",
            "[028/3000] Train Acc: 0.468290 Loss: 1.261931 | Val Acc: 0.052621 loss: 4.978076\n",
            "saving model with acc 0.053\n",
            "[029/3000] Train Acc: 0.469853 Loss: 1.260817 | Val Acc: 0.033065 loss: 5.058074\n",
            "[030/3000] Train Acc: 0.468391 Loss: 1.259718 | Val Acc: 0.027016 loss: 4.942246\n",
            "[031/3000] Train Acc: 0.471264 Loss: 1.258565 | Val Acc: 0.039113 loss: 4.935072\n",
            "[032/3000] Train Acc: 0.469197 Loss: 1.257858 | Val Acc: 0.038508 loss: 5.050411\n",
            "[033/3000] Train Acc: 0.471516 Loss: 1.256582 | Val Acc: 0.050605 loss: 4.939081\n",
            "[034/3000] Train Acc: 0.472827 Loss: 1.255363 | Val Acc: 0.039315 loss: 5.022325\n",
            "[035/3000] Train Acc: 0.472626 Loss: 1.253755 | Val Acc: 0.051411 loss: 5.097228\n",
            "[036/3000] Train Acc: 0.473483 Loss: 1.252326 | Val Acc: 0.036694 loss: 5.045081\n",
            "[037/3000] Train Acc: 0.473281 Loss: 1.250970 | Val Acc: 0.048992 loss: 5.203019\n",
            "[038/3000] Train Acc: 0.474188 Loss: 1.250225 | Val Acc: 0.046774 loss: 5.033494\n",
            "[039/3000] Train Acc: 0.474592 Loss: 1.248510 | Val Acc: 0.043750 loss: 5.048199\n",
            "[040/3000] Train Acc: 0.477566 Loss: 1.246834 | Val Acc: 0.053831 loss: 5.012015\n",
            "saving model with acc 0.054\n",
            "[041/3000] Train Acc: 0.476860 Loss: 1.246175 | Val Acc: 0.042137 loss: 5.101841\n",
            "[042/3000] Train Acc: 0.478776 Loss: 1.244488 | Val Acc: 0.054032 loss: 5.134917\n",
            "saving model with acc 0.054\n",
            "[043/3000] Train Acc: 0.477415 Loss: 1.242803 | Val Acc: 0.043548 loss: 5.195460\n",
            "[044/3000] Train Acc: 0.477566 Loss: 1.241645 | Val Acc: 0.057661 loss: 5.144661\n",
            "saving model with acc 0.058\n",
            "[045/3000] Train Acc: 0.478927 Loss: 1.240418 | Val Acc: 0.056653 loss: 5.179485\n",
            "[046/3000] Train Acc: 0.479230 Loss: 1.239715 | Val Acc: 0.045363 loss: 5.170651\n",
            "[047/3000] Train Acc: 0.481549 Loss: 1.237574 | Val Acc: 0.051411 loss: 5.242138\n",
            "[048/3000] Train Acc: 0.483061 Loss: 1.236050 | Val Acc: 0.056250 loss: 5.099290\n",
            "[049/3000] Train Acc: 0.483061 Loss: 1.235356 | Val Acc: 0.048790 loss: 5.198651\n",
            "[050/3000] Train Acc: 0.482406 Loss: 1.233353 | Val Acc: 0.049597 loss: 5.265459\n",
            "[051/3000] Train Acc: 0.485229 Loss: 1.231660 | Val Acc: 0.042339 loss: 5.227799\n",
            "[052/3000] Train Acc: 0.484069 Loss: 1.230071 | Val Acc: 0.051210 loss: 5.260848\n",
            "[053/3000] Train Acc: 0.486237 Loss: 1.228546 | Val Acc: 0.047782 loss: 5.260223\n",
            "[054/3000] Train Acc: 0.487447 Loss: 1.226808 | Val Acc: 0.033065 loss: 5.371081\n",
            "[055/3000] Train Acc: 0.487195 Loss: 1.225368 | Val Acc: 0.051210 loss: 5.298886\n",
            "[056/3000] Train Acc: 0.487447 Loss: 1.223330 | Val Acc: 0.033065 loss: 5.368539\n",
            "[057/3000] Train Acc: 0.490069 Loss: 1.221400 | Val Acc: 0.047177 loss: 5.427250\n",
            "[058/3000] Train Acc: 0.490472 Loss: 1.219838 | Val Acc: 0.050000 loss: 5.267551\n",
            "[059/3000] Train Acc: 0.490270 Loss: 1.216821 | Val Acc: 0.052016 loss: 5.268222\n",
            "[060/3000] Train Acc: 0.491934 Loss: 1.215944 | Val Acc: 0.043548 loss: 5.373458\n",
            "[061/3000] Train Acc: 0.493648 Loss: 1.213358 | Val Acc: 0.047581 loss: 5.258917\n",
            "[062/3000] Train Acc: 0.494303 Loss: 1.211213 | Val Acc: 0.047581 loss: 5.283224\n",
            "[063/3000] Train Acc: 0.496874 Loss: 1.209821 | Val Acc: 0.051008 loss: 5.348073\n",
            "[064/3000] Train Acc: 0.495513 Loss: 1.206963 | Val Acc: 0.054032 loss: 5.430747\n",
            "[065/3000] Train Acc: 0.497278 Loss: 1.204606 | Val Acc: 0.051815 loss: 5.361790\n",
            "[066/3000] Train Acc: 0.498135 Loss: 1.202497 | Val Acc: 0.055645 loss: 5.476821\n",
            "[067/3000] Train Acc: 0.500454 Loss: 1.199359 | Val Acc: 0.047984 loss: 5.345816\n",
            "[068/3000] Train Acc: 0.503479 Loss: 1.197365 | Val Acc: 0.042944 loss: 5.452577\n",
            "[069/3000] Train Acc: 0.503176 Loss: 1.194691 | Val Acc: 0.054637 loss: 5.277479\n",
            "[070/3000] Train Acc: 0.503428 Loss: 1.191498 | Val Acc: 0.046573 loss: 5.325902\n",
            "[071/3000] Train Acc: 0.506050 Loss: 1.188681 | Val Acc: 0.052419 loss: 5.491437\n",
            "[072/3000] Train Acc: 0.506604 Loss: 1.185350 | Val Acc: 0.049597 loss: 5.249336\n",
            "[073/3000] Train Acc: 0.507864 Loss: 1.182646 | Val Acc: 0.045565 loss: 5.400653\n",
            "[074/3000] Train Acc: 0.511091 Loss: 1.178853 | Val Acc: 0.045766 loss: 5.352012\n",
            "[075/3000] Train Acc: 0.512855 Loss: 1.175645 | Val Acc: 0.045161 loss: 5.377060\n",
            "[076/3000] Train Acc: 0.514721 Loss: 1.172340 | Val Acc: 0.056048 loss: 5.378882\n",
            "[077/3000] Train Acc: 0.517998 Loss: 1.168193 | Val Acc: 0.050403 loss: 5.342648\n",
            "[078/3000] Train Acc: 0.521527 Loss: 1.164098 | Val Acc: 0.063105 loss: 5.408632\n",
            "saving model with acc 0.063\n",
            "[079/3000] Train Acc: 0.521174 Loss: 1.161461 | Val Acc: 0.052218 loss: 5.385509\n",
            "[080/3000] Train Acc: 0.523140 Loss: 1.156626 | Val Acc: 0.058871 loss: 5.367543\n",
            "[081/3000] Train Acc: 0.531105 Loss: 1.152893 | Val Acc: 0.053024 loss: 5.336243\n",
            "[082/3000] Train Acc: 0.531760 Loss: 1.147841 | Val Acc: 0.046169 loss: 5.353492\n",
            "[083/3000] Train Acc: 0.532063 Loss: 1.143740 | Val Acc: 0.045363 loss: 5.377852\n",
            "[084/3000] Train Acc: 0.535491 Loss: 1.139232 | Val Acc: 0.049798 loss: 5.382998\n",
            "[085/3000] Train Acc: 0.537205 Loss: 1.135344 | Val Acc: 0.047177 loss: 5.366199\n",
            "[086/3000] Train Acc: 0.542297 Loss: 1.130008 | Val Acc: 0.044758 loss: 5.236360\n",
            "[087/3000] Train Acc: 0.543860 Loss: 1.125796 | Val Acc: 0.033871 loss: 5.347164\n",
            "[088/3000] Train Acc: 0.547036 Loss: 1.122302 | Val Acc: 0.057258 loss: 5.282289\n",
            "[089/3000] Train Acc: 0.551321 Loss: 1.115737 | Val Acc: 0.053427 loss: 5.252218\n",
            "[090/3000] Train Acc: 0.553287 Loss: 1.112037 | Val Acc: 0.039919 loss: 5.281067\n",
            "[091/3000] Train Acc: 0.554951 Loss: 1.106810 | Val Acc: 0.065121 loss: 5.327857\n",
            "saving model with acc 0.065\n",
            "[092/3000] Train Acc: 0.556967 Loss: 1.104237 | Val Acc: 0.047581 loss: 5.438420\n",
            "[093/3000] Train Acc: 0.559236 Loss: 1.098302 | Val Acc: 0.076815 loss: 5.324530\n",
            "saving model with acc 0.077\n",
            "[094/3000] Train Acc: 0.563874 Loss: 1.092718 | Val Acc: 0.053831 loss: 5.291024\n",
            "[095/3000] Train Acc: 0.566445 Loss: 1.088101 | Val Acc: 0.050806 loss: 5.443088\n",
            "[096/3000] Train Acc: 0.568058 Loss: 1.082903 | Val Acc: 0.057661 loss: 5.433380\n",
            "[097/3000] Train Acc: 0.570226 Loss: 1.079376 | Val Acc: 0.048589 loss: 5.349308\n",
            "[098/3000] Train Acc: 0.572797 Loss: 1.074427 | Val Acc: 0.054234 loss: 5.330353\n",
            "[099/3000] Train Acc: 0.573402 Loss: 1.069393 | Val Acc: 0.050403 loss: 5.340636\n",
            "[100/3000] Train Acc: 0.578141 Loss: 1.064588 | Val Acc: 0.047177 loss: 5.329914\n",
            "[101/3000] Train Acc: 0.578040 Loss: 1.058633 | Val Acc: 0.056452 loss: 5.342171\n",
            "[102/3000] Train Acc: 0.583031 Loss: 1.054017 | Val Acc: 0.057460 loss: 5.390500\n",
            "[103/3000] Train Acc: 0.583434 Loss: 1.049167 | Val Acc: 0.053831 loss: 5.273691\n",
            "[104/3000] Train Acc: 0.589131 Loss: 1.043802 | Val Acc: 0.045565 loss: 5.265688\n",
            "[105/3000] Train Acc: 0.591248 Loss: 1.038202 | Val Acc: 0.050000 loss: 5.223296\n",
            "[106/3000] Train Acc: 0.593567 Loss: 1.033939 | Val Acc: 0.064919 loss: 5.334458\n",
            "[107/3000] Train Acc: 0.596995 Loss: 1.029262 | Val Acc: 0.058266 loss: 5.334038\n",
            "[108/3000] Train Acc: 0.599365 Loss: 1.023745 | Val Acc: 0.045565 loss: 5.380600\n",
            "[109/3000] Train Acc: 0.603398 Loss: 1.018814 | Val Acc: 0.062097 loss: 5.417269\n",
            "[110/3000] Train Acc: 0.606271 Loss: 1.013009 | Val Acc: 0.051008 loss: 5.302452\n",
            "[111/3000] Train Acc: 0.609851 Loss: 1.007546 | Val Acc: 0.077419 loss: 5.362186\n",
            "saving model with acc 0.077\n",
            "[112/3000] Train Acc: 0.613985 Loss: 1.001343 | Val Acc: 0.062702 loss: 5.226289\n",
            "[113/3000] Train Acc: 0.615951 Loss: 0.996724 | Val Acc: 0.054637 loss: 5.240279\n",
            "[114/3000] Train Acc: 0.616606 Loss: 0.992561 | Val Acc: 0.058266 loss: 5.309705\n",
            "[115/3000] Train Acc: 0.620135 Loss: 0.987407 | Val Acc: 0.052016 loss: 5.260766\n",
            "[116/3000] Train Acc: 0.622706 Loss: 0.982353 | Val Acc: 0.064516 loss: 5.127495\n",
            "[117/3000] Train Acc: 0.625731 Loss: 0.977242 | Val Acc: 0.070363 loss: 5.347314\n",
            "[118/3000] Train Acc: 0.629966 Loss: 0.972317 | Val Acc: 0.049194 loss: 5.240683\n",
            "[119/3000] Train Acc: 0.631579 Loss: 0.965161 | Val Acc: 0.059677 loss: 5.302550\n",
            "[120/3000] Train Acc: 0.632486 Loss: 0.961705 | Val Acc: 0.057258 loss: 5.269590\n",
            "[121/3000] Train Acc: 0.635864 Loss: 0.957131 | Val Acc: 0.053024 loss: 5.299267\n",
            "[122/3000] Train Acc: 0.640553 Loss: 0.951714 | Val Acc: 0.073992 loss: 5.340230\n",
            "[123/3000] Train Acc: 0.641359 Loss: 0.946877 | Val Acc: 0.064718 loss: 5.282043\n",
            "[124/3000] Train Acc: 0.642519 Loss: 0.940322 | Val Acc: 0.066734 loss: 5.203151\n",
            "[125/3000] Train Acc: 0.647510 Loss: 0.936236 | Val Acc: 0.082460 loss: 5.269814\n",
            "saving model with acc 0.082\n",
            "[126/3000] Train Acc: 0.645846 Loss: 0.932555 | Val Acc: 0.089718 loss: 5.254119\n",
            "saving model with acc 0.090\n",
            "[127/3000] Train Acc: 0.652803 Loss: 0.925090 | Val Acc: 0.064315 loss: 5.141293\n",
            "[128/3000] Train Acc: 0.654265 Loss: 0.920918 | Val Acc: 0.079637 loss: 5.297298\n",
            "[129/3000] Train Acc: 0.657239 Loss: 0.915975 | Val Acc: 0.065927 loss: 5.277931\n",
            "[130/3000] Train Acc: 0.657895 Loss: 0.911470 | Val Acc: 0.068952 loss: 5.182845\n",
            "[131/3000] Train Acc: 0.663440 Loss: 0.906349 | Val Acc: 0.073589 loss: 5.265830\n",
            "[132/3000] Train Acc: 0.665457 Loss: 0.900379 | Val Acc: 0.059274 loss: 5.344511\n",
            "[133/3000] Train Acc: 0.667927 Loss: 0.895834 | Val Acc: 0.082460 loss: 5.277204\n",
            "[134/3000] Train Acc: 0.668784 Loss: 0.891585 | Val Acc: 0.080242 loss: 5.312808\n",
            "[135/3000] Train Acc: 0.670901 Loss: 0.887476 | Val Acc: 0.076411 loss: 5.250298\n",
            "[136/3000] Train Acc: 0.671809 Loss: 0.882255 | Val Acc: 0.068952 loss: 5.239577\n",
            "[137/3000] Train Acc: 0.675791 Loss: 0.876016 | Val Acc: 0.050202 loss: 5.351768\n",
            "[138/3000] Train Acc: 0.678161 Loss: 0.870622 | Val Acc: 0.092540 loss: 5.325904\n",
            "saving model with acc 0.093\n",
            "[139/3000] Train Acc: 0.677858 Loss: 0.867489 | Val Acc: 0.074798 loss: 5.381376\n",
            "[140/3000] Train Acc: 0.681942 Loss: 0.861866 | Val Acc: 0.088105 loss: 5.254320\n",
            "[141/3000] Train Acc: 0.685370 Loss: 0.857691 | Val Acc: 0.060685 loss: 5.131941\n",
            "[142/3000] Train Acc: 0.684815 Loss: 0.853229 | Val Acc: 0.084677 loss: 5.208555\n",
            "[143/3000] Train Acc: 0.686630 Loss: 0.847217 | Val Acc: 0.072984 loss: 5.242613\n",
            "[144/3000] Train Acc: 0.685219 Loss: 0.841812 | Val Acc: 0.065726 loss: 5.228275\n",
            "[145/3000] Train Acc: 0.689353 Loss: 0.837689 | Val Acc: 0.091532 loss: 5.167237\n",
            "[146/3000] Train Acc: 0.693991 Loss: 0.832457 | Val Acc: 0.091331 loss: 5.154551\n",
            "[147/3000] Train Acc: 0.695554 Loss: 0.827935 | Val Acc: 0.076613 loss: 5.207130\n",
            "[148/3000] Train Acc: 0.695856 Loss: 0.823271 | Val Acc: 0.078024 loss: 5.320035\n",
            "[149/3000] Train Acc: 0.698024 Loss: 0.820407 | Val Acc: 0.091935 loss: 5.357472\n",
            "[150/3000] Train Acc: 0.702259 Loss: 0.814297 | Val Acc: 0.108266 loss: 5.314926\n",
            "saving model with acc 0.108\n",
            "[151/3000] Train Acc: 0.702359 Loss: 0.808499 | Val Acc: 0.078226 loss: 5.161968\n",
            "[152/3000] Train Acc: 0.705787 Loss: 0.804403 | Val Acc: 0.106653 loss: 5.136955\n",
            "[153/3000] Train Acc: 0.706594 Loss: 0.800494 | Val Acc: 0.086089 loss: 5.291783\n",
            "[154/3000] Train Acc: 0.711787 Loss: 0.794695 | Val Acc: 0.082460 loss: 5.331548\n",
            "[155/3000] Train Acc: 0.711787 Loss: 0.791476 | Val Acc: 0.107056 loss: 5.127708\n",
            "[156/3000] Train Acc: 0.713450 Loss: 0.786509 | Val Acc: 0.070968 loss: 5.170393\n",
            "[157/3000] Train Acc: 0.714358 Loss: 0.782803 | Val Acc: 0.093750 loss: 5.237163\n",
            "[158/3000] Train Acc: 0.717635 Loss: 0.776482 | Val Acc: 0.102419 loss: 5.189392\n",
            "[159/3000] Train Acc: 0.721012 Loss: 0.773104 | Val Acc: 0.078427 loss: 5.188247\n",
            "[160/3000] Train Acc: 0.722172 Loss: 0.768850 | Val Acc: 0.081250 loss: 5.255811\n",
            "[161/3000] Train Acc: 0.725852 Loss: 0.763688 | Val Acc: 0.094960 loss: 5.289122\n",
            "[162/3000] Train Acc: 0.723331 Loss: 0.759877 | Val Acc: 0.079435 loss: 5.253124\n",
            "[163/3000] Train Acc: 0.728020 Loss: 0.753974 | Val Acc: 0.090927 loss: 5.133976\n",
            "[164/3000] Train Acc: 0.732759 Loss: 0.750565 | Val Acc: 0.088911 loss: 5.143265\n",
            "[165/3000] Train Acc: 0.733817 Loss: 0.746160 | Val Acc: 0.109677 loss: 5.078887\n",
            "saving model with acc 0.110\n",
            "[166/3000] Train Acc: 0.735531 Loss: 0.740473 | Val Acc: 0.110282 loss: 5.100545\n",
            "saving model with acc 0.110\n",
            "[167/3000] Train Acc: 0.734926 Loss: 0.738040 | Val Acc: 0.099194 loss: 5.167586\n",
            "[168/3000] Train Acc: 0.734221 Loss: 0.735254 | Val Acc: 0.066331 loss: 5.204530\n",
            "[169/3000] Train Acc: 0.736086 Loss: 0.730087 | Val Acc: 0.102016 loss: 5.167224\n",
            "[170/3000] Train Acc: 0.741531 Loss: 0.724219 | Val Acc: 0.075000 loss: 5.246189\n",
            "[171/3000] Train Acc: 0.743698 Loss: 0.719048 | Val Acc: 0.076613 loss: 5.243924\n",
            "[172/3000] Train Acc: 0.744051 Loss: 0.716767 | Val Acc: 0.096774 loss: 5.168685\n",
            "[173/3000] Train Acc: 0.745664 Loss: 0.710916 | Val Acc: 0.094960 loss: 5.192084\n",
            "[174/3000] Train Acc: 0.749193 Loss: 0.706702 | Val Acc: 0.104032 loss: 5.292550\n",
            "[175/3000] Train Acc: 0.749345 Loss: 0.703992 | Val Acc: 0.107258 loss: 5.102705\n",
            "[176/3000] Train Acc: 0.749798 Loss: 0.699734 | Val Acc: 0.102016 loss: 4.995684\n",
            "[177/3000] Train Acc: 0.753630 Loss: 0.696932 | Val Acc: 0.092742 loss: 5.108332\n",
            "[178/3000] Train Acc: 0.755697 Loss: 0.688013 | Val Acc: 0.090121 loss: 5.113829\n",
            "[179/3000] Train Acc: 0.756554 Loss: 0.686079 | Val Acc: 0.082056 loss: 5.214982\n",
            "[180/3000] Train Acc: 0.759478 Loss: 0.681298 | Val Acc: 0.095565 loss: 5.284605\n",
            "[181/3000] Train Acc: 0.759377 Loss: 0.679125 | Val Acc: 0.080645 loss: 5.140954\n",
            "[182/3000] Train Acc: 0.761141 Loss: 0.673663 | Val Acc: 0.100605 loss: 5.111508\n",
            "[183/3000] Train Acc: 0.763309 Loss: 0.670694 | Val Acc: 0.098790 loss: 5.132652\n",
            "[184/3000] Train Acc: 0.762603 Loss: 0.670861 | Val Acc: 0.108468 loss: 5.205200\n",
            "[185/3000] Train Acc: 0.766132 Loss: 0.662002 | Val Acc: 0.107661 loss: 5.270230\n",
            "[186/3000] Train Acc: 0.766284 Loss: 0.659132 | Val Acc: 0.098185 loss: 5.166995\n",
            "[187/3000] Train Acc: 0.769157 Loss: 0.655558 | Val Acc: 0.107056 loss: 5.124373\n",
            "[188/3000] Train Acc: 0.771073 Loss: 0.650192 | Val Acc: 0.097581 loss: 5.203891\n",
            "[189/3000] Train Acc: 0.774299 Loss: 0.647734 | Val Acc: 0.118750 loss: 5.120141\n",
            "saving model with acc 0.119\n",
            "[190/3000] Train Acc: 0.773997 Loss: 0.645294 | Val Acc: 0.094355 loss: 5.015003\n",
            "[191/3000] Train Acc: 0.776467 Loss: 0.639584 | Val Acc: 0.100403 loss: 5.113919\n",
            "[192/3000] Train Acc: 0.777929 Loss: 0.634929 | Val Acc: 0.098790 loss: 5.320547\n",
            "[193/3000] Train Acc: 0.778887 Loss: 0.632543 | Val Acc: 0.094153 loss: 5.140275\n",
            "[194/3000] Train Acc: 0.780298 Loss: 0.628957 | Val Acc: 0.109677 loss: 5.104089\n",
            "[195/3000] Train Acc: 0.780046 Loss: 0.627161 | Val Acc: 0.092944 loss: 5.150596\n",
            "[196/3000] Train Acc: 0.780903 Loss: 0.623801 | Val Acc: 0.090726 loss: 5.069114\n",
            "[197/3000] Train Acc: 0.784382 Loss: 0.616598 | Val Acc: 0.075605 loss: 5.210384\n",
            "[198/3000] Train Acc: 0.785894 Loss: 0.616531 | Val Acc: 0.096371 loss: 5.237427\n",
            "[199/3000] Train Acc: 0.787155 Loss: 0.610012 | Val Acc: 0.121774 loss: 5.122214\n",
            "saving model with acc 0.122\n",
            "[200/3000] Train Acc: 0.787810 Loss: 0.610795 | Val Acc: 0.116532 loss: 5.072708\n",
            "[201/3000] Train Acc: 0.789524 Loss: 0.605128 | Val Acc: 0.104234 loss: 5.130131\n",
            "[202/3000] Train Acc: 0.791339 Loss: 0.600326 | Val Acc: 0.100403 loss: 5.042731\n",
            "[203/3000] Train Acc: 0.788213 Loss: 0.601060 | Val Acc: 0.097782 loss: 5.149659\n",
            "[204/3000] Train Acc: 0.795422 Loss: 0.594517 | Val Acc: 0.096976 loss: 5.057008\n",
            "[205/3000] Train Acc: 0.796985 Loss: 0.589049 | Val Acc: 0.131653 loss: 5.170927\n",
            "saving model with acc 0.132\n",
            "[206/3000] Train Acc: 0.796532 Loss: 0.588250 | Val Acc: 0.114315 loss: 5.182856\n",
            "[207/3000] Train Acc: 0.796733 Loss: 0.584047 | Val Acc: 0.099597 loss: 5.183489\n",
            "[208/3000] Train Acc: 0.800817 Loss: 0.579966 | Val Acc: 0.088710 loss: 5.199650\n",
            "[209/3000] Train Acc: 0.801976 Loss: 0.577277 | Val Acc: 0.120565 loss: 5.101236\n",
            "[210/3000] Train Acc: 0.802228 Loss: 0.574103 | Val Acc: 0.111089 loss: 5.112772\n",
            "[211/3000] Train Acc: 0.801825 Loss: 0.570824 | Val Acc: 0.118548 loss: 5.022035\n",
            "[212/3000] Train Acc: 0.803640 Loss: 0.570348 | Val Acc: 0.096976 loss: 5.025977\n",
            "[213/3000] Train Acc: 0.802884 Loss: 0.564442 | Val Acc: 0.112097 loss: 5.159995\n",
            "[214/3000] Train Acc: 0.805757 Loss: 0.565791 | Val Acc: 0.114718 loss: 5.182210\n",
            "[215/3000] Train Acc: 0.807522 Loss: 0.561045 | Val Acc: 0.128427 loss: 5.002152\n",
            "[216/3000] Train Acc: 0.807421 Loss: 0.556769 | Val Acc: 0.120968 loss: 5.290520\n",
            "[217/3000] Train Acc: 0.810496 Loss: 0.551799 | Val Acc: 0.121976 loss: 5.060660\n",
            "[218/3000] Train Acc: 0.814428 Loss: 0.548400 | Val Acc: 0.122782 loss: 5.130079\n",
            "[219/3000] Train Acc: 0.812664 Loss: 0.546537 | Val Acc: 0.104839 loss: 5.191064\n",
            "[220/3000] Train Acc: 0.812361 Loss: 0.547440 | Val Acc: 0.122984 loss: 5.061808\n",
            "[221/3000] Train Acc: 0.815537 Loss: 0.539949 | Val Acc: 0.121371 loss: 4.982150\n",
            "[222/3000] Train Acc: 0.816647 Loss: 0.538566 | Val Acc: 0.115323 loss: 5.166621\n",
            "[223/3000] Train Acc: 0.816647 Loss: 0.534812 | Val Acc: 0.119960 loss: 5.193016\n",
            "[224/3000] Train Acc: 0.817100 Loss: 0.530944 | Val Acc: 0.105847 loss: 5.104227\n",
            "[225/3000] Train Acc: 0.818814 Loss: 0.529214 | Val Acc: 0.122177 loss: 5.072703\n",
            "[226/3000] Train Acc: 0.821990 Loss: 0.525805 | Val Acc: 0.129839 loss: 5.038918\n",
            "[227/3000] Train Acc: 0.820982 Loss: 0.525873 | Val Acc: 0.101815 loss: 5.157812\n",
            "[228/3000] Train Acc: 0.823503 Loss: 0.520008 | Val Acc: 0.112097 loss: 5.111754\n",
            "[229/3000] Train Acc: 0.823956 Loss: 0.517684 | Val Acc: 0.113105 loss: 5.066544\n",
            "[230/3000] Train Acc: 0.824309 Loss: 0.516435 | Val Acc: 0.114315 loss: 5.041750\n",
            "[231/3000] Train Acc: 0.827233 Loss: 0.511400 | Val Acc: 0.095161 loss: 5.312123\n",
            "[232/3000] Train Acc: 0.828040 Loss: 0.511127 | Val Acc: 0.122782 loss: 5.198426\n",
            "[233/3000] Train Acc: 0.828947 Loss: 0.506684 | Val Acc: 0.121371 loss: 4.997366\n",
            "[234/3000] Train Acc: 0.829552 Loss: 0.504472 | Val Acc: 0.113710 loss: 4.979826\n",
            "[235/3000] Train Acc: 0.832628 Loss: 0.499740 | Val Acc: 0.125605 loss: 4.958015\n",
            "[236/3000] Train Acc: 0.829704 Loss: 0.499306 | Val Acc: 0.123589 loss: 4.999528\n",
            "[237/3000] Train Acc: 0.832678 Loss: 0.496450 | Val Acc: 0.120161 loss: 5.062355\n",
            "[238/3000] Train Acc: 0.832023 Loss: 0.495845 | Val Acc: 0.121573 loss: 5.203877\n",
            "[239/3000] Train Acc: 0.835652 Loss: 0.490197 | Val Acc: 0.108065 loss: 5.019644\n",
            "[240/3000] Train Acc: 0.836560 Loss: 0.486509 | Val Acc: 0.117137 loss: 5.160573\n",
            "[241/3000] Train Acc: 0.837770 Loss: 0.486538 | Val Acc: 0.134677 loss: 4.958077\n",
            "saving model with acc 0.135\n",
            "[242/3000] Train Acc: 0.837921 Loss: 0.485377 | Val Acc: 0.117540 loss: 5.111960\n",
            "[243/3000] Train Acc: 0.838828 Loss: 0.478681 | Val Acc: 0.123992 loss: 5.137283\n",
            "[244/3000] Train Acc: 0.839383 Loss: 0.477849 | Val Acc: 0.104637 loss: 5.152988\n",
            "[245/3000] Train Acc: 0.840341 Loss: 0.478169 | Val Acc: 0.121169 loss: 5.056053\n",
            "[246/3000] Train Acc: 0.843013 Loss: 0.473944 | Val Acc: 0.133669 loss: 5.038757\n",
            "[247/3000] Train Acc: 0.841803 Loss: 0.469811 | Val Acc: 0.122177 loss: 4.986125\n",
            "[248/3000] Train Acc: 0.843013 Loss: 0.468713 | Val Acc: 0.125202 loss: 5.129769\n",
            "[249/3000] Train Acc: 0.844172 Loss: 0.468138 | Val Acc: 0.133266 loss: 5.032528\n",
            "[250/3000] Train Acc: 0.844576 Loss: 0.463221 | Val Acc: 0.128226 loss: 5.003777\n",
            "[251/3000] Train Acc: 0.845130 Loss: 0.462065 | Val Acc: 0.119153 loss: 5.014014\n",
            "[252/3000] Train Acc: 0.845937 Loss: 0.458516 | Val Acc: 0.119960 loss: 5.000196\n",
            "[253/3000] Train Acc: 0.849617 Loss: 0.455134 | Val Acc: 0.128427 loss: 5.029209\n",
            "[254/3000] Train Acc: 0.848760 Loss: 0.452831 | Val Acc: 0.119758 loss: 5.173098\n",
            "[255/3000] Train Acc: 0.849516 Loss: 0.452795 | Val Acc: 0.117742 loss: 5.104324\n",
            "[256/3000] Train Acc: 0.852138 Loss: 0.447860 | Val Acc: 0.123387 loss: 5.126294\n",
            "[257/3000] Train Acc: 0.853347 Loss: 0.446534 | Val Acc: 0.118145 loss: 5.130805\n",
            "[258/3000] Train Acc: 0.852440 Loss: 0.444575 | Val Acc: 0.130847 loss: 5.125774\n",
            "[259/3000] Train Acc: 0.852591 Loss: 0.446359 | Val Acc: 0.119153 loss: 5.190970\n",
            "[260/3000] Train Acc: 0.853448 Loss: 0.438615 | Val Acc: 0.104234 loss: 5.155151\n",
            "[261/3000] Train Acc: 0.852188 Loss: 0.438240 | Val Acc: 0.130040 loss: 5.064297\n",
            "[262/3000] Train Acc: 0.855566 Loss: 0.435717 | Val Acc: 0.126008 loss: 5.100256\n",
            "[263/3000] Train Acc: 0.857683 Loss: 0.431684 | Val Acc: 0.116935 loss: 5.145090\n",
            "[264/3000] Train Acc: 0.856322 Loss: 0.431549 | Val Acc: 0.124798 loss: 5.051729\n",
            "[265/3000] Train Acc: 0.857885 Loss: 0.427308 | Val Acc: 0.123185 loss: 5.093600\n",
            "[266/3000] Train Acc: 0.858439 Loss: 0.424292 | Val Acc: 0.120968 loss: 5.103365\n",
            "[267/3000] Train Acc: 0.857733 Loss: 0.424373 | Val Acc: 0.116331 loss: 5.205285\n",
            "[268/3000] Train Acc: 0.860355 Loss: 0.423047 | Val Acc: 0.121371 loss: 5.055081\n",
            "[269/3000] Train Acc: 0.861414 Loss: 0.419394 | Val Acc: 0.110685 loss: 5.124958\n",
            "[270/3000] Train Acc: 0.860909 Loss: 0.416544 | Val Acc: 0.123589 loss: 5.052924\n",
            "[271/3000] Train Acc: 0.862271 Loss: 0.414231 | Val Acc: 0.121169 loss: 5.050848\n",
            "[272/3000] Train Acc: 0.863077 Loss: 0.413119 | Val Acc: 0.131250 loss: 5.036003\n",
            "[273/3000] Train Acc: 0.861716 Loss: 0.412698 | Val Acc: 0.115726 loss: 5.084986\n",
            "[274/3000] Train Acc: 0.864186 Loss: 0.408980 | Val Acc: 0.127621 loss: 4.995002\n",
            "[275/3000] Train Acc: 0.865043 Loss: 0.408656 | Val Acc: 0.130645 loss: 5.052350\n",
            "[276/3000] Train Acc: 0.863833 Loss: 0.407923 | Val Acc: 0.127218 loss: 5.202824\n",
            "[277/3000] Train Acc: 0.868270 Loss: 0.404056 | Val Acc: 0.122782 loss: 5.218572\n",
            "[278/3000] Train Acc: 0.868320 Loss: 0.399681 | Val Acc: 0.126008 loss: 5.097169\n",
            "[279/3000] Train Acc: 0.868371 Loss: 0.398627 | Val Acc: 0.127621 loss: 5.034031\n",
            "[280/3000] Train Acc: 0.869328 Loss: 0.399026 | Val Acc: 0.122782 loss: 5.148796\n",
            "[281/3000] Train Acc: 0.869681 Loss: 0.395994 | Val Acc: 0.112903 loss: 5.274258\n",
            "[282/3000] Train Acc: 0.870639 Loss: 0.393305 | Val Acc: 0.132056 loss: 4.968158\n",
            "[283/3000] Train Acc: 0.871446 Loss: 0.391017 | Val Acc: 0.120565 loss: 5.179994\n",
            "[284/3000] Train Acc: 0.871345 Loss: 0.388938 | Val Acc: 0.114516 loss: 5.183795\n",
            "[285/3000] Train Acc: 0.872505 Loss: 0.385730 | Val Acc: 0.140927 loss: 5.127303\n",
            "saving model with acc 0.141\n",
            "[286/3000] Train Acc: 0.873160 Loss: 0.386970 | Val Acc: 0.130847 loss: 5.111386\n",
            "[287/3000] Train Acc: 0.874824 Loss: 0.381480 | Val Acc: 0.123185 loss: 5.237115\n",
            "[288/3000] Train Acc: 0.874571 Loss: 0.383865 | Val Acc: 0.112298 loss: 5.046375\n",
            "[289/3000] Train Acc: 0.875529 Loss: 0.377483 | Val Acc: 0.129032 loss: 5.026707\n",
            "[290/3000] Train Acc: 0.878201 Loss: 0.375099 | Val Acc: 0.128427 loss: 5.174827\n",
            "[291/3000] Train Acc: 0.876840 Loss: 0.377386 | Val Acc: 0.126613 loss: 4.918910\n",
            "[292/3000] Train Acc: 0.876084 Loss: 0.375132 | Val Acc: 0.128024 loss: 5.062948\n",
            "[293/3000] Train Acc: 0.876941 Loss: 0.371085 | Val Acc: 0.125806 loss: 5.079508\n",
            "[294/3000] Train Acc: 0.881982 Loss: 0.368231 | Val Acc: 0.121573 loss: 5.091340\n",
            "[295/3000] Train Acc: 0.880873 Loss: 0.364556 | Val Acc: 0.127621 loss: 4.919535\n",
            "[296/3000] Train Acc: 0.880218 Loss: 0.367233 | Val Acc: 0.115121 loss: 5.104284\n",
            "[297/3000] Train Acc: 0.881327 Loss: 0.362788 | Val Acc: 0.123992 loss: 5.045989\n",
            "[298/3000] Train Acc: 0.880218 Loss: 0.362964 | Val Acc: 0.122379 loss: 5.055477\n",
            "[299/3000] Train Acc: 0.883898 Loss: 0.358544 | Val Acc: 0.136895 loss: 5.077802\n",
            "[300/3000] Train Acc: 0.883243 Loss: 0.358893 | Val Acc: 0.124597 loss: 5.161076\n",
            "[301/3000] Train Acc: 0.886721 Loss: 0.353651 | Val Acc: 0.127218 loss: 5.387692\n",
            "[302/3000] Train Acc: 0.881579 Loss: 0.355151 | Val Acc: 0.120565 loss: 5.145760\n",
            "[303/3000] Train Acc: 0.884705 Loss: 0.352572 | Val Acc: 0.120766 loss: 5.233396\n",
            "[304/3000] Train Acc: 0.884352 Loss: 0.354323 | Val Acc: 0.127218 loss: 5.191301\n",
            "[305/3000] Train Acc: 0.887780 Loss: 0.348595 | Val Acc: 0.130040 loss: 4.962060\n",
            "[306/3000] Train Acc: 0.885814 Loss: 0.347937 | Val Acc: 0.125403 loss: 5.127211\n",
            "[307/3000] Train Acc: 0.886519 Loss: 0.345306 | Val Acc: 0.127218 loss: 5.011131\n",
            "[308/3000] Train Acc: 0.887326 Loss: 0.345544 | Val Acc: 0.140524 loss: 5.042520\n",
            "[309/3000] Train Acc: 0.889443 Loss: 0.341222 | Val Acc: 0.122782 loss: 4.989335\n",
            "[310/3000] Train Acc: 0.889696 Loss: 0.339228 | Val Acc: 0.132258 loss: 5.082033\n",
            "[311/3000] Train Acc: 0.889645 Loss: 0.337660 | Val Acc: 0.125403 loss: 5.270277\n",
            "[312/3000] Train Acc: 0.891309 Loss: 0.335746 | Val Acc: 0.121774 loss: 5.205104\n",
            "[313/3000] Train Acc: 0.890149 Loss: 0.335753 | Val Acc: 0.128226 loss: 5.253638\n",
            "[314/3000] Train Acc: 0.890351 Loss: 0.334532 | Val Acc: 0.127621 loss: 5.280066\n",
            "[315/3000] Train Acc: 0.891914 Loss: 0.332169 | Val Acc: 0.125202 loss: 5.348319\n",
            "[316/3000] Train Acc: 0.893174 Loss: 0.328008 | Val Acc: 0.135081 loss: 5.175285\n",
            "[317/3000] Train Acc: 0.895140 Loss: 0.326151 | Val Acc: 0.129032 loss: 5.244036\n",
            "[318/3000] Train Acc: 0.894384 Loss: 0.326333 | Val Acc: 0.128024 loss: 5.059800\n",
            "[319/3000] Train Acc: 0.896653 Loss: 0.326294 | Val Acc: 0.134879 loss: 4.969325\n",
            "[320/3000] Train Acc: 0.895846 Loss: 0.322311 | Val Acc: 0.132863 loss: 5.096989\n",
            "[321/3000] Train Acc: 0.897762 Loss: 0.319419 | Val Acc: 0.128226 loss: 4.969665\n",
            "[322/3000] Train Acc: 0.897963 Loss: 0.320097 | Val Acc: 0.116129 loss: 5.178830\n",
            "[323/3000] Train Acc: 0.898014 Loss: 0.318306 | Val Acc: 0.125806 loss: 5.159696\n",
            "[324/3000] Train Acc: 0.900686 Loss: 0.314484 | Val Acc: 0.113306 loss: 5.258769\n",
            "[325/3000] Train Acc: 0.899324 Loss: 0.313615 | Val Acc: 0.134879 loss: 5.069464\n",
            "[326/3000] Train Acc: 0.898820 Loss: 0.314101 | Val Acc: 0.133065 loss: 4.996921\n",
            "[327/3000] Train Acc: 0.901291 Loss: 0.309876 | Val Acc: 0.128024 loss: 5.160580\n",
            "[328/3000] Train Acc: 0.900232 Loss: 0.309154 | Val Acc: 0.127621 loss: 5.133071\n",
            "[329/3000] Train Acc: 0.903358 Loss: 0.307920 | Val Acc: 0.131048 loss: 4.996987\n",
            "[330/3000] Train Acc: 0.904567 Loss: 0.305661 | Val Acc: 0.136290 loss: 5.130602\n",
            "[331/3000] Train Acc: 0.902248 Loss: 0.302615 | Val Acc: 0.125806 loss: 5.178284\n",
            "[332/3000] Train Acc: 0.903559 Loss: 0.302362 | Val Acc: 0.117339 loss: 5.120633\n",
            "[333/3000] Train Acc: 0.904215 Loss: 0.299888 | Val Acc: 0.121573 loss: 5.158981\n",
            "[334/3000] Train Acc: 0.904769 Loss: 0.298254 | Val Acc: 0.127218 loss: 4.991207\n",
            "[335/3000] Train Acc: 0.906282 Loss: 0.295276 | Val Acc: 0.138508 loss: 5.048875\n",
            "[336/3000] Train Acc: 0.904769 Loss: 0.297843 | Val Acc: 0.142339 loss: 5.100349\n",
            "saving model with acc 0.142\n",
            "[337/3000] Train Acc: 0.905475 Loss: 0.294680 | Val Acc: 0.128024 loss: 5.054450\n",
            "[338/3000] Train Acc: 0.908298 Loss: 0.290217 | Val Acc: 0.143145 loss: 5.165768\n",
            "saving model with acc 0.143\n",
            "[339/3000] Train Acc: 0.904618 Loss: 0.294906 | Val Acc: 0.127419 loss: 5.079160\n",
            "[340/3000] Train Acc: 0.907693 Loss: 0.290379 | Val Acc: 0.130645 loss: 5.191685\n",
            "[341/3000] Train Acc: 0.907088 Loss: 0.289423 | Val Acc: 0.140323 loss: 5.074436\n",
            "[342/3000] Train Acc: 0.909861 Loss: 0.285344 | Val Acc: 0.130645 loss: 5.123031\n",
            "[343/3000] Train Acc: 0.908348 Loss: 0.285695 | Val Acc: 0.117742 loss: 5.175180\n",
            "[344/3000] Train Acc: 0.908903 Loss: 0.286108 | Val Acc: 0.129435 loss: 5.327537\n",
            "[345/3000] Train Acc: 0.910063 Loss: 0.282526 | Val Acc: 0.134274 loss: 5.172191\n",
            "[346/3000] Train Acc: 0.911474 Loss: 0.278872 | Val Acc: 0.141935 loss: 4.954403\n",
            "[347/3000] Train Acc: 0.911827 Loss: 0.278813 | Val Acc: 0.137097 loss: 5.191000\n",
            "[348/3000] Train Acc: 0.910415 Loss: 0.282292 | Val Acc: 0.119355 loss: 5.268572\n",
            "[349/3000] Train Acc: 0.913138 Loss: 0.277585 | Val Acc: 0.127419 loss: 5.177735\n",
            "[350/3000] Train Acc: 0.912936 Loss: 0.274595 | Val Acc: 0.138105 loss: 5.307481\n",
            "[351/3000] Train Acc: 0.913037 Loss: 0.274405 | Val Acc: 0.130040 loss: 5.274299\n",
            "[352/3000] Train Acc: 0.915810 Loss: 0.271043 | Val Acc: 0.128831 loss: 5.293377\n",
            "[353/3000] Train Acc: 0.914801 Loss: 0.271450 | Val Acc: 0.135685 loss: 5.010127\n",
            "[354/3000] Train Acc: 0.916364 Loss: 0.268617 | Val Acc: 0.138306 loss: 5.137825\n",
            "[355/3000] Train Acc: 0.917423 Loss: 0.266601 | Val Acc: 0.131250 loss: 5.245214\n",
            "[356/3000] Train Acc: 0.915255 Loss: 0.266119 | Val Acc: 0.134073 loss: 5.048240\n",
            "[357/3000] Train Acc: 0.918986 Loss: 0.262802 | Val Acc: 0.132661 loss: 5.157977\n",
            "[358/3000] Train Acc: 0.916364 Loss: 0.266490 | Val Acc: 0.131452 loss: 5.084446\n",
            "[359/3000] Train Acc: 0.918482 Loss: 0.259910 | Val Acc: 0.131250 loss: 5.444242\n",
            "[360/3000] Train Acc: 0.916667 Loss: 0.266895 | Val Acc: 0.138105 loss: 5.047227\n",
            "[361/3000] Train Acc: 0.918532 Loss: 0.261307 | Val Acc: 0.137500 loss: 4.950773\n",
            "[362/3000] Train Acc: 0.920246 Loss: 0.256656 | Val Acc: 0.131855 loss: 5.311380\n",
            "[363/3000] Train Acc: 0.920296 Loss: 0.255165 | Val Acc: 0.133065 loss: 5.332611\n",
            "[364/3000] Train Acc: 0.921053 Loss: 0.253996 | Val Acc: 0.134677 loss: 5.119649\n",
            "[365/3000] Train Acc: 0.923321 Loss: 0.252894 | Val Acc: 0.126210 loss: 5.023664\n",
            "[366/3000] Train Acc: 0.922515 Loss: 0.250880 | Val Acc: 0.142540 loss: 5.099382\n",
            "[367/3000] Train Acc: 0.922464 Loss: 0.250745 | Val Acc: 0.129839 loss: 5.135987\n",
            "[368/3000] Train Acc: 0.923523 Loss: 0.248001 | Val Acc: 0.143750 loss: 4.975855\n",
            "saving model with acc 0.144\n",
            "[369/3000] Train Acc: 0.923120 Loss: 0.249075 | Val Acc: 0.139113 loss: 5.172289\n",
            "[370/3000] Train Acc: 0.924128 Loss: 0.245731 | Val Acc: 0.139516 loss: 5.082209\n",
            "[371/3000] Train Acc: 0.923422 Loss: 0.247700 | Val Acc: 0.123589 loss: 5.230030\n",
            "[372/3000] Train Acc: 0.924330 Loss: 0.244521 | Val Acc: 0.127823 loss: 5.293903\n",
            "[373/3000] Train Acc: 0.927707 Loss: 0.239862 | Val Acc: 0.141935 loss: 5.023466\n",
            "[374/3000] Train Acc: 0.924934 Loss: 0.242665 | Val Acc: 0.126815 loss: 5.104769\n",
            "[375/3000] Train Acc: 0.924531 Loss: 0.240418 | Val Acc: 0.129637 loss: 5.173502\n",
            "[376/3000] Train Acc: 0.927102 Loss: 0.237677 | Val Acc: 0.134879 loss: 5.097870\n",
            "[377/3000] Train Acc: 0.927858 Loss: 0.236120 | Val Acc: 0.125202 loss: 5.127100\n",
            "[378/3000] Train Acc: 0.928715 Loss: 0.233277 | Val Acc: 0.126008 loss: 5.184638\n",
            "[379/3000] Train Acc: 0.927354 Loss: 0.235232 | Val Acc: 0.131250 loss: 5.304374\n",
            "[380/3000] Train Acc: 0.928867 Loss: 0.233263 | Val Acc: 0.136895 loss: 5.292617\n",
            "[381/3000] Train Acc: 0.929270 Loss: 0.232251 | Val Acc: 0.137702 loss: 5.205680\n",
            "[382/3000] Train Acc: 0.927758 Loss: 0.232203 | Val Acc: 0.139516 loss: 4.978735\n",
            "[383/3000] Train Acc: 0.929572 Loss: 0.229373 | Val Acc: 0.139516 loss: 5.207235\n",
            "[384/3000] Train Acc: 0.930682 Loss: 0.228137 | Val Acc: 0.133669 loss: 5.159932\n",
            "[385/3000] Train Acc: 0.928816 Loss: 0.229859 | Val Acc: 0.138911 loss: 5.209774\n",
            "[386/3000] Train Acc: 0.932144 Loss: 0.227035 | Val Acc: 0.141331 loss: 5.151377\n",
            "[387/3000] Train Acc: 0.931438 Loss: 0.225515 | Val Acc: 0.128831 loss: 5.252240\n",
            "[388/3000] Train Acc: 0.932799 Loss: 0.223192 | Val Acc: 0.142137 loss: 4.957373\n",
            "[389/3000] Train Acc: 0.933606 Loss: 0.219327 | Val Acc: 0.133871 loss: 5.209044\n",
            "[390/3000] Train Acc: 0.931791 Loss: 0.220049 | Val Acc: 0.136290 loss: 5.225321\n",
            "[391/3000] Train Acc: 0.932496 Loss: 0.220695 | Val Acc: 0.133468 loss: 5.213695\n",
            "[392/3000] Train Acc: 0.931186 Loss: 0.219398 | Val Acc: 0.136492 loss: 5.409491\n",
            "[393/3000] Train Acc: 0.934412 Loss: 0.215674 | Val Acc: 0.131452 loss: 5.229343\n",
            "[394/3000] Train Acc: 0.933706 Loss: 0.219497 | Val Acc: 0.128226 loss: 5.183812\n",
            "[395/3000] Train Acc: 0.935572 Loss: 0.214814 | Val Acc: 0.142339 loss: 5.109928\n",
            "[396/3000] Train Acc: 0.935673 Loss: 0.212543 | Val Acc: 0.133266 loss: 4.987563\n",
            "[397/3000] Train Acc: 0.934815 Loss: 0.213162 | Val Acc: 0.134073 loss: 5.213837\n",
            "[398/3000] Train Acc: 0.934463 Loss: 0.214525 | Val Acc: 0.133871 loss: 5.210782\n",
            "[399/3000] Train Acc: 0.934412 Loss: 0.211138 | Val Acc: 0.129637 loss: 5.308226\n",
            "[400/3000] Train Acc: 0.936328 Loss: 0.209833 | Val Acc: 0.127823 loss: 5.226245\n",
            "[401/3000] Train Acc: 0.936731 Loss: 0.207423 | Val Acc: 0.138508 loss: 5.096552\n",
            "[402/3000] Train Acc: 0.936378 Loss: 0.208901 | Val Acc: 0.128831 loss: 5.014361\n",
            "[403/3000] Train Acc: 0.938849 Loss: 0.205892 | Val Acc: 0.137298 loss: 5.382758\n",
            "[404/3000] Train Acc: 0.936933 Loss: 0.206242 | Val Acc: 0.126815 loss: 5.113688\n",
            "[405/3000] Train Acc: 0.937639 Loss: 0.205030 | Val Acc: 0.127218 loss: 5.217868\n",
            "[406/3000] Train Acc: 0.937689 Loss: 0.204521 | Val Acc: 0.137298 loss: 5.117311\n",
            "[407/3000] Train Acc: 0.940210 Loss: 0.200631 | Val Acc: 0.148185 loss: 5.317482\n",
            "saving model with acc 0.148\n",
            "[408/3000] Train Acc: 0.940714 Loss: 0.200170 | Val Acc: 0.135282 loss: 5.236615\n",
            "[409/3000] Train Acc: 0.939756 Loss: 0.198281 | Val Acc: 0.130040 loss: 5.460147\n",
            "[410/3000] Train Acc: 0.941117 Loss: 0.197596 | Val Acc: 0.127621 loss: 5.216002\n",
            "[411/3000] Train Acc: 0.942025 Loss: 0.196305 | Val Acc: 0.135685 loss: 5.174776\n",
            "[412/3000] Train Acc: 0.941016 Loss: 0.197295 | Val Acc: 0.132056 loss: 5.241911\n",
            "[413/3000] Train Acc: 0.939201 Loss: 0.196334 | Val Acc: 0.138508 loss: 5.308784\n",
            "[414/3000] Train Acc: 0.940714 Loss: 0.194996 | Val Acc: 0.143548 loss: 5.262671\n",
            "[415/3000] Train Acc: 0.940159 Loss: 0.195424 | Val Acc: 0.140524 loss: 5.169439\n",
            "[416/3000] Train Acc: 0.943083 Loss: 0.191113 | Val Acc: 0.124798 loss: 5.345066\n",
            "[417/3000] Train Acc: 0.944545 Loss: 0.190342 | Val Acc: 0.139516 loss: 5.033983\n",
            "[418/3000] Train Acc: 0.943940 Loss: 0.188113 | Val Acc: 0.133266 loss: 5.223031\n",
            "[419/3000] Train Acc: 0.943587 Loss: 0.189080 | Val Acc: 0.130444 loss: 5.422730\n",
            "[420/3000] Train Acc: 0.944092 Loss: 0.187095 | Val Acc: 0.134274 loss: 5.167992\n",
            "[421/3000] Train Acc: 0.943940 Loss: 0.187284 | Val Acc: 0.132056 loss: 5.012143\n",
            "[422/3000] Train Acc: 0.944797 Loss: 0.186463 | Val Acc: 0.141532 loss: 5.143460\n",
            "[423/3000] Train Acc: 0.944495 Loss: 0.186393 | Val Acc: 0.136492 loss: 5.412696\n",
            "[424/3000] Train Acc: 0.946411 Loss: 0.182340 | Val Acc: 0.140323 loss: 5.129253\n",
            "[425/3000] Train Acc: 0.945352 Loss: 0.183300 | Val Acc: 0.141129 loss: 5.365835\n",
            "[426/3000] Train Acc: 0.946007 Loss: 0.183129 | Val Acc: 0.136290 loss: 5.182097\n",
            "[427/3000] Train Acc: 0.947066 Loss: 0.178521 | Val Acc: 0.131048 loss: 5.365011\n",
            "[428/3000] Train Acc: 0.946259 Loss: 0.180506 | Val Acc: 0.131250 loss: 5.204568\n",
            "[429/3000] Train Acc: 0.947368 Loss: 0.177661 | Val Acc: 0.130645 loss: 5.301751\n",
            "[430/3000] Train Acc: 0.947822 Loss: 0.179402 | Val Acc: 0.119355 loss: 5.282049\n",
            "[431/3000] Train Acc: 0.947167 Loss: 0.177135 | Val Acc: 0.140121 loss: 5.207557\n",
            "[432/3000] Train Acc: 0.948225 Loss: 0.175862 | Val Acc: 0.139516 loss: 5.360090\n",
            "[433/3000] Train Acc: 0.947671 Loss: 0.176808 | Val Acc: 0.134073 loss: 5.468401\n",
            "[434/3000] Train Acc: 0.949687 Loss: 0.172187 | Val Acc: 0.140323 loss: 5.117117\n",
            "[435/3000] Train Acc: 0.947167 Loss: 0.174022 | Val Acc: 0.124798 loss: 5.304894\n",
            "[436/3000] Train Acc: 0.948125 Loss: 0.174694 | Val Acc: 0.140927 loss: 5.222632\n",
            "[437/3000] Train Acc: 0.950444 Loss: 0.170392 | Val Acc: 0.140927 loss: 5.407149\n",
            "[438/3000] Train Acc: 0.950797 Loss: 0.169746 | Val Acc: 0.136492 loss: 5.167050\n",
            "[439/3000] Train Acc: 0.947469 Loss: 0.174589 | Val Acc: 0.135484 loss: 5.305932\n",
            "[440/3000] Train Acc: 0.949738 Loss: 0.169003 | Val Acc: 0.139315 loss: 5.392937\n",
            "[441/3000] Train Acc: 0.951049 Loss: 0.167908 | Val Acc: 0.145766 loss: 5.496338\n",
            "[442/3000] Train Acc: 0.950797 Loss: 0.166230 | Val Acc: 0.139113 loss: 5.261432\n",
            "[443/3000] Train Acc: 0.953216 Loss: 0.163902 | Val Acc: 0.137500 loss: 5.555387\n",
            "[444/3000] Train Acc: 0.952763 Loss: 0.163874 | Val Acc: 0.140726 loss: 5.559424\n",
            "[445/3000] Train Acc: 0.952309 Loss: 0.163016 | Val Acc: 0.127621 loss: 5.166044\n",
            "[446/3000] Train Acc: 0.951754 Loss: 0.163810 | Val Acc: 0.129839 loss: 5.383999\n",
            "[447/3000] Train Acc: 0.953620 Loss: 0.161852 | Val Acc: 0.145968 loss: 5.295506\n",
            "[448/3000] Train Acc: 0.953166 Loss: 0.163057 | Val Acc: 0.137702 loss: 5.377544\n",
            "[449/3000] Train Acc: 0.954225 Loss: 0.159162 | Val Acc: 0.141129 loss: 5.493585\n",
            "[450/3000] Train Acc: 0.952611 Loss: 0.159641 | Val Acc: 0.141532 loss: 5.176667\n",
            "[451/3000] Train Acc: 0.954578 Loss: 0.157518 | Val Acc: 0.138105 loss: 5.343295\n",
            "[452/3000] Train Acc: 0.953166 Loss: 0.159644 | Val Acc: 0.132460 loss: 5.210801\n",
            "[453/3000] Train Acc: 0.954830 Loss: 0.155387 | Val Acc: 0.142540 loss: 5.313712\n",
            "[454/3000] Train Acc: 0.954779 Loss: 0.155352 | Val Acc: 0.138306 loss: 5.208113\n",
            "[455/3000] Train Acc: 0.954830 Loss: 0.155168 | Val Acc: 0.137702 loss: 5.553900\n",
            "[456/3000] Train Acc: 0.953267 Loss: 0.155777 | Val Acc: 0.134073 loss: 5.367110\n",
            "[457/3000] Train Acc: 0.958207 Loss: 0.150433 | Val Acc: 0.143548 loss: 5.288999\n",
            "[458/3000] Train Acc: 0.957703 Loss: 0.150031 | Val Acc: 0.131048 loss: 5.434167\n",
            "[459/3000] Train Acc: 0.955787 Loss: 0.152901 | Val Acc: 0.135081 loss: 5.351719\n",
            "[460/3000] Train Acc: 0.956745 Loss: 0.148714 | Val Acc: 0.138508 loss: 5.390294\n",
            "[461/3000] Train Acc: 0.957249 Loss: 0.151324 | Val Acc: 0.142339 loss: 5.372708\n",
            "[462/3000] Train Acc: 0.957955 Loss: 0.147650 | Val Acc: 0.129234 loss: 5.409482\n",
            "[463/3000] Train Acc: 0.957048 Loss: 0.148297 | Val Acc: 0.135081 loss: 5.392992\n",
            "[464/3000] Train Acc: 0.958711 Loss: 0.146467 | Val Acc: 0.135081 loss: 5.219337\n",
            "[465/3000] Train Acc: 0.957804 Loss: 0.147238 | Val Acc: 0.145766 loss: 5.470954\n",
            "[466/3000] Train Acc: 0.959165 Loss: 0.145724 | Val Acc: 0.144153 loss: 5.579987\n",
            "[467/3000] Train Acc: 0.959720 Loss: 0.142033 | Val Acc: 0.137702 loss: 5.063861\n",
            "[468/3000] Train Acc: 0.957451 Loss: 0.146644 | Val Acc: 0.140121 loss: 5.207067\n",
            "[469/3000] Train Acc: 0.959216 Loss: 0.142280 | Val Acc: 0.138710 loss: 5.246531\n",
            "[470/3000] Train Acc: 0.959972 Loss: 0.141403 | Val Acc: 0.139113 loss: 5.482464\n",
            "[471/3000] Train Acc: 0.959165 Loss: 0.143051 | Val Acc: 0.134879 loss: 5.319287\n",
            "[472/3000] Train Acc: 0.960274 Loss: 0.140650 | Val Acc: 0.141129 loss: 5.400376\n",
            "[473/3000] Train Acc: 0.959871 Loss: 0.139511 | Val Acc: 0.128024 loss: 5.316494\n",
            "[474/3000] Train Acc: 0.960728 Loss: 0.139449 | Val Acc: 0.145565 loss: 5.327624\n",
            "[475/3000] Train Acc: 0.959367 Loss: 0.140894 | Val Acc: 0.142540 loss: 5.561995\n",
            "[476/3000] Train Acc: 0.962442 Loss: 0.135157 | Val Acc: 0.140726 loss: 5.420482\n",
            "[477/3000] Train Acc: 0.963400 Loss: 0.134038 | Val Acc: 0.135685 loss: 5.519051\n",
            "[478/3000] Train Acc: 0.962694 Loss: 0.135867 | Val Acc: 0.146976 loss: 5.247407\n",
            "[479/3000] Train Acc: 0.962392 Loss: 0.135889 | Val Acc: 0.137500 loss: 5.390995\n",
            "[480/3000] Train Acc: 0.961232 Loss: 0.136009 | Val Acc: 0.143750 loss: 5.218113\n",
            "[481/3000] Train Acc: 0.961585 Loss: 0.134265 | Val Acc: 0.132661 loss: 5.544024\n",
            "[482/3000] Train Acc: 0.962543 Loss: 0.135495 | Val Acc: 0.143548 loss: 5.208067\n",
            "[483/3000] Train Acc: 0.964106 Loss: 0.131492 | Val Acc: 0.136895 loss: 5.510429\n",
            "[484/3000] Train Acc: 0.963501 Loss: 0.130340 | Val Acc: 0.141734 loss: 5.439784\n",
            "[485/3000] Train Acc: 0.962392 Loss: 0.132915 | Val Acc: 0.135282 loss: 5.396119\n",
            "[486/3000] Train Acc: 0.963501 Loss: 0.128376 | Val Acc: 0.133468 loss: 5.483272\n",
            "[487/3000] Train Acc: 0.961283 Loss: 0.134307 | Val Acc: 0.132056 loss: 5.755698\n",
            "[488/3000] Train Acc: 0.962997 Loss: 0.131219 | Val Acc: 0.145363 loss: 5.357230\n",
            "[489/3000] Train Acc: 0.963904 Loss: 0.128214 | Val Acc: 0.143952 loss: 5.230959\n",
            "[490/3000] Train Acc: 0.965467 Loss: 0.125749 | Val Acc: 0.142137 loss: 5.361401\n",
            "[491/3000] Train Acc: 0.966021 Loss: 0.124394 | Val Acc: 0.132460 loss: 5.527506\n",
            "[492/3000] Train Acc: 0.964610 Loss: 0.127014 | Val Acc: 0.142137 loss: 5.490255\n",
            "[493/3000] Train Acc: 0.965265 Loss: 0.125662 | Val Acc: 0.138508 loss: 5.448901\n",
            "[494/3000] Train Acc: 0.966021 Loss: 0.122949 | Val Acc: 0.131653 loss: 5.540125\n",
            "[495/3000] Train Acc: 0.967030 Loss: 0.121171 | Val Acc: 0.142540 loss: 5.282952\n",
            "[496/3000] Train Acc: 0.967231 Loss: 0.122600 | Val Acc: 0.144556 loss: 5.552793\n",
            "[497/3000] Train Acc: 0.966677 Loss: 0.120500 | Val Acc: 0.130444 loss: 5.543737\n",
            "[498/3000] Train Acc: 0.967231 Loss: 0.120201 | Val Acc: 0.150806 loss: 5.431887\n",
            "saving model with acc 0.151\n",
            "[499/3000] Train Acc: 0.966425 Loss: 0.122028 | Val Acc: 0.141935 loss: 5.616336\n",
            "[500/3000] Train Acc: 0.967030 Loss: 0.120842 | Val Acc: 0.145363 loss: 5.527501\n",
            "[501/3000] Train Acc: 0.965870 Loss: 0.120907 | Val Acc: 0.139516 loss: 5.600117\n",
            "[502/3000] Train Acc: 0.967483 Loss: 0.119201 | Val Acc: 0.135484 loss: 5.498468\n",
            "[503/3000] Train Acc: 0.968441 Loss: 0.117229 | Val Acc: 0.136290 loss: 5.434354\n",
            "[504/3000] Train Acc: 0.967534 Loss: 0.117122 | Val Acc: 0.137097 loss: 5.605358\n",
            "[505/3000] Train Acc: 0.968895 Loss: 0.116176 | Val Acc: 0.144556 loss: 5.323197\n",
            "[506/3000] Train Acc: 0.967887 Loss: 0.115425 | Val Acc: 0.143750 loss: 5.539873\n",
            "[507/3000] Train Acc: 0.969550 Loss: 0.113825 | Val Acc: 0.141129 loss: 5.531885\n",
            "[508/3000] Train Acc: 0.967786 Loss: 0.115801 | Val Acc: 0.142742 loss: 5.267568\n",
            "[509/3000] Train Acc: 0.968592 Loss: 0.114327 | Val Acc: 0.138911 loss: 5.629948\n",
            "[510/3000] Train Acc: 0.968693 Loss: 0.112542 | Val Acc: 0.130040 loss: 5.625895\n",
            "[511/3000] Train Acc: 0.970105 Loss: 0.111789 | Val Acc: 0.146371 loss: 5.572875\n",
            "[512/3000] Train Acc: 0.970307 Loss: 0.112811 | Val Acc: 0.142944 loss: 5.566053\n",
            "[513/3000] Train Acc: 0.970760 Loss: 0.110661 | Val Acc: 0.145363 loss: 5.480658\n",
            "[514/3000] Train Acc: 0.971315 Loss: 0.109022 | Val Acc: 0.142742 loss: 5.524849\n",
            "[515/3000] Train Acc: 0.971668 Loss: 0.107704 | Val Acc: 0.143145 loss: 5.451589\n",
            "[516/3000] Train Acc: 0.971113 Loss: 0.108118 | Val Acc: 0.128629 loss: 5.573069\n",
            "[517/3000] Train Acc: 0.970861 Loss: 0.107371 | Val Acc: 0.143347 loss: 5.688448\n",
            "[518/3000] Train Acc: 0.971113 Loss: 0.105855 | Val Acc: 0.137903 loss: 5.635347\n",
            "[519/3000] Train Acc: 0.971869 Loss: 0.105916 | Val Acc: 0.141331 loss: 5.461214\n",
            "[520/3000] Train Acc: 0.973432 Loss: 0.104910 | Val Acc: 0.126411 loss: 5.860861\n",
            "[521/3000] Train Acc: 0.971466 Loss: 0.106721 | Val Acc: 0.139315 loss: 5.822472\n",
            "[522/3000] Train Acc: 0.972928 Loss: 0.103178 | Val Acc: 0.136895 loss: 5.476110\n",
            "[523/3000] Train Acc: 0.972676 Loss: 0.101847 | Val Acc: 0.131653 loss: 5.624707\n",
            "[524/3000] Train Acc: 0.971012 Loss: 0.103694 | Val Acc: 0.141129 loss: 5.421160\n",
            "[525/3000] Train Acc: 0.972978 Loss: 0.101919 | Val Acc: 0.134677 loss: 5.449635\n",
            "[526/3000] Train Acc: 0.973079 Loss: 0.102522 | Val Acc: 0.153024 loss: 5.836750\n",
            "saving model with acc 0.153\n",
            "[527/3000] Train Acc: 0.972626 Loss: 0.104051 | Val Acc: 0.147984 loss: 5.644266\n",
            "[528/3000] Train Acc: 0.972978 Loss: 0.099802 | Val Acc: 0.141935 loss: 5.749700\n",
            "[529/3000] Train Acc: 0.973180 Loss: 0.099756 | Val Acc: 0.141129 loss: 5.752399\n",
            "[530/3000] Train Acc: 0.971264 Loss: 0.104190 | Val Acc: 0.138508 loss: 5.830426\n",
            "[531/3000] Train Acc: 0.972777 Loss: 0.099146 | Val Acc: 0.139113 loss: 5.619925\n",
            "[532/3000] Train Acc: 0.974995 Loss: 0.096905 | Val Acc: 0.144758 loss: 5.515195\n",
            "[533/3000] Train Acc: 0.974592 Loss: 0.097621 | Val Acc: 0.142339 loss: 5.778464\n",
            "[534/3000] Train Acc: 0.974793 Loss: 0.096430 | Val Acc: 0.132863 loss: 5.499057\n",
            "[535/3000] Train Acc: 0.976255 Loss: 0.094250 | Val Acc: 0.139113 loss: 5.617320\n",
            "[536/3000] Train Acc: 0.974743 Loss: 0.095930 | Val Acc: 0.144556 loss: 5.801170\n",
            "[537/3000] Train Acc: 0.975550 Loss: 0.094610 | Val Acc: 0.135484 loss: 5.987302\n",
            "[538/3000] Train Acc: 0.975550 Loss: 0.093272 | Val Acc: 0.143548 loss: 5.375935\n",
            "[539/3000] Train Acc: 0.976558 Loss: 0.092878 | Val Acc: 0.143548 loss: 5.828871\n",
            "[540/3000] Train Acc: 0.974088 Loss: 0.095441 | Val Acc: 0.142944 loss: 5.709410\n",
            "[541/3000] Train Acc: 0.976306 Loss: 0.092830 | Val Acc: 0.140524 loss: 5.475548\n",
            "[542/3000] Train Acc: 0.976003 Loss: 0.091310 | Val Acc: 0.138710 loss: 5.611884\n",
            "[543/3000] Train Acc: 0.975953 Loss: 0.091179 | Val Acc: 0.139718 loss: 5.538797\n",
            "[544/3000] Train Acc: 0.975297 Loss: 0.093607 | Val Acc: 0.142540 loss: 5.627032\n",
            "[545/3000] Train Acc: 0.977717 Loss: 0.087305 | Val Acc: 0.143750 loss: 5.833644\n",
            "[546/3000] Train Acc: 0.975701 Loss: 0.089926 | Val Acc: 0.143952 loss: 5.591991\n",
            "[547/3000] Train Acc: 0.976003 Loss: 0.089936 | Val Acc: 0.143750 loss: 5.870121\n",
            "[548/3000] Train Acc: 0.975852 Loss: 0.092443 | Val Acc: 0.140726 loss: 5.623849\n",
            "[549/3000] Train Acc: 0.977768 Loss: 0.086446 | Val Acc: 0.142742 loss: 6.010552\n",
            "[550/3000] Train Acc: 0.977667 Loss: 0.085499 | Val Acc: 0.147782 loss: 5.656572\n",
            "[551/3000] Train Acc: 0.976608 Loss: 0.087745 | Val Acc: 0.145363 loss: 5.643002\n",
            "[552/3000] Train Acc: 0.978373 Loss: 0.086072 | Val Acc: 0.142742 loss: 5.653257\n",
            "[553/3000] Train Acc: 0.979028 Loss: 0.084726 | Val Acc: 0.141532 loss: 5.621230\n",
            "[554/3000] Train Acc: 0.978272 Loss: 0.084842 | Val Acc: 0.144153 loss: 5.901294\n",
            "[555/3000] Train Acc: 0.978726 Loss: 0.083366 | Val Acc: 0.146169 loss: 5.630716\n",
            "[556/3000] Train Acc: 0.978373 Loss: 0.085550 | Val Acc: 0.151210 loss: 5.914627\n",
            "[557/3000] Train Acc: 0.978826 Loss: 0.083924 | Val Acc: 0.145766 loss: 5.760126\n",
            "[558/3000] Train Acc: 0.977163 Loss: 0.085391 | Val Acc: 0.144556 loss: 5.852832\n",
            "[559/3000] Train Acc: 0.978978 Loss: 0.083193 | Val Acc: 0.139113 loss: 5.991568\n",
            "[560/3000] Train Acc: 0.979683 Loss: 0.079815 | Val Acc: 0.134879 loss: 6.037045\n",
            "[561/3000] Train Acc: 0.979381 Loss: 0.081696 | Val Acc: 0.136089 loss: 5.753074\n",
            "[562/3000] Train Acc: 0.980238 Loss: 0.080561 | Val Acc: 0.146774 loss: 5.864354\n",
            "[563/3000] Train Acc: 0.978373 Loss: 0.081691 | Val Acc: 0.145968 loss: 5.861668\n",
            "[564/3000] Train Acc: 0.979683 Loss: 0.079022 | Val Acc: 0.154234 loss: 5.854215\n",
            "saving model with acc 0.154\n",
            "[565/3000] Train Acc: 0.978826 Loss: 0.081429 | Val Acc: 0.141532 loss: 5.832986\n",
            "[566/3000] Train Acc: 0.980339 Loss: 0.078045 | Val Acc: 0.143750 loss: 5.642814\n",
            "[567/3000] Train Acc: 0.980591 Loss: 0.076458 | Val Acc: 0.142742 loss: 5.670211\n",
            "[568/3000] Train Acc: 0.980540 Loss: 0.077223 | Val Acc: 0.140323 loss: 5.885666\n",
            "[569/3000] Train Acc: 0.980490 Loss: 0.077816 | Val Acc: 0.143952 loss: 5.829727\n",
            "[570/3000] Train Acc: 0.980843 Loss: 0.077544 | Val Acc: 0.138508 loss: 6.154781\n",
            "[571/3000] Train Acc: 0.979331 Loss: 0.078310 | Val Acc: 0.143548 loss: 5.875681\n",
            "[572/3000] Train Acc: 0.980591 Loss: 0.076379 | Val Acc: 0.142944 loss: 5.654286\n",
            "[573/3000] Train Acc: 0.981549 Loss: 0.074548 | Val Acc: 0.153629 loss: 5.730177\n",
            "[574/3000] Train Acc: 0.981700 Loss: 0.073734 | Val Acc: 0.153629 loss: 5.949372\n",
            "[575/3000] Train Acc: 0.981145 Loss: 0.074683 | Val Acc: 0.146573 loss: 5.848948\n",
            "[576/3000] Train Acc: 0.981246 Loss: 0.074718 | Val Acc: 0.146573 loss: 5.736782\n",
            "[577/3000] Train Acc: 0.981347 Loss: 0.074195 | Val Acc: 0.146169 loss: 5.838233\n",
            "[578/3000] Train Acc: 0.980641 Loss: 0.075124 | Val Acc: 0.145565 loss: 6.122720\n",
            "[579/3000] Train Acc: 0.982002 Loss: 0.072353 | Val Acc: 0.143548 loss: 5.943832\n",
            "[580/3000] Train Acc: 0.981095 Loss: 0.072129 | Val Acc: 0.157056 loss: 5.540122\n",
            "saving model with acc 0.157\n",
            "[581/3000] Train Acc: 0.983414 Loss: 0.069620 | Val Acc: 0.150605 loss: 5.710515\n",
            "[582/3000] Train Acc: 0.982406 Loss: 0.070386 | Val Acc: 0.148790 loss: 5.873515\n",
            "[583/3000] Train Acc: 0.982254 Loss: 0.070716 | Val Acc: 0.155040 loss: 5.650196\n",
            "[584/3000] Train Acc: 0.983817 Loss: 0.068332 | Val Acc: 0.141734 loss: 5.888825\n",
            "[585/3000] Train Acc: 0.981750 Loss: 0.071384 | Val Acc: 0.143548 loss: 5.981042\n",
            "[586/3000] Train Acc: 0.981498 Loss: 0.072300 | Val Acc: 0.143347 loss: 5.686020\n",
            "[587/3000] Train Acc: 0.982759 Loss: 0.068486 | Val Acc: 0.147581 loss: 6.000167\n",
            "[588/3000] Train Acc: 0.982355 Loss: 0.068941 | Val Acc: 0.149194 loss: 5.915441\n",
            "[589/3000] Train Acc: 0.984170 Loss: 0.066268 | Val Acc: 0.148992 loss: 5.777674\n",
            "[590/3000] Train Acc: 0.983817 Loss: 0.067139 | Val Acc: 0.145161 loss: 5.923195\n",
            "[591/3000] Train Acc: 0.983364 Loss: 0.066510 | Val Acc: 0.144758 loss: 6.036409\n",
            "[592/3000] Train Acc: 0.984271 Loss: 0.065026 | Val Acc: 0.135887 loss: 6.243470\n",
            "[593/3000] Train Acc: 0.982658 Loss: 0.067689 | Val Acc: 0.145363 loss: 6.062632\n",
            "[594/3000] Train Acc: 0.983969 Loss: 0.066136 | Val Acc: 0.141532 loss: 6.257394\n",
            "[595/3000] Train Acc: 0.984473 Loss: 0.063878 | Val Acc: 0.136694 loss: 6.139157\n",
            "[596/3000] Train Acc: 0.983666 Loss: 0.063905 | Val Acc: 0.147782 loss: 5.904294\n",
            "[597/3000] Train Acc: 0.983212 Loss: 0.065260 | Val Acc: 0.142742 loss: 6.080066\n",
            "[598/3000] Train Acc: 0.983112 Loss: 0.065670 | Val Acc: 0.154637 loss: 5.832937\n",
            "[599/3000] Train Acc: 0.984069 Loss: 0.062532 | Val Acc: 0.146169 loss: 6.034523\n",
            "[600/3000] Train Acc: 0.984977 Loss: 0.062822 | Val Acc: 0.152016 loss: 5.894452\n",
            "[601/3000] Train Acc: 0.984826 Loss: 0.061649 | Val Acc: 0.153427 loss: 5.918067\n",
            "[602/3000] Train Acc: 0.985078 Loss: 0.061633 | Val Acc: 0.143750 loss: 6.288621\n",
            "[603/3000] Train Acc: 0.985380 Loss: 0.061155 | Val Acc: 0.148992 loss: 5.920733\n",
            "[604/3000] Train Acc: 0.985531 Loss: 0.060603 | Val Acc: 0.148992 loss: 5.845375\n",
            "[605/3000] Train Acc: 0.985884 Loss: 0.058563 | Val Acc: 0.145565 loss: 6.243202\n",
            "[606/3000] Train Acc: 0.984120 Loss: 0.063022 | Val Acc: 0.150403 loss: 6.114615\n",
            "[607/3000] Train Acc: 0.985330 Loss: 0.059167 | Val Acc: 0.140927 loss: 6.003182\n",
            "[608/3000] Train Acc: 0.986187 Loss: 0.057580 | Val Acc: 0.141532 loss: 6.034272\n",
            "[609/3000] Train Acc: 0.985733 Loss: 0.059546 | Val Acc: 0.149597 loss: 6.068784\n",
            "[610/3000] Train Acc: 0.985683 Loss: 0.060510 | Val Acc: 0.150806 loss: 5.886342\n",
            "[611/3000] Train Acc: 0.984826 Loss: 0.060373 | Val Acc: 0.155847 loss: 5.751752\n",
            "[612/3000] Train Acc: 0.986288 Loss: 0.056420 | Val Acc: 0.151008 loss: 5.889185\n",
            "[613/3000] Train Acc: 0.987145 Loss: 0.056114 | Val Acc: 0.148185 loss: 6.093550\n",
            "[614/3000] Train Acc: 0.985783 Loss: 0.057835 | Val Acc: 0.153226 loss: 6.170876\n",
            "[615/3000] Train Acc: 0.987044 Loss: 0.056217 | Val Acc: 0.155040 loss: 6.095287\n",
            "[616/3000] Train Acc: 0.986590 Loss: 0.056634 | Val Acc: 0.154435 loss: 6.114720\n",
            "[617/3000] Train Acc: 0.986893 Loss: 0.056106 | Val Acc: 0.144758 loss: 6.195203\n",
            "[618/3000] Train Acc: 0.985582 Loss: 0.057316 | Val Acc: 0.162903 loss: 5.787677\n",
            "saving model with acc 0.163\n",
            "[619/3000] Train Acc: 0.986338 Loss: 0.055458 | Val Acc: 0.147984 loss: 5.998334\n",
            "[620/3000] Train Acc: 0.987699 Loss: 0.054267 | Val Acc: 0.150403 loss: 6.370867\n",
            "[621/3000] Train Acc: 0.988153 Loss: 0.052264 | Val Acc: 0.147581 loss: 6.379095\n",
            "[622/3000] Train Acc: 0.986792 Loss: 0.054603 | Val Acc: 0.155444 loss: 6.139555\n",
            "[623/3000] Train Acc: 0.986439 Loss: 0.054527 | Val Acc: 0.151815 loss: 6.145320\n",
            "[624/3000] Train Acc: 0.987750 Loss: 0.052320 | Val Acc: 0.151210 loss: 5.966767\n",
            "[625/3000] Train Acc: 0.987850 Loss: 0.051803 | Val Acc: 0.157863 loss: 6.053109\n",
            "[626/3000] Train Acc: 0.988203 Loss: 0.050747 | Val Acc: 0.148790 loss: 5.923790\n",
            "[627/3000] Train Acc: 0.988455 Loss: 0.050920 | Val Acc: 0.153226 loss: 6.113822\n",
            "[628/3000] Train Acc: 0.987951 Loss: 0.051383 | Val Acc: 0.160685 loss: 5.985560\n",
            "[629/3000] Train Acc: 0.988909 Loss: 0.051262 | Val Acc: 0.151815 loss: 6.242126\n",
            "[630/3000] Train Acc: 0.988102 Loss: 0.051795 | Val Acc: 0.151008 loss: 6.126080\n",
            "[631/3000] Train Acc: 0.987850 Loss: 0.051669 | Val Acc: 0.147581 loss: 6.331217\n",
            "[632/3000] Train Acc: 0.987145 Loss: 0.050902 | Val Acc: 0.149798 loss: 6.181653\n",
            "[633/3000] Train Acc: 0.988959 Loss: 0.049157 | Val Acc: 0.154435 loss: 6.232036\n",
            "[634/3000] Train Acc: 0.988102 Loss: 0.049154 | Val Acc: 0.153024 loss: 6.177637\n",
            "[635/3000] Train Acc: 0.987245 Loss: 0.051540 | Val Acc: 0.136694 loss: 6.440106\n",
            "[636/3000] Train Acc: 0.989262 Loss: 0.047658 | Val Acc: 0.150403 loss: 6.269929\n",
            "[637/3000] Train Acc: 0.987145 Loss: 0.051739 | Val Acc: 0.152218 loss: 6.253532\n",
            "[638/3000] Train Acc: 0.988455 Loss: 0.049024 | Val Acc: 0.149395 loss: 6.446230\n",
            "[639/3000] Train Acc: 0.989766 Loss: 0.046236 | Val Acc: 0.146976 loss: 6.604197\n",
            "[640/3000] Train Acc: 0.988254 Loss: 0.047123 | Val Acc: 0.154032 loss: 6.146903\n",
            "[641/3000] Train Acc: 0.989867 Loss: 0.045420 | Val Acc: 0.158669 loss: 6.227477\n",
            "[642/3000] Train Acc: 0.988959 Loss: 0.046808 | Val Acc: 0.163508 loss: 6.070046\n",
            "saving model with acc 0.164\n",
            "[643/3000] Train Acc: 0.988455 Loss: 0.048206 | Val Acc: 0.162702 loss: 5.820792\n",
            "[644/3000] Train Acc: 0.988707 Loss: 0.046428 | Val Acc: 0.153024 loss: 6.381061\n",
            "[645/3000] Train Acc: 0.989212 Loss: 0.045447 | Val Acc: 0.151210 loss: 6.542767\n",
            "[646/3000] Train Acc: 0.989917 Loss: 0.043639 | Val Acc: 0.155040 loss: 6.259508\n",
            "[647/3000] Train Acc: 0.989615 Loss: 0.044715 | Val Acc: 0.143145 loss: 6.241875\n",
            "[648/3000] Train Acc: 0.990573 Loss: 0.044240 | Val Acc: 0.153427 loss: 5.994129\n",
            "[649/3000] Train Acc: 0.990774 Loss: 0.042106 | Val Acc: 0.157258 loss: 6.187221\n",
            "[650/3000] Train Acc: 0.989464 Loss: 0.044345 | Val Acc: 0.158669 loss: 6.410808\n",
            "[651/3000] Train Acc: 0.989010 Loss: 0.044464 | Val Acc: 0.154435 loss: 6.288103\n",
            "[652/3000] Train Acc: 0.990270 Loss: 0.042499 | Val Acc: 0.153024 loss: 6.500595\n",
            "[653/3000] Train Acc: 0.989615 Loss: 0.045597 | Val Acc: 0.156452 loss: 6.398808\n",
            "[654/3000] Train Acc: 0.988657 Loss: 0.045276 | Val Acc: 0.156250 loss: 6.295640\n",
            "[655/3000] Train Acc: 0.990069 Loss: 0.042694 | Val Acc: 0.161694 loss: 6.392395\n",
            "[656/3000] Train Acc: 0.991379 Loss: 0.039568 | Val Acc: 0.155040 loss: 6.345718\n",
            "[657/3000] Train Acc: 0.990774 Loss: 0.042208 | Val Acc: 0.153427 loss: 6.372433\n",
            "[658/3000] Train Acc: 0.990724 Loss: 0.039618 | Val Acc: 0.142339 loss: 6.685808\n",
            "[659/3000] Train Acc: 0.990421 Loss: 0.040503 | Val Acc: 0.173185 loss: 5.950250\n",
            "saving model with acc 0.173\n",
            "[660/3000] Train Acc: 0.990270 Loss: 0.041229 | Val Acc: 0.153831 loss: 6.345724\n",
            "[661/3000] Train Acc: 0.990573 Loss: 0.040958 | Val Acc: 0.160081 loss: 6.352722\n",
            "[662/3000] Train Acc: 0.990321 Loss: 0.041180 | Val Acc: 0.162702 loss: 6.049576\n",
            "[663/3000] Train Acc: 0.991531 Loss: 0.037746 | Val Acc: 0.152823 loss: 6.246060\n",
            "[664/3000] Train Acc: 0.991480 Loss: 0.037370 | Val Acc: 0.153427 loss: 6.377865\n",
            "[665/3000] Train Acc: 0.991278 Loss: 0.038522 | Val Acc: 0.160887 loss: 6.258271\n",
            "[666/3000] Train Acc: 0.990926 Loss: 0.039760 | Val Acc: 0.155444 loss: 6.379431\n",
            "[667/3000] Train Acc: 0.990623 Loss: 0.040401 | Val Acc: 0.161895 loss: 6.360874\n",
            "[668/3000] Train Acc: 0.990623 Loss: 0.038637 | Val Acc: 0.155040 loss: 6.292786\n",
            "[669/3000] Train Acc: 0.991480 Loss: 0.037153 | Val Acc: 0.166734 loss: 5.867509\n",
            "[670/3000] Train Acc: 0.990522 Loss: 0.040138 | Val Acc: 0.164516 loss: 6.400255\n",
            "[671/3000] Train Acc: 0.990926 Loss: 0.038187 | Val Acc: 0.161694 loss: 6.452093\n",
            "[672/3000] Train Acc: 0.991026 Loss: 0.037716 | Val Acc: 0.158468 loss: 6.495290\n",
            "[673/3000] Train Acc: 0.991430 Loss: 0.035837 | Val Acc: 0.162500 loss: 6.480526\n",
            "[674/3000] Train Acc: 0.991984 Loss: 0.035978 | Val Acc: 0.158266 loss: 6.246572\n",
            "[675/3000] Train Acc: 0.991480 Loss: 0.037054 | Val Acc: 0.150605 loss: 6.611976\n",
            "[676/3000] Train Acc: 0.992388 Loss: 0.035348 | Val Acc: 0.159073 loss: 6.389499\n",
            "[677/3000] Train Acc: 0.992337 Loss: 0.034483 | Val Acc: 0.157460 loss: 6.360958\n",
            "[678/3000] Train Acc: 0.992388 Loss: 0.033844 | Val Acc: 0.165726 loss: 6.160793\n",
            "[679/3000] Train Acc: 0.989564 Loss: 0.039293 | Val Acc: 0.153427 loss: 6.507145\n",
            "[680/3000] Train Acc: 0.991531 Loss: 0.035452 | Val Acc: 0.166935 loss: 6.218566\n",
            "[681/3000] Train Acc: 0.991127 Loss: 0.037383 | Val Acc: 0.154234 loss: 6.666385\n",
            "[682/3000] Train Acc: 0.992740 Loss: 0.034275 | Val Acc: 0.159073 loss: 6.504475\n",
            "[683/3000] Train Acc: 0.992337 Loss: 0.033573 | Val Acc: 0.179234 loss: 6.155707\n",
            "saving model with acc 0.179\n",
            "[684/3000] Train Acc: 0.990623 Loss: 0.036597 | Val Acc: 0.153831 loss: 6.410826\n",
            "[685/3000] Train Acc: 0.993043 Loss: 0.031637 | Val Acc: 0.165121 loss: 6.216257\n",
            "[686/3000] Train Acc: 0.992690 Loss: 0.033407 | Val Acc: 0.161492 loss: 6.396346\n",
            "[687/3000] Train Acc: 0.993446 Loss: 0.031351 | Val Acc: 0.158669 loss: 6.545317\n",
            "[688/3000] Train Acc: 0.992589 Loss: 0.034160 | Val Acc: 0.168347 loss: 6.428828\n",
            "[689/3000] Train Acc: 0.993043 Loss: 0.031900 | Val Acc: 0.164113 loss: 6.262809\n",
            "[690/3000] Train Acc: 0.992791 Loss: 0.032628 | Val Acc: 0.147782 loss: 7.045557\n",
            "[691/3000] Train Acc: 0.993043 Loss: 0.031249 | Val Acc: 0.156855 loss: 6.586754\n",
            "[692/3000] Train Acc: 0.993043 Loss: 0.030105 | Val Acc: 0.166331 loss: 6.644535\n",
            "[693/3000] Train Acc: 0.992892 Loss: 0.032993 | Val Acc: 0.155645 loss: 6.725785\n",
            "[694/3000] Train Acc: 0.992740 Loss: 0.032442 | Val Acc: 0.167944 loss: 6.602154\n",
            "[695/3000] Train Acc: 0.993144 Loss: 0.031290 | Val Acc: 0.168952 loss: 6.476703\n",
            "[696/3000] Train Acc: 0.994152 Loss: 0.029212 | Val Acc: 0.159073 loss: 6.545326\n",
            "[697/3000] Train Acc: 0.993900 Loss: 0.029336 | Val Acc: 0.159073 loss: 6.818534\n",
            "[698/3000] Train Acc: 0.992035 Loss: 0.033418 | Val Acc: 0.166532 loss: 6.518145\n",
            "[699/3000] Train Acc: 0.994253 Loss: 0.028172 | Val Acc: 0.161290 loss: 6.799697\n",
            "[700/3000] Train Acc: 0.994303 Loss: 0.028441 | Val Acc: 0.165726 loss: 6.448270\n",
            "[701/3000] Train Acc: 0.993850 Loss: 0.028592 | Val Acc: 0.162500 loss: 6.568403\n",
            "[702/3000] Train Acc: 0.993648 Loss: 0.028864 | Val Acc: 0.161694 loss: 6.481408\n",
            "[703/3000] Train Acc: 0.992388 Loss: 0.031848 | Val Acc: 0.168952 loss: 6.227396\n",
            "[704/3000] Train Acc: 0.994908 Loss: 0.026244 | Val Acc: 0.167540 loss: 6.344782\n",
            "[705/3000] Train Acc: 0.993900 Loss: 0.029219 | Val Acc: 0.162702 loss: 6.778362\n",
            "[706/3000] Train Acc: 0.994505 Loss: 0.026582 | Val Acc: 0.165726 loss: 6.536370\n",
            "[707/3000] Train Acc: 0.993749 Loss: 0.028623 | Val Acc: 0.164718 loss: 6.439445\n",
            "[708/3000] Train Acc: 0.994354 Loss: 0.026881 | Val Acc: 0.169153 loss: 6.495574\n",
            "[709/3000] Train Acc: 0.993547 Loss: 0.028579 | Val Acc: 0.167742 loss: 6.387192\n",
            "[710/3000] Train Acc: 0.993900 Loss: 0.028635 | Val Acc: 0.168347 loss: 6.670725\n",
            "[711/3000] Train Acc: 0.993648 Loss: 0.028669 | Val Acc: 0.161290 loss: 6.752230\n",
            "[712/3000] Train Acc: 0.994959 Loss: 0.026476 | Val Acc: 0.162500 loss: 6.837330\n",
            "[713/3000] Train Acc: 0.994908 Loss: 0.025600 | Val Acc: 0.155444 loss: 7.094981\n",
            "[714/3000] Train Acc: 0.993749 Loss: 0.027981 | Val Acc: 0.166734 loss: 6.602799\n",
            "[715/3000] Train Acc: 0.993547 Loss: 0.027952 | Val Acc: 0.175000 loss: 6.427019\n",
            "[716/3000] Train Acc: 0.995412 Loss: 0.024110 | Val Acc: 0.163306 loss: 6.884019\n",
            "[717/3000] Train Acc: 0.994404 Loss: 0.025519 | Val Acc: 0.159073 loss: 6.772246\n",
            "[718/3000] Train Acc: 0.995312 Loss: 0.025244 | Val Acc: 0.164315 loss: 6.862274\n",
            "[719/3000] Train Acc: 0.995362 Loss: 0.023664 | Val Acc: 0.166935 loss: 6.455846\n",
            "[720/3000] Train Acc: 0.995513 Loss: 0.024597 | Val Acc: 0.161895 loss: 6.644874\n",
            "[721/3000] Train Acc: 0.994757 Loss: 0.025162 | Val Acc: 0.171371 loss: 6.626934\n",
            "[722/3000] Train Acc: 0.994505 Loss: 0.024280 | Val Acc: 0.167540 loss: 6.478205\n",
            "[723/3000] Train Acc: 0.995059 Loss: 0.025621 | Val Acc: 0.155040 loss: 7.303089\n",
            "[724/3000] Train Acc: 0.994404 Loss: 0.027710 | Val Acc: 0.166129 loss: 6.930574\n",
            "[725/3000] Train Acc: 0.995513 Loss: 0.022667 | Val Acc: 0.162500 loss: 6.735298\n",
            "[726/3000] Train Acc: 0.996017 Loss: 0.021687 | Val Acc: 0.162097 loss: 6.593587\n",
            "[727/3000] Train Acc: 0.996521 Loss: 0.021459 | Val Acc: 0.170363 loss: 6.724410\n",
            "[728/3000] Train Acc: 0.994051 Loss: 0.026020 | Val Acc: 0.173992 loss: 6.681462\n",
            "[729/3000] Train Acc: 0.995765 Loss: 0.022409 | Val Acc: 0.160685 loss: 6.776959\n",
            "[730/3000] Train Acc: 0.994757 Loss: 0.025003 | Val Acc: 0.171573 loss: 6.707299\n",
            "[731/3000] Train Acc: 0.996572 Loss: 0.020449 | Val Acc: 0.174798 loss: 6.558341\n",
            "[732/3000] Train Acc: 0.996269 Loss: 0.020891 | Val Acc: 0.168145 loss: 6.851733\n",
            "[733/3000] Train Acc: 0.995917 Loss: 0.023625 | Val Acc: 0.167944 loss: 6.739611\n",
            "[734/3000] Train Acc: 0.995160 Loss: 0.022506 | Val Acc: 0.170766 loss: 6.844418\n",
            "[735/3000] Train Acc: 0.995765 Loss: 0.021410 | Val Acc: 0.162097 loss: 6.996827\n",
            "[736/3000] Train Acc: 0.994908 Loss: 0.023132 | Val Acc: 0.167339 loss: 6.965973\n",
            "[737/3000] Train Acc: 0.995312 Loss: 0.023220 | Val Acc: 0.158468 loss: 7.195863\n",
            "[738/3000] Train Acc: 0.996017 Loss: 0.021001 | Val Acc: 0.168952 loss: 7.214781\n",
            "[739/3000] Train Acc: 0.995866 Loss: 0.020898 | Val Acc: 0.168145 loss: 6.994637\n",
            "[740/3000] Train Acc: 0.996169 Loss: 0.020332 | Val Acc: 0.170766 loss: 6.543057\n",
            "[741/3000] Train Acc: 0.995059 Loss: 0.022968 | Val Acc: 0.172581 loss: 6.606721\n",
            "[742/3000] Train Acc: 0.996421 Loss: 0.019944 | Val Acc: 0.165121 loss: 7.208076\n",
            "[743/3000] Train Acc: 0.996622 Loss: 0.019678 | Val Acc: 0.163105 loss: 7.110318\n",
            "[744/3000] Train Acc: 0.996673 Loss: 0.019776 | Val Acc: 0.169556 loss: 6.726838\n",
            "[745/3000] Train Acc: 0.996219 Loss: 0.020312 | Val Acc: 0.172782 loss: 6.675610\n",
            "[746/3000] Train Acc: 0.997177 Loss: 0.018502 | Val Acc: 0.172581 loss: 6.830262\n",
            "[747/3000] Train Acc: 0.995816 Loss: 0.022254 | Val Acc: 0.158065 loss: 7.054090\n",
            "[748/3000] Train Acc: 0.994908 Loss: 0.022037 | Val Acc: 0.170766 loss: 6.969106\n",
            "[749/3000] Train Acc: 0.996017 Loss: 0.019747 | Val Acc: 0.169355 loss: 6.834839\n",
            "[750/3000] Train Acc: 0.995664 Loss: 0.021773 | Val Acc: 0.167137 loss: 6.835144\n",
            "[751/3000] Train Acc: 0.996169 Loss: 0.019753 | Val Acc: 0.173387 loss: 7.023389\n",
            "[752/3000] Train Acc: 0.997832 Loss: 0.016834 | Val Acc: 0.175000 loss: 6.825666\n",
            "[753/3000] Train Acc: 0.997076 Loss: 0.017841 | Val Acc: 0.167944 loss: 6.987387\n",
            "[754/3000] Train Acc: 0.997379 Loss: 0.016054 | Val Acc: 0.176008 loss: 6.797682\n",
            "[755/3000] Train Acc: 0.997076 Loss: 0.018266 | Val Acc: 0.167742 loss: 6.930233\n",
            "[756/3000] Train Acc: 0.996925 Loss: 0.018118 | Val Acc: 0.175605 loss: 6.745592\n",
            "[757/3000] Train Acc: 0.996370 Loss: 0.019595 | Val Acc: 0.178629 loss: 6.759567\n",
            "[758/3000] Train Acc: 0.996219 Loss: 0.020214 | Val Acc: 0.169758 loss: 7.010408\n",
            "[759/3000] Train Acc: 0.997328 Loss: 0.016465 | Val Acc: 0.170161 loss: 6.998266\n",
            "[760/3000] Train Acc: 0.996723 Loss: 0.018621 | Val Acc: 0.175000 loss: 6.822624\n",
            "[761/3000] Train Acc: 0.996673 Loss: 0.019527 | Val Acc: 0.164113 loss: 7.019504\n",
            "[762/3000] Train Acc: 0.997177 Loss: 0.016068 | Val Acc: 0.170565 loss: 7.110362\n",
            "[763/3000] Train Acc: 0.997126 Loss: 0.017314 | Val Acc: 0.162500 loss: 7.133726\n",
            "[764/3000] Train Acc: 0.997076 Loss: 0.017993 | Val Acc: 0.171169 loss: 7.150679\n",
            "[765/3000] Train Acc: 0.996824 Loss: 0.017812 | Val Acc: 0.174798 loss: 6.791090\n",
            "[766/3000] Train Acc: 0.996673 Loss: 0.016381 | Val Acc: 0.168952 loss: 6.975535\n",
            "[767/3000] Train Acc: 0.997983 Loss: 0.014461 | Val Acc: 0.169556 loss: 6.934380\n",
            "[768/3000] Train Acc: 0.996925 Loss: 0.017943 | Val Acc: 0.178226 loss: 6.940199\n",
            "[769/3000] Train Acc: 0.995614 Loss: 0.020958 | Val Acc: 0.169355 loss: 7.336032\n",
            "[770/3000] Train Acc: 0.997731 Loss: 0.015142 | Val Acc: 0.178226 loss: 6.770831\n",
            "[771/3000] Train Acc: 0.997782 Loss: 0.014769 | Val Acc: 0.168952 loss: 7.067521\n",
            "[772/3000] Train Acc: 0.997076 Loss: 0.016104 | Val Acc: 0.165524 loss: 7.495102\n",
            "[773/3000] Train Acc: 0.996975 Loss: 0.016668 | Val Acc: 0.167540 loss: 7.147041\n",
            "[774/3000] Train Acc: 0.997328 Loss: 0.016459 | Val Acc: 0.153427 loss: 7.390418\n",
            "[775/3000] Train Acc: 0.995917 Loss: 0.019370 | Val Acc: 0.160484 loss: 7.280002\n",
            "[776/3000] Train Acc: 0.998286 Loss: 0.012595 | Val Acc: 0.166129 loss: 7.142404\n",
            "[777/3000] Train Acc: 0.997933 Loss: 0.014119 | Val Acc: 0.174194 loss: 6.834838\n",
            "[778/3000] Train Acc: 0.997731 Loss: 0.014429 | Val Acc: 0.165726 loss: 7.387957\n",
            "[779/3000] Train Acc: 0.997832 Loss: 0.013750 | Val Acc: 0.166734 loss: 7.068185\n",
            "[780/3000] Train Acc: 0.997177 Loss: 0.015275 | Val Acc: 0.175806 loss: 6.980278\n",
            "[781/3000] Train Acc: 0.998034 Loss: 0.013919 | Val Acc: 0.152823 loss: 7.768266\n",
            "[782/3000] Train Acc: 0.997681 Loss: 0.014327 | Val Acc: 0.168750 loss: 7.171889\n",
            "[783/3000] Train Acc: 0.997328 Loss: 0.015138 | Val Acc: 0.171169 loss: 7.054778\n",
            "[784/3000] Train Acc: 0.997782 Loss: 0.013825 | Val Acc: 0.172782 loss: 7.301864\n",
            "[785/3000] Train Acc: 0.996017 Loss: 0.016779 | Val Acc: 0.161089 loss: 7.314438\n",
            "[786/3000] Train Acc: 0.997983 Loss: 0.014159 | Val Acc: 0.177419 loss: 6.891399\n",
            "[787/3000] Train Acc: 0.997883 Loss: 0.012920 | Val Acc: 0.174395 loss: 7.337464\n",
            "[788/3000] Train Acc: 0.996521 Loss: 0.016670 | Val Acc: 0.149597 loss: 7.889061\n",
            "[789/3000] Train Acc: 0.992640 Loss: 0.024917 | Val Acc: 0.179234 loss: 7.042498\n",
            "[790/3000] Train Acc: 0.998034 Loss: 0.012156 | Val Acc: 0.173387 loss: 7.185922\n",
            "[791/3000] Train Acc: 0.998084 Loss: 0.011888 | Val Acc: 0.160887 loss: 7.481625\n",
            "[792/3000] Train Acc: 0.997933 Loss: 0.012739 | Val Acc: 0.167944 loss: 7.131562\n",
            "[793/3000] Train Acc: 0.998286 Loss: 0.011550 | Val Acc: 0.174395 loss: 7.115070\n",
            "[794/3000] Train Acc: 0.998790 Loss: 0.011275 | Val Acc: 0.169355 loss: 7.381478\n",
            "[795/3000] Train Acc: 0.996219 Loss: 0.017369 | Val Acc: 0.166129 loss: 7.546252\n",
            "[796/3000] Train Acc: 0.997883 Loss: 0.013497 | Val Acc: 0.168750 loss: 7.258887\n",
            "[797/3000] Train Acc: 0.997983 Loss: 0.012434 | Val Acc: 0.172379 loss: 7.231582\n",
            "[798/3000] Train Acc: 0.998437 Loss: 0.010754 | Val Acc: 0.172782 loss: 7.331981\n",
            "[799/3000] Train Acc: 0.998084 Loss: 0.011883 | Val Acc: 0.169960 loss: 7.412081\n",
            "[800/3000] Train Acc: 0.997832 Loss: 0.012863 | Val Acc: 0.175000 loss: 7.312874\n",
            "[801/3000] Train Acc: 0.998286 Loss: 0.012002 | Val Acc: 0.170968 loss: 7.726057\n",
            "[802/3000] Train Acc: 0.996723 Loss: 0.016825 | Val Acc: 0.167540 loss: 7.538735\n",
            "[803/3000] Train Acc: 0.998387 Loss: 0.011089 | Val Acc: 0.171573 loss: 7.354560\n",
            "[804/3000] Train Acc: 0.998488 Loss: 0.011492 | Val Acc: 0.173790 loss: 7.325122\n",
            "[805/3000] Train Acc: 0.998185 Loss: 0.011571 | Val Acc: 0.175000 loss: 7.418871\n",
            "[806/3000] Train Acc: 0.997782 Loss: 0.013796 | Val Acc: 0.171169 loss: 7.608045\n",
            "[807/3000] Train Acc: 0.996521 Loss: 0.016515 | Val Acc: 0.170968 loss: 7.554115\n",
            "[808/3000] Train Acc: 0.998639 Loss: 0.010728 | Val Acc: 0.172782 loss: 7.265107\n",
            "[809/3000] Train Acc: 0.995967 Loss: 0.016123 | Val Acc: 0.179032 loss: 7.459645\n",
            "[810/3000] Train Acc: 0.998488 Loss: 0.010861 | Val Acc: 0.181048 loss: 7.172300\n",
            "saving model with acc 0.181\n",
            "[811/3000] Train Acc: 0.998639 Loss: 0.009457 | Val Acc: 0.170161 loss: 7.566897\n",
            "[812/3000] Train Acc: 0.998941 Loss: 0.009360 | Val Acc: 0.174194 loss: 7.367417\n",
            "[813/3000] Train Acc: 0.998034 Loss: 0.012061 | Val Acc: 0.172782 loss: 7.316441\n",
            "[814/3000] Train Acc: 0.998538 Loss: 0.010153 | Val Acc: 0.178024 loss: 7.260906\n",
            "[815/3000] Train Acc: 0.998236 Loss: 0.010762 | Val Acc: 0.173790 loss: 7.338394\n",
            "[816/3000] Train Acc: 0.998336 Loss: 0.010546 | Val Acc: 0.188911 loss: 7.235863\n",
            "saving model with acc 0.189\n",
            "[817/3000] Train Acc: 0.996874 Loss: 0.015279 | Val Acc: 0.172177 loss: 7.585463\n",
            "[818/3000] Train Acc: 0.998992 Loss: 0.008963 | Val Acc: 0.186694 loss: 6.886685\n",
            "[819/3000] Train Acc: 0.998588 Loss: 0.009765 | Val Acc: 0.167137 loss: 7.571647\n",
            "[820/3000] Train Acc: 0.996975 Loss: 0.014744 | Val Acc: 0.172177 loss: 7.558933\n",
            "[821/3000] Train Acc: 0.998891 Loss: 0.008709 | Val Acc: 0.164718 loss: 7.729060\n",
            "[822/3000] Train Acc: 0.997631 Loss: 0.013077 | Val Acc: 0.174798 loss: 7.435499\n",
            "[823/3000] Train Acc: 0.998084 Loss: 0.010523 | Val Acc: 0.177621 loss: 7.248559\n",
            "[824/3000] Train Acc: 0.999042 Loss: 0.008436 | Val Acc: 0.175403 loss: 7.411149\n",
            "[825/3000] Train Acc: 0.998387 Loss: 0.009284 | Val Acc: 0.169960 loss: 7.936559\n",
            "[826/3000] Train Acc: 0.996421 Loss: 0.016509 | Val Acc: 0.174798 loss: 7.527510\n",
            "[827/3000] Train Acc: 0.997883 Loss: 0.011577 | Val Acc: 0.170766 loss: 7.414325\n",
            "[828/3000] Train Acc: 0.998588 Loss: 0.009274 | Val Acc: 0.179032 loss: 7.350985\n",
            "[829/3000] Train Acc: 0.998336 Loss: 0.010696 | Val Acc: 0.178629 loss: 7.296813\n",
            "[830/3000] Train Acc: 0.998236 Loss: 0.009849 | Val Acc: 0.188710 loss: 7.236007\n",
            "[831/3000] Train Acc: 0.999093 Loss: 0.008548 | Val Acc: 0.170363 loss: 7.759062\n",
            "[832/3000] Train Acc: 0.998034 Loss: 0.011084 | Val Acc: 0.171976 loss: 7.520692\n",
            "[833/3000] Train Acc: 0.998538 Loss: 0.008929 | Val Acc: 0.170968 loss: 7.810792\n",
            "[834/3000] Train Acc: 0.998488 Loss: 0.009161 | Val Acc: 0.169153 loss: 7.791945\n",
            "[835/3000] Train Acc: 0.998286 Loss: 0.010469 | Val Acc: 0.181048 loss: 7.609505\n",
            "[836/3000] Train Acc: 0.998286 Loss: 0.010861 | Val Acc: 0.181855 loss: 7.579371\n",
            "[837/3000] Train Acc: 0.998588 Loss: 0.009079 | Val Acc: 0.177218 loss: 7.392499\n",
            "[838/3000] Train Acc: 0.998286 Loss: 0.009848 | Val Acc: 0.175403 loss: 7.356874\n",
            "[839/3000] Train Acc: 0.996824 Loss: 0.015163 | Val Acc: 0.168548 loss: 7.904032\n",
            "[840/3000] Train Acc: 0.998790 Loss: 0.008909 | Val Acc: 0.170766 loss: 7.602199\n",
            "[841/3000] Train Acc: 0.998941 Loss: 0.007196 | Val Acc: 0.169960 loss: 7.693718\n",
            "[842/3000] Train Acc: 0.998236 Loss: 0.010453 | Val Acc: 0.185887 loss: 7.571383\n",
            "[843/3000] Train Acc: 0.998236 Loss: 0.009524 | Val Acc: 0.165927 loss: 7.932543\n",
            "[844/3000] Train Acc: 0.999143 Loss: 0.007709 | Val Acc: 0.179032 loss: 7.642518\n",
            "[845/3000] Train Acc: 0.998286 Loss: 0.010315 | Val Acc: 0.174395 loss: 7.438734\n",
            "[846/3000] Train Acc: 0.997177 Loss: 0.011875 | Val Acc: 0.166532 loss: 7.891414\n",
            "[847/3000] Train Acc: 0.998538 Loss: 0.009452 | Val Acc: 0.179839 loss: 7.743370\n",
            "[848/3000] Train Acc: 0.998639 Loss: 0.008666 | Val Acc: 0.172581 loss: 7.597472\n",
            "[849/3000] Train Acc: 0.999143 Loss: 0.007180 | Val Acc: 0.176613 loss: 7.890060\n",
            "[850/3000] Train Acc: 0.998891 Loss: 0.007903 | Val Acc: 0.179032 loss: 7.751483\n",
            "[851/3000] Train Acc: 0.998790 Loss: 0.008954 | Val Acc: 0.172177 loss: 7.911293\n",
            "[852/3000] Train Acc: 0.998840 Loss: 0.008121 | Val Acc: 0.175806 loss: 7.771032\n",
            "[853/3000] Train Acc: 0.998891 Loss: 0.008565 | Val Acc: 0.172984 loss: 7.814569\n",
            "[854/3000] Train Acc: 0.998336 Loss: 0.009923 | Val Acc: 0.165524 loss: 7.960940\n",
            "[855/3000] Train Acc: 0.998538 Loss: 0.009532 | Val Acc: 0.173992 loss: 7.869570\n",
            "[856/3000] Train Acc: 0.998689 Loss: 0.008769 | Val Acc: 0.182863 loss: 7.354441\n",
            "[857/3000] Train Acc: 0.998941 Loss: 0.008119 | Val Acc: 0.175000 loss: 7.814858\n",
            "[858/3000] Train Acc: 0.997983 Loss: 0.010109 | Val Acc: 0.176008 loss: 7.989978\n",
            "[859/3000] Train Acc: 0.999244 Loss: 0.007048 | Val Acc: 0.168145 loss: 8.190991\n",
            "[860/3000] Train Acc: 0.998891 Loss: 0.007596 | Val Acc: 0.177419 loss: 7.840880\n",
            "[861/3000] Train Acc: 0.999546 Loss: 0.005989 | Val Acc: 0.180847 loss: 7.595750\n",
            "[862/3000] Train Acc: 0.997681 Loss: 0.010598 | Val Acc: 0.166129 loss: 7.768231\n",
            "[863/3000] Train Acc: 0.998387 Loss: 0.008596 | Val Acc: 0.173992 loss: 8.160081\n",
            "[864/3000] Train Acc: 0.998740 Loss: 0.007559 | Val Acc: 0.175000 loss: 7.777408\n",
            "[865/3000] Train Acc: 0.997983 Loss: 0.009272 | Val Acc: 0.168347 loss: 8.573652\n",
            "[866/3000] Train Acc: 0.997832 Loss: 0.010681 | Val Acc: 0.177823 loss: 7.766183\n",
            "[867/3000] Train Acc: 0.999193 Loss: 0.006356 | Val Acc: 0.185887 loss: 7.681942\n",
            "[868/3000] Train Acc: 0.998992 Loss: 0.006829 | Val Acc: 0.178024 loss: 8.030301\n",
            "[869/3000] Train Acc: 0.998538 Loss: 0.008423 | Val Acc: 0.168347 loss: 8.466274\n",
            "[870/3000] Train Acc: 0.999042 Loss: 0.007222 | Val Acc: 0.180242 loss: 7.532116\n",
            "[871/3000] Train Acc: 0.998236 Loss: 0.008860 | Val Acc: 0.183871 loss: 7.774324\n",
            "[872/3000] Train Acc: 0.998689 Loss: 0.006961 | Val Acc: 0.191935 loss: 7.661716\n",
            "saving model with acc 0.192\n",
            "[873/3000] Train Acc: 0.999193 Loss: 0.006803 | Val Acc: 0.173185 loss: 8.122699\n",
            "[874/3000] Train Acc: 0.998941 Loss: 0.006837 | Val Acc: 0.178427 loss: 8.092780\n",
            "[875/3000] Train Acc: 0.998891 Loss: 0.006908 | Val Acc: 0.158669 loss: 8.581502\n",
            "[876/3000] Train Acc: 0.999698 Loss: 0.004918 | Val Acc: 0.184274 loss: 7.840793\n",
            "[877/3000] Train Acc: 0.999143 Loss: 0.006681 | Val Acc: 0.184073 loss: 7.862318\n",
            "[878/3000] Train Acc: 0.994959 Loss: 0.019520 | Val Acc: 0.177016 loss: 8.251223\n",
            "[879/3000] Train Acc: 0.999445 Loss: 0.005572 | Val Acc: 0.183266 loss: 7.943475\n",
            "[880/3000] Train Acc: 0.999698 Loss: 0.004818 | Val Acc: 0.181653 loss: 8.049049\n",
            "[881/3000] Train Acc: 0.999244 Loss: 0.005962 | Val Acc: 0.180444 loss: 7.872020\n",
            "[882/3000] Train Acc: 0.998790 Loss: 0.006707 | Val Acc: 0.175806 loss: 8.012923\n",
            "[883/3000] Train Acc: 0.998740 Loss: 0.006684 | Val Acc: 0.187702 loss: 7.658999\n",
            "[884/3000] Train Acc: 0.999093 Loss: 0.006234 | Val Acc: 0.176613 loss: 8.128396\n",
            "[885/3000] Train Acc: 0.998840 Loss: 0.007368 | Val Acc: 0.158871 loss: 8.895781\n",
            "[886/3000] Train Acc: 0.999244 Loss: 0.006356 | Val Acc: 0.163710 loss: 8.567911\n",
            "[887/3000] Train Acc: 0.998790 Loss: 0.007151 | Val Acc: 0.173790 loss: 8.347202\n",
            "[888/3000] Train Acc: 0.997883 Loss: 0.010192 | Val Acc: 0.169960 loss: 8.428329\n",
            "[889/3000] Train Acc: 0.998891 Loss: 0.006862 | Val Acc: 0.177419 loss: 8.259060\n",
            "[890/3000] Train Acc: 0.999597 Loss: 0.004727 | Val Acc: 0.171774 loss: 8.478224\n",
            "[891/3000] Train Acc: 0.999193 Loss: 0.006528 | Val Acc: 0.181653 loss: 8.028101\n",
            "[892/3000] Train Acc: 0.999294 Loss: 0.005774 | Val Acc: 0.180645 loss: 8.126108\n",
            "[893/3000] Train Acc: 0.998185 Loss: 0.008175 | Val Acc: 0.185887 loss: 7.937610\n",
            "[894/3000] Train Acc: 0.999294 Loss: 0.005638 | Val Acc: 0.180040 loss: 8.358873\n",
            "[895/3000] Train Acc: 0.997429 Loss: 0.010725 | Val Acc: 0.175202 loss: 8.265770\n",
            "[896/3000] Train Acc: 0.998790 Loss: 0.007012 | Val Acc: 0.177621 loss: 8.452824\n",
            "[897/3000] Train Acc: 0.999647 Loss: 0.004865 | Val Acc: 0.183669 loss: 7.864006\n",
            "[898/3000] Train Acc: 0.999244 Loss: 0.006045 | Val Acc: 0.178024 loss: 8.265519\n",
            "[899/3000] Train Acc: 0.998941 Loss: 0.006411 | Val Acc: 0.193548 loss: 7.616733\n",
            "saving model with acc 0.194\n",
            "[900/3000] Train Acc: 0.998941 Loss: 0.006118 | Val Acc: 0.168952 loss: 8.621009\n",
            "[901/3000] Train Acc: 0.999395 Loss: 0.005080 | Val Acc: 0.175000 loss: 8.458612\n",
            "[902/3000] Train Acc: 0.996370 Loss: 0.012632 | Val Acc: 0.171774 loss: 8.451127\n",
            "[903/3000] Train Acc: 0.999597 Loss: 0.004187 | Val Acc: 0.177823 loss: 8.167202\n",
            "[904/3000] Train Acc: 0.999244 Loss: 0.004839 | Val Acc: 0.172984 loss: 8.451500\n",
            "[905/3000] Train Acc: 0.999647 Loss: 0.004029 | Val Acc: 0.179234 loss: 8.291518\n",
            "[906/3000] Train Acc: 0.998790 Loss: 0.006929 | Val Acc: 0.182056 loss: 7.823780\n",
            "[907/3000] Train Acc: 0.998588 Loss: 0.007705 | Val Acc: 0.175605 loss: 8.508209\n",
            "[908/3000] Train Acc: 0.998992 Loss: 0.005437 | Val Acc: 0.186694 loss: 8.027915\n",
            "[909/3000] Train Acc: 0.999345 Loss: 0.004851 | Val Acc: 0.199194 loss: 7.660741\n",
            "saving model with acc 0.199\n",
            "[910/3000] Train Acc: 0.998941 Loss: 0.006444 | Val Acc: 0.184879 loss: 8.141321\n",
            "[911/3000] Train Acc: 0.999042 Loss: 0.005645 | Val Acc: 0.179234 loss: 8.550614\n",
            "[912/3000] Train Acc: 0.999143 Loss: 0.006009 | Val Acc: 0.183266 loss: 8.238791\n",
            "[913/3000] Train Acc: 0.999395 Loss: 0.005847 | Val Acc: 0.180645 loss: 8.443923\n",
            "[914/3000] Train Acc: 0.998538 Loss: 0.007050 | Val Acc: 0.178427 loss: 8.627190\n",
            "[915/3000] Train Acc: 0.997580 Loss: 0.011399 | Val Acc: 0.186290 loss: 8.196991\n",
            "[916/3000] Train Acc: 0.999546 Loss: 0.004472 | Val Acc: 0.171169 loss: 8.604471\n",
            "[917/3000] Train Acc: 0.999345 Loss: 0.005210 | Val Acc: 0.186895 loss: 8.014794\n",
            "[918/3000] Train Acc: 0.998084 Loss: 0.007321 | Val Acc: 0.182056 loss: 8.314570\n",
            "[919/3000] Train Acc: 0.999244 Loss: 0.004558 | Val Acc: 0.180444 loss: 8.340793\n",
            "[920/3000] Train Acc: 0.999496 Loss: 0.004576 | Val Acc: 0.160081 loss: 9.290438\n",
            "[921/3000] Train Acc: 0.998941 Loss: 0.005789 | Val Acc: 0.188105 loss: 8.213999\n",
            "[922/3000] Train Acc: 0.999597 Loss: 0.003671 | Val Acc: 0.168347 loss: 8.542058\n",
            "[923/3000] Train Acc: 0.998437 Loss: 0.008134 | Val Acc: 0.183669 loss: 8.162711\n",
            "[924/3000] Train Acc: 0.998992 Loss: 0.005570 | Val Acc: 0.179032 loss: 8.317550\n",
            "[925/3000] Train Acc: 0.998941 Loss: 0.005392 | Val Acc: 0.187500 loss: 8.265806\n",
            "[926/3000] Train Acc: 0.998588 Loss: 0.007556 | Val Acc: 0.179234 loss: 8.434063\n",
            "[927/3000] Train Acc: 0.999546 Loss: 0.004483 | Val Acc: 0.180645 loss: 8.199954\n",
            "[928/3000] Train Acc: 0.999445 Loss: 0.003457 | Val Acc: 0.189315 loss: 8.087380\n",
            "[929/3000] Train Acc: 0.998840 Loss: 0.006149 | Val Acc: 0.182056 loss: 8.680368\n",
            "[930/3000] Train Acc: 0.999193 Loss: 0.005312 | Val Acc: 0.180444 loss: 8.154439\n",
            "[931/3000] Train Acc: 0.999647 Loss: 0.003886 | Val Acc: 0.170363 loss: 8.711878\n",
            "[932/3000] Train Acc: 0.996774 Loss: 0.013036 | Val Acc: 0.188508 loss: 8.123313\n",
            "[933/3000] Train Acc: 0.998941 Loss: 0.005315 | Val Acc: 0.181250 loss: 9.044794\n",
            "[934/3000] Train Acc: 0.996421 Loss: 0.012977 | Val Acc: 0.180847 loss: 8.560903\n",
            "[935/3000] Train Acc: 0.999496 Loss: 0.003509 | Val Acc: 0.189113 loss: 8.089782\n",
            "[936/3000] Train Acc: 0.999445 Loss: 0.003942 | Val Acc: 0.179839 loss: 8.454505\n",
            "[937/3000] Train Acc: 0.999395 Loss: 0.004250 | Val Acc: 0.196976 loss: 8.033984\n",
            "[938/3000] Train Acc: 0.999294 Loss: 0.004140 | Val Acc: 0.179032 loss: 8.624059\n",
            "[939/3000] Train Acc: 0.998740 Loss: 0.006603 | Val Acc: 0.173992 loss: 8.745570\n",
            "[940/3000] Train Acc: 0.998941 Loss: 0.005836 | Val Acc: 0.185887 loss: 8.428491\n",
            "[941/3000] Train Acc: 0.999798 Loss: 0.003359 | Val Acc: 0.197581 loss: 8.001366\n",
            "[942/3000] Train Acc: 0.999395 Loss: 0.004389 | Val Acc: 0.180040 loss: 8.570276\n",
            "[943/3000] Train Acc: 0.998740 Loss: 0.005876 | Val Acc: 0.173185 loss: 8.794099\n",
            "[944/3000] Train Acc: 0.997832 Loss: 0.008965 | Val Acc: 0.181250 loss: 8.592380\n",
            "[945/3000] Train Acc: 0.998840 Loss: 0.006294 | Val Acc: 0.186694 loss: 8.209097\n",
            "[946/3000] Train Acc: 0.998588 Loss: 0.007013 | Val Acc: 0.183065 loss: 8.461690\n",
            "[947/3000] Train Acc: 0.999597 Loss: 0.003038 | Val Acc: 0.182863 loss: 8.406336\n",
            "[948/3000] Train Acc: 0.999042 Loss: 0.005396 | Val Acc: 0.178831 loss: 8.601321\n",
            "[949/3000] Train Acc: 0.998941 Loss: 0.005250 | Val Acc: 0.177218 loss: 8.564549\n",
            "[950/3000] Train Acc: 0.999496 Loss: 0.003920 | Val Acc: 0.183669 loss: 8.417549\n",
            "[951/3000] Train Acc: 0.998437 Loss: 0.006972 | Val Acc: 0.182460 loss: 8.518607\n",
            "[952/3000] Train Acc: 0.998840 Loss: 0.006049 | Val Acc: 0.196573 loss: 7.945279\n",
            "[953/3000] Train Acc: 0.999093 Loss: 0.005337 | Val Acc: 0.174597 loss: 9.027373\n",
            "[954/3000] Train Acc: 0.999244 Loss: 0.003733 | Val Acc: 0.186492 loss: 8.406486\n",
            "[955/3000] Train Acc: 0.997883 Loss: 0.008034 | Val Acc: 0.185081 loss: 8.452860\n",
            "[956/3000] Train Acc: 0.999395 Loss: 0.003737 | Val Acc: 0.182661 loss: 8.613589\n",
            "[957/3000] Train Acc: 0.998891 Loss: 0.005700 | Val Acc: 0.172379 loss: 9.135957\n",
            "[958/3000] Train Acc: 0.999647 Loss: 0.003783 | Val Acc: 0.180444 loss: 8.655709\n",
            "[959/3000] Train Acc: 0.999647 Loss: 0.003586 | Val Acc: 0.170161 loss: 9.050192\n",
            "[960/3000] Train Acc: 0.997530 Loss: 0.009229 | Val Acc: 0.184274 loss: 8.597198\n",
            "[961/3000] Train Acc: 0.999143 Loss: 0.004794 | Val Acc: 0.183871 loss: 8.648359\n",
            "[962/3000] Train Acc: 0.999698 Loss: 0.002895 | Val Acc: 0.176815 loss: 8.855882\n",
            "[963/3000] Train Acc: 0.999546 Loss: 0.003517 | Val Acc: 0.170161 loss: 9.362296\n",
            "[964/3000] Train Acc: 0.999546 Loss: 0.003855 | Val Acc: 0.178427 loss: 8.801018\n",
            "[965/3000] Train Acc: 0.999395 Loss: 0.004464 | Val Acc: 0.183266 loss: 8.640835\n",
            "[966/3000] Train Acc: 0.998336 Loss: 0.007220 | Val Acc: 0.181452 loss: 8.610420\n",
            "[967/3000] Train Acc: 0.999445 Loss: 0.003816 | Val Acc: 0.185685 loss: 8.698823\n",
            "[968/3000] Train Acc: 0.998840 Loss: 0.005953 | Val Acc: 0.174798 loss: 8.932708\n",
            "[969/3000] Train Acc: 0.997731 Loss: 0.008578 | Val Acc: 0.175806 loss: 9.179994\n",
            "[970/3000] Train Acc: 0.999345 Loss: 0.004190 | Val Acc: 0.182056 loss: 8.938751\n",
            "[971/3000] Train Acc: 0.999395 Loss: 0.003451 | Val Acc: 0.188508 loss: 8.416642\n",
            "[972/3000] Train Acc: 0.999445 Loss: 0.004185 | Val Acc: 0.178226 loss: 8.801413\n",
            "[973/3000] Train Acc: 0.997883 Loss: 0.006987 | Val Acc: 0.161492 loss: 9.252022\n",
            "[974/3000] Train Acc: 0.996774 Loss: 0.010141 | Val Acc: 0.179032 loss: 8.648584\n",
            "[975/3000] Train Acc: 0.999597 Loss: 0.003158 | Val Acc: 0.190927 loss: 8.388108\n",
            "[976/3000] Train Acc: 0.999546 Loss: 0.002644 | Val Acc: 0.177823 loss: 9.031630\n",
            "[977/3000] Train Acc: 0.999698 Loss: 0.002455 | Val Acc: 0.185685 loss: 8.658011\n",
            "[978/3000] Train Acc: 0.999395 Loss: 0.004213 | Val Acc: 0.178427 loss: 8.890854\n",
            "[979/3000] Train Acc: 0.999849 Loss: 0.002400 | Val Acc: 0.186694 loss: 8.598721\n",
            "[980/3000] Train Acc: 0.995463 Loss: 0.014006 | Val Acc: 0.181653 loss: 9.273471\n",
            "[981/3000] Train Acc: 0.998891 Loss: 0.005796 | Val Acc: 0.183468 loss: 8.869723\n",
            "[982/3000] Train Acc: 0.999698 Loss: 0.002571 | Val Acc: 0.176411 loss: 8.998601\n",
            "[983/3000] Train Acc: 0.999546 Loss: 0.002678 | Val Acc: 0.176411 loss: 8.839612\n",
            "[984/3000] Train Acc: 0.999193 Loss: 0.003649 | Val Acc: 0.196573 loss: 8.432492\n",
            "[985/3000] Train Acc: 0.998740 Loss: 0.006629 | Val Acc: 0.195363 loss: 8.435034\n",
            "[986/3000] Train Acc: 0.998639 Loss: 0.006660 | Val Acc: 0.176815 loss: 9.055287\n",
            "[987/3000] Train Acc: 0.999445 Loss: 0.003526 | Val Acc: 0.193952 loss: 8.641458\n",
            "[988/3000] Train Acc: 0.999698 Loss: 0.002560 | Val Acc: 0.183065 loss: 9.233048\n",
            "[989/3000] Train Acc: 0.998034 Loss: 0.007454 | Val Acc: 0.176613 loss: 8.949196\n",
            "[990/3000] Train Acc: 0.999698 Loss: 0.002820 | Val Acc: 0.182863 loss: 8.835488\n",
            "[991/3000] Train Acc: 0.999546 Loss: 0.002828 | Val Acc: 0.182661 loss: 8.997758\n",
            "[992/3000] Train Acc: 0.999395 Loss: 0.003463 | Val Acc: 0.175806 loss: 9.083452\n",
            "[993/3000] Train Acc: 0.996925 Loss: 0.010404 | Val Acc: 0.182661 loss: 8.833467\n",
            "[994/3000] Train Acc: 0.999546 Loss: 0.002935 | Val Acc: 0.185887 loss: 8.680590\n",
            "[995/3000] Train Acc: 0.997278 Loss: 0.009539 | Val Acc: 0.181250 loss: 9.150397\n",
            "[996/3000] Train Acc: 0.999597 Loss: 0.002605 | Val Acc: 0.184476 loss: 8.724273\n",
            "[997/3000] Train Acc: 0.999546 Loss: 0.003549 | Val Acc: 0.181452 loss: 8.940277\n",
            "[998/3000] Train Acc: 0.999294 Loss: 0.004020 | Val Acc: 0.188508 loss: 8.669749\n",
            "[999/3000] Train Acc: 0.999698 Loss: 0.002531 | Val Acc: 0.179435 loss: 8.957749\n",
            "[1000/3000] Train Acc: 0.999597 Loss: 0.002718 | Val Acc: 0.169758 loss: 9.330329\n",
            "[1001/3000] Train Acc: 0.999244 Loss: 0.003391 | Val Acc: 0.169960 loss: 9.423100\n",
            "[1002/3000] Train Acc: 0.998135 Loss: 0.007880 | Val Acc: 0.178024 loss: 9.090156\n",
            "[1003/3000] Train Acc: 0.998689 Loss: 0.005777 | Val Acc: 0.161492 loss: 9.966809\n",
            "[1004/3000] Train Acc: 0.999546 Loss: 0.003713 | Val Acc: 0.176613 loss: 9.162356\n",
            "[1005/3000] Train Acc: 0.999244 Loss: 0.004058 | Val Acc: 0.180847 loss: 8.754032\n",
            "[1006/3000] Train Acc: 0.997177 Loss: 0.009526 | Val Acc: 0.178024 loss: 9.328877\n",
            "[1007/3000] Train Acc: 0.999647 Loss: 0.002577 | Val Acc: 0.182661 loss: 9.024885\n",
            "[1008/3000] Train Acc: 0.999546 Loss: 0.002397 | Val Acc: 0.184274 loss: 8.964711\n",
            "[1009/3000] Train Acc: 0.999546 Loss: 0.003230 | Val Acc: 0.182056 loss: 9.020449\n",
            "[1010/3000] Train Acc: 0.999143 Loss: 0.004550 | Val Acc: 0.195766 loss: 8.408679\n",
            "[1011/3000] Train Acc: 0.997883 Loss: 0.008413 | Val Acc: 0.179234 loss: 9.139791\n",
            "[1012/3000] Train Acc: 0.999445 Loss: 0.003074 | Val Acc: 0.196371 loss: 8.610867\n",
            "[1013/3000] Train Acc: 0.999748 Loss: 0.002613 | Val Acc: 0.176008 loss: 9.287425\n",
            "[1014/3000] Train Acc: 0.995967 Loss: 0.012728 | Val Acc: 0.169758 loss: 9.595540\n",
            "[1015/3000] Train Acc: 0.999597 Loss: 0.003081 | Val Acc: 0.178226 loss: 9.144739\n",
            "[1016/3000] Train Acc: 0.999546 Loss: 0.002826 | Val Acc: 0.193952 loss: 8.819508\n",
            "[1017/3000] Train Acc: 0.999849 Loss: 0.001907 | Val Acc: 0.180444 loss: 9.340254\n",
            "[1018/3000] Train Acc: 0.999597 Loss: 0.002510 | Val Acc: 0.190121 loss: 8.751662\n",
            "[1019/3000] Train Acc: 0.999546 Loss: 0.002920 | Val Acc: 0.175605 loss: 9.081504\n",
            "[1020/3000] Train Acc: 0.997328 Loss: 0.009222 | Val Acc: 0.181048 loss: 9.244259\n",
            "[1021/3000] Train Acc: 0.999193 Loss: 0.004256 | Val Acc: 0.188306 loss: 8.957128\n",
            "[1022/3000] Train Acc: 0.999244 Loss: 0.003705 | Val Acc: 0.172379 loss: 9.605326\n",
            "[1023/3000] Train Acc: 0.999445 Loss: 0.002965 | Val Acc: 0.183669 loss: 8.848454\n",
            "[1024/3000] Train Acc: 0.998084 Loss: 0.007656 | Val Acc: 0.172581 loss: 9.459958\n",
            "[1025/3000] Train Acc: 0.999698 Loss: 0.002446 | Val Acc: 0.182460 loss: 9.205325\n",
            "[1026/3000] Train Acc: 0.996269 Loss: 0.012710 | Val Acc: 0.162097 loss: 10.628492\n",
            "[1027/3000] Train Acc: 0.998790 Loss: 0.005064 | Val Acc: 0.164718 loss: 10.308677\n",
            "[1028/3000] Train Acc: 0.998639 Loss: 0.005707 | Val Acc: 0.180645 loss: 9.232874\n",
            "[1029/3000] Train Acc: 0.999647 Loss: 0.002341 | Val Acc: 0.177823 loss: 9.507799\n",
            "[1030/3000] Train Acc: 0.999849 Loss: 0.001951 | Val Acc: 0.189516 loss: 8.978518\n",
            "[1031/3000] Train Acc: 0.999445 Loss: 0.003112 | Val Acc: 0.187903 loss: 8.998819\n",
            "[1032/3000] Train Acc: 0.999445 Loss: 0.002925 | Val Acc: 0.182460 loss: 9.123485\n",
            "[1033/3000] Train Acc: 0.998639 Loss: 0.004546 | Val Acc: 0.186694 loss: 9.096284\n",
            "[1034/3000] Train Acc: 0.999244 Loss: 0.003676 | Val Acc: 0.171371 loss: 9.461042\n",
            "[1035/3000] Train Acc: 0.998740 Loss: 0.005768 | Val Acc: 0.177218 loss: 9.476043\n",
            "[1036/3000] Train Acc: 0.998437 Loss: 0.005380 | Val Acc: 0.193952 loss: 8.859715\n",
            "[1037/3000] Train Acc: 0.999496 Loss: 0.002989 | Val Acc: 0.181250 loss: 9.324911\n",
            "[1038/3000] Train Acc: 0.999597 Loss: 0.002883 | Val Acc: 0.197984 loss: 8.540307\n",
            "[1039/3000] Train Acc: 0.997983 Loss: 0.007856 | Val Acc: 0.184677 loss: 9.228729\n",
            "[1040/3000] Train Acc: 0.999546 Loss: 0.002762 | Val Acc: 0.164516 loss: 10.099614\n",
            "[1041/3000] Train Acc: 0.999698 Loss: 0.002293 | Val Acc: 0.176613 loss: 9.464645\n",
            "[1042/3000] Train Acc: 0.999294 Loss: 0.003579 | Val Acc: 0.185484 loss: 9.302971\n",
            "[1043/3000] Train Acc: 0.999093 Loss: 0.003770 | Val Acc: 0.175000 loss: 9.561250\n",
            "[1044/3000] Train Acc: 0.998639 Loss: 0.006790 | Val Acc: 0.181855 loss: 9.300590\n",
            "[1045/3000] Train Acc: 0.999597 Loss: 0.002493 | Val Acc: 0.189113 loss: 8.965914\n",
            "[1046/3000] Train Acc: 0.999546 Loss: 0.002599 | Val Acc: 0.194355 loss: 8.745017\n",
            "[1047/3000] Train Acc: 0.997026 Loss: 0.010895 | Val Acc: 0.178024 loss: 10.056489\n",
            "[1048/3000] Train Acc: 0.997883 Loss: 0.006887 | Val Acc: 0.192339 loss: 8.938246\n",
            "[1049/3000] Train Acc: 0.999698 Loss: 0.002245 | Val Acc: 0.186089 loss: 9.217393\n",
            "[1050/3000] Train Acc: 0.999698 Loss: 0.002068 | Val Acc: 0.185887 loss: 9.262970\n",
            "[1051/3000] Train Acc: 0.999748 Loss: 0.002085 | Val Acc: 0.191734 loss: 9.059256\n",
            "[1052/3000] Train Acc: 0.998840 Loss: 0.004461 | Val Acc: 0.181653 loss: 9.234817\n",
            "[1053/3000] Train Acc: 0.999597 Loss: 0.002843 | Val Acc: 0.182258 loss: 9.358812\n",
            "[1054/3000] Train Acc: 0.999798 Loss: 0.001902 | Val Acc: 0.182863 loss: 9.335899\n",
            "[1055/3000] Train Acc: 0.999899 Loss: 0.001900 | Val Acc: 0.181855 loss: 9.482121\n",
            "[1056/3000] Train Acc: 0.999294 Loss: 0.003523 | Val Acc: 0.185685 loss: 9.215806\n",
            "[1057/3000] Train Acc: 0.997026 Loss: 0.009877 | Val Acc: 0.180444 loss: 9.326185\n",
            "[1058/3000] Train Acc: 0.998840 Loss: 0.005284 | Val Acc: 0.175403 loss: 9.735984\n",
            "[1059/3000] Train Acc: 0.999597 Loss: 0.002462 | Val Acc: 0.186895 loss: 9.277187\n",
            "[1060/3000] Train Acc: 0.999395 Loss: 0.003121 | Val Acc: 0.162097 loss: 10.321838\n",
            "[1061/3000] Train Acc: 0.999546 Loss: 0.002537 | Val Acc: 0.187097 loss: 9.224218\n",
            "[1062/3000] Train Acc: 0.999597 Loss: 0.002355 | Val Acc: 0.181048 loss: 9.446577\n",
            "[1063/3000] Train Acc: 0.999849 Loss: 0.001884 | Val Acc: 0.190121 loss: 9.107122\n",
            "[1064/3000] Train Acc: 0.999445 Loss: 0.002622 | Val Acc: 0.183065 loss: 9.445716\n",
            "[1065/3000] Train Acc: 0.997479 Loss: 0.008991 | Val Acc: 0.183871 loss: 9.120640\n",
            "[1066/3000] Train Acc: 0.999798 Loss: 0.001732 | Val Acc: 0.191129 loss: 9.067760\n",
            "[1067/3000] Train Acc: 0.999647 Loss: 0.002435 | Val Acc: 0.183065 loss: 9.717317\n",
            "[1068/3000] Train Acc: 0.999244 Loss: 0.003946 | Val Acc: 0.179839 loss: 9.603273\n",
            "[1069/3000] Train Acc: 0.999294 Loss: 0.003897 | Val Acc: 0.189718 loss: 9.521148\n",
            "[1070/3000] Train Acc: 0.998891 Loss: 0.005160 | Val Acc: 0.187500 loss: 9.301663\n",
            "[1071/3000] Train Acc: 0.999899 Loss: 0.001967 | Val Acc: 0.186089 loss: 9.228024\n",
            "[1072/3000] Train Acc: 0.999698 Loss: 0.002284 | Val Acc: 0.177016 loss: 9.831961\n",
            "[1073/3000] Train Acc: 0.998286 Loss: 0.006547 | Val Acc: 0.183871 loss: 9.547840\n",
            "[1074/3000] Train Acc: 0.999546 Loss: 0.002637 | Val Acc: 0.182056 loss: 9.916250\n",
            "[1075/3000] Train Acc: 0.998740 Loss: 0.004612 | Val Acc: 0.182460 loss: 9.449874\n",
            "[1076/3000] Train Acc: 0.999798 Loss: 0.001744 | Val Acc: 0.183468 loss: 9.335426\n",
            "[1077/3000] Train Acc: 0.999748 Loss: 0.002024 | Val Acc: 0.177823 loss: 9.711145\n",
            "[1078/3000] Train Acc: 0.999496 Loss: 0.002215 | Val Acc: 0.178024 loss: 9.903122\n",
            "[1079/3000] Train Acc: 0.997479 Loss: 0.008967 | Val Acc: 0.185081 loss: 9.512261\n",
            "[1080/3000] Train Acc: 0.999445 Loss: 0.003082 | Val Acc: 0.176210 loss: 9.965859\n",
            "[1081/3000] Train Acc: 0.999748 Loss: 0.001763 | Val Acc: 0.175403 loss: 9.918127\n",
            "[1082/3000] Train Acc: 0.999647 Loss: 0.002350 | Val Acc: 0.173992 loss: 10.151857\n",
            "[1083/3000] Train Acc: 0.999244 Loss: 0.003711 | Val Acc: 0.185484 loss: 9.282665\n",
            "[1084/3000] Train Acc: 0.999849 Loss: 0.001555 | Val Acc: 0.177621 loss: 9.815509\n",
            "[1085/3000] Train Acc: 0.997832 Loss: 0.007504 | Val Acc: 0.158468 loss: 9.931887\n",
            "[1086/3000] Train Acc: 0.997126 Loss: 0.009901 | Val Acc: 0.185887 loss: 9.240342\n",
            "[1087/3000] Train Acc: 0.999748 Loss: 0.001829 | Val Acc: 0.179435 loss: 9.379824\n",
            "[1088/3000] Train Acc: 0.999244 Loss: 0.003378 | Val Acc: 0.176613 loss: 9.805247\n",
            "[1089/3000] Train Acc: 0.999748 Loss: 0.001829 | Val Acc: 0.167137 loss: 9.765580\n",
            "[1090/3000] Train Acc: 0.999798 Loss: 0.001721 | Val Acc: 0.182258 loss: 9.482593\n",
            "[1091/3000] Train Acc: 0.999395 Loss: 0.002688 | Val Acc: 0.184677 loss: 9.450800\n",
            "[1092/3000] Train Acc: 0.999899 Loss: 0.001397 | Val Acc: 0.186694 loss: 9.331076\n",
            "[1093/3000] Train Acc: 0.996269 Loss: 0.010654 | Val Acc: 0.194355 loss: 8.894388\n",
            "[1094/3000] Train Acc: 0.999597 Loss: 0.002253 | Val Acc: 0.181250 loss: 9.801018\n",
            "[1095/3000] Train Acc: 0.999748 Loss: 0.001969 | Val Acc: 0.188710 loss: 9.406473\n",
            "[1096/3000] Train Acc: 0.999798 Loss: 0.001695 | Val Acc: 0.189718 loss: 9.223035\n",
            "[1097/3000] Train Acc: 0.998387 Loss: 0.006277 | Val Acc: 0.181855 loss: 9.742764\n",
            "[1098/3000] Train Acc: 0.998135 Loss: 0.007300 | Val Acc: 0.185282 loss: 9.667470\n",
            "[1099/3000] Train Acc: 0.999748 Loss: 0.001875 | Val Acc: 0.188508 loss: 9.913077\n",
            "[1100/3000] Train Acc: 0.999496 Loss: 0.002325 | Val Acc: 0.178831 loss: 9.873120\n",
            "[1101/3000] Train Acc: 0.999546 Loss: 0.002262 | Val Acc: 0.172984 loss: 10.184436\n",
            "[1102/3000] Train Acc: 0.999849 Loss: 0.001304 | Val Acc: 0.183065 loss: 9.562838\n",
            "[1103/3000] Train Acc: 0.998437 Loss: 0.006366 | Val Acc: 0.177016 loss: 10.057322\n",
            "[1104/3000] Train Acc: 0.999698 Loss: 0.002067 | Val Acc: 0.184274 loss: 9.622805\n",
            "[1105/3000] Train Acc: 0.999294 Loss: 0.003599 | Val Acc: 0.184073 loss: 9.607258\n",
            "[1106/3000] Train Acc: 0.999345 Loss: 0.003194 | Val Acc: 0.169960 loss: 10.236513\n",
            "[1107/3000] Train Acc: 0.999496 Loss: 0.002676 | Val Acc: 0.180242 loss: 9.612157\n",
            "[1108/3000] Train Acc: 0.998387 Loss: 0.005848 | Val Acc: 0.184274 loss: 9.860445\n",
            "[1109/3000] Train Acc: 0.999597 Loss: 0.003287 | Val Acc: 0.185081 loss: 9.624665\n",
            "[1110/3000] Train Acc: 1.000000 Loss: 0.001273 | Val Acc: 0.183468 loss: 9.728320\n",
            "[1111/3000] Train Acc: 0.999950 Loss: 0.001103 | Val Acc: 0.180645 loss: 9.754944\n",
            "[1112/3000] Train Acc: 0.999950 Loss: 0.001029 | Val Acc: 0.178629 loss: 9.848650\n",
            "[1113/3000] Train Acc: 0.998740 Loss: 0.004671 | Val Acc: 0.187298 loss: 9.713216\n",
            "[1114/3000] Train Acc: 0.999445 Loss: 0.003649 | Val Acc: 0.171169 loss: 10.142220\n",
            "[1115/3000] Train Acc: 0.998840 Loss: 0.004349 | Val Acc: 0.200000 loss: 8.907070\n",
            "saving model with acc 0.200\n",
            "[1116/3000] Train Acc: 0.999445 Loss: 0.003122 | Val Acc: 0.180242 loss: 9.956375\n",
            "[1117/3000] Train Acc: 0.999597 Loss: 0.002834 | Val Acc: 0.195766 loss: 9.305034\n",
            "[1118/3000] Train Acc: 0.999445 Loss: 0.002429 | Val Acc: 0.187097 loss: 9.572636\n",
            "[1119/3000] Train Acc: 0.998891 Loss: 0.003879 | Val Acc: 0.178226 loss: 10.156966\n",
            "[1120/3000] Train Acc: 0.999899 Loss: 0.001305 | Val Acc: 0.189919 loss: 9.563432\n",
            "[1121/3000] Train Acc: 0.998336 Loss: 0.005445 | Val Acc: 0.203831 loss: 8.808615\n",
            "saving model with acc 0.204\n",
            "[1122/3000] Train Acc: 0.995160 Loss: 0.018687 | Val Acc: 0.188105 loss: 9.394566\n",
            "[1123/3000] Train Acc: 0.999798 Loss: 0.001587 | Val Acc: 0.188508 loss: 9.538312\n",
            "[1124/3000] Train Acc: 0.999899 Loss: 0.001392 | Val Acc: 0.180040 loss: 9.883903\n",
            "[1125/3000] Train Acc: 0.999748 Loss: 0.001588 | Val Acc: 0.180645 loss: 9.719780\n",
            "[1126/3000] Train Acc: 0.999546 Loss: 0.002279 | Val Acc: 0.177621 loss: 9.852872\n",
            "[1127/3000] Train Acc: 0.999798 Loss: 0.001939 | Val Acc: 0.186492 loss: 9.494102\n",
            "[1128/3000] Train Acc: 0.999143 Loss: 0.003644 | Val Acc: 0.191532 loss: 9.244944\n",
            "[1129/3000] Train Acc: 0.998790 Loss: 0.004360 | Val Acc: 0.195161 loss: 9.340646\n",
            "[1130/3000] Train Acc: 0.999647 Loss: 0.002612 | Val Acc: 0.187097 loss: 9.495804\n",
            "[1131/3000] Train Acc: 0.999445 Loss: 0.002651 | Val Acc: 0.182258 loss: 9.882744\n",
            "[1132/3000] Train Acc: 0.998992 Loss: 0.003830 | Val Acc: 0.187298 loss: 9.708771\n",
            "[1133/3000] Train Acc: 0.997076 Loss: 0.010221 | Val Acc: 0.183871 loss: 9.516548\n",
            "[1134/3000] Train Acc: 0.999950 Loss: 0.001484 | Val Acc: 0.180040 loss: 9.877653\n",
            "[1135/3000] Train Acc: 0.999748 Loss: 0.002045 | Val Acc: 0.186492 loss: 9.638325\n",
            "[1136/3000] Train Acc: 0.999445 Loss: 0.002762 | Val Acc: 0.183468 loss: 9.847973\n",
            "[1137/3000] Train Acc: 0.999647 Loss: 0.002194 | Val Acc: 0.189113 loss: 9.100650\n",
            "[1138/3000] Train Acc: 0.999445 Loss: 0.002669 | Val Acc: 0.183065 loss: 9.789303\n",
            "[1139/3000] Train Acc: 0.999294 Loss: 0.002888 | Val Acc: 0.183266 loss: 9.923019\n",
            "[1140/3000] Train Acc: 0.999698 Loss: 0.001887 | Val Acc: 0.186290 loss: 9.776101\n",
            "[1141/3000] Train Acc: 0.996723 Loss: 0.011002 | Val Acc: 0.186290 loss: 9.781312\n",
            "[1142/3000] Train Acc: 0.999849 Loss: 0.001271 | Val Acc: 0.185081 loss: 9.698053\n",
            "[1143/3000] Train Acc: 0.999899 Loss: 0.000984 | Val Acc: 0.181048 loss: 9.964135\n",
            "[1144/3000] Train Acc: 0.999597 Loss: 0.002405 | Val Acc: 0.135282 loss: 11.690750\n",
            "[1145/3000] Train Acc: 0.995967 Loss: 0.012930 | Val Acc: 0.179032 loss: 10.147374\n",
            "[1146/3000] Train Acc: 0.999849 Loss: 0.001130 | Val Acc: 0.185484 loss: 10.005705\n",
            "[1147/3000] Train Acc: 0.999899 Loss: 0.001052 | Val Acc: 0.183065 loss: 9.882281\n",
            "[1148/3000] Train Acc: 0.999698 Loss: 0.001449 | Val Acc: 0.194153 loss: 9.329817\n",
            "[1149/3000] Train Acc: 0.999698 Loss: 0.001701 | Val Acc: 0.176210 loss: 10.415190\n",
            "[1150/3000] Train Acc: 0.999849 Loss: 0.001250 | Val Acc: 0.167944 loss: 11.118478\n",
            "[1151/3000] Train Acc: 0.996017 Loss: 0.012048 | Val Acc: 0.192339 loss: 9.268918\n",
            "[1152/3000] Train Acc: 0.999597 Loss: 0.001737 | Val Acc: 0.184476 loss: 10.009222\n",
            "[1153/3000] Train Acc: 0.999950 Loss: 0.001066 | Val Acc: 0.195766 loss: 9.317084\n",
            "[1154/3000] Train Acc: 0.999093 Loss: 0.003985 | Val Acc: 0.190121 loss: 9.569980\n",
            "[1155/3000] Train Acc: 0.999496 Loss: 0.002302 | Val Acc: 0.190726 loss: 9.515348\n",
            "[1156/3000] Train Acc: 0.999899 Loss: 0.001274 | Val Acc: 0.175403 loss: 10.262891\n",
            "[1157/3000] Train Acc: 0.997832 Loss: 0.007927 | Val Acc: 0.184677 loss: 9.589318\n",
            "[1158/3000] Train Acc: 0.999798 Loss: 0.001314 | Val Acc: 0.180645 loss: 9.774147\n",
            "[1159/3000] Train Acc: 0.999798 Loss: 0.001395 | Val Acc: 0.188105 loss: 9.636635\n",
            "[1160/3000] Train Acc: 0.999748 Loss: 0.001886 | Val Acc: 0.186694 loss: 9.773854\n",
            "[1161/3000] Train Acc: 0.998639 Loss: 0.004693 | Val Acc: 0.179032 loss: 10.073515\n",
            "[1162/3000] Train Acc: 0.996572 Loss: 0.012870 | Val Acc: 0.196169 loss: 9.258887\n",
            "[1163/3000] Train Acc: 0.999899 Loss: 0.001196 | Val Acc: 0.192540 loss: 9.308617\n",
            "[1164/3000] Train Acc: 0.999899 Loss: 0.001082 | Val Acc: 0.202016 loss: 9.137843\n",
            "[1165/3000] Train Acc: 0.999849 Loss: 0.001224 | Val Acc: 0.197984 loss: 9.398465\n",
            "[1166/3000] Train Acc: 0.999950 Loss: 0.001062 | Val Acc: 0.183065 loss: 9.953722\n",
            "[1167/3000] Train Acc: 0.995765 Loss: 0.013225 | Val Acc: 0.183065 loss: 9.770681\n",
            "[1168/3000] Train Acc: 0.999647 Loss: 0.002195 | Val Acc: 0.183669 loss: 9.797647\n",
            "[1169/3000] Train Acc: 0.999748 Loss: 0.001738 | Val Acc: 0.184677 loss: 9.841150\n",
            "[1170/3000] Train Acc: 0.999748 Loss: 0.001616 | Val Acc: 0.187903 loss: 9.614701\n",
            "[1171/3000] Train Acc: 0.999849 Loss: 0.001034 | Val Acc: 0.177621 loss: 10.250068\n",
            "[1172/3000] Train Acc: 0.999597 Loss: 0.002455 | Val Acc: 0.172379 loss: 10.534852\n",
            "[1173/3000] Train Acc: 0.999698 Loss: 0.002524 | Val Acc: 0.181048 loss: 10.151986\n",
            "[1174/3000] Train Acc: 0.999193 Loss: 0.004042 | Val Acc: 0.188105 loss: 9.596197\n",
            "[1175/3000] Train Acc: 0.999193 Loss: 0.003016 | Val Acc: 0.184476 loss: 9.737105\n",
            "[1176/3000] Train Acc: 0.999193 Loss: 0.003702 | Val Acc: 0.182863 loss: 10.029923\n",
            "[1177/3000] Train Acc: 0.999647 Loss: 0.001511 | Val Acc: 0.187702 loss: 9.828098\n",
            "[1178/3000] Train Acc: 0.999647 Loss: 0.001741 | Val Acc: 0.170565 loss: 10.561581\n",
            "[1179/3000] Train Acc: 0.995866 Loss: 0.013646 | Val Acc: 0.183468 loss: 9.931998\n",
            "[1180/3000] Train Acc: 0.999698 Loss: 0.001573 | Val Acc: 0.184677 loss: 10.026293\n",
            "[1181/3000] Train Acc: 0.999748 Loss: 0.001560 | Val Acc: 0.185887 loss: 9.936449\n",
            "[1182/3000] Train Acc: 0.999798 Loss: 0.001360 | Val Acc: 0.186492 loss: 10.021078\n",
            "[1183/3000] Train Acc: 0.999647 Loss: 0.001835 | Val Acc: 0.181653 loss: 10.144520\n",
            "[1184/3000] Train Acc: 0.997731 Loss: 0.007539 | Val Acc: 0.187500 loss: 10.053312\n",
            "[1185/3000] Train Acc: 0.996774 Loss: 0.011677 | Val Acc: 0.181452 loss: 10.137470\n",
            "[1186/3000] Train Acc: 0.999647 Loss: 0.001863 | Val Acc: 0.175403 loss: 10.199403\n",
            "[1187/3000] Train Acc: 0.999950 Loss: 0.001128 | Val Acc: 0.185887 loss: 9.987055\n",
            "[1188/3000] Train Acc: 0.999950 Loss: 0.000925 | Val Acc: 0.180242 loss: 10.154148\n",
            "[1189/3000] Train Acc: 0.999244 Loss: 0.003217 | Val Acc: 0.182460 loss: 10.160586\n",
            "[1190/3000] Train Acc: 0.998891 Loss: 0.003845 | Val Acc: 0.197379 loss: 9.503738\n",
            "[1191/3000] Train Acc: 0.999950 Loss: 0.001024 | Val Acc: 0.179032 loss: 10.348717\n",
            "[1192/3000] Train Acc: 0.999849 Loss: 0.000923 | Val Acc: 0.183669 loss: 10.122216\n",
            "[1193/3000] Train Acc: 0.999849 Loss: 0.001096 | Val Acc: 0.184073 loss: 10.070267\n",
            "[1194/3000] Train Acc: 0.998538 Loss: 0.005517 | Val Acc: 0.188306 loss: 9.970690\n",
            "[1195/3000] Train Acc: 0.999193 Loss: 0.003184 | Val Acc: 0.197177 loss: 9.517277\n",
            "[1196/3000] Train Acc: 0.999093 Loss: 0.003377 | Val Acc: 0.196371 loss: 9.186564\n",
            "[1197/3000] Train Acc: 0.998740 Loss: 0.004631 | Val Acc: 0.186492 loss: 9.967932\n",
            "[1198/3000] Train Acc: 0.999849 Loss: 0.000994 | Val Acc: 0.186694 loss: 10.000878\n",
            "[1199/3000] Train Acc: 0.999698 Loss: 0.001323 | Val Acc: 0.190323 loss: 9.887244\n",
            "[1200/3000] Train Acc: 0.999798 Loss: 0.001376 | Val Acc: 0.181855 loss: 10.132650\n",
            "[1201/3000] Train Acc: 0.996622 Loss: 0.011603 | Val Acc: 0.181653 loss: 10.195240\n",
            "[1202/3000] Train Acc: 0.999395 Loss: 0.002156 | Val Acc: 0.183065 loss: 10.102060\n",
            "[1203/3000] Train Acc: 0.999798 Loss: 0.001364 | Val Acc: 0.185685 loss: 10.279365\n",
            "[1204/3000] Train Acc: 0.999698 Loss: 0.001528 | Val Acc: 0.184274 loss: 10.286226\n",
            "[1205/3000] Train Acc: 0.999748 Loss: 0.001438 | Val Acc: 0.184274 loss: 10.232010\n",
            "[1206/3000] Train Acc: 0.999597 Loss: 0.001675 | Val Acc: 0.187097 loss: 10.408789\n",
            "[1207/3000] Train Acc: 0.999698 Loss: 0.001386 | Val Acc: 0.189516 loss: 10.003059\n",
            "[1208/3000] Train Acc: 0.998336 Loss: 0.005480 | Val Acc: 0.184274 loss: 10.264458\n",
            "[1209/3000] Train Acc: 0.999647 Loss: 0.001933 | Val Acc: 0.195766 loss: 9.479158\n",
            "[1210/3000] Train Acc: 0.997782 Loss: 0.007158 | Val Acc: 0.191331 loss: 9.784403\n",
            "[1211/3000] Train Acc: 0.999849 Loss: 0.001643 | Val Acc: 0.186694 loss: 9.985461\n",
            "[1212/3000] Train Acc: 0.999698 Loss: 0.001550 | Val Acc: 0.185685 loss: 10.162887\n",
            "[1213/3000] Train Acc: 0.999345 Loss: 0.002490 | Val Acc: 0.174597 loss: 10.581419\n",
            "[1214/3000] Train Acc: 0.999345 Loss: 0.002676 | Val Acc: 0.184476 loss: 10.410680\n",
            "[1215/3000] Train Acc: 0.998840 Loss: 0.003333 | Val Acc: 0.172581 loss: 10.987041\n",
            "[1216/3000] Train Acc: 0.998336 Loss: 0.006328 | Val Acc: 0.174395 loss: 10.721737\n",
            "[1217/3000] Train Acc: 0.999395 Loss: 0.002600 | Val Acc: 0.181855 loss: 10.397565\n",
            "[1218/3000] Train Acc: 0.999748 Loss: 0.001239 | Val Acc: 0.178226 loss: 10.481625\n",
            "[1219/3000] Train Acc: 0.998740 Loss: 0.004469 | Val Acc: 0.172177 loss: 10.773842\n",
            "[1220/3000] Train Acc: 0.999950 Loss: 0.001169 | Val Acc: 0.187702 loss: 9.932167\n",
            "[1221/3000] Train Acc: 0.999849 Loss: 0.001143 | Val Acc: 0.184879 loss: 10.070271\n",
            "[1222/3000] Train Acc: 0.999244 Loss: 0.003318 | Val Acc: 0.184073 loss: 10.100147\n",
            "[1223/3000] Train Acc: 0.999950 Loss: 0.000982 | Val Acc: 0.182460 loss: 10.062027\n",
            "[1224/3000] Train Acc: 0.999849 Loss: 0.001212 | Val Acc: 0.174395 loss: 10.635283\n",
            "[1225/3000] Train Acc: 0.997328 Loss: 0.009576 | Val Acc: 0.180242 loss: 10.353171\n",
            "[1226/3000] Train Acc: 0.999496 Loss: 0.002016 | Val Acc: 0.167540 loss: 10.452638\n",
            "[1227/3000] Train Acc: 0.999546 Loss: 0.002358 | Val Acc: 0.182056 loss: 10.283589\n",
            "[1228/3000] Train Acc: 0.999849 Loss: 0.001204 | Val Acc: 0.180444 loss: 10.174507\n",
            "[1229/3000] Train Acc: 0.997429 Loss: 0.009531 | Val Acc: 0.176411 loss: 10.317386\n",
            "[1230/3000] Train Acc: 1.000000 Loss: 0.000839 | Val Acc: 0.182258 loss: 10.203622\n",
            "[1231/3000] Train Acc: 0.999950 Loss: 0.000746 | Val Acc: 0.187500 loss: 9.945718\n",
            "[1232/3000] Train Acc: 0.999698 Loss: 0.001371 | Val Acc: 0.183669 loss: 10.207970\n",
            "[1233/3000] Train Acc: 0.999647 Loss: 0.001364 | Val Acc: 0.199798 loss: 9.522569\n",
            "[1234/3000] Train Acc: 0.999294 Loss: 0.002332 | Val Acc: 0.178024 loss: 10.054300\n",
            "[1235/3000] Train Acc: 0.998840 Loss: 0.005426 | Val Acc: 0.183468 loss: 10.198546\n",
            "[1236/3000] Train Acc: 0.999698 Loss: 0.001427 | Val Acc: 0.179637 loss: 10.370258\n",
            "[1237/3000] Train Acc: 0.998992 Loss: 0.003601 | Val Acc: 0.177621 loss: 10.576947\n",
            "[1238/3000] Train Acc: 0.999849 Loss: 0.001624 | Val Acc: 0.182056 loss: 10.212102\n",
            "[1239/3000] Train Acc: 0.999849 Loss: 0.000858 | Val Acc: 0.180645 loss: 10.321606\n",
            "[1240/3000] Train Acc: 0.999294 Loss: 0.002631 | Val Acc: 0.181855 loss: 10.304905\n",
            "[1241/3000] Train Acc: 0.998740 Loss: 0.004973 | Val Acc: 0.184274 loss: 10.695144\n",
            "[1242/3000] Train Acc: 0.999899 Loss: 0.001350 | Val Acc: 0.169960 loss: 10.990243\n",
            "[1243/3000] Train Acc: 0.999698 Loss: 0.001439 | Val Acc: 0.194758 loss: 9.756443\n",
            "[1244/3000] Train Acc: 0.998588 Loss: 0.004123 | Val Acc: 0.183065 loss: 10.166547\n",
            "[1245/3000] Train Acc: 0.999748 Loss: 0.001226 | Val Acc: 0.181452 loss: 10.551059\n",
            "[1246/3000] Train Acc: 0.999950 Loss: 0.000945 | Val Acc: 0.178226 loss: 10.572199\n",
            "[1247/3000] Train Acc: 0.999395 Loss: 0.002658 | Val Acc: 0.174597 loss: 10.765512\n",
            "[1248/3000] Train Acc: 0.999193 Loss: 0.002868 | Val Acc: 0.200403 loss: 9.740870\n",
            "[1249/3000] Train Acc: 0.999395 Loss: 0.003290 | Val Acc: 0.180444 loss: 10.312280\n",
            "[1250/3000] Train Acc: 0.999597 Loss: 0.001974 | Val Acc: 0.186089 loss: 10.447889\n",
            "[1251/3000] Train Acc: 0.999950 Loss: 0.000792 | Val Acc: 0.193750 loss: 9.889663\n",
            "[1252/3000] Train Acc: 0.996471 Loss: 0.010031 | Val Acc: 0.189315 loss: 9.834008\n",
            "[1253/3000] Train Acc: 0.999798 Loss: 0.001293 | Val Acc: 0.187500 loss: 10.145684\n",
            "[1254/3000] Train Acc: 0.999950 Loss: 0.000798 | Val Acc: 0.174597 loss: 10.856742\n",
            "[1255/3000] Train Acc: 0.999849 Loss: 0.000876 | Val Acc: 0.193145 loss: 9.776047\n",
            "[1256/3000] Train Acc: 0.999950 Loss: 0.000733 | Val Acc: 0.186694 loss: 10.217463\n",
            "[1257/3000] Train Acc: 0.998992 Loss: 0.003705 | Val Acc: 0.184677 loss: 10.552583\n",
            "[1258/3000] Train Acc: 0.999798 Loss: 0.000871 | Val Acc: 0.178831 loss: 10.367560\n",
            "[1259/3000] Train Acc: 0.999950 Loss: 0.001015 | Val Acc: 0.184677 loss: 10.306855\n",
            "[1260/3000] Train Acc: 0.999546 Loss: 0.002830 | Val Acc: 0.185484 loss: 10.532318\n",
            "[1261/3000] Train Acc: 0.998941 Loss: 0.004067 | Val Acc: 0.184073 loss: 10.450874\n",
            "[1262/3000] Train Acc: 0.999042 Loss: 0.004115 | Val Acc: 0.187702 loss: 10.375318\n",
            "[1263/3000] Train Acc: 0.997681 Loss: 0.007066 | Val Acc: 0.177823 loss: 10.493096\n",
            "[1264/3000] Train Acc: 0.999496 Loss: 0.001798 | Val Acc: 0.185887 loss: 10.293124\n",
            "[1265/3000] Train Acc: 0.998740 Loss: 0.004186 | Val Acc: 0.180242 loss: 10.682673\n",
            "[1266/3000] Train Acc: 0.999899 Loss: 0.000948 | Val Acc: 0.189919 loss: 10.059008\n",
            "[1267/3000] Train Acc: 0.999193 Loss: 0.003041 | Val Acc: 0.189919 loss: 10.220210\n",
            "[1268/3000] Train Acc: 0.999899 Loss: 0.000771 | Val Acc: 0.185282 loss: 10.410452\n",
            "[1269/3000] Train Acc: 0.999899 Loss: 0.000563 | Val Acc: 0.185081 loss: 10.218909\n",
            "[1270/3000] Train Acc: 0.999546 Loss: 0.002319 | Val Acc: 0.170968 loss: 10.848599\n",
            "[1271/3000] Train Acc: 0.999950 Loss: 0.000703 | Val Acc: 0.185282 loss: 10.423217\n",
            "[1272/3000] Train Acc: 0.999950 Loss: 0.000890 | Val Acc: 0.187298 loss: 10.359302\n",
            "[1273/3000] Train Acc: 0.999193 Loss: 0.003816 | Val Acc: 0.190726 loss: 9.898253\n",
            "[1274/3000] Train Acc: 0.999698 Loss: 0.002129 | Val Acc: 0.183871 loss: 10.642869\n",
            "[1275/3000] Train Acc: 0.999950 Loss: 0.000784 | Val Acc: 0.186694 loss: 10.286670\n",
            "[1276/3000] Train Acc: 0.996219 Loss: 0.012623 | Val Acc: 0.187702 loss: 10.366306\n",
            "[1277/3000] Train Acc: 1.000000 Loss: 0.000796 | Val Acc: 0.181250 loss: 10.567137\n",
            "[1278/3000] Train Acc: 0.999345 Loss: 0.001581 | Val Acc: 0.179032 loss: 11.116997\n",
            "[1279/3000] Train Acc: 0.999445 Loss: 0.002267 | Val Acc: 0.193145 loss: 10.394723\n",
            "[1280/3000] Train Acc: 0.999698 Loss: 0.001963 | Val Acc: 0.171774 loss: 11.113770\n",
            "[1281/3000] Train Acc: 0.999798 Loss: 0.000892 | Val Acc: 0.193347 loss: 10.066262\n",
            "[1282/3000] Train Acc: 0.999546 Loss: 0.001817 | Val Acc: 0.186694 loss: 10.446478\n",
            "[1283/3000] Train Acc: 0.999798 Loss: 0.000911 | Val Acc: 0.186895 loss: 10.752805\n",
            "[1284/3000] Train Acc: 0.995816 Loss: 0.013528 | Val Acc: 0.187702 loss: 10.390656\n",
            "[1285/3000] Train Acc: 1.000000 Loss: 0.000701 | Val Acc: 0.188710 loss: 10.343608\n",
            "[1286/3000] Train Acc: 0.999748 Loss: 0.001271 | Val Acc: 0.185685 loss: 10.340035\n",
            "[1287/3000] Train Acc: 0.999597 Loss: 0.001660 | Val Acc: 0.184677 loss: 10.649271\n",
            "[1288/3000] Train Acc: 0.999798 Loss: 0.001253 | Val Acc: 0.182661 loss: 10.440978\n",
            "[1289/3000] Train Acc: 0.999748 Loss: 0.001211 | Val Acc: 0.181048 loss: 10.582102\n",
            "[1290/3000] Train Acc: 0.999244 Loss: 0.002656 | Val Acc: 0.177823 loss: 10.710818\n",
            "[1291/3000] Train Acc: 0.998740 Loss: 0.003968 | Val Acc: 0.191331 loss: 10.221828\n",
            "[1292/3000] Train Acc: 0.999193 Loss: 0.003254 | Val Acc: 0.184476 loss: 10.470893\n",
            "[1293/3000] Train Acc: 0.999143 Loss: 0.003025 | Val Acc: 0.180444 loss: 10.533996\n",
            "[1294/3000] Train Acc: 0.999950 Loss: 0.000924 | Val Acc: 0.185484 loss: 10.447129\n",
            "[1295/3000] Train Acc: 1.000000 Loss: 0.000629 | Val Acc: 0.184274 loss: 10.399077\n",
            "[1296/3000] Train Acc: 0.999445 Loss: 0.001623 | Val Acc: 0.190524 loss: 10.275353\n",
            "[1297/3000] Train Acc: 0.999143 Loss: 0.004127 | Val Acc: 0.179637 loss: 10.804416\n",
            "[1298/3000] Train Acc: 0.998790 Loss: 0.004038 | Val Acc: 0.185887 loss: 10.333620\n",
            "[1299/3000] Train Acc: 0.999798 Loss: 0.001109 | Val Acc: 0.187097 loss: 10.397601\n",
            "[1300/3000] Train Acc: 0.999950 Loss: 0.000588 | Val Acc: 0.186895 loss: 10.398517\n",
            "[1301/3000] Train Acc: 0.999798 Loss: 0.001145 | Val Acc: 0.176411 loss: 11.071974\n",
            "[1302/3000] Train Acc: 0.996269 Loss: 0.012415 | Val Acc: 0.187903 loss: 10.585148\n",
            "[1303/3000] Train Acc: 0.999849 Loss: 0.001083 | Val Acc: 0.179032 loss: 10.560061\n",
            "[1304/3000] Train Acc: 0.999899 Loss: 0.000736 | Val Acc: 0.186895 loss: 10.342047\n",
            "[1305/3000] Train Acc: 0.999849 Loss: 0.000793 | Val Acc: 0.181653 loss: 11.037612\n",
            "[1306/3000] Train Acc: 0.998185 Loss: 0.005359 | Val Acc: 0.166532 loss: 11.268157\n",
            "[1307/3000] Train Acc: 0.998941 Loss: 0.004277 | Val Acc: 0.193952 loss: 10.234712\n",
            "[1308/3000] Train Acc: 1.000000 Loss: 0.000575 | Val Acc: 0.183468 loss: 10.651202\n",
            "[1309/3000] Train Acc: 0.999698 Loss: 0.001109 | Val Acc: 0.196573 loss: 10.122811\n",
            "[1310/3000] Train Acc: 0.999748 Loss: 0.001397 | Val Acc: 0.192944 loss: 10.203694\n",
            "[1311/3000] Train Acc: 0.999798 Loss: 0.001044 | Val Acc: 0.176815 loss: 11.037110\n",
            "[1312/3000] Train Acc: 0.999193 Loss: 0.003357 | Val Acc: 0.198387 loss: 9.994137\n",
            "[1313/3000] Train Acc: 0.999849 Loss: 0.001146 | Val Acc: 0.188710 loss: 10.465691\n",
            "[1314/3000] Train Acc: 0.999798 Loss: 0.001414 | Val Acc: 0.198185 loss: 10.009192\n",
            "[1315/3000] Train Acc: 0.996118 Loss: 0.011526 | Val Acc: 0.179032 loss: 10.879215\n",
            "[1316/3000] Train Acc: 0.999899 Loss: 0.001037 | Val Acc: 0.186492 loss: 10.478393\n",
            "[1317/3000] Train Acc: 0.999950 Loss: 0.000751 | Val Acc: 0.184879 loss: 10.645757\n",
            "[1318/3000] Train Acc: 0.999698 Loss: 0.001194 | Val Acc: 0.186694 loss: 10.484825\n",
            "[1319/3000] Train Acc: 0.999899 Loss: 0.000755 | Val Acc: 0.196573 loss: 9.951747\n",
            "[1320/3000] Train Acc: 0.995160 Loss: 0.015457 | Val Acc: 0.185282 loss: 10.451133\n",
            "[1321/3000] Train Acc: 0.999899 Loss: 0.000967 | Val Acc: 0.186089 loss: 10.525762\n",
            "[1322/3000] Train Acc: 0.999899 Loss: 0.000879 | Val Acc: 0.184073 loss: 10.613373\n",
            "[1323/3000] Train Acc: 0.999950 Loss: 0.000535 | Val Acc: 0.188911 loss: 10.392812\n",
            "[1324/3000] Train Acc: 0.999496 Loss: 0.002165 | Val Acc: 0.183468 loss: 10.842841\n",
            "[1325/3000] Train Acc: 0.999950 Loss: 0.000633 | Val Acc: 0.182460 loss: 10.691046\n",
            "[1326/3000] Train Acc: 0.999748 Loss: 0.001137 | Val Acc: 0.183669 loss: 10.679706\n",
            "[1327/3000] Train Acc: 1.000000 Loss: 0.000390 | Val Acc: 0.184879 loss: 10.500357\n",
            "[1328/3000] Train Acc: 0.997530 Loss: 0.007696 | Val Acc: 0.190726 loss: 10.240588\n",
            "[1329/3000] Train Acc: 0.998639 Loss: 0.005992 | Val Acc: 0.179839 loss: 10.690266\n",
            "[1330/3000] Train Acc: 1.000000 Loss: 0.000579 | Val Acc: 0.181250 loss: 10.744324\n",
            "[1331/3000] Train Acc: 0.999395 Loss: 0.001968 | Val Acc: 0.182056 loss: 10.723029\n",
            "[1332/3000] Train Acc: 0.999950 Loss: 0.001007 | Val Acc: 0.173589 loss: 10.831937\n",
            "[1333/3000] Train Acc: 0.999950 Loss: 0.000627 | Val Acc: 0.191935 loss: 10.262687\n",
            "[1334/3000] Train Acc: 0.999143 Loss: 0.003044 | Val Acc: 0.182056 loss: 10.858644\n",
            "[1335/3000] Train Acc: 1.000000 Loss: 0.000495 | Val Acc: 0.186290 loss: 10.474430\n",
            "[1336/3000] Train Acc: 0.999244 Loss: 0.002561 | Val Acc: 0.183468 loss: 10.687123\n",
            "[1337/3000] Train Acc: 0.997076 Loss: 0.008033 | Val Acc: 0.184476 loss: 10.858608\n",
            "[1338/3000] Train Acc: 0.999798 Loss: 0.001262 | Val Acc: 0.184677 loss: 10.688309\n",
            "[1339/3000] Train Acc: 0.999950 Loss: 0.000801 | Val Acc: 0.184274 loss: 10.916875\n",
            "[1340/3000] Train Acc: 0.999899 Loss: 0.000763 | Val Acc: 0.183871 loss: 10.691512\n",
            "[1341/3000] Train Acc: 0.997177 Loss: 0.009055 | Val Acc: 0.183871 loss: 10.731153\n",
            "[1342/3000] Train Acc: 1.000000 Loss: 0.000623 | Val Acc: 0.187097 loss: 10.518066\n",
            "[1343/3000] Train Acc: 0.999748 Loss: 0.001081 | Val Acc: 0.178629 loss: 10.959552\n",
            "[1344/3000] Train Acc: 0.998084 Loss: 0.005878 | Val Acc: 0.187702 loss: 10.584445\n",
            "[1345/3000] Train Acc: 1.000000 Loss: 0.000668 | Val Acc: 0.182460 loss: 10.847708\n",
            "[1346/3000] Train Acc: 0.999546 Loss: 0.001758 | Val Acc: 0.183266 loss: 10.664484\n",
            "[1347/3000] Train Acc: 0.999546 Loss: 0.001828 | Val Acc: 0.192540 loss: 10.253105\n",
            "[1348/3000] Train Acc: 0.999597 Loss: 0.001495 | Val Acc: 0.185081 loss: 10.657692\n",
            "[1349/3000] Train Acc: 0.999698 Loss: 0.001099 | Val Acc: 0.179839 loss: 11.560965\n",
            "[1350/3000] Train Acc: 0.999597 Loss: 0.002158 | Val Acc: 0.186694 loss: 10.721465\n",
            "[1351/3000] Train Acc: 0.999647 Loss: 0.001768 | Val Acc: 0.181855 loss: 10.669867\n",
            "[1352/3000] Train Acc: 0.998639 Loss: 0.004926 | Val Acc: 0.188508 loss: 10.717545\n",
            "[1353/3000] Train Acc: 0.999849 Loss: 0.000911 | Val Acc: 0.187500 loss: 10.567459\n",
            "[1354/3000] Train Acc: 0.999546 Loss: 0.002184 | Val Acc: 0.179839 loss: 11.200481\n",
            "[1355/3000] Train Acc: 0.999899 Loss: 0.000924 | Val Acc: 0.185081 loss: 10.752192\n",
            "[1356/3000] Train Acc: 0.999748 Loss: 0.001041 | Val Acc: 0.169355 loss: 11.625655\n",
            "[1357/3000] Train Acc: 0.998488 Loss: 0.004865 | Val Acc: 0.184677 loss: 10.743099\n",
            "[1358/3000] Train Acc: 0.999899 Loss: 0.001003 | Val Acc: 0.170766 loss: 11.717441\n",
            "[1359/3000] Train Acc: 0.999496 Loss: 0.001649 | Val Acc: 0.185887 loss: 10.759267\n",
            "[1360/3000] Train Acc: 0.999849 Loss: 0.001179 | Val Acc: 0.185887 loss: 10.746090\n",
            "[1361/3000] Train Acc: 0.997580 Loss: 0.008455 | Val Acc: 0.188105 loss: 10.543211\n",
            "[1362/3000] Train Acc: 0.997278 Loss: 0.008705 | Val Acc: 0.188306 loss: 10.541466\n",
            "[1363/3000] Train Acc: 0.999950 Loss: 0.000701 | Val Acc: 0.183669 loss: 10.737992\n",
            "[1364/3000] Train Acc: 0.999798 Loss: 0.001108 | Val Acc: 0.185484 loss: 10.516826\n",
            "[1365/3000] Train Acc: 1.000000 Loss: 0.000559 | Val Acc: 0.175403 loss: 11.109967\n",
            "[1366/3000] Train Acc: 0.999546 Loss: 0.001715 | Val Acc: 0.169153 loss: 11.737419\n",
            "[1367/3000] Train Acc: 0.999950 Loss: 0.000774 | Val Acc: 0.186492 loss: 10.897749\n",
            "[1368/3000] Train Acc: 0.997832 Loss: 0.006438 | Val Acc: 0.191129 loss: 10.503184\n",
            "[1369/3000] Train Acc: 1.000000 Loss: 0.000712 | Val Acc: 0.184476 loss: 10.841213\n",
            "[1370/3000] Train Acc: 0.999899 Loss: 0.000661 | Val Acc: 0.183468 loss: 10.822817\n",
            "[1371/3000] Train Acc: 0.999546 Loss: 0.001632 | Val Acc: 0.172581 loss: 11.549689\n",
            "[1372/3000] Train Acc: 0.999748 Loss: 0.001683 | Val Acc: 0.180847 loss: 11.026347\n",
            "[1373/3000] Train Acc: 0.996068 Loss: 0.010215 | Val Acc: 0.188710 loss: 11.022452\n",
            "[1374/3000] Train Acc: 0.999899 Loss: 0.001232 | Val Acc: 0.182863 loss: 11.034576\n",
            "[1375/3000] Train Acc: 0.999950 Loss: 0.000526 | Val Acc: 0.178226 loss: 11.125189\n",
            "[1376/3000] Train Acc: 0.999899 Loss: 0.000709 | Val Acc: 0.186895 loss: 10.748236\n",
            "[1377/3000] Train Acc: 0.999849 Loss: 0.000638 | Val Acc: 0.174395 loss: 11.588992\n",
            "[1378/3000] Train Acc: 0.999899 Loss: 0.000912 | Val Acc: 0.179839 loss: 11.192072\n",
            "[1379/3000] Train Acc: 0.999445 Loss: 0.002367 | Val Acc: 0.185282 loss: 10.900787\n",
            "[1380/3000] Train Acc: 0.999899 Loss: 0.000740 | Val Acc: 0.187298 loss: 10.441162\n",
            "[1381/3000] Train Acc: 0.999244 Loss: 0.003356 | Val Acc: 0.184677 loss: 10.626654\n",
            "[1382/3000] Train Acc: 0.997631 Loss: 0.007944 | Val Acc: 0.189919 loss: 10.938015\n",
            "[1383/3000] Train Acc: 1.000000 Loss: 0.000440 | Val Acc: 0.187298 loss: 10.975154\n",
            "[1384/3000] Train Acc: 0.999647 Loss: 0.001523 | Val Acc: 0.184879 loss: 11.003234\n",
            "[1385/3000] Train Acc: 0.999597 Loss: 0.001381 | Val Acc: 0.164113 loss: 11.546728\n",
            "[1386/3000] Train Acc: 0.998992 Loss: 0.004186 | Val Acc: 0.191935 loss: 10.783182\n",
            "[1387/3000] Train Acc: 0.999748 Loss: 0.002022 | Val Acc: 0.181855 loss: 11.445028\n",
            "[1388/3000] Train Acc: 0.999647 Loss: 0.002148 | Val Acc: 0.183669 loss: 11.058113\n",
            "[1389/3000] Train Acc: 0.999445 Loss: 0.002122 | Val Acc: 0.177016 loss: 11.131381\n",
            "[1390/3000] Train Acc: 0.999748 Loss: 0.001590 | Val Acc: 0.189919 loss: 10.398018\n",
            "[1391/3000] Train Acc: 0.998639 Loss: 0.005286 | Val Acc: 0.186895 loss: 10.703280\n",
            "[1392/3000] Train Acc: 1.000000 Loss: 0.000403 | Val Acc: 0.186290 loss: 10.995059\n",
            "[1393/3000] Train Acc: 0.999899 Loss: 0.000559 | Val Acc: 0.185282 loss: 10.868384\n",
            "[1394/3000] Train Acc: 0.999546 Loss: 0.002071 | Val Acc: 0.182056 loss: 11.275654\n",
            "[1395/3000] Train Acc: 0.999193 Loss: 0.002422 | Val Acc: 0.180847 loss: 10.981827\n",
            "[1396/3000] Train Acc: 0.999950 Loss: 0.000669 | Val Acc: 0.179032 loss: 11.179502\n",
            "[1397/3000] Train Acc: 0.998336 Loss: 0.006085 | Val Acc: 0.177218 loss: 11.481463\n",
            "[1398/3000] Train Acc: 0.998992 Loss: 0.004029 | Val Acc: 0.189315 loss: 10.487640\n",
            "[1399/3000] Train Acc: 1.000000 Loss: 0.000579 | Val Acc: 0.186492 loss: 10.877558\n",
            "[1400/3000] Train Acc: 0.999899 Loss: 0.000714 | Val Acc: 0.180847 loss: 10.891459\n",
            "[1401/3000] Train Acc: 0.998588 Loss: 0.004331 | Val Acc: 0.166734 loss: 11.472864\n",
            "[1402/3000] Train Acc: 0.999798 Loss: 0.001390 | Val Acc: 0.184677 loss: 10.841352\n",
            "[1403/3000] Train Acc: 0.999798 Loss: 0.001063 | Val Acc: 0.175202 loss: 11.233019\n",
            "[1404/3000] Train Acc: 0.999899 Loss: 0.000602 | Val Acc: 0.186694 loss: 10.847158\n",
            "[1405/3000] Train Acc: 0.999950 Loss: 0.000515 | Val Acc: 0.186895 loss: 10.965582\n",
            "[1406/3000] Train Acc: 0.996874 Loss: 0.011561 | Val Acc: 0.163508 loss: 11.634256\n",
            "[1407/3000] Train Acc: 0.998740 Loss: 0.004297 | Val Acc: 0.180444 loss: 11.086290\n",
            "[1408/3000] Train Acc: 0.999950 Loss: 0.000839 | Val Acc: 0.184476 loss: 10.877271\n",
            "[1409/3000] Train Acc: 0.999950 Loss: 0.000465 | Val Acc: 0.184879 loss: 10.980881\n",
            "[1410/3000] Train Acc: 1.000000 Loss: 0.000420 | Val Acc: 0.184879 loss: 11.301497\n",
            "[1411/3000] Train Acc: 1.000000 Loss: 0.000461 | Val Acc: 0.173992 loss: 11.413988\n",
            "[1412/3000] Train Acc: 0.999950 Loss: 0.000428 | Val Acc: 0.182258 loss: 11.275839\n",
            "[1413/3000] Train Acc: 1.000000 Loss: 0.000461 | Val Acc: 0.190323 loss: 10.637233\n",
            "[1414/3000] Train Acc: 0.995816 Loss: 0.012460 | Val Acc: 0.184073 loss: 11.234483\n",
            "[1415/3000] Train Acc: 0.999899 Loss: 0.001173 | Val Acc: 0.188306 loss: 10.838455\n",
            "[1416/3000] Train Acc: 1.000000 Loss: 0.000462 | Val Acc: 0.179637 loss: 11.332094\n",
            "[1417/3000] Train Acc: 1.000000 Loss: 0.000500 | Val Acc: 0.182258 loss: 11.106397\n",
            "[1418/3000] Train Acc: 1.000000 Loss: 0.000535 | Val Acc: 0.188508 loss: 10.938625\n",
            "[1419/3000] Train Acc: 1.000000 Loss: 0.000312 | Val Acc: 0.185887 loss: 11.061999\n",
            "[1420/3000] Train Acc: 1.000000 Loss: 0.000626 | Val Acc: 0.185887 loss: 10.861078\n",
            "[1421/3000] Train Acc: 0.996622 Loss: 0.011060 | Val Acc: 0.179234 loss: 11.257734\n",
            "[1422/3000] Train Acc: 0.999597 Loss: 0.001621 | Val Acc: 0.181048 loss: 11.190031\n",
            "[1423/3000] Train Acc: 1.000000 Loss: 0.000412 | Val Acc: 0.188105 loss: 10.843810\n",
            "[1424/3000] Train Acc: 0.999950 Loss: 0.000373 | Val Acc: 0.187702 loss: 11.030239\n",
            "[1425/3000] Train Acc: 0.997883 Loss: 0.007867 | Val Acc: 0.192540 loss: 10.240560\n",
            "[1426/3000] Train Acc: 0.999950 Loss: 0.000845 | Val Acc: 0.188306 loss: 10.858919\n",
            "[1427/3000] Train Acc: 0.999899 Loss: 0.000487 | Val Acc: 0.171169 loss: 11.901199\n",
            "[1428/3000] Train Acc: 0.998588 Loss: 0.004127 | Val Acc: 0.181653 loss: 10.684685\n",
            "[1429/3000] Train Acc: 0.999345 Loss: 0.002567 | Val Acc: 0.187903 loss: 10.837448\n",
            "[1430/3000] Train Acc: 0.999849 Loss: 0.000785 | Val Acc: 0.184476 loss: 10.941656\n",
            "[1431/3000] Train Acc: 0.999445 Loss: 0.002132 | Val Acc: 0.184879 loss: 11.033132\n",
            "[1432/3000] Train Acc: 0.998034 Loss: 0.005783 | Val Acc: 0.188508 loss: 11.142818\n",
            "[1433/3000] Train Acc: 0.998689 Loss: 0.004575 | Val Acc: 0.193750 loss: 10.439665\n",
            "[1434/3000] Train Acc: 0.999950 Loss: 0.000818 | Val Acc: 0.185887 loss: 10.930122\n",
            "[1435/3000] Train Acc: 0.999849 Loss: 0.000744 | Val Acc: 0.189516 loss: 10.960932\n",
            "[1436/3000] Train Acc: 1.000000 Loss: 0.000729 | Val Acc: 0.185282 loss: 10.966276\n",
            "[1437/3000] Train Acc: 1.000000 Loss: 0.000398 | Val Acc: 0.178427 loss: 11.255786\n",
            "[1438/3000] Train Acc: 0.999849 Loss: 0.000924 | Val Acc: 0.184073 loss: 11.001254\n",
            "[1439/3000] Train Acc: 1.000000 Loss: 0.000667 | Val Acc: 0.189113 loss: 11.038121\n",
            "[1440/3000] Train Acc: 0.999950 Loss: 0.000409 | Val Acc: 0.183871 loss: 11.022367\n",
            "[1441/3000] Train Acc: 0.997076 Loss: 0.009781 | Val Acc: 0.190524 loss: 10.622787\n",
            "[1442/3000] Train Acc: 0.999899 Loss: 0.000937 | Val Acc: 0.182258 loss: 11.381501\n",
            "[1443/3000] Train Acc: 0.999395 Loss: 0.002536 | Val Acc: 0.183669 loss: 11.128766\n",
            "[1444/3000] Train Acc: 0.997731 Loss: 0.006286 | Val Acc: 0.186694 loss: 10.911040\n",
            "[1445/3000] Train Acc: 1.000000 Loss: 0.000416 | Val Acc: 0.175202 loss: 11.577811\n",
            "[1446/3000] Train Acc: 1.000000 Loss: 0.000473 | Val Acc: 0.182863 loss: 11.333102\n",
            "[1447/3000] Train Acc: 0.999345 Loss: 0.001752 | Val Acc: 0.183266 loss: 11.302098\n",
            "[1448/3000] Train Acc: 1.000000 Loss: 0.000458 | Val Acc: 0.190927 loss: 10.928004\n",
            "[1449/3000] Train Acc: 0.999546 Loss: 0.001430 | Val Acc: 0.183871 loss: 11.143194\n",
            "[1450/3000] Train Acc: 1.000000 Loss: 0.000485 | Val Acc: 0.192339 loss: 10.676747\n",
            "[1451/3000] Train Acc: 0.995312 Loss: 0.014190 | Val Acc: 0.189919 loss: 11.296229\n",
            "[1452/3000] Train Acc: 0.999849 Loss: 0.001231 | Val Acc: 0.185887 loss: 11.465014\n",
            "[1453/3000] Train Acc: 1.000000 Loss: 0.000435 | Val Acc: 0.185685 loss: 11.352832\n",
            "[1454/3000] Train Acc: 1.000000 Loss: 0.000331 | Val Acc: 0.189113 loss: 11.146705\n",
            "[1455/3000] Train Acc: 0.999647 Loss: 0.001424 | Val Acc: 0.184073 loss: 11.265796\n",
            "[1456/3000] Train Acc: 0.999143 Loss: 0.003070 | Val Acc: 0.176613 loss: 11.904722\n",
            "[1457/3000] Train Acc: 0.999546 Loss: 0.002116 | Val Acc: 0.196371 loss: 10.730725\n",
            "[1458/3000] Train Acc: 0.999798 Loss: 0.001107 | Val Acc: 0.190726 loss: 10.995189\n",
            "[1459/3000] Train Acc: 0.999849 Loss: 0.000784 | Val Acc: 0.189718 loss: 11.019843\n",
            "[1460/3000] Train Acc: 0.999546 Loss: 0.001699 | Val Acc: 0.175000 loss: 11.851794\n",
            "[1461/3000] Train Acc: 0.999546 Loss: 0.001742 | Val Acc: 0.188105 loss: 10.961244\n",
            "[1462/3000] Train Acc: 0.999950 Loss: 0.000586 | Val Acc: 0.190726 loss: 10.845552\n",
            "[1463/3000] Train Acc: 0.999647 Loss: 0.001151 | Val Acc: 0.171774 loss: 11.964712\n",
            "[1464/3000] Train Acc: 0.997983 Loss: 0.006403 | Val Acc: 0.187298 loss: 10.920684\n",
            "[1465/3000] Train Acc: 1.000000 Loss: 0.000614 | Val Acc: 0.185887 loss: 11.004833\n",
            "[1466/3000] Train Acc: 0.999445 Loss: 0.002124 | Val Acc: 0.187903 loss: 10.750928\n",
            "[1467/3000] Train Acc: 0.999294 Loss: 0.003038 | Val Acc: 0.183468 loss: 11.458392\n",
            "[1468/3000] Train Acc: 0.999546 Loss: 0.001596 | Val Acc: 0.170161 loss: 12.275033\n",
            "[1469/3000] Train Acc: 0.996118 Loss: 0.013115 | Val Acc: 0.178629 loss: 11.272932\n",
            "[1470/3000] Train Acc: 0.999445 Loss: 0.002004 | Val Acc: 0.185282 loss: 11.143707\n",
            "[1471/3000] Train Acc: 1.000000 Loss: 0.000369 | Val Acc: 0.192137 loss: 10.847048\n",
            "[1472/3000] Train Acc: 1.000000 Loss: 0.000315 | Val Acc: 0.183871 loss: 11.057452\n",
            "[1473/3000] Train Acc: 0.999798 Loss: 0.000809 | Val Acc: 0.186694 loss: 11.048229\n",
            "[1474/3000] Train Acc: 1.000000 Loss: 0.000396 | Val Acc: 0.189718 loss: 11.106523\n",
            "[1475/3000] Train Acc: 1.000000 Loss: 0.000318 | Val Acc: 0.188508 loss: 11.076817\n",
            "[1476/3000] Train Acc: 0.997479 Loss: 0.007331 | Val Acc: 0.168548 loss: 12.007245\n",
            "[1477/3000] Train Acc: 0.999496 Loss: 0.001930 | Val Acc: 0.185081 loss: 11.230316\n",
            "[1478/3000] Train Acc: 0.999849 Loss: 0.000947 | Val Acc: 0.184476 loss: 11.443136\n",
            "[1479/3000] Train Acc: 0.999748 Loss: 0.000725 | Val Acc: 0.189919 loss: 11.041557\n",
            "[1480/3000] Train Acc: 0.999899 Loss: 0.000723 | Val Acc: 0.180444 loss: 11.595135\n",
            "[1481/3000] Train Acc: 0.997530 Loss: 0.008125 | Val Acc: 0.178226 loss: 11.660668\n",
            "[1482/3000] Train Acc: 0.999950 Loss: 0.000485 | Val Acc: 0.186694 loss: 10.985714\n",
            "[1483/3000] Train Acc: 0.999849 Loss: 0.000634 | Val Acc: 0.181250 loss: 11.315624\n",
            "[1484/3000] Train Acc: 0.999899 Loss: 0.000457 | Val Acc: 0.186694 loss: 11.083440\n",
            "[1485/3000] Train Acc: 0.999950 Loss: 0.000569 | Val Acc: 0.185484 loss: 11.195990\n",
            "[1486/3000] Train Acc: 0.999546 Loss: 0.001754 | Val Acc: 0.179234 loss: 11.554880\n",
            "[1487/3000] Train Acc: 1.000000 Loss: 0.000391 | Val Acc: 0.188105 loss: 10.968076\n",
            "[1488/3000] Train Acc: 0.996521 Loss: 0.009446 | Val Acc: 0.180847 loss: 11.527710\n",
            "[1489/3000] Train Acc: 1.000000 Loss: 0.000510 | Val Acc: 0.185282 loss: 11.334793\n",
            "[1490/3000] Train Acc: 1.000000 Loss: 0.000319 | Val Acc: 0.179032 loss: 11.661155\n",
            "[1491/3000] Train Acc: 0.999950 Loss: 0.000504 | Val Acc: 0.170565 loss: 12.306294\n",
            "[1492/3000] Train Acc: 0.999345 Loss: 0.002493 | Val Acc: 0.181250 loss: 11.153881\n",
            "[1493/3000] Train Acc: 0.999445 Loss: 0.001946 | Val Acc: 0.166129 loss: 12.013341\n",
            "[1494/3000] Train Acc: 0.999496 Loss: 0.002726 | Val Acc: 0.174597 loss: 12.110484\n",
            "[1495/3000] Train Acc: 0.999748 Loss: 0.001818 | Val Acc: 0.171573 loss: 12.160961\n",
            "[1496/3000] Train Acc: 1.000000 Loss: 0.000537 | Val Acc: 0.193548 loss: 10.961562\n",
            "[1497/3000] Train Acc: 0.999093 Loss: 0.003172 | Val Acc: 0.190927 loss: 10.952083\n",
            "[1498/3000] Train Acc: 0.999798 Loss: 0.001216 | Val Acc: 0.185081 loss: 11.261928\n",
            "[1499/3000] Train Acc: 0.999698 Loss: 0.001360 | Val Acc: 0.181250 loss: 11.251118\n",
            "[1500/3000] Train Acc: 0.998034 Loss: 0.005578 | Val Acc: 0.184879 loss: 11.544752\n",
            "[1501/3000] Train Acc: 0.999950 Loss: 0.000917 | Val Acc: 0.181855 loss: 11.304030\n",
            "[1502/3000] Train Acc: 0.999899 Loss: 0.000532 | Val Acc: 0.187903 loss: 11.061596\n",
            "[1503/3000] Train Acc: 1.000000 Loss: 0.000319 | Val Acc: 0.191935 loss: 11.068074\n",
            "[1504/3000] Train Acc: 0.999950 Loss: 0.000471 | Val Acc: 0.194960 loss: 10.592253\n",
            "[1505/3000] Train Acc: 0.999950 Loss: 0.000623 | Val Acc: 0.186895 loss: 11.305321\n",
            "[1506/3000] Train Acc: 0.998992 Loss: 0.003327 | Val Acc: 0.169960 loss: 11.740532\n",
            "[1507/3000] Train Acc: 0.999143 Loss: 0.002637 | Val Acc: 0.177218 loss: 11.361673\n",
            "[1508/3000] Train Acc: 0.999345 Loss: 0.002150 | Val Acc: 0.187298 loss: 11.050122\n",
            "[1509/3000] Train Acc: 1.000000 Loss: 0.000337 | Val Acc: 0.186290 loss: 11.402010\n",
            "[1510/3000] Train Acc: 0.998840 Loss: 0.003242 | Val Acc: 0.154032 loss: 13.247090\n",
            "[1511/3000] Train Acc: 0.998992 Loss: 0.003380 | Val Acc: 0.196573 loss: 10.973922\n",
            "[1512/3000] Train Acc: 0.999496 Loss: 0.001900 | Val Acc: 0.183669 loss: 11.277799\n",
            "[1513/3000] Train Acc: 0.999798 Loss: 0.001159 | Val Acc: 0.183266 loss: 11.214474\n",
            "[1514/3000] Train Acc: 1.000000 Loss: 0.000317 | Val Acc: 0.182661 loss: 11.358437\n",
            "[1515/3000] Train Acc: 0.999798 Loss: 0.000698 | Val Acc: 0.186694 loss: 11.137440\n",
            "[1516/3000] Train Acc: 0.999546 Loss: 0.001483 | Val Acc: 0.170363 loss: 12.420613\n",
            "[1517/3000] Train Acc: 0.999143 Loss: 0.003261 | Val Acc: 0.201210 loss: 10.841697\n",
            "[1518/3000] Train Acc: 0.999798 Loss: 0.001050 | Val Acc: 0.178024 loss: 11.462920\n",
            "[1519/3000] Train Acc: 0.995211 Loss: 0.014831 | Val Acc: 0.192339 loss: 11.169568\n",
            "[1520/3000] Train Acc: 0.999950 Loss: 0.000587 | Val Acc: 0.185887 loss: 11.519961\n",
            "[1521/3000] Train Acc: 1.000000 Loss: 0.000341 | Val Acc: 0.187702 loss: 11.379975\n",
            "[1522/3000] Train Acc: 0.999950 Loss: 0.000384 | Val Acc: 0.190927 loss: 11.122316\n",
            "[1523/3000] Train Acc: 0.999849 Loss: 0.000561 | Val Acc: 0.188508 loss: 11.176079\n",
            "[1524/3000] Train Acc: 0.999748 Loss: 0.000894 | Val Acc: 0.191532 loss: 11.135773\n",
            "[1525/3000] Train Acc: 0.999597 Loss: 0.001347 | Val Acc: 0.188508 loss: 11.274577\n",
            "[1526/3000] Train Acc: 1.000000 Loss: 0.000299 | Val Acc: 0.189718 loss: 11.179487\n",
            "[1527/3000] Train Acc: 0.997933 Loss: 0.006973 | Val Acc: 0.187500 loss: 11.303498\n",
            "[1528/3000] Train Acc: 1.000000 Loss: 0.000352 | Val Acc: 0.183065 loss: 11.447559\n",
            "[1529/3000] Train Acc: 1.000000 Loss: 0.000308 | Val Acc: 0.187298 loss: 11.174965\n",
            "[1530/3000] Train Acc: 1.000000 Loss: 0.000243 | Val Acc: 0.188306 loss: 11.224618\n",
            "[1531/3000] Train Acc: 0.999193 Loss: 0.002601 | Val Acc: 0.171573 loss: 11.321202\n",
            "[1532/3000] Train Acc: 0.998437 Loss: 0.005261 | Val Acc: 0.192339 loss: 11.005585\n",
            "[1533/3000] Train Acc: 0.999950 Loss: 0.000447 | Val Acc: 0.194153 loss: 10.809668\n",
            "[1534/3000] Train Acc: 0.999899 Loss: 0.000417 | Val Acc: 0.196976 loss: 10.545683\n",
            "[1535/3000] Train Acc: 0.999950 Loss: 0.000558 | Val Acc: 0.190121 loss: 11.034955\n",
            "[1536/3000] Train Acc: 0.999748 Loss: 0.000941 | Val Acc: 0.180040 loss: 12.039801\n",
            "[1537/3000] Train Acc: 0.995967 Loss: 0.013940 | Val Acc: 0.205444 loss: 10.555171\n",
            "saving model with acc 0.205\n",
            "[1538/3000] Train Acc: 0.999899 Loss: 0.000697 | Val Acc: 0.206653 loss: 10.535710\n",
            "saving model with acc 0.207\n",
            "[1539/3000] Train Acc: 0.999899 Loss: 0.000599 | Val Acc: 0.190927 loss: 11.277042\n",
            "[1540/3000] Train Acc: 0.999950 Loss: 0.000486 | Val Acc: 0.203024 loss: 10.604159\n",
            "[1541/3000] Train Acc: 1.000000 Loss: 0.000371 | Val Acc: 0.193952 loss: 11.021425\n",
            "[1542/3000] Train Acc: 1.000000 Loss: 0.000277 | Val Acc: 0.192339 loss: 11.063338\n",
            "[1543/3000] Train Acc: 0.999899 Loss: 0.000633 | Val Acc: 0.189315 loss: 10.980445\n",
            "[1544/3000] Train Acc: 0.999093 Loss: 0.003527 | Val Acc: 0.183871 loss: 11.633539\n",
            "[1545/3000] Train Acc: 0.999395 Loss: 0.002186 | Val Acc: 0.189315 loss: 11.351966\n",
            "[1546/3000] Train Acc: 0.998387 Loss: 0.004423 | Val Acc: 0.173387 loss: 12.222119\n",
            "[1547/3000] Train Acc: 0.998185 Loss: 0.005319 | Val Acc: 0.191532 loss: 10.961448\n",
            "[1548/3000] Train Acc: 1.000000 Loss: 0.000297 | Val Acc: 0.189516 loss: 11.088518\n",
            "[1549/3000] Train Acc: 1.000000 Loss: 0.000237 | Val Acc: 0.187903 loss: 11.252794\n",
            "[1550/3000] Train Acc: 1.000000 Loss: 0.000234 | Val Acc: 0.180444 loss: 11.701591\n",
            "[1551/3000] Train Acc: 0.999647 Loss: 0.001561 | Val Acc: 0.202621 loss: 10.443535\n",
            "[1552/3000] Train Acc: 0.998084 Loss: 0.006196 | Val Acc: 0.189516 loss: 11.173129\n",
            "[1553/3000] Train Acc: 0.999899 Loss: 0.000817 | Val Acc: 0.194355 loss: 11.219536\n",
            "[1554/3000] Train Acc: 0.999294 Loss: 0.002217 | Val Acc: 0.197177 loss: 11.155153\n",
            "[1555/3000] Train Acc: 0.999950 Loss: 0.000484 | Val Acc: 0.192540 loss: 11.323788\n",
            "[1556/3000] Train Acc: 0.999647 Loss: 0.001549 | Val Acc: 0.190927 loss: 11.209519\n",
            "[1557/3000] Train Acc: 0.999849 Loss: 0.001334 | Val Acc: 0.193548 loss: 11.489351\n",
            "[1558/3000] Train Acc: 0.995110 Loss: 0.015707 | Val Acc: 0.180242 loss: 12.005423\n",
            "[1559/3000] Train Acc: 0.999950 Loss: 0.000522 | Val Acc: 0.183669 loss: 11.763077\n",
            "[1560/3000] Train Acc: 1.000000 Loss: 0.000329 | Val Acc: 0.183669 loss: 11.753475\n",
            "[1561/3000] Train Acc: 1.000000 Loss: 0.000257 | Val Acc: 0.186290 loss: 11.618716\n",
            "[1562/3000] Train Acc: 1.000000 Loss: 0.000242 | Val Acc: 0.182460 loss: 11.789628\n",
            "[1563/3000] Train Acc: 1.000000 Loss: 0.000303 | Val Acc: 0.185484 loss: 11.592165\n",
            "[1564/3000] Train Acc: 1.000000 Loss: 0.000264 | Val Acc: 0.190524 loss: 11.353697\n",
            "[1565/3000] Train Acc: 0.999899 Loss: 0.000472 | Val Acc: 0.185685 loss: 11.628635\n",
            "[1566/3000] Train Acc: 0.996219 Loss: 0.012951 | Val Acc: 0.195565 loss: 11.244848\n",
            "[1567/3000] Train Acc: 1.000000 Loss: 0.000586 | Val Acc: 0.188306 loss: 11.470607\n",
            "[1568/3000] Train Acc: 1.000000 Loss: 0.000366 | Val Acc: 0.180847 loss: 11.823989\n",
            "[1569/3000] Train Acc: 1.000000 Loss: 0.000326 | Val Acc: 0.186694 loss: 11.461808\n",
            "[1570/3000] Train Acc: 1.000000 Loss: 0.000305 | Val Acc: 0.187298 loss: 11.524686\n",
            "[1571/3000] Train Acc: 1.000000 Loss: 0.000251 | Val Acc: 0.182056 loss: 11.839111\n",
            "[1572/3000] Train Acc: 1.000000 Loss: 0.000271 | Val Acc: 0.185484 loss: 11.684769\n",
            "[1573/3000] Train Acc: 0.997278 Loss: 0.010828 | Val Acc: 0.190121 loss: 11.163788\n",
            "[1574/3000] Train Acc: 1.000000 Loss: 0.000401 | Val Acc: 0.186694 loss: 11.331139\n",
            "[1575/3000] Train Acc: 1.000000 Loss: 0.000290 | Val Acc: 0.187298 loss: 11.244569\n",
            "[1576/3000] Train Acc: 1.000000 Loss: 0.000333 | Val Acc: 0.183266 loss: 11.432840\n",
            "[1577/3000] Train Acc: 1.000000 Loss: 0.000267 | Val Acc: 0.188508 loss: 11.310785\n",
            "[1578/3000] Train Acc: 0.999849 Loss: 0.001012 | Val Acc: 0.190726 loss: 11.081611\n",
            "[1579/3000] Train Acc: 0.999294 Loss: 0.003517 | Val Acc: 0.207258 loss: 10.143769\n",
            "saving model with acc 0.207\n",
            "[1580/3000] Train Acc: 0.997782 Loss: 0.007339 | Val Acc: 0.185282 loss: 11.607809\n",
            "[1581/3000] Train Acc: 1.000000 Loss: 0.000399 | Val Acc: 0.184073 loss: 11.525788\n",
            "[1582/3000] Train Acc: 1.000000 Loss: 0.000330 | Val Acc: 0.186290 loss: 11.500766\n",
            "[1583/3000] Train Acc: 1.000000 Loss: 0.000245 | Val Acc: 0.188105 loss: 11.528752\n",
            "[1584/3000] Train Acc: 0.999899 Loss: 0.000567 | Val Acc: 0.188710 loss: 11.324489\n",
            "[1585/3000] Train Acc: 0.999950 Loss: 0.000394 | Val Acc: 0.187097 loss: 11.473856\n",
            "[1586/3000] Train Acc: 1.000000 Loss: 0.000240 | Val Acc: 0.188306 loss: 11.370724\n",
            "[1587/3000] Train Acc: 0.999748 Loss: 0.001388 | Val Acc: 0.167944 loss: 12.541344\n",
            "[1588/3000] Train Acc: 0.996874 Loss: 0.009485 | Val Acc: 0.188710 loss: 11.009075\n",
            "[1589/3000] Train Acc: 0.999748 Loss: 0.001076 | Val Acc: 0.179637 loss: 11.794099\n",
            "[1590/3000] Train Acc: 0.999798 Loss: 0.001011 | Val Acc: 0.186694 loss: 11.583730\n",
            "[1591/3000] Train Acc: 0.999849 Loss: 0.000522 | Val Acc: 0.159476 loss: 13.106035\n",
            "[1592/3000] Train Acc: 0.999698 Loss: 0.001286 | Val Acc: 0.194960 loss: 10.960243\n",
            "[1593/3000] Train Acc: 0.999042 Loss: 0.003047 | Val Acc: 0.178831 loss: 11.909972\n",
            "[1594/3000] Train Acc: 0.999899 Loss: 0.000546 | Val Acc: 0.183871 loss: 11.530541\n",
            "[1595/3000] Train Acc: 1.000000 Loss: 0.000281 | Val Acc: 0.184677 loss: 11.464591\n",
            "[1596/3000] Train Acc: 0.999950 Loss: 0.000312 | Val Acc: 0.178831 loss: 11.830358\n",
            "[1597/3000] Train Acc: 0.999698 Loss: 0.001233 | Val Acc: 0.184274 loss: 11.538158\n",
            "[1598/3000] Train Acc: 0.999748 Loss: 0.001085 | Val Acc: 0.161895 loss: 12.873279\n",
            "[1599/3000] Train Acc: 0.996572 Loss: 0.011368 | Val Acc: 0.181250 loss: 11.675417\n",
            "[1600/3000] Train Acc: 0.999445 Loss: 0.002360 | Val Acc: 0.181653 loss: 11.765367\n",
            "[1601/3000] Train Acc: 1.000000 Loss: 0.000428 | Val Acc: 0.186694 loss: 11.651130\n",
            "[1602/3000] Train Acc: 1.000000 Loss: 0.000239 | Val Acc: 0.189919 loss: 11.367278\n",
            "[1603/3000] Train Acc: 0.999950 Loss: 0.000259 | Val Acc: 0.168347 loss: 12.737346\n",
            "[1604/3000] Train Acc: 0.998790 Loss: 0.003914 | Val Acc: 0.176008 loss: 11.859505\n",
            "[1605/3000] Train Acc: 0.999597 Loss: 0.001421 | Val Acc: 0.190121 loss: 11.284260\n",
            "[1606/3000] Train Acc: 0.999698 Loss: 0.001092 | Val Acc: 0.189516 loss: 11.471293\n",
            "[1607/3000] Train Acc: 1.000000 Loss: 0.000395 | Val Acc: 0.187702 loss: 11.525656\n",
            "[1608/3000] Train Acc: 1.000000 Loss: 0.000214 | Val Acc: 0.191532 loss: 11.331358\n",
            "[1609/3000] Train Acc: 0.999244 Loss: 0.002950 | Val Acc: 0.184073 loss: 12.004332\n",
            "[1610/3000] Train Acc: 0.999042 Loss: 0.002627 | Val Acc: 0.190323 loss: 11.327408\n",
            "[1611/3000] Train Acc: 0.999899 Loss: 0.000479 | Val Acc: 0.180847 loss: 11.741901\n",
            "[1612/3000] Train Acc: 0.995160 Loss: 0.014239 | Val Acc: 0.186694 loss: 11.487145\n",
            "[1613/3000] Train Acc: 1.000000 Loss: 0.000403 | Val Acc: 0.183871 loss: 11.567741\n",
            "[1614/3000] Train Acc: 1.000000 Loss: 0.000260 | Val Acc: 0.188105 loss: 11.540570\n",
            "[1615/3000] Train Acc: 1.000000 Loss: 0.000235 | Val Acc: 0.191734 loss: 11.423189\n",
            "[1616/3000] Train Acc: 1.000000 Loss: 0.000231 | Val Acc: 0.186290 loss: 11.732018\n",
            "[1617/3000] Train Acc: 1.000000 Loss: 0.000260 | Val Acc: 0.195161 loss: 11.283608\n",
            "[1618/3000] Train Acc: 0.999950 Loss: 0.000293 | Val Acc: 0.179032 loss: 11.829774\n",
            "[1619/3000] Train Acc: 0.998840 Loss: 0.003438 | Val Acc: 0.183871 loss: 11.610677\n",
            "[1620/3000] Train Acc: 0.998437 Loss: 0.004747 | Val Acc: 0.187702 loss: 11.420792\n",
            "[1621/3000] Train Acc: 1.000000 Loss: 0.000349 | Val Acc: 0.192944 loss: 11.258690\n",
            "[1622/3000] Train Acc: 0.999546 Loss: 0.001891 | Val Acc: 0.183468 loss: 11.623724\n",
            "[1623/3000] Train Acc: 0.999950 Loss: 0.000449 | Val Acc: 0.198589 loss: 10.965848\n",
            "[1624/3000] Train Acc: 1.000000 Loss: 0.000282 | Val Acc: 0.187500 loss: 11.460612\n",
            "[1625/3000] Train Acc: 1.000000 Loss: 0.000201 | Val Acc: 0.188306 loss: 11.415521\n",
            "[1626/3000] Train Acc: 0.996975 Loss: 0.009107 | Val Acc: 0.190524 loss: 11.530707\n",
            "[1627/3000] Train Acc: 0.999798 Loss: 0.000950 | Val Acc: 0.185081 loss: 11.643506\n",
            "[1628/3000] Train Acc: 0.999950 Loss: 0.000336 | Val Acc: 0.185887 loss: 11.696116\n",
            "[1629/3000] Train Acc: 0.999950 Loss: 0.000339 | Val Acc: 0.184879 loss: 11.837065\n",
            "[1630/3000] Train Acc: 1.000000 Loss: 0.000247 | Val Acc: 0.187500 loss: 11.698026\n",
            "[1631/3000] Train Acc: 1.000000 Loss: 0.000314 | Val Acc: 0.188105 loss: 11.480158\n",
            "[1632/3000] Train Acc: 1.000000 Loss: 0.000269 | Val Acc: 0.186290 loss: 11.718750\n",
            "[1633/3000] Train Acc: 0.994959 Loss: 0.014490 | Val Acc: 0.193145 loss: 11.615019\n",
            "[1634/3000] Train Acc: 1.000000 Loss: 0.000400 | Val Acc: 0.189516 loss: 11.647892\n",
            "[1635/3000] Train Acc: 1.000000 Loss: 0.000322 | Val Acc: 0.188911 loss: 11.587171\n",
            "[1636/3000] Train Acc: 1.000000 Loss: 0.000237 | Val Acc: 0.185685 loss: 11.798183\n",
            "[1637/3000] Train Acc: 1.000000 Loss: 0.000215 | Val Acc: 0.187298 loss: 11.682241\n",
            "[1638/3000] Train Acc: 1.000000 Loss: 0.000201 | Val Acc: 0.188508 loss: 11.683636\n",
            "[1639/3000] Train Acc: 1.000000 Loss: 0.000255 | Val Acc: 0.189315 loss: 11.703474\n",
            "[1640/3000] Train Acc: 0.998538 Loss: 0.005380 | Val Acc: 0.203226 loss: 10.449456\n",
            "[1641/3000] Train Acc: 0.998286 Loss: 0.005241 | Val Acc: 0.189718 loss: 11.644445\n",
            "[1642/3000] Train Acc: 1.000000 Loss: 0.000337 | Val Acc: 0.185887 loss: 11.749140\n",
            "[1643/3000] Train Acc: 1.000000 Loss: 0.000221 | Val Acc: 0.187903 loss: 11.577759\n",
            "[1644/3000] Train Acc: 1.000000 Loss: 0.000271 | Val Acc: 0.182460 loss: 11.800198\n",
            "[1645/3000] Train Acc: 0.998689 Loss: 0.004282 | Val Acc: 0.204839 loss: 10.754559\n",
            "[1646/3000] Train Acc: 0.999698 Loss: 0.001327 | Val Acc: 0.185282 loss: 11.646218\n",
            "[1647/3000] Train Acc: 1.000000 Loss: 0.000304 | Val Acc: 0.186694 loss: 11.636445\n",
            "[1648/3000] Train Acc: 1.000000 Loss: 0.000211 | Val Acc: 0.174798 loss: 12.455307\n",
            "[1649/3000] Train Acc: 0.998840 Loss: 0.003805 | Val Acc: 0.201008 loss: 10.708665\n",
            "[1650/3000] Train Acc: 0.999647 Loss: 0.001176 | Val Acc: 0.190726 loss: 11.424640\n",
            "[1651/3000] Train Acc: 0.999950 Loss: 0.000369 | Val Acc: 0.186290 loss: 11.676488\n",
            "[1652/3000] Train Acc: 0.999798 Loss: 0.001109 | Val Acc: 0.155847 loss: 13.488432\n",
            "[1653/3000] Train Acc: 0.998236 Loss: 0.006190 | Val Acc: 0.160887 loss: 13.741484\n",
            "[1654/3000] Train Acc: 0.998639 Loss: 0.004870 | Val Acc: 0.185282 loss: 11.802267\n",
            "[1655/3000] Train Acc: 0.999849 Loss: 0.000712 | Val Acc: 0.183065 loss: 11.977567\n",
            "[1656/3000] Train Acc: 1.000000 Loss: 0.000321 | Val Acc: 0.187903 loss: 11.771230\n",
            "[1657/3000] Train Acc: 0.999647 Loss: 0.000902 | Val Acc: 0.191935 loss: 11.524012\n",
            "[1658/3000] Train Acc: 1.000000 Loss: 0.000355 | Val Acc: 0.187097 loss: 11.780300\n",
            "[1659/3000] Train Acc: 0.999950 Loss: 0.000395 | Val Acc: 0.184476 loss: 11.887266\n",
            "[1660/3000] Train Acc: 0.997328 Loss: 0.006882 | Val Acc: 0.160887 loss: 13.055757\n",
            "[1661/3000] Train Acc: 0.998588 Loss: 0.004246 | Val Acc: 0.186895 loss: 11.474082\n",
            "[1662/3000] Train Acc: 1.000000 Loss: 0.000237 | Val Acc: 0.185282 loss: 11.803092\n",
            "[1663/3000] Train Acc: 1.000000 Loss: 0.000228 | Val Acc: 0.191129 loss: 11.434312\n",
            "[1664/3000] Train Acc: 0.999899 Loss: 0.000387 | Val Acc: 0.192540 loss: 11.121331\n",
            "[1665/3000] Train Acc: 0.999899 Loss: 0.000463 | Val Acc: 0.193952 loss: 11.225145\n",
            "[1666/3000] Train Acc: 0.999899 Loss: 0.000508 | Val Acc: 0.183669 loss: 12.191202\n",
            "[1667/3000] Train Acc: 0.997782 Loss: 0.007143 | Val Acc: 0.191129 loss: 11.528741\n",
            "[1668/3000] Train Acc: 0.998084 Loss: 0.005339 | Val Acc: 0.189315 loss: 11.511800\n",
            "[1669/3000] Train Acc: 0.999950 Loss: 0.000613 | Val Acc: 0.188306 loss: 11.793474\n",
            "[1670/3000] Train Acc: 0.999950 Loss: 0.000417 | Val Acc: 0.194355 loss: 11.360446\n",
            "[1671/3000] Train Acc: 0.999950 Loss: 0.000393 | Val Acc: 0.192944 loss: 11.456626\n",
            "[1672/3000] Train Acc: 1.000000 Loss: 0.000184 | Val Acc: 0.190927 loss: 11.578698\n",
            "[1673/3000] Train Acc: 0.999748 Loss: 0.000923 | Val Acc: 0.166532 loss: 12.797165\n",
            "[1674/3000] Train Acc: 0.997177 Loss: 0.008572 | Val Acc: 0.186290 loss: 11.935582\n",
            "[1675/3000] Train Acc: 1.000000 Loss: 0.000380 | Val Acc: 0.175000 loss: 12.487491\n",
            "[1676/3000] Train Acc: 0.999798 Loss: 0.000684 | Val Acc: 0.194556 loss: 11.508172\n",
            "[1677/3000] Train Acc: 1.000000 Loss: 0.000219 | Val Acc: 0.179637 loss: 12.197129\n",
            "[1678/3000] Train Acc: 1.000000 Loss: 0.000181 | Val Acc: 0.187097 loss: 11.843289\n",
            "[1679/3000] Train Acc: 1.000000 Loss: 0.000174 | Val Acc: 0.192944 loss: 11.553533\n",
            "[1680/3000] Train Acc: 0.999698 Loss: 0.000969 | Val Acc: 0.185887 loss: 11.379815\n",
            "[1681/3000] Train Acc: 0.997479 Loss: 0.008491 | Val Acc: 0.187500 loss: 11.818769\n",
            "[1682/3000] Train Acc: 0.999748 Loss: 0.001174 | Val Acc: 0.191935 loss: 11.503000\n",
            "[1683/3000] Train Acc: 1.000000 Loss: 0.000321 | Val Acc: 0.195565 loss: 11.178107\n",
            "[1684/3000] Train Acc: 0.999899 Loss: 0.000825 | Val Acc: 0.182460 loss: 11.997929\n",
            "[1685/3000] Train Acc: 0.999193 Loss: 0.002558 | Val Acc: 0.169355 loss: 12.707483\n",
            "[1686/3000] Train Acc: 0.999345 Loss: 0.002158 | Val Acc: 0.188911 loss: 11.694042\n",
            "[1687/3000] Train Acc: 0.999899 Loss: 0.000466 | Val Acc: 0.189113 loss: 11.943373\n",
            "[1688/3000] Train Acc: 0.999899 Loss: 0.000414 | Val Acc: 0.174597 loss: 12.481580\n",
            "[1689/3000] Train Acc: 0.998437 Loss: 0.005553 | Val Acc: 0.185081 loss: 12.239912\n",
            "[1690/3000] Train Acc: 0.999698 Loss: 0.001084 | Val Acc: 0.194153 loss: 11.441044\n",
            "[1691/3000] Train Acc: 0.999748 Loss: 0.001112 | Val Acc: 0.192944 loss: 11.365597\n",
            "[1692/3000] Train Acc: 1.000000 Loss: 0.000345 | Val Acc: 0.188306 loss: 11.726329\n",
            "[1693/3000] Train Acc: 1.000000 Loss: 0.000180 | Val Acc: 0.189315 loss: 11.769836\n",
            "[1694/3000] Train Acc: 0.999647 Loss: 0.001013 | Val Acc: 0.186895 loss: 12.030181\n",
            "[1695/3000] Train Acc: 1.000000 Loss: 0.000247 | Val Acc: 0.191935 loss: 11.739391\n",
            "[1696/3000] Train Acc: 0.995614 Loss: 0.011642 | Val Acc: 0.192944 loss: 11.680662\n",
            "[1697/3000] Train Acc: 0.999899 Loss: 0.000576 | Val Acc: 0.175806 loss: 12.452907\n",
            "[1698/3000] Train Acc: 0.999950 Loss: 0.000346 | Val Acc: 0.191129 loss: 11.763262\n",
            "[1699/3000] Train Acc: 1.000000 Loss: 0.000275 | Val Acc: 0.187097 loss: 11.974633\n",
            "[1700/3000] Train Acc: 1.000000 Loss: 0.000183 | Val Acc: 0.189718 loss: 11.871718\n",
            "[1701/3000] Train Acc: 1.000000 Loss: 0.000194 | Val Acc: 0.190121 loss: 11.888432\n",
            "[1702/3000] Train Acc: 1.000000 Loss: 0.000175 | Val Acc: 0.192137 loss: 11.453105\n",
            "[1703/3000] Train Acc: 1.000000 Loss: 0.000295 | Val Acc: 0.190323 loss: 11.645745\n",
            "[1704/3000] Train Acc: 1.000000 Loss: 0.000281 | Val Acc: 0.189919 loss: 11.698589\n",
            "[1705/3000] Train Acc: 1.000000 Loss: 0.000227 | Val Acc: 0.181855 loss: 12.184311\n",
            "[1706/3000] Train Acc: 0.996774 Loss: 0.011485 | Val Acc: 0.173185 loss: 12.495561\n",
            "[1707/3000] Train Acc: 0.999899 Loss: 0.000590 | Val Acc: 0.182661 loss: 11.959623\n",
            "[1708/3000] Train Acc: 1.000000 Loss: 0.000238 | Val Acc: 0.184476 loss: 11.803991\n",
            "[1709/3000] Train Acc: 1.000000 Loss: 0.000201 | Val Acc: 0.184476 loss: 11.858155\n",
            "[1710/3000] Train Acc: 1.000000 Loss: 0.000196 | Val Acc: 0.178629 loss: 12.184541\n",
            "[1711/3000] Train Acc: 1.000000 Loss: 0.000191 | Val Acc: 0.187500 loss: 11.823595\n",
            "[1712/3000] Train Acc: 1.000000 Loss: 0.000284 | Val Acc: 0.187097 loss: 11.830063\n",
            "[1713/3000] Train Acc: 1.000000 Loss: 0.000199 | Val Acc: 0.189718 loss: 11.601978\n",
            "[1714/3000] Train Acc: 1.000000 Loss: 0.000220 | Val Acc: 0.181048 loss: 12.045722\n",
            "[1715/3000] Train Acc: 0.995866 Loss: 0.012739 | Val Acc: 0.186492 loss: 11.960687\n",
            "[1716/3000] Train Acc: 1.000000 Loss: 0.000475 | Val Acc: 0.182661 loss: 12.000390\n",
            "[1717/3000] Train Acc: 0.999950 Loss: 0.000352 | Val Acc: 0.182460 loss: 12.027997\n",
            "[1718/3000] Train Acc: 1.000000 Loss: 0.000357 | Val Acc: 0.184879 loss: 11.769336\n",
            "[1719/3000] Train Acc: 1.000000 Loss: 0.000179 | Val Acc: 0.188105 loss: 11.643818\n",
            "[1720/3000] Train Acc: 1.000000 Loss: 0.000236 | Val Acc: 0.189113 loss: 11.574632\n",
            "[1721/3000] Train Acc: 0.997983 Loss: 0.006647 | Val Acc: 0.185887 loss: 11.637877\n",
            "[1722/3000] Train Acc: 1.000000 Loss: 0.000288 | Val Acc: 0.181250 loss: 12.031959\n",
            "[1723/3000] Train Acc: 1.000000 Loss: 0.000308 | Val Acc: 0.197581 loss: 11.042278\n",
            "[1724/3000] Train Acc: 0.999395 Loss: 0.002160 | Val Acc: 0.184879 loss: 11.562988\n",
            "[1725/3000] Train Acc: 1.000000 Loss: 0.000281 | Val Acc: 0.187097 loss: 11.520308\n",
            "[1726/3000] Train Acc: 1.000000 Loss: 0.000163 | Val Acc: 0.180242 loss: 12.081425\n",
            "[1727/3000] Train Acc: 0.997530 Loss: 0.007449 | Val Acc: 0.190726 loss: 11.527759\n",
            "[1728/3000] Train Acc: 0.999899 Loss: 0.000800 | Val Acc: 0.189516 loss: 11.514644\n",
            "[1729/3000] Train Acc: 0.999899 Loss: 0.000525 | Val Acc: 0.182258 loss: 12.530460\n",
            "[1730/3000] Train Acc: 0.997731 Loss: 0.007104 | Val Acc: 0.184073 loss: 11.722104\n",
            "[1731/3000] Train Acc: 0.999950 Loss: 0.000425 | Val Acc: 0.196169 loss: 11.256304\n",
            "[1732/3000] Train Acc: 1.000000 Loss: 0.000264 | Val Acc: 0.184677 loss: 11.828820\n",
            "[1733/3000] Train Acc: 1.000000 Loss: 0.000211 | Val Acc: 0.188508 loss: 11.735190\n",
            "[1734/3000] Train Acc: 0.999950 Loss: 0.000414 | Val Acc: 0.186694 loss: 11.729639\n",
            "[1735/3000] Train Acc: 0.999597 Loss: 0.001436 | Val Acc: 0.187097 loss: 11.831559\n",
            "[1736/3000] Train Acc: 1.000000 Loss: 0.000251 | Val Acc: 0.187097 loss: 11.814853\n",
            "[1737/3000] Train Acc: 0.997530 Loss: 0.007768 | Val Acc: 0.176613 loss: 11.778401\n",
            "[1738/3000] Train Acc: 0.999647 Loss: 0.001541 | Val Acc: 0.179637 loss: 11.932970\n",
            "[1739/3000] Train Acc: 0.999798 Loss: 0.000884 | Val Acc: 0.177016 loss: 11.965203\n",
            "[1740/3000] Train Acc: 1.000000 Loss: 0.000255 | Val Acc: 0.184476 loss: 11.593117\n",
            "[1741/3000] Train Acc: 0.997580 Loss: 0.006820 | Val Acc: 0.185484 loss: 11.462163\n",
            "[1742/3000] Train Acc: 0.999698 Loss: 0.001720 | Val Acc: 0.173185 loss: 12.279843\n",
            "[1743/3000] Train Acc: 0.999899 Loss: 0.000552 | Val Acc: 0.189315 loss: 11.407658\n",
            "[1744/3000] Train Acc: 0.999748 Loss: 0.000904 | Val Acc: 0.183065 loss: 11.848472\n",
            "[1745/3000] Train Acc: 0.999698 Loss: 0.000935 | Val Acc: 0.185685 loss: 11.789225\n",
            "[1746/3000] Train Acc: 0.999950 Loss: 0.000350 | Val Acc: 0.184677 loss: 11.996301\n",
            "[1747/3000] Train Acc: 0.999950 Loss: 0.000296 | Val Acc: 0.195363 loss: 11.035361\n",
            "[1748/3000] Train Acc: 0.999345 Loss: 0.003312 | Val Acc: 0.191331 loss: 11.588511\n",
            "[1749/3000] Train Acc: 0.999698 Loss: 0.001003 | Val Acc: 0.196169 loss: 11.760857\n",
            "[1750/3000] Train Acc: 0.998336 Loss: 0.004697 | Val Acc: 0.178427 loss: 12.302393\n",
            "[1751/3000] Train Acc: 0.999748 Loss: 0.001037 | Val Acc: 0.187097 loss: 11.771069\n",
            "[1752/3000] Train Acc: 1.000000 Loss: 0.000220 | Val Acc: 0.187500 loss: 11.654927\n",
            "[1753/3000] Train Acc: 1.000000 Loss: 0.000265 | Val Acc: 0.183065 loss: 12.121421\n",
            "[1754/3000] Train Acc: 1.000000 Loss: 0.000227 | Val Acc: 0.189315 loss: 11.495226\n",
            "[1755/3000] Train Acc: 1.000000 Loss: 0.000312 | Val Acc: 0.179637 loss: 12.096922\n",
            "[1756/3000] Train Acc: 0.999899 Loss: 0.000469 | Val Acc: 0.162903 loss: 13.078315\n",
            "[1757/3000] Train Acc: 0.995614 Loss: 0.013174 | Val Acc: 0.181855 loss: 11.824949\n",
            "[1758/3000] Train Acc: 1.000000 Loss: 0.000330 | Val Acc: 0.185887 loss: 11.665155\n",
            "[1759/3000] Train Acc: 1.000000 Loss: 0.000202 | Val Acc: 0.178427 loss: 12.231952\n",
            "[1760/3000] Train Acc: 1.000000 Loss: 0.000185 | Val Acc: 0.180847 loss: 12.091493\n",
            "[1761/3000] Train Acc: 1.000000 Loss: 0.000178 | Val Acc: 0.179032 loss: 12.151918\n",
            "[1762/3000] Train Acc: 1.000000 Loss: 0.000175 | Val Acc: 0.183871 loss: 11.902799\n",
            "[1763/3000] Train Acc: 1.000000 Loss: 0.000450 | Val Acc: 0.185081 loss: 11.894998\n",
            "[1764/3000] Train Acc: 0.996572 Loss: 0.010076 | Val Acc: 0.176613 loss: 12.564133\n",
            "[1765/3000] Train Acc: 1.000000 Loss: 0.000390 | Val Acc: 0.189315 loss: 11.869160\n",
            "[1766/3000] Train Acc: 1.000000 Loss: 0.000229 | Val Acc: 0.189516 loss: 11.928490\n",
            "[1767/3000] Train Acc: 1.000000 Loss: 0.000250 | Val Acc: 0.187500 loss: 12.080699\n",
            "[1768/3000] Train Acc: 0.999899 Loss: 0.000558 | Val Acc: 0.182460 loss: 12.124735\n",
            "[1769/3000] Train Acc: 0.998387 Loss: 0.004954 | Val Acc: 0.180444 loss: 12.082270\n",
            "[1770/3000] Train Acc: 1.000000 Loss: 0.000455 | Val Acc: 0.184677 loss: 11.880122\n",
            "[1771/3000] Train Acc: 1.000000 Loss: 0.000173 | Val Acc: 0.188508 loss: 11.578983\n",
            "[1772/3000] Train Acc: 1.000000 Loss: 0.000264 | Val Acc: 0.184274 loss: 11.844274\n",
            "[1773/3000] Train Acc: 1.000000 Loss: 0.000181 | Val Acc: 0.187500 loss: 11.758850\n",
            "[1774/3000] Train Acc: 1.000000 Loss: 0.000166 | Val Acc: 0.184274 loss: 12.128926\n",
            "[1775/3000] Train Acc: 1.000000 Loss: 0.000191 | Val Acc: 0.178831 loss: 12.515684\n",
            "[1776/3000] Train Acc: 1.000000 Loss: 0.000182 | Val Acc: 0.181250 loss: 12.163483\n",
            "[1777/3000] Train Acc: 0.999093 Loss: 0.003969 | Val Acc: 0.187097 loss: 12.002814\n",
            "[1778/3000] Train Acc: 0.995967 Loss: 0.013329 | Val Acc: 0.188508 loss: 11.910986\n",
            "[1779/3000] Train Acc: 1.000000 Loss: 0.000271 | Val Acc: 0.189113 loss: 11.896299\n",
            "[1780/3000] Train Acc: 1.000000 Loss: 0.000218 | Val Acc: 0.188105 loss: 11.948803\n",
            "[1781/3000] Train Acc: 1.000000 Loss: 0.000168 | Val Acc: 0.185484 loss: 12.076893\n",
            "[1782/3000] Train Acc: 1.000000 Loss: 0.000158 | Val Acc: 0.189315 loss: 11.976669\n",
            "[1783/3000] Train Acc: 1.000000 Loss: 0.000152 | Val Acc: 0.190927 loss: 11.812949\n",
            "[1784/3000] Train Acc: 1.000000 Loss: 0.000221 | Val Acc: 0.186089 loss: 11.968053\n",
            "[1785/3000] Train Acc: 0.997832 Loss: 0.007943 | Val Acc: 0.173185 loss: 12.754065\n",
            "[1786/3000] Train Acc: 0.999748 Loss: 0.000999 | Val Acc: 0.181250 loss: 12.411122\n",
            "[1787/3000] Train Acc: 0.999849 Loss: 0.000630 | Val Acc: 0.183065 loss: 12.445375\n",
            "[1788/3000] Train Acc: 0.999294 Loss: 0.002752 | Val Acc: 0.176210 loss: 12.397714\n",
            "[1789/3000] Train Acc: 0.999950 Loss: 0.000635 | Val Acc: 0.179032 loss: 12.238930\n",
            "[1790/3000] Train Acc: 0.997731 Loss: 0.006438 | Val Acc: 0.172581 loss: 12.859106\n",
            "[1791/3000] Train Acc: 0.999798 Loss: 0.000766 | Val Acc: 0.196774 loss: 11.322372\n",
            "[1792/3000] Train Acc: 0.999849 Loss: 0.000913 | Val Acc: 0.187097 loss: 12.246364\n",
            "[1793/3000] Train Acc: 1.000000 Loss: 0.000201 | Val Acc: 0.190323 loss: 11.911301\n",
            "[1794/3000] Train Acc: 1.000000 Loss: 0.000154 | Val Acc: 0.191129 loss: 11.819393\n",
            "[1795/3000] Train Acc: 1.000000 Loss: 0.000141 | Val Acc: 0.192742 loss: 11.712771\n",
            "[1796/3000] Train Acc: 0.997580 Loss: 0.006224 | Val Acc: 0.190927 loss: 12.242651\n",
            "[1797/3000] Train Acc: 0.998135 Loss: 0.005493 | Val Acc: 0.177823 loss: 12.333463\n",
            "[1798/3000] Train Acc: 1.000000 Loss: 0.000299 | Val Acc: 0.179032 loss: 12.330117\n",
            "[1799/3000] Train Acc: 1.000000 Loss: 0.000188 | Val Acc: 0.185484 loss: 11.964701\n",
            "[1800/3000] Train Acc: 1.000000 Loss: 0.000159 | Val Acc: 0.188105 loss: 11.750212\n",
            "[1801/3000] Train Acc: 1.000000 Loss: 0.000182 | Val Acc: 0.186694 loss: 11.963661\n",
            "[1802/3000] Train Acc: 0.999950 Loss: 0.000245 | Val Acc: 0.184476 loss: 12.050955\n",
            "[1803/3000] Train Acc: 0.999950 Loss: 0.000470 | Val Acc: 0.181048 loss: 12.429234\n",
            "[1804/3000] Train Acc: 0.995110 Loss: 0.014724 | Val Acc: 0.206452 loss: 10.848378\n",
            "[1805/3000] Train Acc: 0.999849 Loss: 0.000750 | Val Acc: 0.187298 loss: 11.837440\n",
            "[1806/3000] Train Acc: 1.000000 Loss: 0.000210 | Val Acc: 0.186694 loss: 11.860528\n",
            "[1807/3000] Train Acc: 1.000000 Loss: 0.000175 | Val Acc: 0.185887 loss: 11.897557\n",
            "[1808/3000] Train Acc: 1.000000 Loss: 0.000160 | Val Acc: 0.186694 loss: 11.879374\n",
            "[1809/3000] Train Acc: 1.000000 Loss: 0.000144 | Val Acc: 0.186290 loss: 11.924432\n",
            "[1810/3000] Train Acc: 1.000000 Loss: 0.000182 | Val Acc: 0.185484 loss: 11.972790\n",
            "[1811/3000] Train Acc: 1.000000 Loss: 0.000215 | Val Acc: 0.187903 loss: 11.804726\n",
            "[1812/3000] Train Acc: 0.995917 Loss: 0.014467 | Val Acc: 0.184879 loss: 11.939840\n",
            "[1813/3000] Train Acc: 0.999647 Loss: 0.001475 | Val Acc: 0.187702 loss: 12.268524\n",
            "[1814/3000] Train Acc: 1.000000 Loss: 0.000237 | Val Acc: 0.187702 loss: 11.902655\n",
            "[1815/3000] Train Acc: 1.000000 Loss: 0.000195 | Val Acc: 0.186492 loss: 11.904620\n",
            "[1816/3000] Train Acc: 1.000000 Loss: 0.000162 | Val Acc: 0.187097 loss: 11.940435\n",
            "[1817/3000] Train Acc: 0.999950 Loss: 0.000213 | Val Acc: 0.186895 loss: 11.836962\n",
            "[1818/3000] Train Acc: 0.999950 Loss: 0.000214 | Val Acc: 0.185081 loss: 12.004401\n",
            "[1819/3000] Train Acc: 1.000000 Loss: 0.000149 | Val Acc: 0.183871 loss: 12.213415\n",
            "[1820/3000] Train Acc: 1.000000 Loss: 0.000125 | Val Acc: 0.187702 loss: 11.903321\n",
            "[1821/3000] Train Acc: 0.999698 Loss: 0.001177 | Val Acc: 0.172379 loss: 13.039366\n",
            "[1822/3000] Train Acc: 0.997026 Loss: 0.010150 | Val Acc: 0.180040 loss: 12.480222\n",
            "[1823/3000] Train Acc: 1.000000 Loss: 0.000210 | Val Acc: 0.185282 loss: 12.010782\n",
            "[1824/3000] Train Acc: 1.000000 Loss: 0.000169 | Val Acc: 0.185081 loss: 12.101393\n",
            "[1825/3000] Train Acc: 1.000000 Loss: 0.000154 | Val Acc: 0.184677 loss: 12.197042\n",
            "[1826/3000] Train Acc: 1.000000 Loss: 0.000204 | Val Acc: 0.190927 loss: 11.808008\n",
            "[1827/3000] Train Acc: 1.000000 Loss: 0.000138 | Val Acc: 0.186290 loss: 12.088645\n",
            "[1828/3000] Train Acc: 0.999849 Loss: 0.000921 | Val Acc: 0.185685 loss: 12.150135\n",
            "[1829/3000] Train Acc: 0.997983 Loss: 0.007764 | Val Acc: 0.190121 loss: 11.947074\n",
            "[1830/3000] Train Acc: 0.999950 Loss: 0.000390 | Val Acc: 0.189919 loss: 11.791378\n",
            "[1831/3000] Train Acc: 1.000000 Loss: 0.000183 | Val Acc: 0.184274 loss: 12.177116\n",
            "[1832/3000] Train Acc: 1.000000 Loss: 0.000146 | Val Acc: 0.185081 loss: 12.130090\n",
            "[1833/3000] Train Acc: 1.000000 Loss: 0.000136 | Val Acc: 0.187097 loss: 12.010501\n",
            "[1834/3000] Train Acc: 1.000000 Loss: 0.000198 | Val Acc: 0.191129 loss: 11.963476\n",
            "[1835/3000] Train Acc: 0.996320 Loss: 0.009956 | Val Acc: 0.184274 loss: 12.043564\n",
            "[1836/3000] Train Acc: 0.998387 Loss: 0.004769 | Val Acc: 0.185484 loss: 12.180760\n",
            "[1837/3000] Train Acc: 0.999950 Loss: 0.000324 | Val Acc: 0.185282 loss: 12.274403\n",
            "[1838/3000] Train Acc: 0.999748 Loss: 0.000823 | Val Acc: 0.184677 loss: 12.173174\n",
            "[1839/3000] Train Acc: 1.000000 Loss: 0.000163 | Val Acc: 0.185484 loss: 12.069222\n",
            "[1840/3000] Train Acc: 1.000000 Loss: 0.000145 | Val Acc: 0.186492 loss: 12.029768\n",
            "[1841/3000] Train Acc: 1.000000 Loss: 0.000139 | Val Acc: 0.186290 loss: 12.060277\n",
            "[1842/3000] Train Acc: 1.000000 Loss: 0.000138 | Val Acc: 0.187903 loss: 11.973376\n",
            "[1843/3000] Train Acc: 1.000000 Loss: 0.000149 | Val Acc: 0.190927 loss: 11.817690\n",
            "[1844/3000] Train Acc: 0.996421 Loss: 0.012457 | Val Acc: 0.181452 loss: 12.340490\n",
            "[1845/3000] Train Acc: 1.000000 Loss: 0.000252 | Val Acc: 0.182056 loss: 12.298990\n",
            "[1846/3000] Train Acc: 1.000000 Loss: 0.000185 | Val Acc: 0.180040 loss: 12.405558\n",
            "[1847/3000] Train Acc: 1.000000 Loss: 0.000162 | Val Acc: 0.183468 loss: 12.251695\n",
            "[1848/3000] Train Acc: 1.000000 Loss: 0.000147 | Val Acc: 0.183266 loss: 12.220181\n",
            "[1849/3000] Train Acc: 1.000000 Loss: 0.000133 | Val Acc: 0.180645 loss: 12.368598\n",
            "[1850/3000] Train Acc: 1.000000 Loss: 0.000137 | Val Acc: 0.183468 loss: 12.072461\n",
            "[1851/3000] Train Acc: 1.000000 Loss: 0.000124 | Val Acc: 0.180040 loss: 12.413205\n",
            "[1852/3000] Train Acc: 0.999950 Loss: 0.000381 | Val Acc: 0.184476 loss: 12.071201\n",
            "[1853/3000] Train Acc: 0.996723 Loss: 0.009505 | Val Acc: 0.179234 loss: 12.145307\n",
            "[1854/3000] Train Acc: 0.999546 Loss: 0.001716 | Val Acc: 0.184879 loss: 12.417027\n",
            "[1855/3000] Train Acc: 0.999849 Loss: 0.000658 | Val Acc: 0.190121 loss: 11.898123\n",
            "[1856/3000] Train Acc: 0.999899 Loss: 0.000459 | Val Acc: 0.187903 loss: 12.050470\n",
            "[1857/3000] Train Acc: 1.000000 Loss: 0.000182 | Val Acc: 0.186694 loss: 12.132772\n",
            "[1858/3000] Train Acc: 1.000000 Loss: 0.000197 | Val Acc: 0.185282 loss: 12.219595\n",
            "[1859/3000] Train Acc: 0.999496 Loss: 0.001503 | Val Acc: 0.200806 loss: 11.622531\n",
            "[1860/3000] Train Acc: 0.998689 Loss: 0.004282 | Val Acc: 0.188508 loss: 12.109149\n",
            "[1861/3000] Train Acc: 0.999899 Loss: 0.000420 | Val Acc: 0.184073 loss: 12.180891\n",
            "[1862/3000] Train Acc: 0.999445 Loss: 0.001126 | Val Acc: 0.194758 loss: 11.704456\n",
            "[1863/3000] Train Acc: 0.998538 Loss: 0.004863 | Val Acc: 0.198387 loss: 11.747058\n",
            "[1864/3000] Train Acc: 0.999597 Loss: 0.001178 | Val Acc: 0.182460 loss: 12.410546\n",
            "[1865/3000] Train Acc: 1.000000 Loss: 0.000250 | Val Acc: 0.184677 loss: 12.246339\n",
            "[1866/3000] Train Acc: 1.000000 Loss: 0.000144 | Val Acc: 0.188911 loss: 11.981997\n",
            "[1867/3000] Train Acc: 0.999798 Loss: 0.001255 | Val Acc: 0.189315 loss: 11.894302\n",
            "[1868/3000] Train Acc: 0.999849 Loss: 0.000547 | Val Acc: 0.190121 loss: 11.958402\n",
            "[1869/3000] Train Acc: 1.000000 Loss: 0.000195 | Val Acc: 0.183871 loss: 12.137859\n",
            "[1870/3000] Train Acc: 0.997933 Loss: 0.006044 | Val Acc: 0.182056 loss: 12.500637\n",
            "[1871/3000] Train Acc: 0.999798 Loss: 0.000750 | Val Acc: 0.178226 loss: 12.651128\n",
            "[1872/3000] Train Acc: 1.000000 Loss: 0.000199 | Val Acc: 0.192540 loss: 11.806759\n",
            "[1873/3000] Train Acc: 1.000000 Loss: 0.000191 | Val Acc: 0.188508 loss: 12.013805\n",
            "[1874/3000] Train Acc: 1.000000 Loss: 0.000156 | Val Acc: 0.179032 loss: 12.370131\n",
            "[1875/3000] Train Acc: 1.000000 Loss: 0.000162 | Val Acc: 0.188710 loss: 11.847541\n",
            "[1876/3000] Train Acc: 0.997278 Loss: 0.009099 | Val Acc: 0.156855 loss: 14.153388\n",
            "[1877/3000] Train Acc: 0.999647 Loss: 0.001539 | Val Acc: 0.186290 loss: 12.090648\n",
            "[1878/3000] Train Acc: 1.000000 Loss: 0.000207 | Val Acc: 0.181452 loss: 12.377272\n",
            "[1879/3000] Train Acc: 1.000000 Loss: 0.000157 | Val Acc: 0.186895 loss: 12.152327\n",
            "[1880/3000] Train Acc: 1.000000 Loss: 0.000136 | Val Acc: 0.190121 loss: 11.868761\n",
            "[1881/3000] Train Acc: 1.000000 Loss: 0.000200 | Val Acc: 0.182056 loss: 12.272157\n",
            "[1882/3000] Train Acc: 0.997832 Loss: 0.006017 | Val Acc: 0.175403 loss: 12.603418\n",
            "[1883/3000] Train Acc: 0.999445 Loss: 0.001958 | Val Acc: 0.195363 loss: 11.685837\n",
            "[1884/3000] Train Acc: 0.999546 Loss: 0.001221 | Val Acc: 0.186895 loss: 12.084434\n",
            "[1885/3000] Train Acc: 0.998992 Loss: 0.003390 | Val Acc: 0.193548 loss: 11.767776\n",
            "[1886/3000] Train Acc: 0.999950 Loss: 0.000483 | Val Acc: 0.186694 loss: 11.939576\n",
            "[1887/3000] Train Acc: 0.999950 Loss: 0.000392 | Val Acc: 0.190524 loss: 11.876586\n",
            "[1888/3000] Train Acc: 0.999950 Loss: 0.000483 | Val Acc: 0.186895 loss: 12.164684\n",
            "[1889/3000] Train Acc: 0.999546 Loss: 0.001522 | Val Acc: 0.187097 loss: 12.256396\n",
            "[1890/3000] Train Acc: 0.999496 Loss: 0.001526 | Val Acc: 0.201008 loss: 11.241055\n",
            "[1891/3000] Train Acc: 0.998992 Loss: 0.002507 | Val Acc: 0.183468 loss: 12.253254\n",
            "[1892/3000] Train Acc: 0.999849 Loss: 0.000744 | Val Acc: 0.172581 loss: 13.080375\n",
            "[1893/3000] Train Acc: 0.999244 Loss: 0.002754 | Val Acc: 0.181048 loss: 12.371070\n",
            "[1894/3000] Train Acc: 0.999950 Loss: 0.000632 | Val Acc: 0.188105 loss: 11.885711\n",
            "[1895/3000] Train Acc: 0.998538 Loss: 0.003987 | Val Acc: 0.175806 loss: 12.415912\n",
            "[1896/3000] Train Acc: 1.000000 Loss: 0.000308 | Val Acc: 0.182056 loss: 12.135187\n",
            "[1897/3000] Train Acc: 1.000000 Loss: 0.000180 | Val Acc: 0.186492 loss: 12.062812\n",
            "[1898/3000] Train Acc: 1.000000 Loss: 0.000131 | Val Acc: 0.185887 loss: 12.034389\n",
            "[1899/3000] Train Acc: 1.000000 Loss: 0.000221 | Val Acc: 0.187903 loss: 12.110586\n",
            "[1900/3000] Train Acc: 1.000000 Loss: 0.000268 | Val Acc: 0.189919 loss: 11.826431\n",
            "[1901/3000] Train Acc: 0.999950 Loss: 0.000385 | Val Acc: 0.171371 loss: 13.294341\n",
            "[1902/3000] Train Acc: 0.997580 Loss: 0.008308 | Val Acc: 0.183871 loss: 12.236556\n",
            "[1903/3000] Train Acc: 1.000000 Loss: 0.000359 | Val Acc: 0.188710 loss: 12.080460\n",
            "[1904/3000] Train Acc: 0.999698 Loss: 0.001334 | Val Acc: 0.185282 loss: 12.225637\n",
            "[1905/3000] Train Acc: 1.000000 Loss: 0.000243 | Val Acc: 0.186492 loss: 12.084717\n",
            "[1906/3000] Train Acc: 1.000000 Loss: 0.000230 | Val Acc: 0.188911 loss: 12.011852\n",
            "[1907/3000] Train Acc: 0.999849 Loss: 0.000685 | Val Acc: 0.186492 loss: 12.039122\n",
            "[1908/3000] Train Acc: 1.000000 Loss: 0.000138 | Val Acc: 0.184476 loss: 12.263618\n",
            "[1909/3000] Train Acc: 0.999950 Loss: 0.000385 | Val Acc: 0.206653 loss: 11.364878\n",
            "[1910/3000] Train Acc: 0.999849 Loss: 0.000548 | Val Acc: 0.181653 loss: 12.554787\n",
            "[1911/3000] Train Acc: 0.998488 Loss: 0.005812 | Val Acc: 0.172581 loss: 12.428070\n",
            "[1912/3000] Train Acc: 0.997580 Loss: 0.007558 | Val Acc: 0.185887 loss: 12.077871\n",
            "[1913/3000] Train Acc: 0.999597 Loss: 0.001452 | Val Acc: 0.185887 loss: 12.435045\n",
            "[1914/3000] Train Acc: 1.000000 Loss: 0.000267 | Val Acc: 0.185282 loss: 12.122847\n",
            "[1915/3000] Train Acc: 1.000000 Loss: 0.000223 | Val Acc: 0.187298 loss: 11.955730\n",
            "[1916/3000] Train Acc: 1.000000 Loss: 0.000159 | Val Acc: 0.185887 loss: 12.056053\n",
            "[1917/3000] Train Acc: 1.000000 Loss: 0.000169 | Val Acc: 0.185282 loss: 12.143695\n",
            "[1918/3000] Train Acc: 0.999950 Loss: 0.000201 | Val Acc: 0.195565 loss: 11.664837\n",
            "[1919/3000] Train Acc: 0.996622 Loss: 0.010817 | Val Acc: 0.190726 loss: 12.154324\n",
            "[1920/3000] Train Acc: 1.000000 Loss: 0.000296 | Val Acc: 0.190323 loss: 12.169417\n",
            "[1921/3000] Train Acc: 1.000000 Loss: 0.000186 | Val Acc: 0.186895 loss: 12.331174\n",
            "[1922/3000] Train Acc: 1.000000 Loss: 0.000154 | Val Acc: 0.184476 loss: 12.491214\n",
            "[1923/3000] Train Acc: 1.000000 Loss: 0.000139 | Val Acc: 0.185887 loss: 12.409441\n",
            "[1924/3000] Train Acc: 1.000000 Loss: 0.000127 | Val Acc: 0.189113 loss: 12.176948\n",
            "[1925/3000] Train Acc: 1.000000 Loss: 0.000140 | Val Acc: 0.183266 loss: 12.538797\n",
            "[1926/3000] Train Acc: 1.000000 Loss: 0.000121 | Val Acc: 0.184879 loss: 12.400821\n",
            "[1927/3000] Train Acc: 0.999950 Loss: 0.000341 | Val Acc: 0.186895 loss: 12.103152\n",
            "[1928/3000] Train Acc: 1.000000 Loss: 0.000208 | Val Acc: 0.172379 loss: 12.734163\n",
            "[1929/3000] Train Acc: 0.996118 Loss: 0.011095 | Val Acc: 0.178226 loss: 12.623604\n",
            "[1930/3000] Train Acc: 1.000000 Loss: 0.000336 | Val Acc: 0.178427 loss: 12.598909\n",
            "[1931/3000] Train Acc: 1.000000 Loss: 0.000180 | Val Acc: 0.182056 loss: 12.343149\n",
            "[1932/3000] Train Acc: 1.000000 Loss: 0.000172 | Val Acc: 0.186089 loss: 12.146636\n",
            "[1933/3000] Train Acc: 1.000000 Loss: 0.000151 | Val Acc: 0.182863 loss: 12.276257\n",
            "[1934/3000] Train Acc: 1.000000 Loss: 0.000116 | Val Acc: 0.189315 loss: 12.036634\n",
            "[1935/3000] Train Acc: 1.000000 Loss: 0.000122 | Val Acc: 0.176411 loss: 12.659637\n",
            "[1936/3000] Train Acc: 1.000000 Loss: 0.000113 | Val Acc: 0.185282 loss: 12.200572\n",
            "[1937/3000] Train Acc: 1.000000 Loss: 0.000156 | Val Acc: 0.185484 loss: 12.219106\n",
            "[1938/3000] Train Acc: 0.998488 Loss: 0.004253 | Val Acc: 0.184677 loss: 12.437429\n",
            "[1939/3000] Train Acc: 0.999345 Loss: 0.002528 | Val Acc: 0.183266 loss: 12.517370\n",
            "[1940/3000] Train Acc: 0.999849 Loss: 0.000471 | Val Acc: 0.186089 loss: 12.390727\n",
            "[1941/3000] Train Acc: 1.000000 Loss: 0.000159 | Val Acc: 0.181653 loss: 12.545108\n",
            "[1942/3000] Train Acc: 1.000000 Loss: 0.000127 | Val Acc: 0.184677 loss: 12.375780\n",
            "[1943/3000] Train Acc: 1.000000 Loss: 0.000117 | Val Acc: 0.185887 loss: 12.373734\n",
            "[1944/3000] Train Acc: 1.000000 Loss: 0.000207 | Val Acc: 0.184476 loss: 12.348917\n",
            "[1945/3000] Train Acc: 1.000000 Loss: 0.000124 | Val Acc: 0.188105 loss: 12.419406\n",
            "[1946/3000] Train Acc: 1.000000 Loss: 0.000135 | Val Acc: 0.185484 loss: 12.381190\n",
            "[1947/3000] Train Acc: 1.000000 Loss: 0.000285 | Val Acc: 0.185081 loss: 12.327572\n",
            "[1948/3000] Train Acc: 0.995463 Loss: 0.017926 | Val Acc: 0.179637 loss: 12.443374\n",
            "[1949/3000] Train Acc: 1.000000 Loss: 0.000301 | Val Acc: 0.182258 loss: 12.326374\n",
            "[1950/3000] Train Acc: 1.000000 Loss: 0.000191 | Val Acc: 0.180847 loss: 12.391451\n",
            "[1951/3000] Train Acc: 1.000000 Loss: 0.000157 | Val Acc: 0.181855 loss: 12.381982\n",
            "[1952/3000] Train Acc: 1.000000 Loss: 0.000163 | Val Acc: 0.184476 loss: 12.224604\n",
            "[1953/3000] Train Acc: 1.000000 Loss: 0.000213 | Val Acc: 0.179234 loss: 12.514567\n",
            "[1954/3000] Train Acc: 0.999042 Loss: 0.003495 | Val Acc: 0.191532 loss: 12.024511\n",
            "[1955/3000] Train Acc: 0.998336 Loss: 0.004058 | Val Acc: 0.187702 loss: 12.390557\n",
            "[1956/3000] Train Acc: 0.999899 Loss: 0.000532 | Val Acc: 0.184677 loss: 12.155523\n",
            "[1957/3000] Train Acc: 0.999647 Loss: 0.001003 | Val Acc: 0.186290 loss: 12.108869\n",
            "[1958/3000] Train Acc: 1.000000 Loss: 0.000128 | Val Acc: 0.183468 loss: 12.380953\n",
            "[1959/3000] Train Acc: 1.000000 Loss: 0.000163 | Val Acc: 0.187702 loss: 12.132499\n",
            "[1960/3000] Train Acc: 1.000000 Loss: 0.000151 | Val Acc: 0.188105 loss: 12.065634\n",
            "[1961/3000] Train Acc: 1.000000 Loss: 0.000098 | Val Acc: 0.185081 loss: 12.149704\n",
            "[1962/3000] Train Acc: 0.997631 Loss: 0.008427 | Val Acc: 0.188710 loss: 12.115968\n",
            "[1963/3000] Train Acc: 0.999597 Loss: 0.001693 | Val Acc: 0.181653 loss: 11.945532\n",
            "[1964/3000] Train Acc: 0.999798 Loss: 0.000923 | Val Acc: 0.178427 loss: 12.637406\n",
            "[1965/3000] Train Acc: 1.000000 Loss: 0.000135 | Val Acc: 0.182258 loss: 12.505025\n",
            "[1966/3000] Train Acc: 1.000000 Loss: 0.000110 | Val Acc: 0.184073 loss: 12.367868\n",
            "[1967/3000] Train Acc: 1.000000 Loss: 0.000098 | Val Acc: 0.186089 loss: 12.320288\n",
            "[1968/3000] Train Acc: 1.000000 Loss: 0.000102 | Val Acc: 0.187298 loss: 12.236907\n",
            "[1969/3000] Train Acc: 0.999042 Loss: 0.002801 | Val Acc: 0.196573 loss: 11.947902\n",
            "[1970/3000] Train Acc: 0.998992 Loss: 0.003498 | Val Acc: 0.177218 loss: 12.679408\n",
            "[1971/3000] Train Acc: 1.000000 Loss: 0.000344 | Val Acc: 0.185887 loss: 12.252394\n",
            "[1972/3000] Train Acc: 1.000000 Loss: 0.000176 | Val Acc: 0.184879 loss: 12.455520\n",
            "[1973/3000] Train Acc: 1.000000 Loss: 0.000120 | Val Acc: 0.180040 loss: 12.695190\n",
            "[1974/3000] Train Acc: 0.998891 Loss: 0.003913 | Val Acc: 0.170968 loss: 13.542185\n",
            "[1975/3000] Train Acc: 0.999496 Loss: 0.001682 | Val Acc: 0.189113 loss: 11.915597\n",
            "[1976/3000] Train Acc: 1.000000 Loss: 0.000161 | Val Acc: 0.186089 loss: 12.202407\n",
            "[1977/3000] Train Acc: 1.000000 Loss: 0.000108 | Val Acc: 0.180645 loss: 12.381059\n",
            "[1978/3000] Train Acc: 1.000000 Loss: 0.000123 | Val Acc: 0.190927 loss: 11.977855\n",
            "[1979/3000] Train Acc: 0.995765 Loss: 0.012281 | Val Acc: 0.185484 loss: 12.332306\n",
            "[1980/3000] Train Acc: 0.999899 Loss: 0.000608 | Val Acc: 0.194758 loss: 12.143274\n",
            "[1981/3000] Train Acc: 1.000000 Loss: 0.000172 | Val Acc: 0.193750 loss: 12.230104\n",
            "[1982/3000] Train Acc: 1.000000 Loss: 0.000132 | Val Acc: 0.194355 loss: 12.179764\n",
            "[1983/3000] Train Acc: 1.000000 Loss: 0.000120 | Val Acc: 0.190726 loss: 12.301426\n",
            "[1984/3000] Train Acc: 1.000000 Loss: 0.000127 | Val Acc: 0.184677 loss: 12.600189\n",
            "[1985/3000] Train Acc: 1.000000 Loss: 0.000111 | Val Acc: 0.187500 loss: 12.458237\n",
            "[1986/3000] Train Acc: 0.997429 Loss: 0.007548 | Val Acc: 0.172581 loss: 13.131375\n",
            "[1987/3000] Train Acc: 0.999748 Loss: 0.001142 | Val Acc: 0.200806 loss: 11.515015\n",
            "[1988/3000] Train Acc: 0.999849 Loss: 0.000498 | Val Acc: 0.182258 loss: 12.463251\n",
            "[1989/3000] Train Acc: 1.000000 Loss: 0.000131 | Val Acc: 0.185282 loss: 12.329092\n",
            "[1990/3000] Train Acc: 1.000000 Loss: 0.000111 | Val Acc: 0.187500 loss: 12.243671\n",
            "[1991/3000] Train Acc: 1.000000 Loss: 0.000108 | Val Acc: 0.187702 loss: 12.320971\n",
            "[1992/3000] Train Acc: 1.000000 Loss: 0.000104 | Val Acc: 0.186492 loss: 12.344023\n",
            "[1993/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.191532 loss: 12.318976\n",
            "[1994/3000] Train Acc: 0.996874 Loss: 0.008837 | Val Acc: 0.172177 loss: 13.527931\n",
            "[1995/3000] Train Acc: 0.999798 Loss: 0.000892 | Val Acc: 0.189718 loss: 12.529582\n",
            "[1996/3000] Train Acc: 1.000000 Loss: 0.000168 | Val Acc: 0.188306 loss: 12.520999\n",
            "[1997/3000] Train Acc: 1.000000 Loss: 0.000129 | Val Acc: 0.190323 loss: 12.455549\n",
            "[1998/3000] Train Acc: 1.000000 Loss: 0.000124 | Val Acc: 0.188710 loss: 12.531536\n",
            "[1999/3000] Train Acc: 1.000000 Loss: 0.000112 | Val Acc: 0.189919 loss: 12.417173\n",
            "[2000/3000] Train Acc: 1.000000 Loss: 0.000099 | Val Acc: 0.192137 loss: 12.360722\n",
            "[2001/3000] Train Acc: 0.997026 Loss: 0.008356 | Val Acc: 0.192742 loss: 11.902791\n",
            "[2002/3000] Train Acc: 0.999748 Loss: 0.000929 | Val Acc: 0.190323 loss: 12.023541\n",
            "[2003/3000] Train Acc: 1.000000 Loss: 0.000146 | Val Acc: 0.192137 loss: 12.119838\n",
            "[2004/3000] Train Acc: 1.000000 Loss: 0.000121 | Val Acc: 0.193750 loss: 12.092847\n",
            "[2005/3000] Train Acc: 1.000000 Loss: 0.000105 | Val Acc: 0.193347 loss: 12.061182\n",
            "[2006/3000] Train Acc: 1.000000 Loss: 0.000116 | Val Acc: 0.195363 loss: 12.022918\n",
            "[2007/3000] Train Acc: 1.000000 Loss: 0.000097 | Val Acc: 0.188306 loss: 12.265945\n",
            "[2008/3000] Train Acc: 1.000000 Loss: 0.000088 | Val Acc: 0.194153 loss: 12.000019\n",
            "[2009/3000] Train Acc: 1.000000 Loss: 0.000161 | Val Acc: 0.177218 loss: 12.712912\n",
            "[2010/3000] Train Acc: 0.995866 Loss: 0.014070 | Val Acc: 0.187903 loss: 11.960643\n",
            "[2011/3000] Train Acc: 1.000000 Loss: 0.000347 | Val Acc: 0.192339 loss: 11.791436\n",
            "[2012/3000] Train Acc: 1.000000 Loss: 0.000179 | Val Acc: 0.189113 loss: 12.108442\n",
            "[2013/3000] Train Acc: 1.000000 Loss: 0.000126 | Val Acc: 0.188105 loss: 12.296414\n",
            "[2014/3000] Train Acc: 1.000000 Loss: 0.000110 | Val Acc: 0.188911 loss: 12.229157\n",
            "[2015/3000] Train Acc: 1.000000 Loss: 0.000111 | Val Acc: 0.190323 loss: 12.170795\n",
            "[2016/3000] Train Acc: 1.000000 Loss: 0.000105 | Val Acc: 0.192540 loss: 11.984963\n",
            "[2017/3000] Train Acc: 1.000000 Loss: 0.000150 | Val Acc: 0.190524 loss: 12.145079\n",
            "[2018/3000] Train Acc: 0.999849 Loss: 0.000692 | Val Acc: 0.196774 loss: 11.911652\n",
            "[2019/3000] Train Acc: 0.998336 Loss: 0.004778 | Val Acc: 0.187903 loss: 12.142060\n",
            "[2020/3000] Train Acc: 0.999849 Loss: 0.000669 | Val Acc: 0.186694 loss: 12.075554\n",
            "[2021/3000] Train Acc: 1.000000 Loss: 0.000154 | Val Acc: 0.186089 loss: 12.321127\n",
            "[2022/3000] Train Acc: 1.000000 Loss: 0.000147 | Val Acc: 0.188710 loss: 12.116358\n",
            "[2023/3000] Train Acc: 0.996521 Loss: 0.010447 | Val Acc: 0.181653 loss: 12.658689\n",
            "[2024/3000] Train Acc: 0.999899 Loss: 0.000722 | Val Acc: 0.175605 loss: 13.187936\n",
            "[2025/3000] Train Acc: 0.999950 Loss: 0.000294 | Val Acc: 0.185887 loss: 12.525245\n",
            "[2026/3000] Train Acc: 1.000000 Loss: 0.000130 | Val Acc: 0.184274 loss: 12.644822\n",
            "[2027/3000] Train Acc: 1.000000 Loss: 0.000106 | Val Acc: 0.184677 loss: 12.611288\n",
            "[2028/3000] Train Acc: 1.000000 Loss: 0.000099 | Val Acc: 0.191935 loss: 12.236028\n",
            "[2029/3000] Train Acc: 0.999950 Loss: 0.000434 | Val Acc: 0.184274 loss: 12.657212\n",
            "[2030/3000] Train Acc: 1.000000 Loss: 0.000215 | Val Acc: 0.186089 loss: 12.394109\n",
            "[2031/3000] Train Acc: 0.999899 Loss: 0.000377 | Val Acc: 0.190323 loss: 12.065621\n",
            "[2032/3000] Train Acc: 0.998992 Loss: 0.003073 | Val Acc: 0.187097 loss: 12.586901\n",
            "[2033/3000] Train Acc: 0.998740 Loss: 0.004336 | Val Acc: 0.174597 loss: 13.183259\n",
            "[2034/3000] Train Acc: 0.999647 Loss: 0.002018 | Val Acc: 0.185282 loss: 12.906081\n",
            "[2035/3000] Train Acc: 0.999698 Loss: 0.000939 | Val Acc: 0.191331 loss: 12.616764\n",
            "[2036/3000] Train Acc: 0.999597 Loss: 0.001272 | Val Acc: 0.187702 loss: 12.691374\n",
            "[2037/3000] Train Acc: 1.000000 Loss: 0.000122 | Val Acc: 0.191129 loss: 12.521097\n",
            "[2038/3000] Train Acc: 1.000000 Loss: 0.000090 | Val Acc: 0.191532 loss: 12.270190\n",
            "[2039/3000] Train Acc: 1.000000 Loss: 0.000080 | Val Acc: 0.192742 loss: 12.250873\n",
            "[2040/3000] Train Acc: 1.000000 Loss: 0.000075 | Val Acc: 0.191935 loss: 12.316669\n",
            "[2041/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.192137 loss: 12.296795\n",
            "[2042/3000] Train Acc: 0.997429 Loss: 0.007217 | Val Acc: 0.179435 loss: 13.235993\n",
            "[2043/3000] Train Acc: 0.999496 Loss: 0.001664 | Val Acc: 0.194960 loss: 12.283078\n",
            "[2044/3000] Train Acc: 1.000000 Loss: 0.000179 | Val Acc: 0.193145 loss: 12.354263\n",
            "[2045/3000] Train Acc: 1.000000 Loss: 0.000118 | Val Acc: 0.186694 loss: 12.685784\n",
            "[2046/3000] Train Acc: 1.000000 Loss: 0.000204 | Val Acc: 0.191129 loss: 12.427643\n",
            "[2047/3000] Train Acc: 1.000000 Loss: 0.000098 | Val Acc: 0.193952 loss: 12.211204\n",
            "[2048/3000] Train Acc: 1.000000 Loss: 0.000116 | Val Acc: 0.195968 loss: 12.100435\n",
            "[2049/3000] Train Acc: 1.000000 Loss: 0.000107 | Val Acc: 0.191532 loss: 12.411420\n",
            "[2050/3000] Train Acc: 1.000000 Loss: 0.000144 | Val Acc: 0.191935 loss: 12.401414\n",
            "[2051/3000] Train Acc: 0.996975 Loss: 0.009607 | Val Acc: 0.192540 loss: 12.167047\n",
            "[2052/3000] Train Acc: 0.999597 Loss: 0.001493 | Val Acc: 0.192137 loss: 12.299155\n",
            "[2053/3000] Train Acc: 0.999899 Loss: 0.000347 | Val Acc: 0.188105 loss: 12.460273\n",
            "[2054/3000] Train Acc: 1.000000 Loss: 0.000229 | Val Acc: 0.189315 loss: 12.375204\n",
            "[2055/3000] Train Acc: 1.000000 Loss: 0.000109 | Val Acc: 0.190524 loss: 12.314185\n",
            "[2056/3000] Train Acc: 1.000000 Loss: 0.000116 | Val Acc: 0.188105 loss: 12.472678\n",
            "[2057/3000] Train Acc: 0.999950 Loss: 0.000319 | Val Acc: 0.187298 loss: 12.524527\n",
            "[2058/3000] Train Acc: 1.000000 Loss: 0.000182 | Val Acc: 0.191935 loss: 12.335219\n",
            "[2059/3000] Train Acc: 0.999899 Loss: 0.000451 | Val Acc: 0.190323 loss: 12.411090\n",
            "[2060/3000] Train Acc: 0.998941 Loss: 0.003906 | Val Acc: 0.181452 loss: 12.585668\n",
            "[2061/3000] Train Acc: 0.999647 Loss: 0.001426 | Val Acc: 0.185685 loss: 12.885701\n",
            "[2062/3000] Train Acc: 0.998790 Loss: 0.003477 | Val Acc: 0.197984 loss: 11.507624\n",
            "[2063/3000] Train Acc: 0.999042 Loss: 0.002740 | Val Acc: 0.187298 loss: 12.711684\n",
            "[2064/3000] Train Acc: 0.999950 Loss: 0.000418 | Val Acc: 0.190121 loss: 12.323601\n",
            "[2065/3000] Train Acc: 0.999345 Loss: 0.002095 | Val Acc: 0.183871 loss: 12.395314\n",
            "[2066/3000] Train Acc: 1.000000 Loss: 0.000545 | Val Acc: 0.180242 loss: 12.745608\n",
            "[2067/3000] Train Acc: 1.000000 Loss: 0.000161 | Val Acc: 0.189516 loss: 12.411162\n",
            "[2068/3000] Train Acc: 1.000000 Loss: 0.000123 | Val Acc: 0.180847 loss: 12.615928\n",
            "[2069/3000] Train Acc: 1.000000 Loss: 0.000095 | Val Acc: 0.186492 loss: 12.582879\n",
            "[2070/3000] Train Acc: 1.000000 Loss: 0.000133 | Val Acc: 0.191734 loss: 12.262116\n",
            "[2071/3000] Train Acc: 1.000000 Loss: 0.000126 | Val Acc: 0.178831 loss: 12.953335\n",
            "[2072/3000] Train Acc: 1.000000 Loss: 0.000098 | Val Acc: 0.185887 loss: 12.567711\n",
            "[2073/3000] Train Acc: 1.000000 Loss: 0.000128 | Val Acc: 0.206048 loss: 11.468687\n",
            "[2074/3000] Train Acc: 0.996622 Loss: 0.010986 | Val Acc: 0.183065 loss: 12.435262\n",
            "[2075/3000] Train Acc: 1.000000 Loss: 0.000166 | Val Acc: 0.179234 loss: 12.631006\n",
            "[2076/3000] Train Acc: 1.000000 Loss: 0.000128 | Val Acc: 0.182258 loss: 12.589313\n",
            "[2077/3000] Train Acc: 1.000000 Loss: 0.000121 | Val Acc: 0.184073 loss: 12.382590\n",
            "[2078/3000] Train Acc: 0.999294 Loss: 0.002469 | Val Acc: 0.179032 loss: 12.849169\n",
            "[2079/3000] Train Acc: 1.000000 Loss: 0.000181 | Val Acc: 0.185484 loss: 12.471303\n",
            "[2080/3000] Train Acc: 1.000000 Loss: 0.000174 | Val Acc: 0.185081 loss: 12.328940\n",
            "[2081/3000] Train Acc: 1.000000 Loss: 0.000102 | Val Acc: 0.186290 loss: 12.443967\n",
            "[2082/3000] Train Acc: 1.000000 Loss: 0.000104 | Val Acc: 0.187298 loss: 12.419460\n",
            "[2083/3000] Train Acc: 1.000000 Loss: 0.000087 | Val Acc: 0.192944 loss: 12.126813\n",
            "[2084/3000] Train Acc: 0.999950 Loss: 0.000259 | Val Acc: 0.197984 loss: 11.837878\n",
            "[2085/3000] Train Acc: 0.994908 Loss: 0.018046 | Val Acc: 0.186694 loss: 12.575182\n",
            "[2086/3000] Train Acc: 1.000000 Loss: 0.000316 | Val Acc: 0.187298 loss: 12.424221\n",
            "[2087/3000] Train Acc: 1.000000 Loss: 0.000140 | Val Acc: 0.188105 loss: 12.574171\n",
            "[2088/3000] Train Acc: 1.000000 Loss: 0.000118 | Val Acc: 0.188105 loss: 12.542537\n",
            "[2089/3000] Train Acc: 1.000000 Loss: 0.000107 | Val Acc: 0.188911 loss: 12.524599\n",
            "[2090/3000] Train Acc: 1.000000 Loss: 0.000105 | Val Acc: 0.190121 loss: 12.399696\n",
            "[2091/3000] Train Acc: 1.000000 Loss: 0.000102 | Val Acc: 0.186492 loss: 12.661855\n",
            "[2092/3000] Train Acc: 1.000000 Loss: 0.000089 | Val Acc: 0.189516 loss: 12.537915\n",
            "[2093/3000] Train Acc: 1.000000 Loss: 0.000090 | Val Acc: 0.190121 loss: 12.558935\n",
            "[2094/3000] Train Acc: 1.000000 Loss: 0.000119 | Val Acc: 0.189516 loss: 12.458416\n",
            "[2095/3000] Train Acc: 0.999597 Loss: 0.001156 | Val Acc: 0.186089 loss: 12.906097\n",
            "[2096/3000] Train Acc: 0.998185 Loss: 0.005636 | Val Acc: 0.190323 loss: 11.836155\n",
            "[2097/3000] Train Acc: 0.999193 Loss: 0.002527 | Val Acc: 0.195161 loss: 12.159661\n",
            "[2098/3000] Train Acc: 1.000000 Loss: 0.000136 | Val Acc: 0.187702 loss: 12.485878\n",
            "[2099/3000] Train Acc: 1.000000 Loss: 0.000110 | Val Acc: 0.188911 loss: 12.552082\n",
            "[2100/3000] Train Acc: 1.000000 Loss: 0.000103 | Val Acc: 0.183871 loss: 12.730488\n",
            "[2101/3000] Train Acc: 1.000000 Loss: 0.000085 | Val Acc: 0.190121 loss: 12.426510\n",
            "[2102/3000] Train Acc: 1.000000 Loss: 0.000081 | Val Acc: 0.181653 loss: 12.819894\n",
            "[2103/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.189516 loss: 12.455263\n",
            "[2104/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.181653 loss: 12.767366\n",
            "[2105/3000] Train Acc: 1.000000 Loss: 0.000140 | Val Acc: 0.187097 loss: 12.655267\n",
            "[2106/3000] Train Acc: 0.997429 Loss: 0.008102 | Val Acc: 0.180040 loss: 12.902388\n",
            "[2107/3000] Train Acc: 1.000000 Loss: 0.000270 | Val Acc: 0.182056 loss: 12.786628\n",
            "[2108/3000] Train Acc: 1.000000 Loss: 0.000158 | Val Acc: 0.186492 loss: 12.554696\n",
            "[2109/3000] Train Acc: 1.000000 Loss: 0.000105 | Val Acc: 0.188508 loss: 12.442438\n",
            "[2110/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.188911 loss: 12.499418\n",
            "[2111/3000] Train Acc: 1.000000 Loss: 0.000113 | Val Acc: 0.189113 loss: 12.348051\n",
            "[2112/3000] Train Acc: 1.000000 Loss: 0.000085 | Val Acc: 0.191331 loss: 12.353363\n",
            "[2113/3000] Train Acc: 1.000000 Loss: 0.000108 | Val Acc: 0.186089 loss: 12.601683\n",
            "[2114/3000] Train Acc: 1.000000 Loss: 0.000116 | Val Acc: 0.203629 loss: 12.009654\n",
            "[2115/3000] Train Acc: 0.994606 Loss: 0.021216 | Val Acc: 0.181452 loss: 12.765272\n",
            "[2116/3000] Train Acc: 1.000000 Loss: 0.000359 | Val Acc: 0.184476 loss: 12.723146\n",
            "[2117/3000] Train Acc: 1.000000 Loss: 0.000165 | Val Acc: 0.190726 loss: 12.495934\n",
            "[2118/3000] Train Acc: 1.000000 Loss: 0.000141 | Val Acc: 0.189516 loss: 12.609689\n",
            "[2119/3000] Train Acc: 1.000000 Loss: 0.000122 | Val Acc: 0.190323 loss: 12.568136\n",
            "[2120/3000] Train Acc: 1.000000 Loss: 0.000111 | Val Acc: 0.189315 loss: 12.661083\n",
            "[2121/3000] Train Acc: 1.000000 Loss: 0.000101 | Val Acc: 0.190323 loss: 12.529063\n",
            "[2122/3000] Train Acc: 1.000000 Loss: 0.000104 | Val Acc: 0.189516 loss: 12.638580\n",
            "[2123/3000] Train Acc: 1.000000 Loss: 0.000116 | Val Acc: 0.183266 loss: 12.790403\n",
            "[2124/3000] Train Acc: 1.000000 Loss: 0.000088 | Val Acc: 0.175000 loss: 13.312431\n",
            "[2125/3000] Train Acc: 1.000000 Loss: 0.000112 | Val Acc: 0.181653 loss: 12.891086\n",
            "[2126/3000] Train Acc: 0.999798 Loss: 0.000753 | Val Acc: 0.178427 loss: 12.852486\n",
            "[2127/3000] Train Acc: 0.997479 Loss: 0.008041 | Val Acc: 0.184274 loss: 12.732476\n",
            "[2128/3000] Train Acc: 0.999698 Loss: 0.001415 | Val Acc: 0.200806 loss: 12.285226\n",
            "[2129/3000] Train Acc: 0.999950 Loss: 0.000362 | Val Acc: 0.184677 loss: 12.707972\n",
            "[2130/3000] Train Acc: 1.000000 Loss: 0.000110 | Val Acc: 0.183468 loss: 12.848347\n",
            "[2131/3000] Train Acc: 1.000000 Loss: 0.000106 | Val Acc: 0.188710 loss: 12.590542\n",
            "[2132/3000] Train Acc: 1.000000 Loss: 0.000101 | Val Acc: 0.187903 loss: 12.635919\n",
            "[2133/3000] Train Acc: 0.999950 Loss: 0.000242 | Val Acc: 0.188508 loss: 12.752798\n",
            "[2134/3000] Train Acc: 1.000000 Loss: 0.000117 | Val Acc: 0.188911 loss: 12.564009\n",
            "[2135/3000] Train Acc: 1.000000 Loss: 0.000106 | Val Acc: 0.189516 loss: 12.769114\n",
            "[2136/3000] Train Acc: 0.998538 Loss: 0.005395 | Val Acc: 0.176613 loss: 13.156616\n",
            "[2137/3000] Train Acc: 0.999798 Loss: 0.000760 | Val Acc: 0.183065 loss: 12.511348\n",
            "[2138/3000] Train Acc: 1.000000 Loss: 0.000123 | Val Acc: 0.182661 loss: 12.583247\n",
            "[2139/3000] Train Acc: 1.000000 Loss: 0.000091 | Val Acc: 0.187903 loss: 12.516856\n",
            "[2140/3000] Train Acc: 1.000000 Loss: 0.000089 | Val Acc: 0.185081 loss: 12.647228\n",
            "[2141/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.187500 loss: 12.561212\n",
            "[2142/3000] Train Acc: 1.000000 Loss: 0.000085 | Val Acc: 0.184476 loss: 12.576831\n",
            "[2143/3000] Train Acc: 1.000000 Loss: 0.000106 | Val Acc: 0.185685 loss: 12.643444\n",
            "[2144/3000] Train Acc: 0.997883 Loss: 0.007436 | Val Acc: 0.178629 loss: 12.992779\n",
            "[2145/3000] Train Acc: 0.999950 Loss: 0.000465 | Val Acc: 0.188911 loss: 12.447060\n",
            "[2146/3000] Train Acc: 1.000000 Loss: 0.000137 | Val Acc: 0.186290 loss: 12.660872\n",
            "[2147/3000] Train Acc: 1.000000 Loss: 0.000119 | Val Acc: 0.185685 loss: 12.724392\n",
            "[2148/3000] Train Acc: 1.000000 Loss: 0.000093 | Val Acc: 0.183669 loss: 12.832507\n",
            "[2149/3000] Train Acc: 1.000000 Loss: 0.000100 | Val Acc: 0.189919 loss: 12.609770\n",
            "[2150/3000] Train Acc: 1.000000 Loss: 0.000085 | Val Acc: 0.187298 loss: 12.592024\n",
            "[2151/3000] Train Acc: 1.000000 Loss: 0.000087 | Val Acc: 0.180645 loss: 13.294695\n",
            "[2152/3000] Train Acc: 1.000000 Loss: 0.000092 | Val Acc: 0.191129 loss: 12.465128\n",
            "[2153/3000] Train Acc: 0.997278 Loss: 0.009515 | Val Acc: 0.191935 loss: 12.584026\n",
            "[2154/3000] Train Acc: 0.999798 Loss: 0.001126 | Val Acc: 0.185081 loss: 12.707765\n",
            "[2155/3000] Train Acc: 1.000000 Loss: 0.000197 | Val Acc: 0.184677 loss: 13.097198\n",
            "[2156/3000] Train Acc: 1.000000 Loss: 0.000101 | Val Acc: 0.185887 loss: 12.971558\n",
            "[2157/3000] Train Acc: 1.000000 Loss: 0.000093 | Val Acc: 0.185484 loss: 12.923164\n",
            "[2158/3000] Train Acc: 1.000000 Loss: 0.000085 | Val Acc: 0.186492 loss: 12.847631\n",
            "[2159/3000] Train Acc: 1.000000 Loss: 0.000082 | Val Acc: 0.185282 loss: 12.902858\n",
            "[2160/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.188508 loss: 12.753513\n",
            "[2161/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.187097 loss: 12.754507\n",
            "[2162/3000] Train Acc: 1.000000 Loss: 0.000073 | Val Acc: 0.190323 loss: 12.516781\n",
            "[2163/3000] Train Acc: 0.997681 Loss: 0.008083 | Val Acc: 0.195968 loss: 12.253884\n",
            "[2164/3000] Train Acc: 1.000000 Loss: 0.000199 | Val Acc: 0.188911 loss: 12.598587\n",
            "[2165/3000] Train Acc: 1.000000 Loss: 0.000122 | Val Acc: 0.185282 loss: 12.730527\n",
            "[2166/3000] Train Acc: 1.000000 Loss: 0.000102 | Val Acc: 0.188306 loss: 12.606126\n",
            "[2167/3000] Train Acc: 1.000000 Loss: 0.000093 | Val Acc: 0.183065 loss: 12.793557\n",
            "[2168/3000] Train Acc: 1.000000 Loss: 0.000089 | Val Acc: 0.185282 loss: 12.708240\n",
            "[2169/3000] Train Acc: 1.000000 Loss: 0.000082 | Val Acc: 0.185081 loss: 12.581715\n",
            "[2170/3000] Train Acc: 0.996874 Loss: 0.009469 | Val Acc: 0.180040 loss: 13.240448\n",
            "[2171/3000] Train Acc: 0.999798 Loss: 0.000565 | Val Acc: 0.186895 loss: 13.017390\n",
            "[2172/3000] Train Acc: 1.000000 Loss: 0.000123 | Val Acc: 0.186492 loss: 13.027558\n",
            "[2173/3000] Train Acc: 1.000000 Loss: 0.000105 | Val Acc: 0.187903 loss: 12.923793\n",
            "[2174/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.189919 loss: 12.702427\n",
            "[2175/3000] Train Acc: 1.000000 Loss: 0.000109 | Val Acc: 0.184677 loss: 12.970642\n",
            "[2176/3000] Train Acc: 1.000000 Loss: 0.000087 | Val Acc: 0.187097 loss: 12.836143\n",
            "[2177/3000] Train Acc: 1.000000 Loss: 0.000089 | Val Acc: 0.186694 loss: 12.804889\n",
            "[2178/3000] Train Acc: 0.998689 Loss: 0.004765 | Val Acc: 0.174597 loss: 12.928849\n",
            "[2179/3000] Train Acc: 0.998840 Loss: 0.003883 | Val Acc: 0.185484 loss: 12.712099\n",
            "[2180/3000] Train Acc: 1.000000 Loss: 0.000199 | Val Acc: 0.189113 loss: 12.540317\n",
            "[2181/3000] Train Acc: 1.000000 Loss: 0.000107 | Val Acc: 0.188508 loss: 12.526647\n",
            "[2182/3000] Train Acc: 1.000000 Loss: 0.000096 | Val Acc: 0.188508 loss: 12.533663\n",
            "[2183/3000] Train Acc: 1.000000 Loss: 0.000080 | Val Acc: 0.187097 loss: 12.739368\n",
            "[2184/3000] Train Acc: 1.000000 Loss: 0.000074 | Val Acc: 0.189516 loss: 12.653213\n",
            "[2185/3000] Train Acc: 0.999244 Loss: 0.002170 | Val Acc: 0.183065 loss: 12.323344\n",
            "[2186/3000] Train Acc: 0.997631 Loss: 0.005808 | Val Acc: 0.195565 loss: 12.365138\n",
            "[2187/3000] Train Acc: 0.999950 Loss: 0.000369 | Val Acc: 0.190121 loss: 12.280941\n",
            "[2188/3000] Train Acc: 0.999950 Loss: 0.000393 | Val Acc: 0.199194 loss: 12.015512\n",
            "[2189/3000] Train Acc: 1.000000 Loss: 0.000112 | Val Acc: 0.193750 loss: 12.331438\n",
            "[2190/3000] Train Acc: 1.000000 Loss: 0.000080 | Val Acc: 0.189718 loss: 12.643059\n",
            "[2191/3000] Train Acc: 1.000000 Loss: 0.000078 | Val Acc: 0.191532 loss: 12.487979\n",
            "[2192/3000] Train Acc: 1.000000 Loss: 0.000078 | Val Acc: 0.187298 loss: 12.624537\n",
            "[2193/3000] Train Acc: 0.999950 Loss: 0.000195 | Val Acc: 0.190524 loss: 12.494717\n",
            "[2194/3000] Train Acc: 0.998840 Loss: 0.004027 | Val Acc: 0.186492 loss: 12.913268\n",
            "[2195/3000] Train Acc: 0.999849 Loss: 0.001341 | Val Acc: 0.191734 loss: 12.575436\n",
            "[2196/3000] Train Acc: 0.998891 Loss: 0.003322 | Val Acc: 0.175806 loss: 13.631754\n",
            "[2197/3000] Train Acc: 0.999849 Loss: 0.000956 | Val Acc: 0.179435 loss: 13.190555\n",
            "[2198/3000] Train Acc: 0.999193 Loss: 0.002868 | Val Acc: 0.183468 loss: 12.794364\n",
            "[2199/3000] Train Acc: 0.999395 Loss: 0.002761 | Val Acc: 0.175403 loss: 13.702063\n",
            "[2200/3000] Train Acc: 0.999849 Loss: 0.000450 | Val Acc: 0.174798 loss: 13.356257\n",
            "[2201/3000] Train Acc: 0.999849 Loss: 0.001297 | Val Acc: 0.187903 loss: 12.382368\n",
            "[2202/3000] Train Acc: 1.000000 Loss: 0.000215 | Val Acc: 0.192137 loss: 12.627865\n",
            "[2203/3000] Train Acc: 1.000000 Loss: 0.000084 | Val Acc: 0.189113 loss: 12.741943\n",
            "[2204/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.191129 loss: 12.598266\n",
            "[2205/3000] Train Acc: 1.000000 Loss: 0.000066 | Val Acc: 0.191129 loss: 12.619529\n",
            "[2206/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.188710 loss: 12.791477\n",
            "[2207/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.189516 loss: 12.786298\n",
            "[2208/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.191331 loss: 12.593670\n",
            "[2209/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.190927 loss: 12.654952\n",
            "[2210/3000] Train Acc: 0.994404 Loss: 0.016909 | Val Acc: 0.173992 loss: 13.605277\n",
            "[2211/3000] Train Acc: 1.000000 Loss: 0.000480 | Val Acc: 0.174597 loss: 13.375310\n",
            "[2212/3000] Train Acc: 1.000000 Loss: 0.000159 | Val Acc: 0.181855 loss: 12.979874\n",
            "[2213/3000] Train Acc: 1.000000 Loss: 0.000121 | Val Acc: 0.182863 loss: 12.884781\n",
            "[2214/3000] Train Acc: 1.000000 Loss: 0.000106 | Val Acc: 0.185282 loss: 12.808435\n",
            "[2215/3000] Train Acc: 1.000000 Loss: 0.000092 | Val Acc: 0.186492 loss: 12.729696\n",
            "[2216/3000] Train Acc: 1.000000 Loss: 0.000086 | Val Acc: 0.182661 loss: 12.936000\n",
            "[2217/3000] Train Acc: 1.000000 Loss: 0.000080 | Val Acc: 0.186895 loss: 12.716761\n",
            "[2218/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.185685 loss: 12.773531\n",
            "[2219/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.190323 loss: 12.588329\n",
            "[2220/3000] Train Acc: 0.999698 Loss: 0.000626 | Val Acc: 0.197782 loss: 12.681595\n",
            "[2221/3000] Train Acc: 0.995816 Loss: 0.011439 | Val Acc: 0.187903 loss: 12.564800\n",
            "[2222/3000] Train Acc: 0.999950 Loss: 0.000365 | Val Acc: 0.188911 loss: 12.771538\n",
            "[2223/3000] Train Acc: 1.000000 Loss: 0.000132 | Val Acc: 0.193750 loss: 12.530875\n",
            "[2224/3000] Train Acc: 1.000000 Loss: 0.000114 | Val Acc: 0.188911 loss: 12.778850\n",
            "[2225/3000] Train Acc: 1.000000 Loss: 0.000104 | Val Acc: 0.189113 loss: 12.721777\n",
            "[2226/3000] Train Acc: 1.000000 Loss: 0.000097 | Val Acc: 0.194355 loss: 12.491529\n",
            "[2227/3000] Train Acc: 1.000000 Loss: 0.000109 | Val Acc: 0.190121 loss: 12.614009\n",
            "[2228/3000] Train Acc: 0.999950 Loss: 0.000274 | Val Acc: 0.185685 loss: 12.907606\n",
            "[2229/3000] Train Acc: 0.998135 Loss: 0.005685 | Val Acc: 0.192540 loss: 12.468165\n",
            "[2230/3000] Train Acc: 1.000000 Loss: 0.000167 | Val Acc: 0.181452 loss: 13.024749\n",
            "[2231/3000] Train Acc: 0.999950 Loss: 0.000302 | Val Acc: 0.190726 loss: 12.477599\n",
            "[2232/3000] Train Acc: 1.000000 Loss: 0.000134 | Val Acc: 0.186492 loss: 12.821496\n",
            "[2233/3000] Train Acc: 1.000000 Loss: 0.000082 | Val Acc: 0.189315 loss: 12.688007\n",
            "[2234/3000] Train Acc: 1.000000 Loss: 0.000072 | Val Acc: 0.185081 loss: 12.950573\n",
            "[2235/3000] Train Acc: 1.000000 Loss: 0.000084 | Val Acc: 0.186290 loss: 12.797969\n",
            "[2236/3000] Train Acc: 1.000000 Loss: 0.000098 | Val Acc: 0.186089 loss: 12.691728\n",
            "[2237/3000] Train Acc: 0.999395 Loss: 0.001863 | Val Acc: 0.162903 loss: 15.650774\n",
            "[2238/3000] Train Acc: 0.996118 Loss: 0.012887 | Val Acc: 0.182460 loss: 12.980755\n",
            "[2239/3000] Train Acc: 1.000000 Loss: 0.000205 | Val Acc: 0.180242 loss: 13.041657\n",
            "[2240/3000] Train Acc: 1.000000 Loss: 0.000124 | Val Acc: 0.178024 loss: 13.070247\n",
            "[2241/3000] Train Acc: 1.000000 Loss: 0.000105 | Val Acc: 0.181048 loss: 12.920442\n",
            "[2242/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.181855 loss: 12.921992\n",
            "[2243/3000] Train Acc: 1.000000 Loss: 0.000087 | Val Acc: 0.181452 loss: 12.905230\n",
            "[2244/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.184274 loss: 12.810078\n",
            "[2245/3000] Train Acc: 1.000000 Loss: 0.000074 | Val Acc: 0.181855 loss: 12.886424\n",
            "[2246/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.180645 loss: 12.891162\n",
            "[2247/3000] Train Acc: 0.999294 Loss: 0.001779 | Val Acc: 0.182460 loss: 13.090145\n",
            "[2248/3000] Train Acc: 0.999647 Loss: 0.001214 | Val Acc: 0.182056 loss: 12.779197\n",
            "[2249/3000] Train Acc: 1.000000 Loss: 0.000158 | Val Acc: 0.182056 loss: 12.910848\n",
            "[2250/3000] Train Acc: 1.000000 Loss: 0.000082 | Val Acc: 0.183266 loss: 12.842706\n",
            "[2251/3000] Train Acc: 1.000000 Loss: 0.000110 | Val Acc: 0.180242 loss: 12.948257\n",
            "[2252/3000] Train Acc: 1.000000 Loss: 0.000071 | Val Acc: 0.177621 loss: 13.136099\n",
            "[2253/3000] Train Acc: 0.997379 Loss: 0.007802 | Val Acc: 0.189315 loss: 12.647810\n",
            "[2254/3000] Train Acc: 0.999950 Loss: 0.000375 | Val Acc: 0.180847 loss: 13.409509\n",
            "[2255/3000] Train Acc: 0.999193 Loss: 0.002222 | Val Acc: 0.181048 loss: 13.117835\n",
            "[2256/3000] Train Acc: 1.000000 Loss: 0.000229 | Val Acc: 0.192339 loss: 12.643861\n",
            "[2257/3000] Train Acc: 0.999950 Loss: 0.000245 | Val Acc: 0.181048 loss: 13.131678\n",
            "[2258/3000] Train Acc: 1.000000 Loss: 0.000119 | Val Acc: 0.189315 loss: 12.780715\n",
            "[2259/3000] Train Acc: 1.000000 Loss: 0.000081 | Val Acc: 0.189315 loss: 12.780679\n",
            "[2260/3000] Train Acc: 0.996774 Loss: 0.010910 | Val Acc: 0.174194 loss: 13.423880\n",
            "[2261/3000] Train Acc: 1.000000 Loss: 0.000416 | Val Acc: 0.186694 loss: 12.919362\n",
            "[2262/3000] Train Acc: 1.000000 Loss: 0.000124 | Val Acc: 0.185081 loss: 12.983094\n",
            "[2263/3000] Train Acc: 1.000000 Loss: 0.000102 | Val Acc: 0.183468 loss: 12.981341\n",
            "[2264/3000] Train Acc: 1.000000 Loss: 0.000118 | Val Acc: 0.184274 loss: 12.887840\n",
            "[2265/3000] Train Acc: 1.000000 Loss: 0.000085 | Val Acc: 0.184677 loss: 12.889875\n",
            "[2266/3000] Train Acc: 1.000000 Loss: 0.000084 | Val Acc: 0.180645 loss: 13.102050\n",
            "[2267/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.183871 loss: 12.946141\n",
            "[2268/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.185282 loss: 12.961846\n",
            "[2269/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.185282 loss: 12.959908\n",
            "[2270/3000] Train Acc: 0.999849 Loss: 0.000534 | Val Acc: 0.196976 loss: 12.443711\n",
            "[2271/3000] Train Acc: 0.997227 Loss: 0.008540 | Val Acc: 0.186895 loss: 13.020883\n",
            "[2272/3000] Train Acc: 0.999798 Loss: 0.000768 | Val Acc: 0.190927 loss: 12.727997\n",
            "[2273/3000] Train Acc: 0.999950 Loss: 0.000240 | Val Acc: 0.165726 loss: 14.291290\n",
            "[2274/3000] Train Acc: 0.999748 Loss: 0.000654 | Val Acc: 0.200202 loss: 12.367599\n",
            "[2275/3000] Train Acc: 0.999899 Loss: 0.000362 | Val Acc: 0.193145 loss: 12.432865\n",
            "[2276/3000] Train Acc: 0.999849 Loss: 0.000770 | Val Acc: 0.182056 loss: 13.127157\n",
            "[2277/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.187097 loss: 12.894840\n",
            "[2278/3000] Train Acc: 1.000000 Loss: 0.000064 | Val Acc: 0.187903 loss: 12.819315\n",
            "[2279/3000] Train Acc: 1.000000 Loss: 0.000074 | Val Acc: 0.188710 loss: 12.814924\n",
            "[2280/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.185081 loss: 13.064188\n",
            "[2281/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.186895 loss: 12.940572\n",
            "[2282/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.185685 loss: 12.970762\n",
            "[2283/3000] Train Acc: 0.999950 Loss: 0.000221 | Val Acc: 0.163710 loss: 14.411372\n",
            "[2284/3000] Train Acc: 0.997429 Loss: 0.009937 | Val Acc: 0.184677 loss: 12.585323\n",
            "[2285/3000] Train Acc: 0.999294 Loss: 0.002065 | Val Acc: 0.174798 loss: 13.756281\n",
            "[2286/3000] Train Acc: 0.999698 Loss: 0.001260 | Val Acc: 0.188306 loss: 12.846309\n",
            "[2287/3000] Train Acc: 1.000000 Loss: 0.000210 | Val Acc: 0.188911 loss: 12.910161\n",
            "[2288/3000] Train Acc: 1.000000 Loss: 0.000081 | Val Acc: 0.189516 loss: 12.843226\n",
            "[2289/3000] Train Acc: 1.000000 Loss: 0.000073 | Val Acc: 0.187903 loss: 12.857060\n",
            "[2290/3000] Train Acc: 1.000000 Loss: 0.000070 | Val Acc: 0.188508 loss: 12.818720\n",
            "[2291/3000] Train Acc: 1.000000 Loss: 0.000070 | Val Acc: 0.189315 loss: 12.812581\n",
            "[2292/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.187702 loss: 12.923075\n",
            "[2293/3000] Train Acc: 1.000000 Loss: 0.000083 | Val Acc: 0.185887 loss: 12.915692\n",
            "[2294/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.189919 loss: 12.561092\n",
            "[2295/3000] Train Acc: 0.999546 Loss: 0.001702 | Val Acc: 0.205645 loss: 12.099938\n",
            "[2296/3000] Train Acc: 0.996572 Loss: 0.011991 | Val Acc: 0.189516 loss: 12.540933\n",
            "[2297/3000] Train Acc: 1.000000 Loss: 0.000153 | Val Acc: 0.188710 loss: 12.666189\n",
            "[2298/3000] Train Acc: 1.000000 Loss: 0.000109 | Val Acc: 0.187702 loss: 12.733679\n",
            "[2299/3000] Train Acc: 1.000000 Loss: 0.000097 | Val Acc: 0.189718 loss: 12.680610\n",
            "[2300/3000] Train Acc: 1.000000 Loss: 0.000086 | Val Acc: 0.188105 loss: 12.779756\n",
            "[2301/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.184274 loss: 12.823855\n",
            "[2302/3000] Train Acc: 1.000000 Loss: 0.000078 | Val Acc: 0.184677 loss: 12.922359\n",
            "[2303/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.188306 loss: 12.810723\n",
            "[2304/3000] Train Acc: 1.000000 Loss: 0.000070 | Val Acc: 0.189315 loss: 12.767289\n",
            "[2305/3000] Train Acc: 1.000000 Loss: 0.000101 | Val Acc: 0.190927 loss: 12.612889\n",
            "[2306/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.184476 loss: 12.957131\n",
            "[2307/3000] Train Acc: 1.000000 Loss: 0.000103 | Val Acc: 0.169153 loss: 13.803352\n",
            "[2308/3000] Train Acc: 0.999950 Loss: 0.000328 | Val Acc: 0.178226 loss: 13.463179\n",
            "[2309/3000] Train Acc: 1.000000 Loss: 0.000112 | Val Acc: 0.186089 loss: 13.117583\n",
            "[2310/3000] Train Acc: 0.995513 Loss: 0.014309 | Val Acc: 0.185685 loss: 13.049038\n",
            "[2311/3000] Train Acc: 1.000000 Loss: 0.000244 | Val Acc: 0.189516 loss: 12.780265\n",
            "[2312/3000] Train Acc: 1.000000 Loss: 0.000124 | Val Acc: 0.186089 loss: 12.929298\n",
            "[2313/3000] Train Acc: 1.000000 Loss: 0.000105 | Val Acc: 0.187903 loss: 12.940721\n",
            "[2314/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.187903 loss: 12.882941\n",
            "[2315/3000] Train Acc: 1.000000 Loss: 0.000086 | Val Acc: 0.188306 loss: 12.909558\n",
            "[2316/3000] Train Acc: 1.000000 Loss: 0.000080 | Val Acc: 0.187903 loss: 12.932083\n",
            "[2317/3000] Train Acc: 1.000000 Loss: 0.000073 | Val Acc: 0.185685 loss: 13.143472\n",
            "[2318/3000] Train Acc: 1.000000 Loss: 0.000072 | Val Acc: 0.188306 loss: 12.956514\n",
            "[2319/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.190524 loss: 12.838488\n",
            "[2320/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.185484 loss: 13.121664\n",
            "[2321/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.189718 loss: 12.869053\n",
            "[2322/3000] Train Acc: 1.000000 Loss: 0.000059 | Val Acc: 0.186694 loss: 13.023849\n",
            "[2323/3000] Train Acc: 1.000000 Loss: 0.000103 | Val Acc: 0.174395 loss: 13.682547\n",
            "[2324/3000] Train Acc: 0.996118 Loss: 0.015930 | Val Acc: 0.187298 loss: 13.131052\n",
            "[2325/3000] Train Acc: 1.000000 Loss: 0.000276 | Val Acc: 0.188105 loss: 12.980268\n",
            "[2326/3000] Train Acc: 1.000000 Loss: 0.000160 | Val Acc: 0.186895 loss: 13.022430\n",
            "[2327/3000] Train Acc: 1.000000 Loss: 0.000110 | Val Acc: 0.184073 loss: 13.072255\n",
            "[2328/3000] Train Acc: 1.000000 Loss: 0.000133 | Val Acc: 0.190726 loss: 12.811654\n",
            "[2329/3000] Train Acc: 1.000000 Loss: 0.000103 | Val Acc: 0.188911 loss: 12.869175\n",
            "[2330/3000] Train Acc: 1.000000 Loss: 0.000095 | Val Acc: 0.185484 loss: 13.043415\n",
            "[2331/3000] Train Acc: 1.000000 Loss: 0.000105 | Val Acc: 0.190524 loss: 12.807291\n",
            "[2332/3000] Train Acc: 1.000000 Loss: 0.000085 | Val Acc: 0.188911 loss: 12.908426\n",
            "[2333/3000] Train Acc: 0.998941 Loss: 0.003311 | Val Acc: 0.160282 loss: 14.313935\n",
            "[2334/3000] Train Acc: 0.998236 Loss: 0.005077 | Val Acc: 0.185282 loss: 12.873756\n",
            "[2335/3000] Train Acc: 0.999950 Loss: 0.000293 | Val Acc: 0.185685 loss: 12.792863\n",
            "[2336/3000] Train Acc: 0.999950 Loss: 0.000221 | Val Acc: 0.187903 loss: 12.753853\n",
            "[2337/3000] Train Acc: 0.999748 Loss: 0.000859 | Val Acc: 0.193952 loss: 12.515740\n",
            "[2338/3000] Train Acc: 0.999899 Loss: 0.000642 | Val Acc: 0.190121 loss: 12.729151\n",
            "[2339/3000] Train Acc: 1.000000 Loss: 0.000148 | Val Acc: 0.185484 loss: 13.152834\n",
            "[2340/3000] Train Acc: 1.000000 Loss: 0.000164 | Val Acc: 0.168548 loss: 14.097971\n",
            "[2341/3000] Train Acc: 0.996169 Loss: 0.011926 | Val Acc: 0.197782 loss: 12.687069\n",
            "[2342/3000] Train Acc: 1.000000 Loss: 0.000303 | Val Acc: 0.188911 loss: 12.924796\n",
            "[2343/3000] Train Acc: 1.000000 Loss: 0.000126 | Val Acc: 0.194758 loss: 12.764037\n",
            "[2344/3000] Train Acc: 1.000000 Loss: 0.000100 | Val Acc: 0.193347 loss: 12.846049\n",
            "[2345/3000] Train Acc: 1.000000 Loss: 0.000088 | Val Acc: 0.190121 loss: 12.954581\n",
            "[2346/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.192137 loss: 12.863837\n",
            "[2347/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.190121 loss: 13.009942\n",
            "[2348/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.189718 loss: 13.006477\n",
            "[2349/3000] Train Acc: 1.000000 Loss: 0.000066 | Val Acc: 0.192339 loss: 12.840279\n",
            "[2350/3000] Train Acc: 1.000000 Loss: 0.000115 | Val Acc: 0.194960 loss: 12.765685\n",
            "[2351/3000] Train Acc: 0.997379 Loss: 0.006758 | Val Acc: 0.173185 loss: 14.277502\n",
            "[2352/3000] Train Acc: 0.999546 Loss: 0.001516 | Val Acc: 0.178427 loss: 13.504045\n",
            "[2353/3000] Train Acc: 0.999950 Loss: 0.000341 | Val Acc: 0.183468 loss: 13.195292\n",
            "[2354/3000] Train Acc: 0.999950 Loss: 0.000379 | Val Acc: 0.179234 loss: 13.482035\n",
            "[2355/3000] Train Acc: 0.999849 Loss: 0.000653 | Val Acc: 0.187298 loss: 13.197441\n",
            "[2356/3000] Train Acc: 0.999798 Loss: 0.001011 | Val Acc: 0.193347 loss: 13.060675\n",
            "[2357/3000] Train Acc: 0.999698 Loss: 0.001356 | Val Acc: 0.215323 loss: 11.950982\n",
            "saving model with acc 0.215\n",
            "[2358/3000] Train Acc: 0.998840 Loss: 0.003634 | Val Acc: 0.205847 loss: 11.881207\n",
            "[2359/3000] Train Acc: 0.999950 Loss: 0.000458 | Val Acc: 0.192137 loss: 13.163168\n",
            "[2360/3000] Train Acc: 1.000000 Loss: 0.000113 | Val Acc: 0.186694 loss: 13.336777\n",
            "[2361/3000] Train Acc: 0.999899 Loss: 0.000827 | Val Acc: 0.187903 loss: 13.336027\n",
            "[2362/3000] Train Acc: 0.999798 Loss: 0.000544 | Val Acc: 0.202218 loss: 12.424490\n",
            "[2363/3000] Train Acc: 0.997933 Loss: 0.006854 | Val Acc: 0.174798 loss: 14.079393\n",
            "[2364/3000] Train Acc: 0.999899 Loss: 0.000450 | Val Acc: 0.188105 loss: 12.870274\n",
            "[2365/3000] Train Acc: 1.000000 Loss: 0.000115 | Val Acc: 0.187097 loss: 12.810882\n",
            "[2366/3000] Train Acc: 1.000000 Loss: 0.000080 | Val Acc: 0.184073 loss: 13.105718\n",
            "[2367/3000] Train Acc: 1.000000 Loss: 0.000070 | Val Acc: 0.186290 loss: 12.996723\n",
            "[2368/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.188306 loss: 12.922175\n",
            "[2369/3000] Train Acc: 1.000000 Loss: 0.000064 | Val Acc: 0.187097 loss: 12.998837\n",
            "[2370/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.187500 loss: 13.019176\n",
            "[2371/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.187903 loss: 13.012767\n",
            "[2372/3000] Train Acc: 0.996673 Loss: 0.008900 | Val Acc: 0.198790 loss: 12.141614\n",
            "[2373/3000] Train Acc: 0.999950 Loss: 0.000464 | Val Acc: 0.197984 loss: 12.468180\n",
            "[2374/3000] Train Acc: 1.000000 Loss: 0.000140 | Val Acc: 0.200403 loss: 12.555026\n",
            "[2375/3000] Train Acc: 1.000000 Loss: 0.000131 | Val Acc: 0.185685 loss: 12.976758\n",
            "[2376/3000] Train Acc: 1.000000 Loss: 0.000082 | Val Acc: 0.195565 loss: 12.688834\n",
            "[2377/3000] Train Acc: 1.000000 Loss: 0.000074 | Val Acc: 0.193347 loss: 12.764071\n",
            "[2378/3000] Train Acc: 1.000000 Loss: 0.000102 | Val Acc: 0.194355 loss: 12.693702\n",
            "[2379/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.193548 loss: 12.808382\n",
            "[2380/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.195363 loss: 12.601977\n",
            "[2381/3000] Train Acc: 0.997227 Loss: 0.007854 | Val Acc: 0.183065 loss: 12.917534\n",
            "[2382/3000] Train Acc: 1.000000 Loss: 0.000194 | Val Acc: 0.190323 loss: 12.786398\n",
            "[2383/3000] Train Acc: 1.000000 Loss: 0.000109 | Val Acc: 0.187097 loss: 12.989072\n",
            "[2384/3000] Train Acc: 1.000000 Loss: 0.000089 | Val Acc: 0.191935 loss: 12.711524\n",
            "[2385/3000] Train Acc: 1.000000 Loss: 0.000084 | Val Acc: 0.189516 loss: 12.915170\n",
            "[2386/3000] Train Acc: 1.000000 Loss: 0.000095 | Val Acc: 0.186089 loss: 13.102507\n",
            "[2387/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.190726 loss: 12.863270\n",
            "[2388/3000] Train Acc: 1.000000 Loss: 0.000084 | Val Acc: 0.187903 loss: 13.006888\n",
            "[2389/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.190121 loss: 12.822807\n",
            "[2390/3000] Train Acc: 1.000000 Loss: 0.000116 | Val Acc: 0.192137 loss: 12.730899\n",
            "[2391/3000] Train Acc: 0.998790 Loss: 0.003780 | Val Acc: 0.165121 loss: 15.004937\n",
            "[2392/3000] Train Acc: 0.997328 Loss: 0.007518 | Val Acc: 0.190927 loss: 12.774775\n",
            "[2393/3000] Train Acc: 1.000000 Loss: 0.000132 | Val Acc: 0.188105 loss: 12.811640\n",
            "[2394/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.189113 loss: 12.752589\n",
            "[2395/3000] Train Acc: 1.000000 Loss: 0.000082 | Val Acc: 0.186492 loss: 12.842839\n",
            "[2396/3000] Train Acc: 1.000000 Loss: 0.000073 | Val Acc: 0.186895 loss: 12.820878\n",
            "[2397/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.186694 loss: 12.793668\n",
            "[2398/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.187298 loss: 12.840862\n",
            "[2399/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.184274 loss: 12.930468\n",
            "[2400/3000] Train Acc: 1.000000 Loss: 0.000075 | Val Acc: 0.185081 loss: 12.824069\n",
            "[2401/3000] Train Acc: 0.999597 Loss: 0.001105 | Val Acc: 0.169153 loss: 13.659738\n",
            "[2402/3000] Train Acc: 0.996521 Loss: 0.010679 | Val Acc: 0.191532 loss: 13.046618\n",
            "[2403/3000] Train Acc: 0.999950 Loss: 0.000285 | Val Acc: 0.190121 loss: 12.849505\n",
            "[2404/3000] Train Acc: 1.000000 Loss: 0.000103 | Val Acc: 0.191129 loss: 12.933719\n",
            "[2405/3000] Train Acc: 1.000000 Loss: 0.000082 | Val Acc: 0.190323 loss: 12.881986\n",
            "[2406/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.189718 loss: 13.003860\n",
            "[2407/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.189516 loss: 12.989075\n",
            "[2408/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.190121 loss: 13.030269\n",
            "[2409/3000] Train Acc: 1.000000 Loss: 0.000070 | Val Acc: 0.190323 loss: 12.942176\n",
            "[2410/3000] Train Acc: 1.000000 Loss: 0.000060 | Val Acc: 0.189718 loss: 13.086364\n",
            "[2411/3000] Train Acc: 0.997883 Loss: 0.006325 | Val Acc: 0.182661 loss: 12.810664\n",
            "[2412/3000] Train Acc: 0.999395 Loss: 0.001950 | Val Acc: 0.187500 loss: 12.909998\n",
            "[2413/3000] Train Acc: 0.999395 Loss: 0.001838 | Val Acc: 0.175806 loss: 13.201484\n",
            "[2414/3000] Train Acc: 0.999899 Loss: 0.000418 | Val Acc: 0.189919 loss: 12.725066\n",
            "[2415/3000] Train Acc: 1.000000 Loss: 0.000089 | Val Acc: 0.185282 loss: 12.908639\n",
            "[2416/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.191129 loss: 12.736219\n",
            "[2417/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.191331 loss: 12.756719\n",
            "[2418/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.183065 loss: 13.024283\n",
            "[2419/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.188105 loss: 12.859917\n",
            "[2420/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.189315 loss: 12.847478\n",
            "[2421/3000] Train Acc: 1.000000 Loss: 0.000052 | Val Acc: 0.188306 loss: 12.835371\n",
            "[2422/3000] Train Acc: 0.999798 Loss: 0.000644 | Val Acc: 0.192137 loss: 13.011520\n",
            "[2423/3000] Train Acc: 0.996874 Loss: 0.011626 | Val Acc: 0.185484 loss: 13.090219\n",
            "[2424/3000] Train Acc: 1.000000 Loss: 0.000133 | Val Acc: 0.184677 loss: 13.185908\n",
            "[2425/3000] Train Acc: 1.000000 Loss: 0.000092 | Val Acc: 0.184677 loss: 13.143286\n",
            "[2426/3000] Train Acc: 1.000000 Loss: 0.000078 | Val Acc: 0.184879 loss: 13.176849\n",
            "[2427/3000] Train Acc: 1.000000 Loss: 0.000071 | Val Acc: 0.185081 loss: 13.037656\n",
            "[2428/3000] Train Acc: 1.000000 Loss: 0.000066 | Val Acc: 0.183669 loss: 13.215112\n",
            "[2429/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.186694 loss: 13.070426\n",
            "[2430/3000] Train Acc: 1.000000 Loss: 0.000056 | Val Acc: 0.185685 loss: 13.028808\n",
            "[2431/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.185282 loss: 13.118530\n",
            "[2432/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.185081 loss: 13.139779\n",
            "[2433/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.186089 loss: 13.096588\n",
            "[2434/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.186290 loss: 12.997998\n",
            "[2435/3000] Train Acc: 0.997681 Loss: 0.007231 | Val Acc: 0.181452 loss: 13.658548\n",
            "[2436/3000] Train Acc: 0.999899 Loss: 0.000588 | Val Acc: 0.187702 loss: 13.352879\n",
            "[2437/3000] Train Acc: 1.000000 Loss: 0.000135 | Val Acc: 0.190927 loss: 13.263621\n",
            "[2438/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.191935 loss: 13.152258\n",
            "[2439/3000] Train Acc: 1.000000 Loss: 0.000070 | Val Acc: 0.190121 loss: 13.145155\n",
            "[2440/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.190323 loss: 13.288854\n",
            "[2441/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.187702 loss: 13.340434\n",
            "[2442/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.194153 loss: 12.829364\n",
            "[2443/3000] Train Acc: 0.996269 Loss: 0.010783 | Val Acc: 0.189315 loss: 13.427581\n",
            "[2444/3000] Train Acc: 1.000000 Loss: 0.000316 | Val Acc: 0.187298 loss: 13.457447\n",
            "[2445/3000] Train Acc: 1.000000 Loss: 0.000096 | Val Acc: 0.185282 loss: 13.587598\n",
            "[2446/3000] Train Acc: 1.000000 Loss: 0.000085 | Val Acc: 0.190323 loss: 13.409424\n",
            "[2447/3000] Train Acc: 1.000000 Loss: 0.000071 | Val Acc: 0.190524 loss: 13.337422\n",
            "[2448/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.188508 loss: 13.394918\n",
            "[2449/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.187500 loss: 13.385985\n",
            "[2450/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.180242 loss: 13.831981\n",
            "[2451/3000] Train Acc: 0.999849 Loss: 0.000444 | Val Acc: 0.188508 loss: 13.549939\n",
            "[2452/3000] Train Acc: 0.998084 Loss: 0.006003 | Val Acc: 0.186895 loss: 13.010149\n",
            "[2453/3000] Train Acc: 0.999849 Loss: 0.000465 | Val Acc: 0.188911 loss: 13.298192\n",
            "[2454/3000] Train Acc: 1.000000 Loss: 0.000089 | Val Acc: 0.194556 loss: 12.978175\n",
            "[2455/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.188306 loss: 13.237110\n",
            "[2456/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.187500 loss: 13.273887\n",
            "[2457/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.188508 loss: 13.238873\n",
            "[2458/3000] Train Acc: 1.000000 Loss: 0.000052 | Val Acc: 0.190927 loss: 13.166289\n",
            "[2459/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.186290 loss: 13.355360\n",
            "[2460/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.189718 loss: 13.250540\n",
            "[2461/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.189113 loss: 13.226122\n",
            "[2462/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.189113 loss: 13.091833\n",
            "[2463/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.190323 loss: 13.183315\n",
            "[2464/3000] Train Acc: 0.997278 Loss: 0.009834 | Val Acc: 0.187298 loss: 13.119762\n",
            "[2465/3000] Train Acc: 1.000000 Loss: 0.000148 | Val Acc: 0.183468 loss: 13.315074\n",
            "[2466/3000] Train Acc: 1.000000 Loss: 0.000090 | Val Acc: 0.185081 loss: 13.262101\n",
            "[2467/3000] Train Acc: 1.000000 Loss: 0.000075 | Val Acc: 0.185887 loss: 13.213487\n",
            "[2468/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.187298 loss: 13.147260\n",
            "[2469/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.187298 loss: 13.221109\n",
            "[2470/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.188911 loss: 13.082173\n",
            "[2471/3000] Train Acc: 1.000000 Loss: 0.000104 | Val Acc: 0.186694 loss: 13.222152\n",
            "[2472/3000] Train Acc: 1.000000 Loss: 0.000124 | Val Acc: 0.183266 loss: 13.510643\n",
            "[2473/3000] Train Acc: 0.998387 Loss: 0.004466 | Val Acc: 0.185081 loss: 13.290004\n",
            "[2474/3000] Train Acc: 1.000000 Loss: 0.000184 | Val Acc: 0.188508 loss: 12.983530\n",
            "[2475/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.188911 loss: 13.205129\n",
            "[2476/3000] Train Acc: 1.000000 Loss: 0.000059 | Val Acc: 0.185282 loss: 13.294552\n",
            "[2477/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.189113 loss: 13.141026\n",
            "[2478/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.187097 loss: 13.211797\n",
            "[2479/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.188306 loss: 13.167831\n",
            "[2480/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.184476 loss: 13.338806\n",
            "[2481/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.190121 loss: 13.088972\n",
            "[2482/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.186694 loss: 13.267853\n",
            "[2483/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.184677 loss: 13.328489\n",
            "[2484/3000] Train Acc: 0.997580 Loss: 0.006866 | Val Acc: 0.179234 loss: 13.776517\n",
            "[2485/3000] Train Acc: 0.998740 Loss: 0.004618 | Val Acc: 0.191532 loss: 12.952587\n",
            "[2486/3000] Train Acc: 1.000000 Loss: 0.000222 | Val Acc: 0.198589 loss: 12.643091\n",
            "[2487/3000] Train Acc: 1.000000 Loss: 0.000097 | Val Acc: 0.188911 loss: 13.102591\n",
            "[2488/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.187097 loss: 13.235298\n",
            "[2489/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.188105 loss: 13.183593\n",
            "[2490/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.187298 loss: 13.250327\n",
            "[2491/3000] Train Acc: 1.000000 Loss: 0.000052 | Val Acc: 0.186694 loss: 13.194527\n",
            "[2492/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.187097 loss: 13.351544\n",
            "[2493/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.186895 loss: 13.325270\n",
            "[2494/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.185887 loss: 13.356091\n",
            "[2495/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.185081 loss: 13.442035\n",
            "[2496/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.187500 loss: 13.186847\n",
            "[2497/3000] Train Acc: 0.997076 Loss: 0.009601 | Val Acc: 0.195565 loss: 13.286022\n",
            "[2498/3000] Train Acc: 0.998891 Loss: 0.003654 | Val Acc: 0.194758 loss: 13.098446\n",
            "[2499/3000] Train Acc: 1.000000 Loss: 0.000179 | Val Acc: 0.184073 loss: 13.395701\n",
            "[2500/3000] Train Acc: 1.000000 Loss: 0.000092 | Val Acc: 0.185081 loss: 13.350189\n",
            "[2501/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.184677 loss: 13.339411\n",
            "[2502/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.184274 loss: 13.348699\n",
            "[2503/3000] Train Acc: 1.000000 Loss: 0.000064 | Val Acc: 0.183266 loss: 13.397228\n",
            "[2504/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.184073 loss: 13.477379\n",
            "[2505/3000] Train Acc: 1.000000 Loss: 0.000066 | Val Acc: 0.182661 loss: 13.478818\n",
            "[2506/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.183669 loss: 13.372501\n",
            "[2507/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.183468 loss: 13.402545\n",
            "[2508/3000] Train Acc: 1.000000 Loss: 0.000059 | Val Acc: 0.172581 loss: 14.345087\n",
            "[2509/3000] Train Acc: 0.998689 Loss: 0.004232 | Val Acc: 0.174597 loss: 13.658671\n",
            "[2510/3000] Train Acc: 0.998034 Loss: 0.005308 | Val Acc: 0.204234 loss: 12.621683\n",
            "[2511/3000] Train Acc: 1.000000 Loss: 0.000257 | Val Acc: 0.185887 loss: 13.471183\n",
            "[2512/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.189718 loss: 13.144319\n",
            "[2513/3000] Train Acc: 1.000000 Loss: 0.000071 | Val Acc: 0.190927 loss: 13.093310\n",
            "[2514/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.191331 loss: 13.043664\n",
            "[2515/3000] Train Acc: 1.000000 Loss: 0.000059 | Val Acc: 0.190726 loss: 13.118932\n",
            "[2516/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.189516 loss: 13.095923\n",
            "[2517/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.188911 loss: 13.177284\n",
            "[2518/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.190323 loss: 13.139300\n",
            "[2519/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.187097 loss: 13.264386\n",
            "[2520/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.189718 loss: 13.140615\n",
            "[2521/3000] Train Acc: 1.000000 Loss: 0.000095 | Val Acc: 0.187702 loss: 13.078162\n",
            "[2522/3000] Train Acc: 0.994858 Loss: 0.016524 | Val Acc: 0.177823 loss: 13.857129\n",
            "[2523/3000] Train Acc: 1.000000 Loss: 0.000282 | Val Acc: 0.183871 loss: 13.269664\n",
            "[2524/3000] Train Acc: 1.000000 Loss: 0.000104 | Val Acc: 0.185887 loss: 13.122887\n",
            "[2525/3000] Train Acc: 1.000000 Loss: 0.000086 | Val Acc: 0.184677 loss: 13.222289\n",
            "[2526/3000] Train Acc: 1.000000 Loss: 0.000075 | Val Acc: 0.185282 loss: 13.114933\n",
            "[2527/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.184274 loss: 13.174292\n",
            "[2528/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.184476 loss: 13.181958\n",
            "[2529/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.185081 loss: 13.130579\n",
            "[2530/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.185685 loss: 13.120243\n",
            "[2531/3000] Train Acc: 1.000000 Loss: 0.000052 | Val Acc: 0.185484 loss: 13.166389\n",
            "[2532/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.184476 loss: 13.182338\n",
            "[2533/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.185282 loss: 13.294390\n",
            "[2534/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.185282 loss: 13.206265\n",
            "[2535/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.185484 loss: 13.182246\n",
            "[2536/3000] Train Acc: 0.997379 Loss: 0.007749 | Val Acc: 0.196371 loss: 12.515598\n",
            "[2537/3000] Train Acc: 1.000000 Loss: 0.000468 | Val Acc: 0.184476 loss: 13.258972\n",
            "[2538/3000] Train Acc: 1.000000 Loss: 0.000096 | Val Acc: 0.186492 loss: 12.984320\n",
            "[2539/3000] Train Acc: 1.000000 Loss: 0.000072 | Val Acc: 0.185081 loss: 13.141357\n",
            "[2540/3000] Train Acc: 1.000000 Loss: 0.000064 | Val Acc: 0.185081 loss: 13.203316\n",
            "[2541/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.186290 loss: 13.037964\n",
            "[2542/3000] Train Acc: 1.000000 Loss: 0.000059 | Val Acc: 0.185282 loss: 13.152381\n",
            "[2543/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.186290 loss: 13.067849\n",
            "[2544/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.181250 loss: 13.454835\n",
            "[2545/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.185887 loss: 13.147511\n",
            "[2546/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.181653 loss: 13.548659\n",
            "[2547/3000] Train Acc: 0.997681 Loss: 0.007281 | Val Acc: 0.186492 loss: 12.437419\n",
            "[2548/3000] Train Acc: 0.999647 Loss: 0.001113 | Val Acc: 0.184677 loss: 13.232702\n",
            "[2549/3000] Train Acc: 1.000000 Loss: 0.000095 | Val Acc: 0.181048 loss: 13.318952\n",
            "[2550/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.180444 loss: 13.414891\n",
            "[2551/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.181250 loss: 13.385699\n",
            "[2552/3000] Train Acc: 1.000000 Loss: 0.000060 | Val Acc: 0.180242 loss: 13.458412\n",
            "[2553/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.180645 loss: 13.440982\n",
            "[2554/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.181855 loss: 13.407496\n",
            "[2555/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.181250 loss: 13.484266\n",
            "[2556/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.182056 loss: 13.388023\n",
            "[2557/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.184274 loss: 13.245168\n",
            "[2558/3000] Train Acc: 1.000000 Loss: 0.000095 | Val Acc: 0.181653 loss: 13.424749\n",
            "[2559/3000] Train Acc: 0.999849 Loss: 0.000878 | Val Acc: 0.203831 loss: 12.496629\n",
            "[2560/3000] Train Acc: 0.997782 Loss: 0.008511 | Val Acc: 0.188508 loss: 13.091032\n",
            "[2561/3000] Train Acc: 1.000000 Loss: 0.000113 | Val Acc: 0.182661 loss: 13.390019\n",
            "[2562/3000] Train Acc: 1.000000 Loss: 0.000074 | Val Acc: 0.180847 loss: 13.431082\n",
            "[2563/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.183065 loss: 13.314289\n",
            "[2564/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.182863 loss: 13.289919\n",
            "[2565/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.180847 loss: 13.401602\n",
            "[2566/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.182661 loss: 13.298897\n",
            "[2567/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.183669 loss: 13.329267\n",
            "[2568/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.177823 loss: 13.570245\n",
            "[2569/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.180242 loss: 13.471618\n",
            "[2570/3000] Train Acc: 0.996774 Loss: 0.009905 | Val Acc: 0.200605 loss: 12.569803\n",
            "[2571/3000] Train Acc: 0.999798 Loss: 0.000922 | Val Acc: 0.191331 loss: 13.037213\n",
            "[2572/3000] Train Acc: 1.000000 Loss: 0.000133 | Val Acc: 0.191129 loss: 13.208916\n",
            "[2573/3000] Train Acc: 1.000000 Loss: 0.000073 | Val Acc: 0.191532 loss: 13.204995\n",
            "[2574/3000] Train Acc: 1.000000 Loss: 0.000066 | Val Acc: 0.189919 loss: 13.267594\n",
            "[2575/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.192339 loss: 13.133571\n",
            "[2576/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.191532 loss: 13.120069\n",
            "[2577/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.191532 loss: 13.137703\n",
            "[2578/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.190121 loss: 13.265602\n",
            "[2579/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.190524 loss: 13.210673\n",
            "[2580/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.189315 loss: 13.239409\n",
            "[2581/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.185887 loss: 13.570559\n",
            "[2582/3000] Train Acc: 0.996925 Loss: 0.009780 | Val Acc: 0.177419 loss: 13.671276\n",
            "[2583/3000] Train Acc: 0.999899 Loss: 0.000408 | Val Acc: 0.183266 loss: 13.492740\n",
            "[2584/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.183871 loss: 13.491016\n",
            "[2585/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.185081 loss: 13.360888\n",
            "[2586/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.182661 loss: 13.419315\n",
            "[2587/3000] Train Acc: 1.000000 Loss: 0.000060 | Val Acc: 0.186694 loss: 13.221244\n",
            "[2588/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.184677 loss: 13.304335\n",
            "[2589/3000] Train Acc: 1.000000 Loss: 0.000052 | Val Acc: 0.183065 loss: 13.402296\n",
            "[2590/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.183669 loss: 13.335049\n",
            "[2591/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.182661 loss: 13.418201\n",
            "[2592/3000] Train Acc: 1.000000 Loss: 0.000049 | Val Acc: 0.182863 loss: 13.463050\n",
            "[2593/3000] Train Acc: 0.998891 Loss: 0.004095 | Val Acc: 0.179234 loss: 13.639878\n",
            "[2594/3000] Train Acc: 0.998437 Loss: 0.005034 | Val Acc: 0.227016 loss: 11.555543\n",
            "saving model with acc 0.227\n",
            "[2595/3000] Train Acc: 1.000000 Loss: 0.000262 | Val Acc: 0.192742 loss: 12.913601\n",
            "[2596/3000] Train Acc: 1.000000 Loss: 0.000087 | Val Acc: 0.192137 loss: 13.098069\n",
            "[2597/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.190927 loss: 13.062511\n",
            "[2598/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.191532 loss: 13.098681\n",
            "[2599/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.189516 loss: 13.184494\n",
            "[2600/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.188911 loss: 13.224513\n",
            "[2601/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.188105 loss: 13.315716\n",
            "[2602/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.188710 loss: 13.253266\n",
            "[2603/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.190524 loss: 13.052368\n",
            "[2604/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.186895 loss: 13.368810\n",
            "[2605/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.188911 loss: 13.194127\n",
            "[2606/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.187097 loss: 13.334900\n",
            "[2607/3000] Train Acc: 0.996169 Loss: 0.012073 | Val Acc: 0.190323 loss: 13.125331\n",
            "[2608/3000] Train Acc: 0.999849 Loss: 0.000753 | Val Acc: 0.182258 loss: 13.533820\n",
            "[2609/3000] Train Acc: 1.000000 Loss: 0.000107 | Val Acc: 0.182056 loss: 13.447449\n",
            "[2610/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.183266 loss: 13.424993\n",
            "[2611/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.186290 loss: 13.317893\n",
            "[2612/3000] Train Acc: 1.000000 Loss: 0.000059 | Val Acc: 0.184274 loss: 13.438567\n",
            "[2613/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.186290 loss: 13.379046\n",
            "[2614/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.180847 loss: 13.645723\n",
            "[2615/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.187500 loss: 13.277455\n",
            "[2616/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.184274 loss: 13.432175\n",
            "[2617/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.186694 loss: 13.299619\n",
            "[2618/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.187097 loss: 13.288889\n",
            "[2619/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.186290 loss: 13.344454\n",
            "[2620/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.187097 loss: 13.247887\n",
            "[2621/3000] Train Acc: 1.000000 Loss: 0.000049 | Val Acc: 0.182460 loss: 13.549038\n",
            "[2622/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.186895 loss: 13.231307\n",
            "[2623/3000] Train Acc: 0.998639 Loss: 0.004411 | Val Acc: 0.177823 loss: 14.967749\n",
            "[2624/3000] Train Acc: 0.997278 Loss: 0.009013 | Val Acc: 0.175605 loss: 14.145907\n",
            "[2625/3000] Train Acc: 0.999899 Loss: 0.000324 | Val Acc: 0.191129 loss: 13.311756\n",
            "[2626/3000] Train Acc: 1.000000 Loss: 0.000118 | Val Acc: 0.185484 loss: 13.599430\n",
            "[2627/3000] Train Acc: 1.000000 Loss: 0.000096 | Val Acc: 0.193347 loss: 13.117226\n",
            "[2628/3000] Train Acc: 1.000000 Loss: 0.000075 | Val Acc: 0.194153 loss: 13.102401\n",
            "[2629/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.190726 loss: 13.244770\n",
            "[2630/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.189315 loss: 13.270060\n",
            "[2631/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.189315 loss: 13.252189\n",
            "[2632/3000] Train Acc: 1.000000 Loss: 0.000088 | Val Acc: 0.189516 loss: 13.250757\n",
            "[2633/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.185484 loss: 13.433019\n",
            "[2634/3000] Train Acc: 0.996521 Loss: 0.009708 | Val Acc: 0.193548 loss: 13.216483\n",
            "[2635/3000] Train Acc: 0.999597 Loss: 0.001057 | Val Acc: 0.189315 loss: 13.072069\n",
            "[2636/3000] Train Acc: 0.999950 Loss: 0.000275 | Val Acc: 0.185887 loss: 13.515513\n",
            "[2637/3000] Train Acc: 1.000000 Loss: 0.000102 | Val Acc: 0.191129 loss: 13.100210\n",
            "[2638/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.189315 loss: 13.114965\n",
            "[2639/3000] Train Acc: 1.000000 Loss: 0.000056 | Val Acc: 0.188306 loss: 13.233446\n",
            "[2640/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.187298 loss: 13.288921\n",
            "[2641/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.187097 loss: 13.248271\n",
            "[2642/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.187500 loss: 13.223495\n",
            "[2643/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.187500 loss: 13.282153\n",
            "[2644/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.188710 loss: 13.199910\n",
            "[2645/3000] Train Acc: 0.997076 Loss: 0.008972 | Val Acc: 0.191935 loss: 13.083419\n",
            "[2646/3000] Train Acc: 0.999748 Loss: 0.001122 | Val Acc: 0.186694 loss: 13.219811\n",
            "[2647/3000] Train Acc: 1.000000 Loss: 0.000095 | Val Acc: 0.183669 loss: 13.293176\n",
            "[2648/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.185081 loss: 13.240994\n",
            "[2649/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.186694 loss: 13.114262\n",
            "[2650/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.184073 loss: 13.242742\n",
            "[2651/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.187097 loss: 13.130023\n",
            "[2652/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.189113 loss: 12.995096\n",
            "[2653/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.185887 loss: 13.223765\n",
            "[2654/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.185685 loss: 13.167794\n",
            "[2655/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.189516 loss: 13.080641\n",
            "[2656/3000] Train Acc: 1.000000 Loss: 0.000066 | Val Acc: 0.181250 loss: 13.390645\n",
            "[2657/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.181855 loss: 13.452473\n",
            "[2658/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.186089 loss: 13.289735\n",
            "[2659/3000] Train Acc: 0.996169 Loss: 0.010876 | Val Acc: 0.181653 loss: 13.729581\n",
            "[2660/3000] Train Acc: 0.999950 Loss: 0.000415 | Val Acc: 0.184879 loss: 13.502277\n",
            "[2661/3000] Train Acc: 1.000000 Loss: 0.000112 | Val Acc: 0.184476 loss: 13.510570\n",
            "[2662/3000] Train Acc: 1.000000 Loss: 0.000089 | Val Acc: 0.184879 loss: 13.436709\n",
            "[2663/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.185081 loss: 13.426013\n",
            "[2664/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.186290 loss: 13.399568\n",
            "[2665/3000] Train Acc: 1.000000 Loss: 0.000060 | Val Acc: 0.186895 loss: 13.372280\n",
            "[2666/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.186694 loss: 13.341265\n",
            "[2667/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.184274 loss: 13.450203\n",
            "[2668/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.188911 loss: 13.316785\n",
            "[2669/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.184879 loss: 13.441557\n",
            "[2670/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.187903 loss: 13.360806\n",
            "[2671/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.187097 loss: 13.446359\n",
            "[2672/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.189113 loss: 13.388565\n",
            "[2673/3000] Train Acc: 0.996975 Loss: 0.009723 | Val Acc: 0.182863 loss: 13.780756\n",
            "[2674/3000] Train Acc: 0.999647 Loss: 0.000978 | Val Acc: 0.179637 loss: 13.143870\n",
            "[2675/3000] Train Acc: 1.000000 Loss: 0.000117 | Val Acc: 0.181048 loss: 13.224617\n",
            "[2676/3000] Train Acc: 1.000000 Loss: 0.000072 | Val Acc: 0.182258 loss: 13.217956\n",
            "[2677/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.183468 loss: 13.153125\n",
            "[2678/3000] Train Acc: 1.000000 Loss: 0.000056 | Val Acc: 0.182460 loss: 13.226169\n",
            "[2679/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.182460 loss: 13.254068\n",
            "[2680/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.186492 loss: 13.118241\n",
            "[2681/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.183468 loss: 13.252640\n",
            "[2682/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.181653 loss: 13.388899\n",
            "[2683/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.181653 loss: 13.396908\n",
            "[2684/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.184476 loss: 13.314452\n",
            "[2685/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.181855 loss: 13.395366\n",
            "[2686/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.186492 loss: 13.262244\n",
            "[2687/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.188306 loss: 13.181999\n",
            "[2688/3000] Train Acc: 0.997530 Loss: 0.006993 | Val Acc: 0.179032 loss: 14.509752\n",
            "[2689/3000] Train Acc: 0.999496 Loss: 0.002359 | Val Acc: 0.184879 loss: 13.653516\n",
            "[2690/3000] Train Acc: 1.000000 Loss: 0.000122 | Val Acc: 0.188306 loss: 13.548954\n",
            "[2691/3000] Train Acc: 1.000000 Loss: 0.000090 | Val Acc: 0.186290 loss: 13.632236\n",
            "[2692/3000] Train Acc: 1.000000 Loss: 0.000071 | Val Acc: 0.187097 loss: 13.571094\n",
            "[2693/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.186694 loss: 13.517490\n",
            "[2694/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.186492 loss: 13.544314\n",
            "[2695/3000] Train Acc: 1.000000 Loss: 0.000049 | Val Acc: 0.187903 loss: 13.468345\n",
            "[2696/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.186694 loss: 13.495550\n",
            "[2697/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.189315 loss: 13.472476\n",
            "[2698/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.186492 loss: 13.490925\n",
            "[2699/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.188508 loss: 13.407103\n",
            "[2700/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.190121 loss: 13.309704\n",
            "[2701/3000] Train Acc: 0.995816 Loss: 0.015437 | Val Acc: 0.181855 loss: 13.719971\n",
            "[2702/3000] Train Acc: 1.000000 Loss: 0.000276 | Val Acc: 0.185081 loss: 13.394062\n",
            "[2703/3000] Train Acc: 1.000000 Loss: 0.000116 | Val Acc: 0.186895 loss: 13.379401\n",
            "[2704/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.186089 loss: 13.440720\n",
            "[2705/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.185685 loss: 13.452916\n",
            "[2706/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.185887 loss: 13.385674\n",
            "[2707/3000] Train Acc: 1.000000 Loss: 0.000056 | Val Acc: 0.185081 loss: 13.412323\n",
            "[2708/3000] Train Acc: 1.000000 Loss: 0.000052 | Val Acc: 0.183871 loss: 13.496020\n",
            "[2709/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.184677 loss: 13.398460\n",
            "[2710/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.185887 loss: 13.332904\n",
            "[2711/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.184677 loss: 13.464822\n",
            "[2712/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.185887 loss: 13.375645\n",
            "[2713/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.184274 loss: 13.513380\n",
            "[2714/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.183871 loss: 13.534779\n",
            "[2715/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.186895 loss: 13.291974\n",
            "[2716/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.189315 loss: 13.081667\n",
            "[2717/3000] Train Acc: 0.997379 Loss: 0.009548 | Val Acc: 0.189315 loss: 13.703271\n",
            "[2718/3000] Train Acc: 0.999950 Loss: 0.000363 | Val Acc: 0.200202 loss: 12.657058\n",
            "[2719/3000] Train Acc: 0.999950 Loss: 0.000275 | Val Acc: 0.173185 loss: 14.254690\n",
            "[2720/3000] Train Acc: 0.999899 Loss: 0.000574 | Val Acc: 0.190726 loss: 13.406717\n",
            "[2721/3000] Train Acc: 0.999798 Loss: 0.000634 | Val Acc: 0.167137 loss: 14.130218\n",
            "[2722/3000] Train Acc: 0.999445 Loss: 0.001843 | Val Acc: 0.191734 loss: 13.241765\n",
            "[2723/3000] Train Acc: 1.000000 Loss: 0.000075 | Val Acc: 0.193347 loss: 13.244412\n",
            "[2724/3000] Train Acc: 1.000000 Loss: 0.000052 | Val Acc: 0.192540 loss: 13.287941\n",
            "[2725/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.192339 loss: 13.300480\n",
            "[2726/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.192137 loss: 13.334865\n",
            "[2727/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.193347 loss: 13.283835\n",
            "[2728/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.193347 loss: 13.247113\n",
            "[2729/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.188710 loss: 13.465388\n",
            "[2730/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.191129 loss: 13.336047\n",
            "[2731/3000] Train Acc: 1.000000 Loss: 0.000033 | Val Acc: 0.188508 loss: 13.471061\n",
            "[2732/3000] Train Acc: 1.000000 Loss: 0.000031 | Val Acc: 0.194153 loss: 13.138544\n",
            "[2733/3000] Train Acc: 1.000000 Loss: 0.000031 | Val Acc: 0.190524 loss: 13.407274\n",
            "[2734/3000] Train Acc: 1.000000 Loss: 0.000029 | Val Acc: 0.186290 loss: 13.557153\n",
            "[2735/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.190927 loss: 13.347410\n",
            "[2736/3000] Train Acc: 0.997328 Loss: 0.009941 | Val Acc: 0.172379 loss: 16.240717\n",
            "[2737/3000] Train Acc: 0.998740 Loss: 0.003904 | Val Acc: 0.193952 loss: 13.267177\n",
            "[2738/3000] Train Acc: 1.000000 Loss: 0.000099 | Val Acc: 0.191532 loss: 13.420508\n",
            "[2739/3000] Train Acc: 1.000000 Loss: 0.000075 | Val Acc: 0.191935 loss: 13.411546\n",
            "[2740/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.189113 loss: 13.583367\n",
            "[2741/3000] Train Acc: 1.000000 Loss: 0.000059 | Val Acc: 0.191734 loss: 13.493760\n",
            "[2742/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.192540 loss: 13.481811\n",
            "[2743/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.191129 loss: 13.552946\n",
            "[2744/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.190323 loss: 13.596690\n",
            "[2745/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.192137 loss: 13.416525\n",
            "[2746/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.190927 loss: 13.446575\n",
            "[2747/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.186089 loss: 13.619289\n",
            "[2748/3000] Train Acc: 1.000000 Loss: 0.000087 | Val Acc: 0.191532 loss: 13.458257\n",
            "[2749/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.188508 loss: 13.552658\n",
            "[2750/3000] Train Acc: 1.000000 Loss: 0.000056 | Val Acc: 0.185484 loss: 13.825407\n",
            "[2751/3000] Train Acc: 0.999345 Loss: 0.002845 | Val Acc: 0.144355 loss: 16.397680\n",
            "[2752/3000] Train Acc: 0.996421 Loss: 0.011517 | Val Acc: 0.195363 loss: 13.397092\n",
            "[2753/3000] Train Acc: 1.000000 Loss: 0.000125 | Val Acc: 0.189113 loss: 13.631767\n",
            "[2754/3000] Train Acc: 1.000000 Loss: 0.000080 | Val Acc: 0.192339 loss: 13.375868\n",
            "[2755/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.190726 loss: 13.530755\n",
            "[2756/3000] Train Acc: 1.000000 Loss: 0.000060 | Val Acc: 0.190726 loss: 13.527980\n",
            "[2757/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.189315 loss: 13.603866\n",
            "[2758/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.190524 loss: 13.479280\n",
            "[2759/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.189919 loss: 13.575494\n",
            "[2760/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.191331 loss: 13.527820\n",
            "[2761/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.191532 loss: 13.547137\n",
            "[2762/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.193145 loss: 13.304485\n",
            "[2763/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.186694 loss: 13.796311\n",
            "[2764/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.188306 loss: 13.668013\n",
            "[2765/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.187702 loss: 13.571550\n",
            "[2766/3000] Train Acc: 1.000000 Loss: 0.000031 | Val Acc: 0.187097 loss: 13.679374\n",
            "[2767/3000] Train Acc: 0.997731 Loss: 0.008055 | Val Acc: 0.181855 loss: 13.821115\n",
            "[2768/3000] Train Acc: 0.998639 Loss: 0.005070 | Val Acc: 0.193145 loss: 12.863029\n",
            "[2769/3000] Train Acc: 1.000000 Loss: 0.000117 | Val Acc: 0.187903 loss: 13.214179\n",
            "[2770/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.187500 loss: 13.184516\n",
            "[2771/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.187298 loss: 13.245604\n",
            "[2772/3000] Train Acc: 1.000000 Loss: 0.000060 | Val Acc: 0.186694 loss: 13.253120\n",
            "[2773/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.184274 loss: 13.357285\n",
            "[2774/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.187298 loss: 13.210021\n",
            "[2775/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.184677 loss: 13.450480\n",
            "[2776/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.188508 loss: 13.242587\n",
            "[2777/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.188710 loss: 13.183666\n",
            "[2778/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.186089 loss: 13.399824\n",
            "[2779/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.192137 loss: 13.055135\n",
            "[2780/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.188306 loss: 13.268012\n",
            "[2781/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.188710 loss: 13.288239\n",
            "[2782/3000] Train Acc: 0.999849 Loss: 0.000770 | Val Acc: 0.180040 loss: 13.915530\n",
            "[2783/3000] Train Acc: 0.995059 Loss: 0.015943 | Val Acc: 0.180847 loss: 13.449752\n",
            "[2784/3000] Train Acc: 1.000000 Loss: 0.000145 | Val Acc: 0.187500 loss: 13.167457\n",
            "[2785/3000] Train Acc: 1.000000 Loss: 0.000081 | Val Acc: 0.187298 loss: 13.174912\n",
            "[2786/3000] Train Acc: 1.000000 Loss: 0.000068 | Val Acc: 0.188105 loss: 13.163434\n",
            "[2787/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.186089 loss: 13.257234\n",
            "[2788/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.184677 loss: 13.312961\n",
            "[2789/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.186089 loss: 13.244588\n",
            "[2790/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.187702 loss: 13.200742\n",
            "[2791/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.183871 loss: 13.412633\n",
            "[2792/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.184274 loss: 13.326128\n",
            "[2793/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.187097 loss: 13.256041\n",
            "[2794/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.185685 loss: 13.303429\n",
            "[2795/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.186089 loss: 13.308209\n",
            "[2796/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.183871 loss: 13.495714\n",
            "[2797/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.183266 loss: 13.467898\n",
            "[2798/3000] Train Acc: 0.998084 Loss: 0.007498 | Val Acc: 0.167339 loss: 15.109981\n",
            "[2799/3000] Train Acc: 0.999496 Loss: 0.001611 | Val Acc: 0.189919 loss: 13.449266\n",
            "[2800/3000] Train Acc: 1.000000 Loss: 0.000094 | Val Acc: 0.190927 loss: 13.440902\n",
            "[2801/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.190323 loss: 13.546552\n",
            "[2802/3000] Train Acc: 1.000000 Loss: 0.000056 | Val Acc: 0.191331 loss: 13.471236\n",
            "[2803/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.189315 loss: 13.627488\n",
            "[2804/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.191532 loss: 13.474665\n",
            "[2805/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.192540 loss: 13.544956\n",
            "[2806/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.191935 loss: 13.561050\n",
            "[2807/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.191734 loss: 13.573837\n",
            "[2808/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.193952 loss: 13.428618\n",
            "[2809/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.189516 loss: 13.556600\n",
            "[2810/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.192540 loss: 13.434797\n",
            "[2811/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.196573 loss: 12.973688\n",
            "[2812/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.200403 loss: 12.817059\n",
            "[2813/3000] Train Acc: 0.997227 Loss: 0.009821 | Val Acc: 0.174395 loss: 14.816762\n",
            "[2814/3000] Train Acc: 0.999193 Loss: 0.002369 | Val Acc: 0.193750 loss: 13.015421\n",
            "[2815/3000] Train Acc: 1.000000 Loss: 0.000087 | Val Acc: 0.191935 loss: 13.269052\n",
            "[2816/3000] Train Acc: 1.000000 Loss: 0.000064 | Val Acc: 0.190726 loss: 13.318135\n",
            "[2817/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.191935 loss: 13.268746\n",
            "[2818/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.190927 loss: 13.334884\n",
            "[2819/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.190726 loss: 13.272008\n",
            "[2820/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.189718 loss: 13.360621\n",
            "[2821/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.189315 loss: 13.466923\n",
            "[2822/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.190121 loss: 13.414913\n",
            "[2823/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.189516 loss: 13.549883\n",
            "[2824/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.188306 loss: 13.338990\n",
            "[2825/3000] Train Acc: 0.998639 Loss: 0.005082 | Val Acc: 0.169960 loss: 15.118839\n",
            "[2826/3000] Train Acc: 0.997983 Loss: 0.004747 | Val Acc: 0.185685 loss: 13.686831\n",
            "[2827/3000] Train Acc: 1.000000 Loss: 0.000342 | Val Acc: 0.184274 loss: 13.820452\n",
            "[2828/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.187097 loss: 13.418085\n",
            "[2829/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.185081 loss: 13.617907\n",
            "[2830/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.184476 loss: 13.619722\n",
            "[2831/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.186492 loss: 13.413529\n",
            "[2832/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.185282 loss: 13.559654\n",
            "[2833/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.184274 loss: 13.685756\n",
            "[2834/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.186492 loss: 13.601123\n",
            "[2835/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.189315 loss: 13.269465\n",
            "[2836/3000] Train Acc: 1.000000 Loss: 0.000098 | Val Acc: 0.186492 loss: 13.494491\n",
            "[2837/3000] Train Acc: 0.996774 Loss: 0.010631 | Val Acc: 0.192944 loss: 13.263244\n",
            "[2838/3000] Train Acc: 1.000000 Loss: 0.000191 | Val Acc: 0.187097 loss: 13.345286\n",
            "[2839/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.186895 loss: 13.567251\n",
            "[2840/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.185685 loss: 13.651871\n",
            "[2841/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.186492 loss: 13.580436\n",
            "[2842/3000] Train Acc: 1.000000 Loss: 0.000049 | Val Acc: 0.185887 loss: 13.676048\n",
            "[2843/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.187097 loss: 13.540586\n",
            "[2844/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.186089 loss: 13.658528\n",
            "[2845/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.186089 loss: 13.696476\n",
            "[2846/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.187097 loss: 13.672016\n",
            "[2847/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.186895 loss: 13.606966\n",
            "[2848/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.184073 loss: 13.750882\n",
            "[2849/3000] Train Acc: 1.000000 Loss: 0.000032 | Val Acc: 0.186694 loss: 13.585971\n",
            "[2850/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.192540 loss: 13.414074\n",
            "[2851/3000] Train Acc: 0.997681 Loss: 0.006232 | Val Acc: 0.178831 loss: 14.154630\n",
            "[2852/3000] Train Acc: 0.999143 Loss: 0.003413 | Val Acc: 0.180242 loss: 14.347549\n",
            "[2853/3000] Train Acc: 1.000000 Loss: 0.000103 | Val Acc: 0.185081 loss: 13.998036\n",
            "[2854/3000] Train Acc: 1.000000 Loss: 0.000062 | Val Acc: 0.183669 loss: 14.105635\n",
            "[2855/3000] Train Acc: 1.000000 Loss: 0.000054 | Val Acc: 0.184274 loss: 14.007171\n",
            "[2856/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.184073 loss: 13.990254\n",
            "[2857/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.184677 loss: 13.904985\n",
            "[2858/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.184073 loss: 13.988329\n",
            "[2859/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.184274 loss: 13.926821\n",
            "[2860/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.184073 loss: 14.019749\n",
            "[2861/3000] Train Acc: 1.000000 Loss: 0.000079 | Val Acc: 0.183266 loss: 14.384502\n",
            "[2862/3000] Train Acc: 0.996572 Loss: 0.010424 | Val Acc: 0.197782 loss: 13.042582\n",
            "[2863/3000] Train Acc: 0.999950 Loss: 0.000414 | Val Acc: 0.181653 loss: 13.789723\n",
            "[2864/3000] Train Acc: 1.000000 Loss: 0.000076 | Val Acc: 0.180847 loss: 13.852880\n",
            "[2865/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.183065 loss: 13.760722\n",
            "[2866/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.181855 loss: 13.824734\n",
            "[2867/3000] Train Acc: 1.000000 Loss: 0.000048 | Val Acc: 0.183266 loss: 13.749235\n",
            "[2868/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.182460 loss: 13.814729\n",
            "[2869/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.185282 loss: 13.665946\n",
            "[2870/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.185081 loss: 13.694610\n",
            "[2871/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.183871 loss: 13.818536\n",
            "[2872/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.186694 loss: 13.597530\n",
            "[2873/3000] Train Acc: 1.000000 Loss: 0.000069 | Val Acc: 0.189113 loss: 13.511606\n",
            "[2874/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.187500 loss: 13.618231\n",
            "[2875/3000] Train Acc: 0.997530 Loss: 0.007303 | Val Acc: 0.176613 loss: 14.270872\n",
            "[2876/3000] Train Acc: 1.000000 Loss: 0.000121 | Val Acc: 0.185081 loss: 13.772539\n",
            "[2877/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.185484 loss: 13.780089\n",
            "[2878/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.184274 loss: 13.804826\n",
            "[2879/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.183266 loss: 13.810649\n",
            "[2880/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.184677 loss: 13.711985\n",
            "[2881/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.183669 loss: 13.772948\n",
            "[2882/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.183669 loss: 13.805997\n",
            "[2883/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.183871 loss: 13.787251\n",
            "[2884/3000] Train Acc: 1.000000 Loss: 0.000032 | Val Acc: 0.184677 loss: 13.647698\n",
            "[2885/3000] Train Acc: 1.000000 Loss: 0.000032 | Val Acc: 0.182258 loss: 13.786308\n",
            "[2886/3000] Train Acc: 1.000000 Loss: 0.000030 | Val Acc: 0.179637 loss: 14.039963\n",
            "[2887/3000] Train Acc: 0.997731 Loss: 0.007090 | Val Acc: 0.199597 loss: 12.748002\n",
            "[2888/3000] Train Acc: 0.999899 Loss: 0.000551 | Val Acc: 0.214516 loss: 12.321326\n",
            "[2889/3000] Train Acc: 0.999950 Loss: 0.000195 | Val Acc: 0.192339 loss: 13.495926\n",
            "[2890/3000] Train Acc: 1.000000 Loss: 0.000067 | Val Acc: 0.192339 loss: 13.487724\n",
            "[2891/3000] Train Acc: 1.000000 Loss: 0.000053 | Val Acc: 0.193750 loss: 13.411947\n",
            "[2892/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.191734 loss: 13.543062\n",
            "[2893/3000] Train Acc: 1.000000 Loss: 0.000043 | Val Acc: 0.193548 loss: 13.352441\n",
            "[2894/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.191935 loss: 13.464315\n",
            "[2895/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.192339 loss: 13.401360\n",
            "[2896/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.192540 loss: 13.370760\n",
            "[2897/3000] Train Acc: 1.000000 Loss: 0.000033 | Val Acc: 0.191331 loss: 13.394849\n",
            "[2898/3000] Train Acc: 1.000000 Loss: 0.000033 | Val Acc: 0.190121 loss: 13.533375\n",
            "[2899/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.187903 loss: 13.569310\n",
            "[2900/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.193750 loss: 13.459438\n",
            "[2901/3000] Train Acc: 0.996169 Loss: 0.012280 | Val Acc: 0.187298 loss: 13.792601\n",
            "[2902/3000] Train Acc: 1.000000 Loss: 0.000183 | Val Acc: 0.188911 loss: 13.442441\n",
            "[2903/3000] Train Acc: 1.000000 Loss: 0.000083 | Val Acc: 0.190323 loss: 13.372033\n",
            "[2904/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.191331 loss: 13.257175\n",
            "[2905/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.191532 loss: 13.295216\n",
            "[2906/3000] Train Acc: 1.000000 Loss: 0.000049 | Val Acc: 0.190524 loss: 13.325585\n",
            "[2907/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.190927 loss: 13.314766\n",
            "[2908/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.191935 loss: 13.302421\n",
            "[2909/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.191331 loss: 13.297018\n",
            "[2910/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.188710 loss: 13.473741\n",
            "[2911/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.189516 loss: 13.442608\n",
            "[2912/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.189718 loss: 13.439520\n",
            "[2913/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.189718 loss: 13.453730\n",
            "[2914/3000] Train Acc: 1.000000 Loss: 0.000073 | Val Acc: 0.185887 loss: 13.657661\n",
            "[2915/3000] Train Acc: 0.996017 Loss: 0.014688 | Val Acc: 0.179234 loss: 14.156132\n",
            "[2916/3000] Train Acc: 1.000000 Loss: 0.000189 | Val Acc: 0.184073 loss: 13.813833\n",
            "[2917/3000] Train Acc: 1.000000 Loss: 0.000077 | Val Acc: 0.183468 loss: 13.878583\n",
            "[2918/3000] Train Acc: 1.000000 Loss: 0.000063 | Val Acc: 0.184073 loss: 13.804816\n",
            "[2919/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.183669 loss: 13.819048\n",
            "[2920/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.183468 loss: 13.743974\n",
            "[2921/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.184677 loss: 13.683549\n",
            "[2922/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.183468 loss: 13.713202\n",
            "[2923/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.183468 loss: 13.739430\n",
            "[2924/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.183266 loss: 13.760169\n",
            "[2925/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.182661 loss: 13.844848\n",
            "[2926/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.184879 loss: 13.710339\n",
            "[2927/3000] Train Acc: 1.000000 Loss: 0.000031 | Val Acc: 0.185282 loss: 13.661919\n",
            "[2928/3000] Train Acc: 1.000000 Loss: 0.000031 | Val Acc: 0.187702 loss: 13.660081\n",
            "[2929/3000] Train Acc: 1.000000 Loss: 0.000033 | Val Acc: 0.189315 loss: 13.527810\n",
            "[2930/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.182661 loss: 14.045864\n",
            "[2931/3000] Train Acc: 0.996673 Loss: 0.010149 | Val Acc: 0.173992 loss: 14.715824\n",
            "[2932/3000] Train Acc: 0.999899 Loss: 0.000276 | Val Acc: 0.194556 loss: 13.711838\n",
            "[2933/3000] Train Acc: 1.000000 Loss: 0.000070 | Val Acc: 0.191129 loss: 13.719949\n",
            "[2934/3000] Train Acc: 1.000000 Loss: 0.000057 | Val Acc: 0.193145 loss: 13.690198\n",
            "[2935/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.193548 loss: 13.645565\n",
            "[2936/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.192540 loss: 13.660400\n",
            "[2937/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.193548 loss: 13.622566\n",
            "[2938/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.194355 loss: 13.545170\n",
            "[2939/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.192944 loss: 13.610593\n",
            "[2940/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.190323 loss: 13.708482\n",
            "[2941/3000] Train Acc: 0.996169 Loss: 0.012512 | Val Acc: 0.189919 loss: 13.373885\n",
            "[2942/3000] Train Acc: 1.000000 Loss: 0.000175 | Val Acc: 0.190121 loss: 13.535735\n",
            "[2943/3000] Train Acc: 1.000000 Loss: 0.000071 | Val Acc: 0.189516 loss: 13.599828\n",
            "[2944/3000] Train Acc: 1.000000 Loss: 0.000055 | Val Acc: 0.189113 loss: 13.706695\n",
            "[2945/3000] Train Acc: 1.000000 Loss: 0.000051 | Val Acc: 0.189516 loss: 13.697170\n",
            "[2946/3000] Train Acc: 1.000000 Loss: 0.000045 | Val Acc: 0.188911 loss: 13.720631\n",
            "[2947/3000] Train Acc: 1.000000 Loss: 0.000042 | Val Acc: 0.189919 loss: 13.663574\n",
            "[2948/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.189315 loss: 13.717148\n",
            "[2949/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.189113 loss: 13.728587\n",
            "[2950/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.189516 loss: 13.648097\n",
            "[2951/3000] Train Acc: 1.000000 Loss: 0.000032 | Val Acc: 0.187298 loss: 13.820277\n",
            "[2952/3000] Train Acc: 1.000000 Loss: 0.000031 | Val Acc: 0.186895 loss: 13.867367\n",
            "[2953/3000] Train Acc: 1.000000 Loss: 0.000032 | Val Acc: 0.187903 loss: 13.715890\n",
            "[2954/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.189516 loss: 13.709627\n",
            "[2955/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.189315 loss: 13.716050\n",
            "[2956/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.189919 loss: 13.660281\n",
            "[2957/3000] Train Acc: 1.000000 Loss: 0.000030 | Val Acc: 0.194960 loss: 13.404814\n",
            "[2958/3000] Train Acc: 0.997631 Loss: 0.007640 | Val Acc: 0.207661 loss: 12.973143\n",
            "[2959/3000] Train Acc: 0.999899 Loss: 0.000471 | Val Acc: 0.198185 loss: 13.284256\n",
            "[2960/3000] Train Acc: 1.000000 Loss: 0.000130 | Val Acc: 0.193347 loss: 13.562854\n",
            "[2961/3000] Train Acc: 1.000000 Loss: 0.000058 | Val Acc: 0.191532 loss: 13.723218\n",
            "[2962/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.190927 loss: 13.747306\n",
            "[2963/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.190927 loss: 13.667843\n",
            "[2964/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.191129 loss: 13.699148\n",
            "[2965/3000] Train Acc: 1.000000 Loss: 0.000040 | Val Acc: 0.188911 loss: 13.847328\n",
            "[2966/3000] Train Acc: 1.000000 Loss: 0.000035 | Val Acc: 0.184677 loss: 13.976756\n",
            "[2967/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.186290 loss: 13.921306\n",
            "[2968/3000] Train Acc: 1.000000 Loss: 0.000033 | Val Acc: 0.192137 loss: 13.658760\n",
            "[2969/3000] Train Acc: 1.000000 Loss: 0.000032 | Val Acc: 0.188911 loss: 13.795255\n",
            "[2970/3000] Train Acc: 0.996925 Loss: 0.010880 | Val Acc: 0.198589 loss: 13.160812\n",
            "[2971/3000] Train Acc: 0.999899 Loss: 0.000528 | Val Acc: 0.182863 loss: 13.807526\n",
            "[2972/3000] Train Acc: 1.000000 Loss: 0.000074 | Val Acc: 0.194960 loss: 13.241417\n",
            "[2973/3000] Train Acc: 1.000000 Loss: 0.000061 | Val Acc: 0.190323 loss: 13.518721\n",
            "[2974/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.190726 loss: 13.484659\n",
            "[2975/3000] Train Acc: 1.000000 Loss: 0.000047 | Val Acc: 0.190524 loss: 13.484746\n",
            "[2976/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.187702 loss: 13.601170\n",
            "[2977/3000] Train Acc: 1.000000 Loss: 0.000039 | Val Acc: 0.188306 loss: 13.588294\n",
            "[2978/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.189718 loss: 13.539369\n",
            "[2979/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.192742 loss: 13.444247\n",
            "[2980/3000] Train Acc: 1.000000 Loss: 0.000034 | Val Acc: 0.194153 loss: 13.388657\n",
            "[2981/3000] Train Acc: 1.000000 Loss: 0.000038 | Val Acc: 0.190323 loss: 13.468103\n",
            "[2982/3000] Train Acc: 1.000000 Loss: 0.000050 | Val Acc: 0.183871 loss: 14.084369\n",
            "[2983/3000] Train Acc: 0.995866 Loss: 0.013777 | Val Acc: 0.187298 loss: 13.721629\n",
            "[2984/3000] Train Acc: 0.999950 Loss: 0.000478 | Val Acc: 0.185685 loss: 13.785211\n",
            "[2985/3000] Train Acc: 1.000000 Loss: 0.000104 | Val Acc: 0.192540 loss: 13.547303\n",
            "[2986/3000] Train Acc: 1.000000 Loss: 0.000075 | Val Acc: 0.189516 loss: 13.715868\n",
            "[2987/3000] Train Acc: 1.000000 Loss: 0.000064 | Val Acc: 0.189718 loss: 13.675750\n",
            "[2988/3000] Train Acc: 1.000000 Loss: 0.000056 | Val Acc: 0.188911 loss: 13.728455\n",
            "[2989/3000] Train Acc: 1.000000 Loss: 0.000052 | Val Acc: 0.187903 loss: 13.746320\n",
            "[2990/3000] Train Acc: 1.000000 Loss: 0.000046 | Val Acc: 0.187702 loss: 13.773702\n",
            "[2991/3000] Train Acc: 1.000000 Loss: 0.000044 | Val Acc: 0.187903 loss: 13.736284\n",
            "[2992/3000] Train Acc: 1.000000 Loss: 0.000041 | Val Acc: 0.188306 loss: 13.679316\n",
            "[2993/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.188508 loss: 13.689768\n",
            "[2994/3000] Train Acc: 1.000000 Loss: 0.000036 | Val Acc: 0.189113 loss: 13.726418\n",
            "[2995/3000] Train Acc: 1.000000 Loss: 0.000033 | Val Acc: 0.190524 loss: 13.638257\n",
            "[2996/3000] Train Acc: 1.000000 Loss: 0.000037 | Val Acc: 0.184274 loss: 13.816733\n",
            "[2997/3000] Train Acc: 0.995362 Loss: 0.015040 | Val Acc: 0.186492 loss: 14.218619\n",
            "[2998/3000] Train Acc: 0.999748 Loss: 0.000601 | Val Acc: 0.191734 loss: 13.682500\n",
            "[2999/3000] Train Acc: 1.000000 Loss: 0.000081 | Val Acc: 0.192742 loss: 13.688510\n",
            "[3000/3000] Train Acc: 1.000000 Loss: 0.000065 | Val Acc: 0.191331 loss: 13.710404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training use {round(end_time - start_time, 3)}s')"
      ],
      "metadata": {
        "id": "NLnpYLpwYlop",
        "outputId": "65ec91da-a958-481e-c9d1-020c584e21ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training use 2989.121s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Neural Network Test**"
      ],
      "metadata": {
        "id": "ynT-KFltscT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create testing dataset\n",
        "\n",
        "sc = StandardScaler()\n",
        "ss = StandardScaler().fit(X_test)\n",
        "X_test_std = ss.transform(X_test)\n",
        "\n",
        "test_set = IBMDataset(X_test_std, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# create model and load weights from checkpoint\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "metadata": {
        "id": "lukrC4MJWTjM",
        "outputId": "414f904e-26dd-42d4-d842-eb6ee8ee643b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = []\n",
        "model.eval() # set the model to evaluation mode\n",
        "for i, data in enumerate(test_loader):\n",
        "    inputs = data\n",
        "    inputs = inputs.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "    for y in test_pred.cpu().numpy():\n",
        "        predict.append(y)"
      ],
      "metadata": {
        "id": "OlQ1d1fdVt_V"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_result = './dnn_result.csv'\n",
        "\n",
        "new_encoder_map = {'No Churn':0, 'Competitor': 1, 'Dissatisfaction':2, 'Attitude': 3, 'Price':4, 'Other':5}\n",
        "\n",
        "with open(submit_result, 'w') as f:\n",
        "    f.write('Customer ID,Churn Category\\n')\n",
        "    for i in range(len(df_test.values)):\n",
        "        id = str(df_test.values[i]).replace('[\\'', '')\n",
        "        id = id.replace('\\']', '')\n",
        "        pred = new_encoder_map.get(list(encoder_map.keys())[list(encoder_map.values()).index(predict[i])])\n",
        "        f.write(f'{id},{pred}\\n')"
      ],
      "metadata": {
        "id": "11ImkbPjn6qP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(submit_result)"
      ],
      "metadata": {
        "id": "YICyBRaGo43O",
        "outputId": "67f4c8af-0ef4-4ee2-c10f-2ed74e5116e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7efd4847-f202-40fb-bcd9-94319c7f2f31\", \"dnn_result.csv\", 18344)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}